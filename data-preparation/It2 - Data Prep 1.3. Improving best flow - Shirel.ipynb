{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Fine-Tuning Flow - Stage 3: Reducing Salt-and-Pepper Noise and Enhancing Sharpness"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b0f6a4f8289f690"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb7b20b058015433",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the paths\n",
    "folder_path = '../data/subset'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2596400edaa044d9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load image paths\n",
    "def load_images_from_folder(folder_path, extensions=('.png', '.jpg', '.jpeg', '.JPG')):\n",
    "    \"\"\"\n",
    "    Load all image file paths from a specified folder that match the given file extensions.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing the images.\n",
    "    extensions (tuple of str): A tuple of file extensions to filter the images by. \n",
    "                               Default is ('.png', '.jpg', '.jpeg', '.JPG').\n",
    "\n",
    "    Returns:\n",
    "    list: A list of full file paths to images in the folder that match the specified extensions.\n",
    "    \n",
    "    Raises:\n",
    "    FileNotFoundError: If the specified folder does not exist.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        raise FileNotFoundError(f\"The specified folder does not exist: {folder_path}\")\n",
    "\n",
    "    # List comprehension to gather all image paths with the specified extensions\n",
    "    image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(extensions)]\n",
    "\n",
    "    return image_paths\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f97effeeee352681",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load and preprocess images\n",
    "def load_and_preprocess_images(image_paths, resize_dim=(256, 256)):\n",
    "    images = []\n",
    "    image_ids = []\n",
    "\n",
    "    # Initialize tqdm progress bar\n",
    "    for path in tqdm(image_paths, desc=\"Loading and preprocessing images\", unit=\"image\"):\n",
    "        img = cv2.imread(path)\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "        # img_resized = cv2.resize(img_gray, resize_dim)  # Resize for consistency\n",
    "        images.append(img_gray)\n",
    "        image_ids.append(f'Image_{len(images)}')  # Assign image ID as Image_1, Image_2, etc.\n",
    "\n",
    "    return images, image_ids\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e333e08bd6abdba",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load all image file paths from the specified folder\n",
    "image_paths_all = load_images_from_folder(folder_path)\n",
    "\n",
    "# Load and preprocess all images\n",
    "total_images, total_image_ids = load_and_preprocess_images(image_paths_all)\n",
    "\n",
    "# Randomly select 10 images for experimentation\n",
    "# experiment_indices = random.sample(range(len(total_images)), 10)\n",
    "# test_images = [total_images[i] for i in experiment_indices]\n",
    "# test_image_ids = [total_image_ids[i] for i in experiment_indices]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2063c6e03c0d2c0f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Applying the best Flow and techniques from previous steps"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52700c6b57c91a5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the best techniques with their best parameters\n",
    "best_techniques = {\n",
    "    \"Noise Reduction\": lambda img: cv2.medianBlur(img, 3),\n",
    "    \"Histogram Equalization\": lambda img: cv2.equalizeHist(img),\n",
    "    \"Binarization\": lambda img: cv2.adaptiveThreshold(\n",
    "        img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
    "    ),\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a65be9d0784deb94",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to apply the best flow and save all images\n",
    "def apply_best_flow_and_save(images, image_ids, output_folder):\n",
    "    # Create output directory if it does not exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    processed_images = []  # List to store processed images\n",
    "    processed_image_ids = []  # List to store image IDs\n",
    "\n",
    "    for img, img_id in zip(images, image_ids):\n",
    "        processed_image = img.copy()\n",
    "\n",
    "        # Apply each technique in sequence as per the best flow\n",
    "        for step_name, technique_func in best_techniques.items():\n",
    "            processed_image = technique_func(processed_image)\n",
    "\n",
    "        # Save the processed image to the output directory\n",
    "        output_path = os.path.join(output_folder, f\"Best_Flow_Image_{img_id}.jpg\")\n",
    "        cv2.imwrite(output_path, processed_image)\n",
    "\n",
    "        # Store processed image and its ID\n",
    "        processed_images.append(processed_image)\n",
    "        processed_image_ids.append(img_id)\n",
    "\n",
    "    print(f\"All images have been processed and saved in '{output_folder}'.\")\n",
    "\n",
    "    # Return the processed images and their IDs for later processing\n",
    "    return processed_images, processed_image_ids"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1223ac9774d74f21",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Assuming `total_images` and `total_image_ids` are defined and contain the list of images and their IDs\n",
    "processed_images, processed_image_ids = apply_best_flow_and_save(total_images, total_image_ids, \"./Data/It2/Best_Flow_Images\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31fcb45f33c561c3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Image Characteristics Calculation Functions - from data understanding it2\n",
    "def calculate_brightness(image):\n",
    "    return np.mean(image)\n",
    "\n",
    "def calculate_sharpness(image):\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\n",
    "def calculate_contrast(image):\n",
    "    return image.std()\n",
    "\n",
    "def calculate_noise(image):\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    noise = cv2.absdiff(image, blurred)\n",
    "    return np.var(noise)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84463242bfb35ee4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the CSV file with the image statistics\n",
    "# images_stats_path = \"../data-understanding/images_stats.csv\"  \n",
    "# images_stats_df = pd.read_csv(images_stats_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eaa84259e813ea34",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# images_stats_df.columns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f96d0027780e46f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# images_stats_df.drop(['Skew','Line Spacing', 'Tables Detected', 'Resolution', 'Detected Elements','Texture', 'Patterns'],axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d1640a280f060c2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def image_statistics_table(images, imagesId):\n",
    "    stats_data = {'Image': [],\n",
    "                  'Brightness': [],\n",
    "                  'Sharpness': [],\n",
    "                  'Contrast': [],\n",
    "                  'Noise': [],}\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        stats_data['Image'].append(imagesId[i])\n",
    "        stats_data['Brightness'].append(calculate_brightness(img))\n",
    "        stats_data['Sharpness'].append(calculate_sharpness(img))\n",
    "        stats_data['Contrast'].append(calculate_contrast(img))\n",
    "        stats_data['Noise'].append(calculate_noise(img))\n",
    "    # Create a DataFrame to store per-image statistics\n",
    "    df = pd.DataFrame(stats_data)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c0cfd588ed15c48",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "images_stats_df = image_statistics_table(processed_images, processed_image_ids)\n",
    "print(\"Image Statistics Table:\")\n",
    "images_stats_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb09f88013ed4a8e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95227fb442e2ce1c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create folder to save images for comparison\n",
    "output_folder = \"./Data/It2/Fine_Tuned_Flow\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Functions for each step in the image processing pipeline\n",
    "def non_local_means_denoising(image, h=5, templateWindowSize=7, searchWindowSize=21):\n",
    "    \"\"\"Apply Non-Local Means Denoising.\"\"\"\n",
    "    return cv2.fastNlMeansDenoising(image, None, h, templateWindowSize, searchWindowSize)\n",
    "\n",
    "\n",
    "def clahe_histogram_equalization(image, clipLimit=2.0, tileGridSize=(8, 8)):\n",
    "    \"\"\"Apply CLAHE Histogram Equalization.\"\"\"\n",
    "    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n",
    "    return clahe.apply(image)\n",
    "\n",
    "\n",
    "def adaptive_threshold(image, adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C, blockSize=11, C=2):\n",
    "    \"\"\"Apply Adaptive Thresholding.\"\"\"\n",
    "    return cv2.adaptiveThreshold(image, 255, adaptiveMethod, cv2.THRESH_BINARY, blockSize, C)\n",
    "\n",
    "\n",
    "def morphological_opening(image, kernel_size=(3, 3)):\n",
    "    \"\"\"Apply Morphological Opening to reduce salt-and-pepper noise.\"\"\"\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernel_size)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ff93b6aa58919c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluation function to assess improvement in characteristics\n",
    "def advanced_evaluation(image, techniques_dict, original_stats):\n",
    "    evaluation_results = {}\n",
    "\n",
    "    for technique_name, technique_func in techniques_dict.items():\n",
    "        # Apply the technique\n",
    "        processed_image = technique_func(image)\n",
    "\n",
    "        # Calculate characteristics for the processed image\n",
    "        stats = {\n",
    "            \"Brightness\": calculate_brightness(processed_image),\n",
    "            \"Sharpness\": calculate_sharpness(processed_image),\n",
    "            \"Contrast\": calculate_contrast(processed_image),\n",
    "            \"Noise\": calculate_noise(processed_image),\n",
    "        }\n",
    "\n",
    "        # Normalize metrics to comparable ranges (between 0 and 1, roughly)\n",
    "        stats_normalized = {\n",
    "            \"Brightness\": stats[\"Brightness\"] / 255,\n",
    "            \"Sharpness\": stats[\"Sharpness\"] / 1000,\n",
    "            \"Contrast\": stats[\"Contrast\"] / 255,\n",
    "            \"Noise\": stats[\"Noise\"] / 255,\n",
    "        }\n",
    "\n",
    "        # Normalize the original stats for comparison\n",
    "        original_stats_normalized = {\n",
    "            \"Brightness\": original_stats[\"Brightness\"] / 255,\n",
    "            \"Sharpness\": original_stats[\"Sharpness\"] / 1000,\n",
    "            \"Contrast\": original_stats[\"Contrast\"] / 255,\n",
    "            \"Noise\": original_stats[\"Noise\"] / 255,\n",
    "        }\n",
    "\n",
    "        # Weights for each characteristic (to determine their importance)\n",
    "        weights = {\n",
    "            \"Brightness\": 1.0,  # Higher is better (rewarded if improved)\n",
    "            \"Sharpness\": 1.0,    # Higher is better (rewarded if improved) but images were generally sharp already \n",
    "            \"Contrast\": 2.0,     # Higher is better (rewarded if improved) the levels of contrast were lower and obstructed details\n",
    "            \"Noise\": -1.5,       # Lower is better (penalized if increased)\n",
    "        }\n",
    "\n",
    "        # Calculate score using normalized metrics and weights\n",
    "        score = 0\n",
    "        for metric, value in stats_normalized.items():\n",
    "            original_value = original_stats_normalized.get(metric, 0)\n",
    "            score += weights[metric] * (value - original_value)\n",
    "\n",
    "        evaluation_results[technique_name] = {\"Score\": score, \"Stats\": stats}\n",
    "\n",
    "    # Determine the best technique based on the highest score\n",
    "    best_technique = max(evaluation_results, key=lambda x: evaluation_results[x][\"Score\"])\n",
    "    return {\"Best Technique\": best_technique, \"Evaluation Results\": evaluation_results}\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76be56766da0aeeb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Applying the improved flow to all images\n",
    "for img, img_id in zip(total_images, total_image_ids):\n",
    "    original_stats = images_stats_df[images_stats_df['Image'] == img_id].iloc[0].to_dict()\n",
    "\n",
    "    # Step 1: Noise Reduction\n",
    "    noise_reduced_image = non_local_means_denoising(img, h=5, templateWindowSize=7, searchWindowSize=21)\n",
    "\n",
    "    # Step 2: Histogram Equalization\n",
    "    histogram_equalized_image = clahe_histogram_equalization(noise_reduced_image)\n",
    "\n",
    "    # Step 3: Binarization\n",
    "    binarized_image = adaptive_threshold(histogram_equalized_image, adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C, blockSize=11, C=2)\n",
    "\n",
    "    # Step 4: Morphological Opening to reduce salt-and-pepper noise\n",
    "    final_image = morphological_opening(binarized_image, kernel_size=(3, 3))\n",
    "\n",
    "    # Save the final processed image for comparison\n",
    "    output_path = os.path.join(output_folder, f\"Fine_Tuned_Flow_Image_{img_id}.jpg\")\n",
    "    cv2.imwrite(output_path, final_image)\n",
    "\n",
    "    print(f\"Saved fine-tuned processed image for {img_id} at {output_path}\")\n",
    "\n",
    "print(\"All images processed and saved in the Fine-Tuned Flow stage.\")\n"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Improved Flow Explanation\n",
    "\n",
    "The improved flow incorporates advanced techniques and specific parameters to enhance the final image quality. Below, I explain each step in detail, the reasoning behind the technique choices, and how each step contributes to the improved output.\n",
    "\n",
    "#### Final Steps and Techniques\n",
    "\n",
    "##### 1. Noise Reduction (Non-Local Means Denoising)\n",
    "- **Technique**: Non-Local Means Denoising (`h=5`, `templateWindowSize=7`, `searchWindowSize=21`)\n",
    "- **Reasoning**:\n",
    "  - **Improvement Needed**: Median Blur was previously used but had some limitations in preserving details. Non-Local Means proved better in reducing noise while maintaining important features.\n",
    "  - **Why This Step**: Non-Local Means is effective for reducing noise without excessive blurring, which is vital for maintaining legibility in handwritten notes. The chosen parameters (`h=5`) provided a moderate filtering strength to reduce noise without losing essential information.\n",
    "  - **Effect**: This step significantly reduced noise while retaining the original details, which made the subsequent steps more effective.\n",
    "\n",
    "##### 2. Histogram Equalization (CLAHE)\n",
    "- **Technique**: CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "- **Reasoning**:\n",
    "  - **Improvement Needed**: Standard Histogram Equalization often led to over-enhancement, amplifying noise in regions with fewer features.\n",
    "  - **Why This Step**: CLAHE limits contrast enhancement to prevent over-amplification and enhances local regions for more balanced results. It is well-suited for non-uniform lighting conditions, typical in handwritten documents.\n",
    "  - **Effect**: Applying CLAHE improved the contrast and made the handwriting clearer while avoiding artifacts or excessive noise. The text and table lines became more pronounced without compromising on clarity.\n",
    "\n",
    "##### 3. Binarization (Adaptive Threshold)\n",
    "- **Technique**: Adaptive Threshold (`adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C`, `blockSize=11`, `C=2`)\n",
    "- **Reasoning**:\n",
    "  - **Improvement Needed**: Binarization is crucial for separating text from the background, but uniform binarization sometimes created artifacts.\n",
    "  - **Why This Step**: The Adaptive Gaussian Threshold method takes local illumination differences into account, ensuring that text is distinct across varying lighting conditions. The chosen parameters (`blockSize=11`, `C=2`) helped capture more local details and improve text segmentation.\n",
    "  - **Effect**: This step effectively made the text and table lines stand out against the background, resulting in better segmentation of the document content.\n",
    "\n",
    "##### 4. Morphological Operations (Morphological Opening)\n",
    "- **Technique**: Morphological Opening (`kernel_size=(3, 3)`)\n",
    "- **Reasoning**:\n",
    "  - **Improvement Needed**: After the binarization step, salt-and-pepper noise became more noticeable, necessitating further cleanup.\n",
    "  - **Why This Step**: Morphological Opening (erosion followed by dilation) is ideal for removing scattered noise without affecting text shapes. The small kernel size (`3x3`) was chosen to remove noise conservatively, ensuring minimal impact on handwriting and table lines.\n",
    "  - **Effect**: This step significantly reduced noise, providing a cleaner image suitable for downstream tasks like OCR, while preserving thin lines and small handwriting details.\n",
    "\n",
    "### Summary of Improvements in the Flow\n",
    "The improved flow made use of advanced techniques that were fine-tuned through experimentation:\n",
    "\n",
    "1. **Enhanced Noise Reduction**: Switching from Median Blur to Non-Local Means resulted in better preservation of details, while effectively reducing noise.\n",
    "2. **Controlled Contrast Enhancement**: CLAHE offered a more refined way to enhance contrast without over-amplifying regions, avoiding excessive noise.\n",
    "3. **Better Text Segmentation**: Adaptive Threshold with tuned parameters provided better separation of text from the background, which was crucial for handling variations in lighting.\n",
    "4. **Effective Noise Reduction Post-Binarization**: Morphological Opening helped in reducing salt-and-pepper noise while retaining important features.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abe7310e9564541e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ee5e70d91aa792c6",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
