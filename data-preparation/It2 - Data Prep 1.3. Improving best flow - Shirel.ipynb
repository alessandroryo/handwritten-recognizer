{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Fine-Tuning Flow - Stage 3: Reducing Salt-and-Pepper Noise and Enhancing Sharpness"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b0f6a4f8289f690"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T11:11:18.407214Z",
     "start_time": "2024-11-21T11:11:18.395468Z"
    }
   },
   "id": "bb7b20b058015433",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the paths\n",
    "folder_path = '../data/subset'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T11:11:18.423082Z",
     "start_time": "2024-11-21T11:11:18.409403Z"
    }
   },
   "id": "2596400edaa044d9",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load image paths\n",
    "def load_images_from_folder(folder_path, extensions=('.png', '.jpg', '.jpeg', '.JPG')):\n",
    "    \"\"\"\n",
    "    Load all image file paths from a specified folder that match the given file extensions.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing the images.\n",
    "    extensions (tuple of str): A tuple of file extensions to filter the images by. \n",
    "                               Default is ('.png', '.jpg', '.jpeg', '.JPG').\n",
    "\n",
    "    Returns:\n",
    "    list: A list of full file paths to images in the folder that match the specified extensions.\n",
    "    \n",
    "    Raises:\n",
    "    FileNotFoundError: If the specified folder does not exist.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        raise FileNotFoundError(f\"The specified folder does not exist: {folder_path}\")\n",
    "\n",
    "    # List comprehension to gather all image paths with the specified extensions\n",
    "    image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(extensions)]\n",
    "\n",
    "    return image_paths\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T11:11:18.438785Z",
     "start_time": "2024-11-21T11:11:18.425224Z"
    }
   },
   "id": "f97effeeee352681",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load and preprocess images\n",
    "def load_and_preprocess_images(image_paths, resize_dim=(256, 256)):\n",
    "    images = []\n",
    "    image_ids = []\n",
    "\n",
    "    # Initialize tqdm progress bar\n",
    "    for path in tqdm(image_paths, desc=\"Loading and preprocessing images\", unit=\"image\"):\n",
    "        img = cv2.imread(path)\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "        # img_resized = cv2.resize(img_gray, resize_dim)  # Resize for consistency\n",
    "        images.append(img_gray)\n",
    "        image_ids.append(f'Image_{len(images)}')  # Assign image ID as Image_1, Image_2, etc.\n",
    "\n",
    "    return images, image_ids\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T11:11:18.454345Z",
     "start_time": "2024-11-21T11:11:18.440897Z"
    }
   },
   "id": "e333e08bd6abdba",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing images: 100%|██████████| 12/12 [00:02<00:00,  5.24image/s]\n"
     ]
    }
   ],
   "source": [
    "# Load all image file paths from the specified folder\n",
    "image_paths_all = load_images_from_folder(folder_path)\n",
    "\n",
    "# Load and preprocess all images\n",
    "total_images, total_image_ids = load_and_preprocess_images(image_paths_all)\n",
    "\n",
    "# Randomly select 10 images for experimentation\n",
    "# experiment_indices = random.sample(range(len(total_images)), 10)\n",
    "# test_images = [total_images[i] for i in experiment_indices]\n",
    "# test_image_ids = [total_image_ids[i] for i in experiment_indices]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T11:11:20.787337Z",
     "start_time": "2024-11-21T11:11:18.457381Z"
    }
   },
   "id": "2063c6e03c0d2c0f",
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Applying the best Flow and techniques from previous steps"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52700c6b57c91a5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the best techniques with their best parameters\n",
    "best_techniques = {\n",
    "    \"Noise Reduction\": lambda img: cv2.medianBlur(img, 3),\n",
    "    \"Histogram Equalization\": lambda img: cv2.equalizeHist(img),\n",
    "    \"Binarization\": lambda img: cv2.adaptiveThreshold(\n",
    "        img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
    "    ),\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T11:11:20.803459Z",
     "start_time": "2024-11-21T11:11:20.790599Z"
    }
   },
   "id": "a65be9d0784deb94",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to apply the best flow and save all images\n",
    "def apply_best_flow_and_save(images, image_ids, output_folder):\n",
    "    # Create output directory if it does not exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    processed_images = []  # List to store processed images\n",
    "    processed_image_ids = []  # List to store image IDs\n",
    "\n",
    "    for img, img_id in zip(images, image_ids):\n",
    "        processed_image = img.copy()\n",
    "\n",
    "        # Apply each technique in sequence as per the best flow\n",
    "        for step_name, technique_func in best_techniques.items():\n",
    "            processed_image = technique_func(processed_image)\n",
    "\n",
    "        # Save the processed image to the output directory\n",
    "        output_path = os.path.join(output_folder, f\"Best_Flow_Image_{img_id}.jpg\")\n",
    "        cv2.imwrite(output_path, processed_image)\n",
    "\n",
    "        # Store processed image and its ID\n",
    "        processed_images.append(processed_image)\n",
    "        processed_image_ids.append(img_id)\n",
    "\n",
    "    print(f\"All images have been processed and saved in '{output_folder}'.\")\n",
    "\n",
    "    # Return the processed images and their IDs for later processing\n",
    "    return processed_images, processed_image_ids"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T11:11:20.819144Z",
     "start_time": "2024-11-21T11:11:20.804445Z"
    }
   },
   "id": "1223ac9774d74f21",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images have been processed and saved in './Data/It2/Best_Flow_Images'.\n"
     ]
    }
   ],
   "source": [
    "# Assuming `total_images` and `total_image_ids` are defined and contain the list of images and their IDs\n",
    "processed_images, processed_image_ids = apply_best_flow_and_save(total_images, total_image_ids, \"./Data/It2/Best_Flow_Images\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T11:11:24.345571Z",
     "start_time": "2024-11-21T11:11:20.820184Z"
    }
   },
   "id": "31fcb45f33c561c3",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Image Characteristics Calculation Functions - from data understanding it2\n",
    "def calculate_brightness(image):\n",
    "    return np.mean(image)\n",
    "\n",
    "def calculate_sharpness(image):\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\n",
    "def calculate_contrast(image):\n",
    "    return image.std()\n",
    "\n",
    "def calculate_noise(image):\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    noise = cv2.absdiff(image, blurred)\n",
    "    return np.var(noise)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T11:11:24.368322Z",
     "start_time": "2024-11-21T11:11:24.347614Z"
    }
   },
   "id": "84463242bfb35ee4",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the CSV file with the image statistics\n",
    "# images_stats_path = \"../data-understanding/images_stats.csv\"  \n",
    "# images_stats_df = pd.read_csv(images_stats_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T11:11:24.383935Z",
     "start_time": "2024-11-21T11:11:24.369382Z"
    }
   },
   "id": "eaa84259e813ea34",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# images_stats_df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T11:11:24.399795Z",
     "start_time": "2024-11-21T11:11:24.386013Z"
    }
   },
   "id": "3f96d0027780e46f",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# images_stats_df.drop(['Skew','Line Spacing', 'Tables Detected', 'Resolution', 'Detected Elements','Texture', 'Patterns'],axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T11:11:24.415424Z",
     "start_time": "2024-11-21T11:11:24.401889Z"
    }
   },
   "id": "2d1640a280f060c2",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def image_statistics_table(images, imagesId):\n",
    "    stats_data = {'Image': [],\n",
    "                  'Brightness': [],\n",
    "                  'Sharpness': [],\n",
    "                  'Contrast': [],\n",
    "                  'Noise': [],}\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        stats_data['Image'].append(imagesId[i])\n",
    "        stats_data['Brightness'].append(calculate_brightness(img))\n",
    "        stats_data['Sharpness'].append(calculate_sharpness(img))\n",
    "        stats_data['Contrast'].append(calculate_contrast(img))\n",
    "        stats_data['Noise'].append(calculate_noise(img))\n",
    "    # Create a DataFrame to store per-image statistics\n",
    "    df = pd.DataFrame(stats_data)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T11:11:24.431185Z",
     "start_time": "2024-11-21T11:11:24.417527Z"
    }
   },
   "id": "2c0cfd588ed15c48",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Statistics Table:\n"
     ]
    },
    {
     "data": {
      "text/plain": "       Image  Brightness      Sharpness    Contrast        Noise\n0    Image_1  184.064784  101614.709924  114.265810  1911.472467\n1    Image_2  186.841469  100512.937644  112.848748  1923.411572\n2    Image_3  183.869726  103863.664641  114.362161  1912.976895\n3    Image_4  183.213323  102336.881509  114.683371  1890.281215\n4    Image_5  199.461862   84133.322482  105.250845  1860.932980\n5    Image_6  194.386007   89845.786314  108.547281  1895.014561\n6    Image_7  192.806443   88849.927661  109.504879  1889.037366\n7    Image_8  168.084150  109124.750432  120.868427  1773.559901\n8    Image_9  191.851313   85170.015914  110.068881  1798.468646\n9   Image_10  193.391814   90281.637005  109.153648  1849.512335\n10  Image_11  178.691745   86249.746656  116.771809  1702.439431\n11  Image_12  177.471514   79991.283046  117.299181  1634.957319",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_1</td>\n      <td>184.064784</td>\n      <td>101614.709924</td>\n      <td>114.265810</td>\n      <td>1911.472467</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_2</td>\n      <td>186.841469</td>\n      <td>100512.937644</td>\n      <td>112.848748</td>\n      <td>1923.411572</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_3</td>\n      <td>183.869726</td>\n      <td>103863.664641</td>\n      <td>114.362161</td>\n      <td>1912.976895</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_4</td>\n      <td>183.213323</td>\n      <td>102336.881509</td>\n      <td>114.683371</td>\n      <td>1890.281215</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_5</td>\n      <td>199.461862</td>\n      <td>84133.322482</td>\n      <td>105.250845</td>\n      <td>1860.932980</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Image_6</td>\n      <td>194.386007</td>\n      <td>89845.786314</td>\n      <td>108.547281</td>\n      <td>1895.014561</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Image_7</td>\n      <td>192.806443</td>\n      <td>88849.927661</td>\n      <td>109.504879</td>\n      <td>1889.037366</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Image_8</td>\n      <td>168.084150</td>\n      <td>109124.750432</td>\n      <td>120.868427</td>\n      <td>1773.559901</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Image_9</td>\n      <td>191.851313</td>\n      <td>85170.015914</td>\n      <td>110.068881</td>\n      <td>1798.468646</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Image_10</td>\n      <td>193.391814</td>\n      <td>90281.637005</td>\n      <td>109.153648</td>\n      <td>1849.512335</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Image_11</td>\n      <td>178.691745</td>\n      <td>86249.746656</td>\n      <td>116.771809</td>\n      <td>1702.439431</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Image_12</td>\n      <td>177.471514</td>\n      <td>79991.283046</td>\n      <td>117.299181</td>\n      <td>1634.957319</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_stats_df = image_statistics_table(processed_images, processed_image_ids)\n",
    "print(\"Image Statistics Table:\")\n",
    "images_stats_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T11:11:28.433270Z",
     "start_time": "2024-11-21T11:11:24.434246Z"
    }
   },
   "id": "cb09f88013ed4a8e",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "95227fb442e2ce1c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T11:11:28.449151Z",
     "start_time": "2024-11-21T11:11:28.436492Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create folder to save images for comparison\n",
    "output_folder = \"./Data/It2/Fine_Tuned_Flow\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Functions for each step in the image processing pipeline\n",
    "def non_local_means_denoising(image, h=5, templateWindowSize=7, searchWindowSize=21):\n",
    "    \"\"\"Apply Non-Local Means Denoising.\"\"\"\n",
    "    return cv2.fastNlMeansDenoising(image, None, h, templateWindowSize, searchWindowSize)\n",
    "\n",
    "\n",
    "def clahe_histogram_equalization(image, clipLimit=2.0, tileGridSize=(8, 8)):\n",
    "    \"\"\"Apply CLAHE Histogram Equalization.\"\"\"\n",
    "    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n",
    "    return clahe.apply(image)\n",
    "\n",
    "\n",
    "def adaptive_threshold(image, adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C, blockSize=11, C=2):\n",
    "    \"\"\"Apply Adaptive Thresholding.\"\"\"\n",
    "    return cv2.adaptiveThreshold(image, 255, adaptiveMethod, cv2.THRESH_BINARY, blockSize, C)\n",
    "\n",
    "\n",
    "def morphological_opening(image, kernel_size=(3, 3)):\n",
    "    \"\"\"Apply Morphological Opening to reduce salt-and-pepper noise.\"\"\"\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernel_size)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T11:11:28.464805Z",
     "start_time": "2024-11-21T11:11:28.450199Z"
    }
   },
   "id": "9ff93b6aa58919c",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluation function to assess improvement in characteristics\n",
    "def advanced_evaluation(image, techniques_dict, original_stats):\n",
    "    evaluation_results = {}\n",
    "\n",
    "    for technique_name, technique_func in techniques_dict.items():\n",
    "        # Apply the technique\n",
    "        processed_image = technique_func(image)\n",
    "\n",
    "        # Calculate characteristics for the processed image\n",
    "        stats = {\n",
    "            \"Brightness\": calculate_brightness(processed_image),\n",
    "            \"Sharpness\": calculate_sharpness(processed_image),\n",
    "            \"Contrast\": calculate_contrast(processed_image),\n",
    "            \"Noise\": calculate_noise(processed_image),\n",
    "        }\n",
    "\n",
    "        # Normalize metrics to comparable ranges (between 0 and 1, roughly)\n",
    "        stats_normalized = {\n",
    "            \"Brightness\": stats[\"Brightness\"] / 255,\n",
    "            \"Sharpness\": stats[\"Sharpness\"] / 1000,\n",
    "            \"Contrast\": stats[\"Contrast\"] / 255,\n",
    "            \"Noise\": stats[\"Noise\"] / 255,\n",
    "        }\n",
    "\n",
    "        # Normalize the original stats for comparison\n",
    "        original_stats_normalized = {\n",
    "            \"Brightness\": original_stats[\"Brightness\"] / 255,\n",
    "            \"Sharpness\": original_stats[\"Sharpness\"] / 1000,\n",
    "            \"Contrast\": original_stats[\"Contrast\"] / 255,\n",
    "            \"Noise\": original_stats[\"Noise\"] / 255,\n",
    "        }\n",
    "\n",
    "        # Weights for each characteristic (to determine their importance)\n",
    "        weights = {\n",
    "            \"Brightness\": 1.0,  # Higher is better (rewarded if improved)\n",
    "            \"Sharpness\": 1.0,    # Higher is better (rewarded if improved) but images were generally sharp already \n",
    "            \"Contrast\": 2.0,     # Higher is better (rewarded if improved) the levels of contrast were lower and obstructed details\n",
    "            \"Noise\": -1.5,       # Lower is better (penalized if increased)\n",
    "        }\n",
    "\n",
    "        # Calculate score using normalized metrics and weights\n",
    "        score = 0\n",
    "        for metric, value in stats_normalized.items():\n",
    "            original_value = original_stats_normalized.get(metric, 0)\n",
    "            score += weights[metric] * (value - original_value)\n",
    "\n",
    "        evaluation_results[technique_name] = {\"Score\": score, \"Stats\": stats}\n",
    "\n",
    "    # Determine the best technique based on the highest score\n",
    "    best_technique = max(evaluation_results, key=lambda x: evaluation_results[x][\"Score\"])\n",
    "    return {\"Best Technique\": best_technique, \"Evaluation Results\": evaluation_results}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T11:11:28.480623Z",
     "start_time": "2024-11-21T11:11:28.465895Z"
    }
   },
   "id": "76be56766da0aeeb",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved fine-tuned processed image for Image_1 at ./Data/It2/Fine_Tuned_Flow\\Fine_Tuned_Flow_Image_Image_1.jpg\n",
      "Saved fine-tuned processed image for Image_2 at ./Data/It2/Fine_Tuned_Flow\\Fine_Tuned_Flow_Image_Image_2.jpg\n",
      "Saved fine-tuned processed image for Image_3 at ./Data/It2/Fine_Tuned_Flow\\Fine_Tuned_Flow_Image_Image_3.jpg\n",
      "Saved fine-tuned processed image for Image_4 at ./Data/It2/Fine_Tuned_Flow\\Fine_Tuned_Flow_Image_Image_4.jpg\n",
      "Saved fine-tuned processed image for Image_5 at ./Data/It2/Fine_Tuned_Flow\\Fine_Tuned_Flow_Image_Image_5.jpg\n",
      "Saved fine-tuned processed image for Image_6 at ./Data/It2/Fine_Tuned_Flow\\Fine_Tuned_Flow_Image_Image_6.jpg\n",
      "Saved fine-tuned processed image for Image_7 at ./Data/It2/Fine_Tuned_Flow\\Fine_Tuned_Flow_Image_Image_7.jpg\n",
      "Saved fine-tuned processed image for Image_8 at ./Data/It2/Fine_Tuned_Flow\\Fine_Tuned_Flow_Image_Image_8.jpg\n",
      "Saved fine-tuned processed image for Image_9 at ./Data/It2/Fine_Tuned_Flow\\Fine_Tuned_Flow_Image_Image_9.jpg\n",
      "Saved fine-tuned processed image for Image_10 at ./Data/It2/Fine_Tuned_Flow\\Fine_Tuned_Flow_Image_Image_10.jpg\n",
      "Saved fine-tuned processed image for Image_11 at ./Data/It2/Fine_Tuned_Flow\\Fine_Tuned_Flow_Image_Image_11.jpg\n",
      "Saved fine-tuned processed image for Image_12 at ./Data/It2/Fine_Tuned_Flow\\Fine_Tuned_Flow_Image_Image_12.jpg\n",
      "All images processed and saved in the Fine-Tuned Flow stage.\n"
     ]
    }
   ],
   "source": [
    "# Applying the improved flow to all images\n",
    "for img, img_id in zip(total_images, total_image_ids):\n",
    "    original_stats = images_stats_df[images_stats_df['Image'] == img_id].iloc[0].to_dict()\n",
    "\n",
    "    # Step 1: Noise Reduction\n",
    "    noise_reduced_image = non_local_means_denoising(img, h=5, templateWindowSize=7, searchWindowSize=21)\n",
    "\n",
    "    # Step 2: Histogram Equalization\n",
    "    histogram_equalized_image = clahe_histogram_equalization(noise_reduced_image)\n",
    "\n",
    "    # Step 3: Binarization\n",
    "    binarized_image = adaptive_threshold(histogram_equalized_image, adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C, blockSize=11, C=2)\n",
    "\n",
    "    # Step 4: Morphological Opening to reduce salt-and-pepper noise\n",
    "    final_image = morphological_opening(binarized_image, kernel_size=(3, 3))\n",
    "\n",
    "    # Save the final processed image for comparison\n",
    "    output_path = os.path.join(output_folder, f\"Fine_Tuned_Flow_Image_{img_id}.jpg\")\n",
    "    cv2.imwrite(output_path, final_image)\n",
    "\n",
    "    print(f\"Saved fine-tuned processed image for {img_id} at {output_path}\")\n",
    "\n",
    "print(\"All images processed and saved in the Fine-Tuned Flow stage.\")\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-21T11:12:39.185771Z",
     "start_time": "2024-11-21T11:11:28.481681Z"
    }
   },
   "id": "initial_id",
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Improved Flow Explanation\n",
    "\n",
    "The improved flow incorporates advanced techniques and specific parameters to enhance the final image quality. Below, I explain each step in detail, the reasoning behind the technique choices, and how each step contributes to the improved output.\n",
    "\n",
    "#### Final Steps and Techniques\n",
    "\n",
    "##### 1. Noise Reduction (Non-Local Means Denoising)\n",
    "- **Technique**: Non-Local Means Denoising (`h=5`, `templateWindowSize=7`, `searchWindowSize=21`)\n",
    "- **Reasoning**:\n",
    "  - **Improvement Needed**: Median Blur was previously used but had some limitations in preserving details. Non-Local Means proved better in reducing noise while maintaining important features.\n",
    "  - **Why This Step**: Non-Local Means is effective for reducing noise without excessive blurring, which is vital for maintaining legibility in handwritten notes. The chosen parameters (`h=5`) provided a moderate filtering strength to reduce noise without losing essential information.\n",
    "  - **Effect**: This step significantly reduced noise while retaining the original details, which made the subsequent steps more effective.\n",
    "\n",
    "##### 2. Histogram Equalization (CLAHE)\n",
    "- **Technique**: CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "- **Reasoning**:\n",
    "  - **Improvement Needed**: Standard Histogram Equalization often led to over-enhancement, amplifying noise in regions with fewer features.\n",
    "  - **Why This Step**: CLAHE limits contrast enhancement to prevent over-amplification and enhances local regions for more balanced results. It is well-suited for non-uniform lighting conditions, typical in handwritten documents.\n",
    "  - **Effect**: Applying CLAHE improved the contrast and made the handwriting clearer while avoiding artifacts or excessive noise. The text and table lines became more pronounced without compromising on clarity.\n",
    "\n",
    "##### 3. Binarization (Adaptive Threshold)\n",
    "- **Technique**: Adaptive Threshold (`adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C`, `blockSize=11`, `C=2`)\n",
    "- **Reasoning**:\n",
    "  - **Improvement Needed**: Binarization is crucial for separating text from the background, but uniform binarization sometimes created artifacts.\n",
    "  - **Why This Step**: The Adaptive Gaussian Threshold method takes local illumination differences into account, ensuring that text is distinct across varying lighting conditions. The chosen parameters (`blockSize=11`, `C=2`) helped capture more local details and improve text segmentation.\n",
    "  - **Effect**: This step effectively made the text and table lines stand out against the background, resulting in better segmentation of the document content.\n",
    "\n",
    "##### 4. Morphological Operations (Morphological Opening)\n",
    "- **Technique**: Morphological Opening (`kernel_size=(3, 3)`)\n",
    "- **Reasoning**:\n",
    "  - **Improvement Needed**: After the binarization step, salt-and-pepper noise became more noticeable, necessitating further cleanup.\n",
    "  - **Why This Step**: Morphological Opening (erosion followed by dilation) is ideal for removing scattered noise without affecting text shapes. The small kernel size (`3x3`) was chosen to remove noise conservatively, ensuring minimal impact on handwriting and table lines.\n",
    "  - **Effect**: This step significantly reduced noise, providing a cleaner image suitable for downstream tasks like OCR, while preserving thin lines and small handwriting details.\n",
    "\n",
    "### Summary of Improvements in the Flow\n",
    "The improved flow made use of advanced techniques that were fine-tuned through experimentation:\n",
    "\n",
    "1. **Enhanced Noise Reduction**: Switching from Median Blur to Non-Local Means resulted in better preservation of details, while effectively reducing noise.\n",
    "2. **Controlled Contrast Enhancement**: CLAHE offered a more refined way to enhance contrast without over-amplifying regions, avoiding excessive noise.\n",
    "3. **Better Text Segmentation**: Adaptive Threshold with tuned parameters provided better separation of text from the background, which was crucial for handling variations in lighting.\n",
    "4. **Effective Noise Reduction Post-Binarization**: Morphological Opening helped in reducing salt-and-pepper noise while retaining important features.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abe7310e9564541e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T11:12:39.198297Z",
     "start_time": "2024-11-21T11:12:39.188431Z"
    }
   },
   "id": "ee5e70d91aa792c6",
   "execution_count": 52
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
