{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f2763dd6ef39f85",
   "metadata": {},
   "source": [
    "# Data Preparation - IT2 - Choosing best flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c25980e7f919ae",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b59f9c089d5576e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the path to the folder containing the images to be processed\n",
    "folder_path = '../data/subset'  # Update this path to point to your specific folder containing images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe9242f22a8b58c",
   "metadata": {},
   "source": [
    "## Loading Images and stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5e77ec95ee7c9f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load image paths\n",
    "def load_images_from_folder(folder_path, extensions=('.png', '.jpg', '.jpeg', '.JPG')):\n",
    "    \"\"\"\n",
    "    Load all image file paths from a specified folder that match the given file extensions.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing the images.\n",
    "    extensions (tuple of str): A tuple of file extensions to filter the images by. \n",
    "                               Default is ('.png', '.jpg', '.jpeg', '.JPG').\n",
    "\n",
    "    Returns:\n",
    "    list: A list of full file paths to images in the folder that match the specified extensions.\n",
    "    \n",
    "    Raises:\n",
    "    FileNotFoundError: If the specified folder does not exist.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        raise FileNotFoundError(f\"The specified folder does not exist: {folder_path}\")\n",
    "\n",
    "    # List comprehension to gather all image paths with the specified extensions\n",
    "    image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(extensions)]\n",
    "\n",
    "    return image_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361e15f49831c54f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load and preprocess images\n",
    "def load_and_preprocess_images(image_paths, resize_dim=(256, 256)):\n",
    "    images = []\n",
    "    image_ids = []\n",
    "\n",
    "    # Initialize tqdm progress bar\n",
    "    for path in tqdm(image_paths, desc=\"Loading and preprocessing images\", unit=\"image\"):\n",
    "        img = cv2.imread(path)\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "        # img_resized = cv2.resize(img_gray, resize_dim)  # Resize for consistency\n",
    "        images.append(img_gray)\n",
    "        image_ids.append(f'Image_{len(images)}')  # Assign image ID as Image_1, Image_2, etc.\n",
    "\n",
    "    return images, image_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a4ddc7dcb0bfc2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load all image file paths from the specified folder\n",
    "image_paths_all = load_images_from_folder(folder_path)\n",
    "\n",
    "# Load and preprocess all images\n",
    "total_images, total_image_ids = load_and_preprocess_images(image_paths_all)\n",
    "\n",
    "# Randomly select 10 images for experimentation\n",
    "experiment_indices = random.sample(range(len(total_images)), 10)\n",
    "test_images = [total_images[i] for i in experiment_indices]\n",
    "test_image_ids = [total_image_ids[i] for i in experiment_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eaa079e7c6d124",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the CSV file with the image statistics\n",
    "images_stats_path = \"../data-understanding/images_stats.csv\"\n",
    "images_stats_df = pd.read_csv(images_stats_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24c604acb58db6b",
   "metadata": {},
   "source": [
    "## Functions of Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9420b3f68d65e4e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Image Characteristics Calculation Functions - from data understanding it2\n",
    "def calculate_brightness(image):\n",
    "    return np.mean(image)\n",
    "\n",
    "def calculate_sharpness(image):\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\n",
    "def calculate_contrast(image):\n",
    "    return image.std()\n",
    "\n",
    "def calculate_noise(image):\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    noise = cv2.absdiff(image, blurred)\n",
    "    return np.var(noise)\n",
    "\n",
    "# def calculate_skew(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "#     _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "#     coords = np.column_stack(np.where(binary > 0))\n",
    "#     if coords.size == 0:\n",
    "#         return 0\n",
    "#     angle = cv2.minAreaRect(coords)[-1]\n",
    "#     if angle < -45:\n",
    "#         angle = -(90 + angle)\n",
    "#     else:\n",
    "#         angle = -angle\n",
    "#     if abs(angle) < 1e-2:\n",
    "#         angle = 0\n",
    "#     return round(angle, 2)\n",
    "# \n",
    "# def calculate_line_spacing(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "# \n",
    "#     # Ensure the image is in the correct format for findContours\n",
    "#     if image.dtype != np.uint8:\n",
    "#         image = cv2.convertScaleAbs(image)\n",
    "# \n",
    "#     _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "#     contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     heights = [cv2.boundingRect(contour)[3] for contour in contours]\n",
    "#     if len(heights) > 1:\n",
    "#         line_spacing = np.mean(np.diff(sorted(heights)))\n",
    "#     else:\n",
    "#         line_spacing = 0\n",
    "#     return line_spacing\n",
    "# \n",
    "# \n",
    "# def detect_tables(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "# \n",
    "#     # Ensure the image is in the correct format for adaptiveThreshold\n",
    "#     if image.dtype != np.uint8:\n",
    "#         image = cv2.convertScaleAbs(image)\n",
    "# \n",
    "#     # Apply binary threshold and adaptive threshold\n",
    "#     _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "#     binary = cv2.adaptiveThreshold(binary, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "# \n",
    "#     # Find contours in the image\n",
    "#     contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     table_contours = [contour for contour in contours if cv2.contourArea(contour) > 1000]\n",
    "# \n",
    "#     return len(table_contours)\n",
    "# \n",
    "# \n",
    "# def calculate_resolution(image):\n",
    "#     height, width = image.shape[:2]\n",
    "#     return height * width\n",
    "# \n",
    "# def calculate_elements_detection(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "# \n",
    "#     # Ensure the image is in the correct format for findContours\n",
    "#     if image.dtype != np.uint8:\n",
    "#         image = cv2.convertScaleAbs(image)\n",
    "# \n",
    "#     # Apply binary threshold\n",
    "#     _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "# \n",
    "#     # Find contours\n",
    "#     contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     return len(contours)\n",
    "# \n",
    "# \n",
    "# def calculate_texture(image):\n",
    "#     laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "#     return laplacian.std()\n",
    "# \n",
    "# def calculate_patterns(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "# \n",
    "#     # Ensure the image is in the correct format for Canny edge detection\n",
    "#     if image.dtype != np.uint8:\n",
    "#         image = cv2.convertScaleAbs(image)\n",
    "# \n",
    "#     # Apply Canny edge detection\n",
    "#     edges = cv2.Canny(image, 100, 200)\n",
    "# \n",
    "#     # Count the number of edge pixels\n",
    "#     return np.sum(edges > 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76105296fc098baa",
   "metadata": {},
   "source": [
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def advanced_evaluation(image, techniques_dict, original_stats):\n",
    "    evaluation_results = {}\n",
    "\n",
    "    for technique_name, technique_func in techniques_dict.items():\n",
    "        # Apply the technique\n",
    "        processed_image = technique_func(image)\n",
    "\n",
    "        # Calculate characteristics for the processed image\n",
    "        stats = {\n",
    "            \"Brightness\": calculate_brightness(processed_image),\n",
    "            \"Sharpness\": calculate_sharpness(processed_image),\n",
    "            \"Contrast\": calculate_contrast(processed_image),\n",
    "            \"Noise\": calculate_noise(processed_image),\n",
    "        }\n",
    "\n",
    "        # Normalize metrics to comparable ranges (between 0 and 1, roughly)\n",
    "        stats_normalized = {\n",
    "            \"Brightness\": stats[\"Brightness\"] / 255,\n",
    "            \"Sharpness\": stats[\"Sharpness\"] / 1000,\n",
    "            \"Contrast\": stats[\"Contrast\"] / 255,\n",
    "            \"Noise\": stats[\"Noise\"] / 255,\n",
    "        }\n",
    "\n",
    "        # Normalize the original stats for comparison\n",
    "        original_stats_normalized = {\n",
    "            \"Brightness\": original_stats[\"Brightness\"] / 255,\n",
    "            \"Sharpness\": original_stats[\"Sharpness\"] / 1000,\n",
    "            \"Contrast\": original_stats[\"Contrast\"] / 255,\n",
    "            \"Noise\": original_stats[\"Noise\"] / 255,\n",
    "        }\n",
    "\n",
    "        # Weights for each characteristic (to determine their importance)\n",
    "        weights = {\n",
    "            \"Brightness\": 1.0,  # Higher is better (rewarded if improved)\n",
    "            \"Sharpness\": 1.0,    # Higher is better (rewarded if improved) but images were generally sharp already \n",
    "            \"Contrast\": 2.0,     # Higher is better (rewarded if improved) the levels of contrast were lower and obstructed details\n",
    "            \"Noise\": -1.5,       # Lower is better (penalized if increased)\n",
    "        }\n",
    "\n",
    "        # Calculate score using normalized metrics and weights\n",
    "        score = 0\n",
    "        for metric, value in stats_normalized.items():\n",
    "            original_value = original_stats_normalized.get(metric, 0)\n",
    "            score += weights[metric] * (value - original_value)\n",
    "\n",
    "        evaluation_results[technique_name] = {\"Score\": score, \"Stats\": stats}\n",
    "\n",
    "    # Determine the best technique based on the highest score\n",
    "    best_technique = max(evaluation_results, key=lambda x: evaluation_results[x][\"Score\"])\n",
    "    return {\"Best Technique\": best_technique, \"Evaluation Results\": evaluation_results}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3610bf59adbc3b51",
   "metadata": {},
   "source": [
    "## Setting the best techniques based on step 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbfc1560547af5e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the best techniques and parameters for each step\n",
    "best_techniques = {\n",
    "    \"Noise Reduction\": (lambda img: cv2.medianBlur(img, ksize=3)),\n",
    "    \"Histogram Equalization\": (lambda img: cv2.equalizeHist(img)),  # No parameters were found to be beneficial\n",
    "    \"Binarization\": (lambda img: cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, blockSize=11, C=2)),\n",
    "    \"Morphological Operations\": (lambda img: cv2.dilate(img, np.ones((9, 9), np.uint8))),\n",
    "    \"Edge Detection\": (lambda img: cv2.Canny(img, threshold1=50, threshold2=150)),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c95072259bce52",
   "metadata": {},
   "source": [
    "## Using the previous flows found to be most suitable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1849a781f0e5f7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Best Flows from Previous Iteration\n",
    "previous_best_flows = {\n",
    "    \"Flow - CLAHE\": [\n",
    "        (\"Gaussian Blur\", lambda img: cv2.GaussianBlur(img, (5, 5), 0)),\n",
    "        (\"CLAHE\", lambda img: cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(img))\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0642c4b3339434",
   "metadata": {},
   "source": [
    "## Setting flows based on best techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a34877d455cb05",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create New Flows Incrementally\n",
    "new_flows = {\n",
    "    \"Flow 1 Noise Reduction\": [\n",
    "        (\"Noise Reduction\", best_techniques[\"Noise Reduction\"])\n",
    "    ],\n",
    "    \"Flow 2 Noise Reduction + Histogram Equalization\": [\n",
    "        (\"Noise Reduction\", best_techniques[\"Noise Reduction\"]),\n",
    "        (\"Histogram Equalization\", best_techniques[\"Histogram Equalization\"])\n",
    "    ],\n",
    "    \"Flow 3 Noise Reduction + Histogram Equalization + Binarization\": [\n",
    "        (\"Noise Reduction\", best_techniques[\"Noise Reduction\"]),\n",
    "        (\"Histogram Equalization\", best_techniques[\"Histogram Equalization\"]),\n",
    "        (\"Binarization\", best_techniques[\"Binarization\"])\n",
    "    ],\n",
    "    \"Flow 4 Noise Reduction + Histogram Equalization + Binarization + Morphological Operations\": [\n",
    "        (\"Noise Reduction\", best_techniques[\"Noise Reduction\"]),\n",
    "        (\"Histogram Equalization\", best_techniques[\"Histogram Equalization\"]),\n",
    "        (\"Binarization\", best_techniques[\"Binarization\"]),\n",
    "        (\"Morphological Operations\", best_techniques[\"Morphological Operations\"])\n",
    "    ],\n",
    "    \"Flow 5 Full Flow\": [\n",
    "        (\"Noise Reduction\", best_techniques[\"Noise Reduction\"]),\n",
    "        (\"Histogram Equalization\", best_techniques[\"Histogram Equalization\"]),\n",
    "        (\"Binarization\", best_techniques[\"Binarization\"]),\n",
    "        (\"Morphological Operations\", best_techniques[\"Morphological Operations\"]),\n",
    "        (\"Edge Detection\", best_techniques[\"Edge Detection\"])\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147cb3cb7f879f27",
   "metadata": {},
   "source": [
    "## Prepearing and running the flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ba0ef4c75cb75e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine all flows\n",
    "all_flows = {**previous_best_flows, **new_flows}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc83f73b2a4041",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to apply a flow to an image\n",
    "def apply_flow(flow, image):\n",
    "    for step_name, technique in flow:\n",
    "        image = technique(image)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad651372d796060",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing the Flows\n",
    "flow_results = {}\n",
    "\n",
    "# Define a specific image to save across all flows\n",
    "image_to_save_id = total_image_ids[0]  # Choose the first image (or any specific image)\n",
    "\n",
    "# Loop over each flow\n",
    "for flow_name, flow_steps in all_flows.items():\n",
    "    total_score = 0\n",
    "    print(f\"Testing Flow: {flow_name}\\n{'-' * 40}\")\n",
    "\n",
    "    # Loop over each image for evaluation\n",
    "    for img, img_id in zip(total_images, total_image_ids):\n",
    "        original_stats = images_stats_df[images_stats_df['Image'] == img_id].iloc[0].to_dict()\n",
    "\n",
    "        # Apply the flow on the image\n",
    "        processed_image = apply_flow(flow_steps, img)\n",
    "\n",
    "        # Save the processed image only for the selected image ID\n",
    "        if img_id == image_to_save_id:\n",
    "            # Specify the folder to save the processed images for the flows\n",
    "            output_folder_flow = f\"./Data/It2/Flows/{flow_name}\"\n",
    "            os.makedirs(output_folder_flow, exist_ok=True)\n",
    "\n",
    "            # Save the processed image with the flow name and image ID\n",
    "            cv2.imwrite(f\"{output_folder_flow}/{flow_name}_Image_{img_id}.jpg\", processed_image)\n",
    "\n",
    "        # Using advanced evaluation function to evaluate the processed image\n",
    "        evaluation_results = advanced_evaluation(processed_image, {\"Flow\": lambda x: x}, original_stats)\n",
    "\n",
    "        # Access the score for the flow (since only one technique is passed, we can directly fetch it)\n",
    "        flow_score = evaluation_results[\"Evaluation Results\"][\"Flow\"][\"Score\"]\n",
    "\n",
    "        # Add the score to the total score\n",
    "        total_score += flow_score\n",
    "        print(f\"Image {img_id}: Score = {flow_score}\")\n",
    "\n",
    "    # Calculate the average score for the flow\n",
    "    avg_score = total_score / len(total_images)\n",
    "    print(f\"Average Score for Flow '{flow_name}': {avg_score}\\n\")\n",
    "    flow_results[flow_name] = avg_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8d377f5268b95a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display Final Results\n",
    "sorted_results = sorted(flow_results.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nFinal Flow Testing Results (Sorted by Score):\")\n",
    "for flow_name, score in sorted_results:\n",
    "    print(f\"{flow_name}: Average Score = {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f026bf981a4c580",
   "metadata": {},
   "source": [
    "Final Flow Testing Results (Sorted by Score):\n",
    "Flow 3: Noise Reduction + Histogram Equalization + Binarization: Average Score = 83.55\n",
    "Flow 2: Noise Reduction + Histogram Equalization: Average Score = 0.51\n",
    "Flow 4: Noise Reduction + Histogram Equalization + Binarization + Morphological Operations: Average Score = 0.27\n",
    "Flow - CLAHE: Average Score = 0.08\n",
    "Flow 1: Noise Reduction: Average Score = -0.02\n",
    "Flow 5: Full Flow: Average Score = -0.69\n",
    "\n",
    "# Flow Testing Results and Interpretation\n",
    "\n",
    "## 1. Flow 3: Noise Reduction + Histogram Equalization + Binarization\n",
    "- **Score**: 83.55\n",
    "- **Steps**: Noise Reduction, Histogram Equalization, Binarization.\n",
    "- **Interpretation**:\n",
    "  - This flow produced the **highest average score**, indicating that combining these three techniques—**Noise Reduction**, **Histogram Equalization**, and **Binarization**—resulted in a significant improvement in image quality metrics compared to the original images.\n",
    "  - **Binarization** helped make text and table lines more distinct, providing better separation of content from the background.\n",
    "  - However, the absence of **Morphological Operations** and **Edge Detection** means that further refinement and edge enhancement could potentially yield even better results.\n",
    "\n",
    "## 2. Flow 2: Noise Reduction + Histogram Equalization\n",
    "- **Score**: 0.51\n",
    "- **Steps**: Noise Reduction, Histogram Equalization.\n",
    "- **Interpretation**:\n",
    "  - Adding **Histogram Equalization** improved the results compared to just using noise reduction, suggesting that enhancing contrast played a crucial role in making text and lines stand out more.\n",
    "  - The relatively low positive score indicates that although the images were improved, without **Binarization** or more advanced techniques like **Morphological Operations** or **Edge Detection**, the enhancement was limited.\n",
    "\n",
    "## 3. Flow 4: Noise Reduction + Histogram Equalization + Binarization + Morphological Operations\n",
    "- **Score**: 0.27\n",
    "- **Steps**: Noise Reduction, Histogram Equalization, Binarization, Morphological Operations.\n",
    "- **Interpretation**:\n",
    "  - Adding **Morphological Operations** to the binarization step provided some improvement, but not as much as expected compared to Flow 3.\n",
    "  - The low score indicates that while **Morphological Operations** added some structure to the images, they also introduced some level of distortion or data loss that negatively impacted the overall quality.\n",
    "\n",
    "## 4. Flow - CLAHE\n",
    "- **Score**: 0.08\n",
    "- **Steps**: CLAHE.\n",
    "- **Interpretation**:\n",
    "  - This flow, which only used **CLAHE** (Contrast Limited Adaptive Histogram Equalization), yielded a very small positive score.\n",
    "  - The limited improvement suggests that **contrast enhancement** alone, without noise reduction or edge enhancement, was not sufficient to achieve significant quality gains.\n",
    "\n",
    "## 5. Flow 1: Noise Reduction\n",
    "- **Score**: -0.02\n",
    "- **Steps**: Noise Reduction.\n",
    "- **Interpretation**:\n",
    "  - This flow produced a **negative score**, meaning that **Noise Reduction** alone did not improve image quality and instead slightly degraded it.\n",
    "  - The smoothed images lost some contrast and detail, which led to reduced image quality in terms of the evaluation metrics.\n",
    "\n",
    "## 6. Flow 5: Full Flow\n",
    "- **Score**: -0.69\n",
    "- **Steps**: Noise Reduction, Histogram Equalization, Binarization, Morphological Operations, Edge Detection.\n",
    "- **Interpretation**:\n",
    "  - Surprisingly, the **Full Flow**—which combined all the techniques—produced the **lowest average score**.\n",
    "  - This suggests that adding all five techniques together introduced too many transformations, which may have led to over-processing, resulting in the loss of important image characteristics.\n",
    "  - The **Edge Detection** and **Morphological Operations** steps might have contributed to unwanted noise or artifacts, negatively affecting the overall score.\n",
    "\n",
    "## Summary of Findings\n",
    "- **Flow 3** achieved the best result, showing that a combination of **Noise Reduction**, **Histogram Equalization**, and **Binarization** is effective in enhancing the images while keeping transformations minimal.\n",
    "- **Flow 2** also provided some improvement, indicating that **Histogram Equalization** is crucial for enhancing contrast and making features more prominent.\n",
    "- Adding **Morphological Operations**, as in **Flow 4**, did not significantly enhance the results and might have introduced unnecessary noise or detail loss.\n",
    "- The **Full Flow** (Flow 5) produced a negative score, suggesting that combining all techniques together without careful parameter tuning can lead to over-processing.\n",
    "- The **best flows** balance noise reduction, contrast enhancement, and binarization to make content more distinct without over-processing the images.\n",
    "\n",
    "Based on these results, you can conclude that a comprehensive image processing pipeline involving all the steps yields the best preparation for deep learning tasks, but simpler versions of the flow can still yield reasonable improvements depending on the requirements of the task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de9fd33b2569524",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
