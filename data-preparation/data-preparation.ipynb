{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Import Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Global Variables*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the folder containing the images to be processed\n",
    "folder_path = 'data/original'  # Update this path to point to your specific folder containing images\n",
    "\n",
    "# Define the path to the folder where the processed images will be saved\n",
    "output_folder = 'data/processed'  # Update this path to the desired output folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder_path, extensions=('.png', '.jpg', '.jpeg', '.JPG')):\n",
    "    \"\"\"\n",
    "    Load all image file paths from a specified folder that match the given file extensions.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing the images.\n",
    "    extensions (tuple of str): A tuple of file extensions to filter the images by. \n",
    "                               Default is ('.png', '.jpg', '.jpeg', '.JPG').\n",
    "\n",
    "    Returns:\n",
    "    list: A list of full file paths to images in the folder that match the specified extensions.\n",
    "    \n",
    "    Raises:\n",
    "    FileNotFoundError: If the specified folder does not exist.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        raise FileNotFoundError(f\"The specified folder does not exist: {folder_path}\")\n",
    "    \n",
    "    # List comprehension to gather all image paths with the specified extensions\n",
    "    image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(extensions)]\n",
    "    \n",
    "    return image_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_grayscale(image):\n",
    "    \"\"\"\n",
    "    Convert an image from BGR color space to grayscale.\n",
    "\n",
    "    Parameters:\n",
    "    image (numpy.ndarray): The input image in BGR color space, typically loaded using OpenCV.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The converted image in grayscale.\n",
    "\n",
    "    Raises:\n",
    "    TypeError: If the input is not a valid numpy array.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate the input image type\n",
    "    if not isinstance(image, np.ndarray):\n",
    "        raise TypeError(\"Input image must be a numpy array.\")\n",
    "    \n",
    "    # Convert the image from BGR to grayscale\n",
    "    grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    return grayscale_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhance Image Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_image_quality(image):\n",
    "    \"\"\"\n",
    "    Enhance the quality of an image by reducing noise and applying a sharpening filter.\n",
    "\n",
    "    Parameters:\n",
    "    image (numpy.ndarray): The input image, typically loaded using OpenCV.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The enhanced image with reduced noise and increased sharpness.\n",
    "\n",
    "    Raises:\n",
    "    TypeError: If the input is not a valid numpy array.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate the input image type\n",
    "    if not isinstance(image, np.ndarray):\n",
    "        raise TypeError(\"Input image must be a numpy array.\")\n",
    "    \n",
    "    # Apply Gaussian Blur to reduce noise\n",
    "    # GaussianBlur uses a kernel size of 5x5 to smooth the image, which helps in noise reduction.\n",
    "    blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "    # Define a sharpening kernel\n",
    "    # This kernel enhances the edges by amplifying the difference between the central pixel and its neighbors.\n",
    "    sharpening_kernel = np.array([[0, -1, 0],\n",
    "                                  [-1, 5,-1],\n",
    "                                  [0, -1, 0]])\n",
    "    \n",
    "    # Apply the sharpening filter to the blurred image\n",
    "    # filter2D applies the sharpening kernel to the image to increase the contrast of edges.\n",
    "    sharpened_image = cv2.filter2D(blurred_image, -1, sharpening_kernel)\n",
    "\n",
    "    return sharpened_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_threshold(image, block_size=15, C=4):\n",
    "    \"\"\"\n",
    "    Apply adaptive thresholding to an image with specified block size and C value.\n",
    "\n",
    "    Parameters:\n",
    "    image (numpy.ndarray): The input grayscale image to be thresholded.\n",
    "    block_size (int): The size of the pixel neighborhood used to calculate the threshold value.\n",
    "                      Must be an odd number greater than 1. Default is 15.\n",
    "    C (int): A constant subtracted from the mean or weighted mean. It is used to fine-tune \n",
    "             the thresholding. Default is 4.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The thresholded binary image.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If block_size is not an odd number or if it is less than or equal to 1.\n",
    "    TypeError: If the input image is not a numpy array.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate the input image type\n",
    "    if not isinstance(image, np.ndarray):\n",
    "        raise TypeError(\"Input image must be a numpy array.\")\n",
    "\n",
    "    # Validate the block_size parameter\n",
    "    if block_size <= 1 or block_size % 2 == 0:\n",
    "        raise ValueError(\"block_size must be an odd number greater than 1.\")\n",
    "    \n",
    "    # Apply adaptive Gaussian thresholding\n",
    "    # This method calculates the threshold for a pixel based on the mean of a block_size x block_size \n",
    "    # neighborhood of pixels minus the C constant.\n",
    "    threshold_image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                            cv2.THRESH_BINARY, block_size, C)\n",
    "    \n",
    "    return threshold_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_noise(image, kernel_size=(3, 3)):\n",
    "    \"\"\"\n",
    "    Apply a mild Gaussian blur to reduce noise in the image.\n",
    "\n",
    "    Parameters:\n",
    "    image (numpy.ndarray): The input image on which noise reduction will be applied.\n",
    "    kernel_size (tuple of int): The size of the kernel to be used for Gaussian blur.\n",
    "                                Default is (3, 3), which provides a mild blur.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The image with reduced noise.\n",
    "    \n",
    "    Raises:\n",
    "    TypeError: If the input image is not a numpy array.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate the input image type\n",
    "    if not isinstance(image, np.ndarray):\n",
    "        raise TypeError(\"Input image must be a numpy array.\")\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    reduced_noise_image = cv2.GaussianBlur(image, kernel_size, 0)\n",
    "    \n",
    "    return reduced_noise_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(image, output_path):\n",
    "    \"\"\"\n",
    "    Save an image to the specified file path.\n",
    "\n",
    "    Parameters:\n",
    "    image (numpy.ndarray): The image to be saved, typically a processed image.\n",
    "    output_path (str): The path, including the file name and extension, where the image will be saved.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the image is successfully saved, False otherwise.\n",
    "\n",
    "    Raises:\n",
    "    TypeError: If the input image is not a numpy array or if the output path is not a string.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate the input image type\n",
    "    if not isinstance(image, np.ndarray):\n",
    "        raise TypeError(\"Input image must be a numpy array.\")\n",
    "    \n",
    "    # Validate the output path type\n",
    "    if not isinstance(output_path, str):\n",
    "        raise TypeError(\"Output path must be a string.\")\n",
    "    \n",
    "    # Attempt to save the image to the specified path\n",
    "    success = cv2.imwrite(output_path, image)\n",
    "    \n",
    "    # Return whether the save was successful\n",
    "    return success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_images(image_paths, num_images=10, title=\"Image Preview\"):\n",
    "    \"\"\"\n",
    "    Display a preview of random images from a list of image paths.\n",
    "\n",
    "    Parameters:\n",
    "    image_paths (list of str): A list of file paths to the images that will be previewed.\n",
    "    num_images (int): The number of images to display in the preview. Default is 10.\n",
    "    title (str): The title for the preview images. Default is \"Image Preview\".\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If num_images is less than 1 or if image_paths is empty.\n",
    "    TypeError: If image_paths is not a list or if any element in image_paths is not a string.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate that image_paths is a list of strings\n",
    "    if not isinstance(image_paths, list) or not all(isinstance(p, str) for p in image_paths):\n",
    "        raise TypeError(\"image_paths must be a list of strings.\")\n",
    "    \n",
    "    # Validate that num_images is a positive integer\n",
    "    if num_images < 1:\n",
    "        raise ValueError(\"num_images must be at least 1.\")\n",
    "    \n",
    "    # Validate that there are images to preview\n",
    "    if len(image_paths) == 0:\n",
    "        raise ValueError(\"The image_paths list is empty. There are no images to preview.\")\n",
    "    \n",
    "    # Randomly select images to preview, ensuring no more than the available number of images are selected\n",
    "    selected_images = random.sample(image_paths, min(len(image_paths), num_images))\n",
    "    \n",
    "    # Set up the plot for displaying images\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Loop through the selected images and display each one\n",
    "    for i, image_path in enumerate(selected_images):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
    "        if image is None:\n",
    "            print(f\"Warning: Could not read image {image_path}. Skipping.\")\n",
    "            continue\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title(f\"{title} {i+1}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    # Show the plot with the selected images\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Threshold Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_with_adaptive_threshold(image, block_sizes, C_values):\n",
    "    \"\"\"\n",
    "    Experiment with different block sizes and C values on a single image to determine \n",
    "    the best parameters for adaptive thresholding.\n",
    "\n",
    "    Parameters:\n",
    "    image (numpy.ndarray): The input image in BGR or grayscale format.\n",
    "    block_sizes (list of int): A list of block sizes (odd integers) to be tested for adaptive thresholding.\n",
    "    C_values (list of int): A list of C values to be tested for adaptive thresholding.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If block_sizes and C_values lists are not of the same length, \n",
    "                or if block_sizes contains any even numbers or numbers less than or equal to 1.\n",
    "    TypeError: If image is not a numpy array, or if block_sizes or C_values are not lists of integers.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate the input image type\n",
    "    if not isinstance(image, np.ndarray):\n",
    "        raise TypeError(\"Input image must be a numpy array.\")\n",
    "    \n",
    "    # Validate that block_sizes and C_values are lists of integers and are of the same length\n",
    "    if not (isinstance(block_sizes, list) and isinstance(C_values, list)):\n",
    "        raise TypeError(\"block_sizes and C_values must be lists of integers.\")\n",
    "    \n",
    "    if len(block_sizes) != len(C_values):\n",
    "        raise ValueError(\"block_sizes and C_values must be of the same length.\")\n",
    "    \n",
    "    if not all(isinstance(b, int) and b > 1 and b % 2 != 0 for b in block_sizes):\n",
    "        raise ValueError(\"All block_sizes must be odd integers greater than 1.\")\n",
    "    \n",
    "    if not all(isinstance(C, int) for C in C_values):\n",
    "        raise TypeError(\"All C values must be integers.\")\n",
    "    \n",
    "    # Convert the image to grayscale if it is not already\n",
    "    grayscale_image = convert_to_grayscale(image)\n",
    "    \n",
    "    num_values = len(block_sizes)\n",
    "    cols = 2  # Use 2 columns for displaying the images\n",
    "    rows = math.ceil(num_values / cols)  # Calculate the number of rows needed\n",
    "\n",
    "    plt.figure(figsize=(15, 5 * rows))  # Adjust the figure size based on the number of rows\n",
    "    for i, (block_size, C) in enumerate(zip(block_sizes, C_values)):\n",
    "        # Apply adaptive thresholding with the current block size and C value\n",
    "        threshold_image = cv2.adaptiveThreshold(grayscale_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                                cv2.THRESH_BINARY, block_size, C)\n",
    "        plt.subplot(rows, cols, i + 1)  # Position the subplot\n",
    "        plt.imshow(threshold_image, cmap='gray')  # Display the thresholded image in grayscale\n",
    "        plt.title(f\"blockSize: {block_size}, C: {C}\")  # Title indicating the parameters used\n",
    "        plt.axis('off')  # Hide axis lines and labels\n",
    "    \n",
    "    # Display the figure with all subplots\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process and Save Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_all_images(image_paths, output_folder):\n",
    "    \"\"\"\n",
    "    Process all images in the provided list by enhancing their quality, converting them to grayscale,\n",
    "    applying adaptive thresholding, reducing noise, and saving the results to the specified output folder.\n",
    "\n",
    "    Parameters:\n",
    "    image_paths (list of str): A list of file paths to the images that need to be processed.\n",
    "    output_folder (str): The path to the folder where the processed images will be saved.\n",
    "\n",
    "    Raises:\n",
    "    TypeError: If image_paths is not a list of strings or if output_folder is not a string.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate that image_paths is a list of strings\n",
    "    if not isinstance(image_paths, list) or not all(isinstance(p, str) for p in image_paths):\n",
    "        raise TypeError(\"image_paths must be a list of strings.\")\n",
    "    \n",
    "    # Validate that output_folder is a string\n",
    "    if not isinstance(output_folder, str):\n",
    "        raise TypeError(\"output_folder must be a string.\")\n",
    "    \n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Initialize the progress bar for Jupyter notebook\n",
    "    with tqdm(total=len(image_paths), desc=\"Processing images\", unit=\"image\", ncols=400) as pbar:\n",
    "        for image_path in image_paths:\n",
    "            # Read the image from the file path\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                pbar.write(f\"Warning: Could not read image {image_path}. Skipping.\")\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "            \n",
    "            # Enhance the quality of the image (e.g., reduce noise and sharpen)\n",
    "            enhanced_image = enhance_image_quality(image)\n",
    "            \n",
    "            # Convert the enhanced image to grayscale\n",
    "            grayscale_image = convert_to_grayscale(enhanced_image)\n",
    "            \n",
    "            # Apply adaptive thresholding to the grayscale image\n",
    "            threshold_image = apply_threshold(grayscale_image)\n",
    "            \n",
    "            # Reduce noise after applying the thresholding\n",
    "            final_image = reduce_noise(threshold_image)\n",
    "            \n",
    "            # Construct the output file path and save the processed image\n",
    "            filename, file_extension = os.path.splitext(os.path.basename(image_path))\n",
    "            output_path = os.path.join(output_folder, f\"{filename}_Processed{file_extension}\")\n",
    "\n",
    "            save_image(final_image, output_path)\n",
    "            \n",
    "            # Update the progress bar with additional information\n",
    "            pbar.set_postfix({\"Saved\": output_path})\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all image file paths from the specified folder\n",
    "image_paths = load_images_from_folder(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview Random Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview random images before processing\n",
    "preview_images(image_paths, num_images=5, title=\"Original Image Preview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Thresholding Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_sizes = [11, 13, 15, 13]  # Different block sizes to test for adaptive thresholding\n",
    "C_values = [4, 2, 4, 6]  # Different C values to test for adaptive thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random image by generating a random index within the list of image paths\n",
    "image_index = random.randint(0, len(image_paths) - 1)  # Generate a random index\n",
    "experiment_image = cv2.imread(image_paths[image_index])  # Load the randomly selected image\n",
    "\n",
    "# Experiment with different block sizes and C values for adaptive thresholding\n",
    "experiment_with_adaptive_threshold(experiment_image, block_sizes, C_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processed and Saved Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all images by enhancing quality and applying threshold\n",
    "process_and_save_all_images(image_paths, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Processed Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview processed images\n",
    "processed_image_paths = load_images_from_folder(output_folder)\n",
    "preview_images(processed_image_paths, num_images=5, title=\"Processed Image Preview\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alessandroryo",
   "language": "python",
   "name": "alessandroryo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
