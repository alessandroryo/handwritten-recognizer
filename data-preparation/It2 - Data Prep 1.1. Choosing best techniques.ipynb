{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preparation - IT2 - Choosing |best techniques per step in the flow "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6679ab839dfc599"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6db9fa264159cd5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.033783Z",
     "start_time": "2024-11-19T08:16:55.376784Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the path to the folder containing the images to be processed\n",
    "folder_path = '../data/original'  # Update this path to point to your specific folder containing images\n",
    "\n",
    "# Define the path to the folder where the processed images will be saved\n",
    "output_folder = '../data/processed'  # Update this path to the desired output folder"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.048784Z",
     "start_time": "2024-11-19T08:16:57.035784Z"
    }
   },
   "id": "d0b8bdef35d1e5da",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Images and stats"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a22a19fd22d2b9a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder_path, extensions=('.png', '.jpg', '.jpeg', '.JPG')):\n",
    "    \"\"\"\n",
    "    Load all image file paths from a specified folder that match the given file extensions.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing the images.\n",
    "    extensions (tuple of str): A tuple of file extensions to filter the images by. \n",
    "                               Default is ('.png', '.jpg', '.jpeg', '.JPG').\n",
    "\n",
    "    Returns:\n",
    "    list: A list of full file paths to images in the folder that match the specified extensions.\n",
    "    \n",
    "    Raises:\n",
    "    FileNotFoundError: If the specified folder does not exist.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        raise FileNotFoundError(f\"The specified folder does not exist: {folder_path}\")\n",
    "\n",
    "    # List comprehension to gather all image paths with the specified extensions\n",
    "    image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(extensions)]\n",
    "\n",
    "    return image_paths"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.064784Z",
     "start_time": "2024-11-19T08:16:57.049784Z"
    }
   },
   "id": "703777edb6b6cb6b",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to convert to gray scale\n",
    "def load_and_preprocess_images(image_paths, resize_dim=(256, 256)):\n",
    "    images = []\n",
    "    image_ids = []\n",
    "\n",
    "    # Initialize tqdm progress bar\n",
    "    for path in tqdm(image_paths, desc=\"Loading and preprocessing images\", unit=\"image\"):\n",
    "        img = cv2.imread(path)\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "        img_resized = cv2.resize(img_gray, resize_dim)  # Resize for consistency\n",
    "        images.append(img_resized)\n",
    "        image_ids.append(f'Image_{len(images)}')  # Assign image ID as Image_1, Image_2, etc.\n",
    "\n",
    "    return images, image_ids"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.080784Z",
     "start_time": "2024-11-19T08:16:57.065784Z"
    }
   },
   "id": "8097d12ed08ed95c",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the CSV file with the image statistics\n",
    "images_stats_path = \"../data-understanding/images_stats.csv\"  \n",
    "images_stats_df = pd.read_csv(images_stats_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.112784Z",
     "start_time": "2024-11-19T08:16:57.083788Z"
    }
   },
   "id": "f0024219894c26ef",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Image', 'Brightness', 'Sharpness', 'Contrast', 'Noise', 'Skew',\n       'Line Spacing', 'Tables Detected', 'Resolution', 'Detected Elements',\n       'Texture', 'Patterns'],\n      dtype='object')"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_stats_df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.128786Z",
     "start_time": "2024-11-19T08:16:57.113784Z"
    }
   },
   "id": "db335d32477016cb",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions per step"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12f7addce2a50971"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 1: Noise Reduction Techniques"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cf7d2143725450b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Noise Reduction Functions\n",
    "def apply_gaussian_blur(image, ksize=(5, 5)):\n",
    "    \"\"\"Apply Gaussian Blur to reduce noise with the specified kernel size.\"\"\"\n",
    "    return cv2.GaussianBlur(image, ksize, 0)\n",
    "\n",
    "def apply_median_blur(image, ksize=5):\n",
    "    \"\"\"Apply Median Blur to reduce salt-and-pepper noise with the specified kernel size.\"\"\"\n",
    "    return cv2.medianBlur(image, ksize)\n",
    "\n",
    "def apply_non_local_means(image, h=10, templateWindowSize=7, searchWindowSize=21):\n",
    "    \"\"\"Apply Non-Local Means Denoising with specified parameters.\"\"\"\n",
    "    return cv2.fastNlMeansDenoising(image, None, h, templateWindowSize, searchWindowSize)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.144785Z",
     "start_time": "2024-11-19T08:16:57.130784Z"
    }
   },
   "id": "8fe3ee9d85584a63",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2: Histogram Equalization Techniques"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b6cdd42d07d1c96"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Histogram Equalization Functions\n",
    "def apply_histogram_equalization(image):\n",
    "    return cv2.equalizeHist(image)\n",
    "\n",
    "def apply_clahe(image, clipLimit=2.0, tileGridSize=(8, 8)):\n",
    "    \"\"\"Apply CLAHE to enhance image contrast with specified parameters.\"\"\"\n",
    "    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n",
    "    return clahe.apply(image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.160784Z",
     "start_time": "2024-11-19T08:16:57.146787Z"
    }
   },
   "id": "44c99f9c5258c6f3",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3: Binarization Techniques"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29e647d0a546cb82"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Binarization Functions\n",
    "def apply_global_threshold(image, thresholdValue=127):\n",
    "    \"\"\"Apply Global Thresholding with the specified threshold value.\"\"\"\n",
    "    _, binary_image = cv2.threshold(image, thresholdValue, 255, cv2.THRESH_BINARY)\n",
    "    return binary_image\n",
    "\n",
    "def apply_adaptive_threshold(image, adaptiveMethod=cv2.ADAPTIVE_THRESH_MEAN_C, blockSize=11, C=2):\n",
    "    \"\"\"Apply Adaptive Thresholding with the specified method, block size, and constant C.\"\"\"\n",
    "    return cv2.adaptiveThreshold(image, 255, adaptiveMethod, cv2.THRESH_BINARY, blockSize, C)\n",
    "\n",
    "def apply_otsu_threshold(image):\n",
    "    \"\"\"Apply Otsu Thresholding.\"\"\"\n",
    "    _, binary_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return binary_image\n",
    "\n",
    "def apply_inverted_otsu_threshold(image):\n",
    "    \"\"\"Apply Inverted Otsu Thresholding.\"\"\"\n",
    "    _, binary_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    return binary_image\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.176784Z",
     "start_time": "2024-11-19T08:16:57.162784Z"
    }
   },
   "id": "3b2691be436fc225",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 4: Morphological Operations Techniques"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3c7a336f8c8b717"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Morphological Operations Functions\n",
    "def apply_dilation(image, kernel_size=(5, 5)):\n",
    "    \"\"\"Apply Dilation with the specified kernel size.\"\"\"\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations=1)\n",
    "\n",
    "def apply_erosion(image, kernel_size=(5, 5)):\n",
    "    \"\"\"Apply Erosion with the specified kernel size.\"\"\"\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations=1)\n",
    "\n",
    "def apply_opening(image, kernel_size=(5, 5)):\n",
    "    \"\"\"Apply Morphological Opening with the specified kernel size.\"\"\"\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "def apply_closing(image, kernel_size=(5, 5)):\n",
    "    \"\"\"Apply Morphological Closing with the specified kernel size.\"\"\"\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.192786Z",
     "start_time": "2024-11-19T08:16:57.177784Z"
    }
   },
   "id": "da08a64db428ad4a",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 5: Edge Detection Techniques"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5596f364429dda1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Edge Detection Functions\n",
    "def apply_canny_edge(image, threshold1=50, threshold2=150):\n",
    "    \"\"\"Apply Canny Edge Detection with specified thresholds.\"\"\"\n",
    "    return cv2.Canny(image, threshold1, threshold2)\n",
    "\n",
    "def apply_sobel_edge(image, ksize=3, scale=1, delta=0, borderType=cv2.BORDER_DEFAULT):\n",
    "    \"\"\"Apply Sobel Edge Detection with specified parameters.\"\"\"\n",
    "    return cv2.Sobel(image, cv2.CV_64F, 1, 1, ksize=ksize, scale=scale, delta=delta, borderType=borderType)\n",
    "\n",
    "def apply_unsharp_masking(image, amount=1.5, kernel_size=(0, 0)):\n",
    "    \"\"\"Apply Unsharp Masking to sharpen the image.\"\"\"\n",
    "    blurred = cv2.GaussianBlur(image, kernel_size, 0)\n",
    "    sharpened = cv2.addWeighted(image, 1 + amount, blurred, -amount, 0)\n",
    "    return sharpened"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.208784Z",
     "start_time": "2024-11-19T08:16:57.193784Z"
    }
   },
   "id": "76e5c83f8a5c9bc8",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Characteristics Calculation for testing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e79e5c4a578b19f5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Image Characteristics Calculation Functions - from data understanding it2\n",
    "def calculate_brightness(image):\n",
    "    return np.mean(image)\n",
    "\n",
    "def calculate_sharpness(image):\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\n",
    "def calculate_contrast(image):\n",
    "    return image.std()\n",
    "\n",
    "def calculate_noise(image):\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    noise = cv2.absdiff(image, blurred)\n",
    "    return np.var(noise)\n",
    "\n",
    "# def calculate_skew(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "#     _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "#     coords = np.column_stack(np.where(binary > 0))\n",
    "#     if coords.size == 0:\n",
    "#         return 0\n",
    "#     angle = cv2.minAreaRect(coords)[-1]\n",
    "#     if angle < -45:\n",
    "#         angle = -(90 + angle)\n",
    "#     else:\n",
    "#         angle = -angle\n",
    "#     if abs(angle) < 1e-2:\n",
    "#         angle = 0\n",
    "#     return round(angle, 2)\n",
    "# \n",
    "# def calculate_line_spacing(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "#     _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "#     contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     heights = [cv2.boundingRect(contour)[3] for contour in contours]\n",
    "#     if len(heights) > 1:\n",
    "#         line_spacing = np.mean(np.diff(sorted(heights)))\n",
    "#     else:\n",
    "#         line_spacing = 0\n",
    "#     return line_spacing\n",
    "# \n",
    "# def detect_tables(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "#     _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "#     binary = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "#     contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     table_contours = [contour for contour in contours if cv2.contourArea(contour) > 1000]\n",
    "#     return len(table_contours)\n",
    "# \n",
    "# def calculate_resolution(image):\n",
    "#     height, width = image.shape[:2]\n",
    "#     return height * width\n",
    "# \n",
    "# def calculate_elements_detection(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "#     _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "#     contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     return len(contours)\n",
    "# \n",
    "# def calculate_texture(image):\n",
    "#     laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "#     return laplacian.std()\n",
    "# \n",
    "# def calculate_patterns(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "#     edges = cv2.Canny(image, 100, 200)\n",
    "#     return np.sum(edges > 0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.224783Z",
     "start_time": "2024-11-19T08:16:57.209784Z"
    }
   },
   "id": "aec243807f00da68",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation per step"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "203cff1e1647315b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Function of evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6dafdc80cafbb5f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Basic Evaluation Function\n",
    "# -------------------------\n",
    "# def basic_evaluation(image, techniques_dict, original_stats):\n",
    "#     evaluation_results = {}\n",
    "#     for technique_name, technique_func in techniques_dict.items():\n",
    "#         processed_image = technique_func(image)\n",
    "#         stats = {\n",
    "#             \"Brightness\": calculate_brightness(processed_image),\n",
    "#             \"Sharpness\": calculate_sharpness(processed_image),\n",
    "#             \"Contrast\": calculate_contrast(processed_image),\n",
    "#             \"Noise\": calculate_noise(processed_image)\n",
    "#         }\n",
    "# \n",
    "#         # Basic scoring function - prioritizing sharpness, contrast, and minimized noise\n",
    "#         score = stats[\"Sharpness\"] + stats[\"Contrast\"] - stats[\"Noise\"]\n",
    "#         evaluation_results[technique_name] = {\"Score\": score, \"Stats\": stats}\n",
    "# \n",
    "#     best_technique = max(evaluation_results, key=lambda x: evaluation_results[x][\"Score\"])\n",
    "#     return {\"Best Technique\": best_technique, \"Evaluation Results\": evaluation_results}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.240784Z",
     "start_time": "2024-11-19T08:16:57.226786Z"
    }
   },
   "id": "ce72107041cb13b3",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def advanced_evaluation(image, techniques_dict, original_stats):\n",
    "#     evaluation_results = {}\n",
    "# \n",
    "#     for technique_name, technique_func in techniques_dict.items():\n",
    "#         # Apply the technique\n",
    "#         processed_image = technique_func(image)\n",
    "# \n",
    "#         # Calculate characteristics for the processed image\n",
    "#         stats = {\n",
    "#             \"Brightness\": calculate_brightness(processed_image),\n",
    "#             \"Sharpness\": calculate_sharpness(processed_image),\n",
    "#             \"Contrast\": calculate_contrast(processed_image),\n",
    "#             \"Noise\": calculate_noise(processed_image),\n",
    "#             \"Skew\": calculate_skew(processed_image),\n",
    "#             \"Line Spacing\": calculate_line_spacing(processed_image),\n",
    "#             \"Tables Detected\": detect_tables(processed_image),\n",
    "#             \"Resolution\": calculate_resolution(processed_image),\n",
    "#             \"Detected Elements\": calculate_elements_detection(processed_image),\n",
    "#             \"Texture\": calculate_texture(processed_image),\n",
    "#             \"Patterns\": calculate_patterns(processed_image)\n",
    "#         }\n",
    "# \n",
    "#         # Normalize metrics to comparable ranges (between 0 and 1, roughly)\n",
    "#         stats_normalized = {\n",
    "#             \"Brightness\": stats[\"Brightness\"] / 255,\n",
    "#             \"Sharpness\": stats[\"Sharpness\"] / 1000,\n",
    "#             \"Contrast\": stats[\"Contrast\"] / 255,\n",
    "#             \"Noise\": stats[\"Noise\"] / 255,\n",
    "#             \"Skew\": stats[\"Skew\"] / 45,\n",
    "#             \"Line Spacing\": stats[\"Line Spacing\"] / 100,\n",
    "#             \"Tables Detected\": stats[\"Tables Detected\"] / 10,\n",
    "#             \"Resolution\": stats[\"Resolution\"] / (512 * 512),\n",
    "#             \"Detected Elements\": stats[\"Detected Elements\"] / 100,\n",
    "#             \"Texture\": stats[\"Texture\"] / 100,\n",
    "#             \"Patterns\": stats[\"Patterns\"] / 1000\n",
    "#         }\n",
    "# \n",
    "#         # Normalize the original stats for comparison\n",
    "#         original_stats_normalized = {\n",
    "#             \"Brightness\": original_stats[\"Brightness\"] / 255,\n",
    "#             \"Sharpness\": original_stats[\"Sharpness\"] / 1000,\n",
    "#             \"Contrast\": original_stats[\"Contrast\"] / 255,\n",
    "#             \"Noise\": original_stats[\"Noise\"] / 255,\n",
    "#             \"Skew\": original_stats[\"Skew\"] / 45,\n",
    "#             \"Line Spacing\": original_stats[\"Line Spacing\"] / 100,\n",
    "#             \"Tables Detected\": original_stats[\"Tables Detected\"] / 10,\n",
    "#             \"Resolution\": original_stats[\"Resolution\"] / (512 * 512),\n",
    "#             \"Detected Elements\": original_stats[\"Detected Elements\"] / 100,\n",
    "#             \"Texture\": original_stats[\"Texture\"] / 100,\n",
    "#             \"Patterns\": original_stats[\"Patterns\"] / 1000\n",
    "#         }\n",
    "# \n",
    "#         # Weights for each characteristic (to determine their importance)\n",
    "#         weights = {\n",
    "#             \"Brightness\": -1.0,  # Closer to original is better (penalized if different)\n",
    "#             \"Sharpness\": 2.0,    # Higher is better (rewarded if improved)\n",
    "#             \"Contrast\": 1.0,     # Higher is better (rewarded if improved)\n",
    "#             \"Noise\": -1.5,       # Lower is better (penalized if increased)\n",
    "#             \"Skew\": -0.5,        # Closer to original is better (penalized if different)\n",
    "#             \"Line Spacing\": -0.5,  # Closer to original is better (penalized if different)\n",
    "#             \"Tables Detected\": 1.0,  # More tables detected is better\n",
    "#             \"Resolution\": 1.0,    # Higher is better\n",
    "#             \"Detected Elements\": 1.0,  # More elements detected is better\n",
    "#             \"Texture\": 1.0,       # Higher texture complexity is better\n",
    "#             \"Patterns\": 1.0       # More patterns detected is better\n",
    "#         }\n",
    "# \n",
    "#         # Calculate score using normalized metrics and weights\n",
    "#         score = 0\n",
    "#         for metric, value in stats_normalized.items():\n",
    "#             original_value = original_stats_normalized.get(metric, 0)\n",
    "#             score += weights[metric] * (value - original_value)\n",
    "# \n",
    "#         evaluation_results[technique_name] = {\"Score\": score, \"Stats\": stats}\n",
    "# \n",
    "#     # Determine the best technique based on the highest score\n",
    "#     best_technique = max(evaluation_results, key=lambda x: evaluation_results[x][\"Score\"])\n",
    "#     return {\"Best Technique\": best_technique, \"Evaluation Results\": evaluation_results}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.255784Z",
     "start_time": "2024-11-19T08:16:57.244783Z"
    }
   },
   "id": "3067606c27e5a0cd",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Normalization Process\n",
    "\n",
    "**Normalization** is crucial for ensuring that the values of different characteristics (`Brightness`, `Sharpness`, `Contrast`, `Noise`) are on a similar scale. Without normalization, these characteristics might have vastly different ranges, which could skew the evaluation. Here's what happens in the function:\n",
    "\n",
    "1. **Brightness Normalization**:\n",
    "   - The brightness of an image is typically represented on a scale from 0 to 255 (as an 8-bit grayscale value).\n",
    "   - To normalize brightness, we divide it by 255, which brings its range between 0 and 1.\n",
    "\n",
    "2. **Sharpness Normalization**:\n",
    "   - Sharpness is measured as the variance of the Laplacian, which often has larger values than brightness.\n",
    "   - Dividing by `1000` helps normalize it to roughly between 0 and 1. The choice of `1000` is made to ensure that sharpness values are comparable to the other metrics.\n",
    "\n",
    "3. **Contrast Normalization**:\n",
    "   - Contrast is calculated using the standard deviation of pixel values, which usually falls between 0 and 255 for 8-bit images.\n",
    "   - Dividing by 255 brings contrast into the range between 0 and 1.\n",
    "\n",
    "4. **Noise Normalization**:\n",
    "   - The noise measure is the variance of the difference between the original and a blurred version of the image.\n",
    "   - Dividing by 255 brings it to a similar range as the other characteristics, ensuring comparability.\n",
    "\n",
    "By normalizing all metrics to a range between 0 and 1, we ensure that each characteristic has equal weight in the evaluation, preventing one metric from dominating due to a larger numeric range.\n",
    "\n",
    "##### Scoring Calculation\n",
    "\n",
    "Once all metrics are normalized, a score is calculated to determine how well the processed image improves compared to the original. Here's the breakdown of the scoring process:\n",
    "\n",
    "1. **Weights for Characteristics**:\n",
    "   - We assign **weights** to each metric based on its importance:\n",
    "     - **Brightness**: Weight of `-1.0` means that deviation from the original value is penalized.\n",
    "     - **Sharpness**: Weight of `2.0` rewards increased sharpness.\n",
    "     - **Contrast**: Weight of `1.0` rewards increased contrast.\n",
    "     - **Noise**: Weight of `-1.5` penalizes increased noise.\n",
    "\n",
    "2. **Score Calculation**:\n",
    "   - The difference between the normalized processed value and the normalized original value is multiplied by the respective weight.\n",
    "   - If a **positively weighted metric** (like sharpness or contrast) **improves**, it contributes positively to the score.\n",
    "   - If a **negatively weighted metric** (like noise or brightness deviation) **increases**, it contributes negatively, penalizing the score.\n",
    "\n",
    "3. **Best Technique Selection**:\n",
    "   - After calculating the score for each technique, the function selects the one with the **highest score**.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14621ade3e0e3283"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def advanced_evaluation(image, techniques_dict, original_stats):\n",
    "    evaluation_results = {}\n",
    "\n",
    "    for technique_name, technique_func in techniques_dict.items():\n",
    "        # Apply the technique\n",
    "        processed_image = technique_func(image)\n",
    "\n",
    "        # Calculate characteristics for the processed image\n",
    "        stats = {\n",
    "            \"Brightness\": calculate_brightness(processed_image),\n",
    "            \"Sharpness\": calculate_sharpness(processed_image),\n",
    "            \"Contrast\": calculate_contrast(processed_image),\n",
    "            \"Noise\": calculate_noise(processed_image),\n",
    "        }\n",
    "\n",
    "        # Normalize metrics to comparable ranges (between 0 and 1, roughly)\n",
    "        stats_normalized = {\n",
    "            \"Brightness\": stats[\"Brightness\"] / 255,\n",
    "            \"Sharpness\": stats[\"Sharpness\"] / 1000,\n",
    "            \"Contrast\": stats[\"Contrast\"] / 255,\n",
    "            \"Noise\": stats[\"Noise\"] / 255,\n",
    "        }\n",
    "\n",
    "        # Normalize the original stats for comparison\n",
    "        original_stats_normalized = {\n",
    "            \"Brightness\": original_stats[\"Brightness\"] / 255,\n",
    "            \"Sharpness\": original_stats[\"Sharpness\"] / 1000,\n",
    "            \"Contrast\": original_stats[\"Contrast\"] / 255,\n",
    "            \"Noise\": original_stats[\"Noise\"] / 255,\n",
    "        }\n",
    "\n",
    "        # Weights for each characteristic (to determine their importance)\n",
    "        weights = {\n",
    "            \"Brightness\": -1.0,  # Closer to original is better (penalized if different) as they were in a good level before\n",
    "            \"Sharpness\": 2.0,    # Higher is better (rewarded if improved)\n",
    "            \"Contrast\": 1.0,     # Higher is better (rewarded if improved)\n",
    "            \"Noise\": -1.5,       # Lower is better (penalized if increased)\n",
    "        }\n",
    "\n",
    "        # Calculate score using normalized metrics and weights\n",
    "        score = 0\n",
    "        for metric, value in stats_normalized.items():\n",
    "            original_value = original_stats_normalized.get(metric, 0)\n",
    "            score += weights[metric] * (value - original_value)\n",
    "\n",
    "        evaluation_results[technique_name] = {\"Score\": score, \"Stats\": stats}\n",
    "\n",
    "    # Determine the best technique based on the highest score\n",
    "    best_technique = max(evaluation_results, key=lambda x: evaluation_results[x][\"Score\"])\n",
    "    return {\"Best Technique\": best_technique, \"Evaluation Results\": evaluation_results}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.270785Z",
     "start_time": "2024-11-19T08:16:57.257786Z"
    }
   },
   "id": "6bf4a8b130aa7d7f",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function for Each Step testing\n",
    "def run_step(step_name, techniques_dict, test_images, test_image_ids, best_techniques_list):\n",
    "    print(f\"\\nRunning Step: {step_name}\\n{'-' * 40}\")\n",
    "    all_results = []\n",
    "    for img, img_id in zip(test_images, test_image_ids):\n",
    "        # Retrieve original stats from the dataset\n",
    "        original_stats = images_stats_df[images_stats_df['Image'] == img_id].iloc[0].to_dict()\n",
    "\n",
    "        step_result = advanced_evaluation(img, techniques_dict,original_stats)\n",
    "        all_results.append((img_id, original_stats, step_result))\n",
    "        print(f\"Best Technique for {img_id}: {step_result['Best Technique']}\")\n",
    "\n",
    "    # Generate Comparison Table\n",
    "    comparison_data = []\n",
    "    for img_id, original_stats, result in all_results:\n",
    "        # Add original stats row\n",
    "        comparison_data.append([img_id, \"Original\"] + list(original_stats.values())[1:])  # Skip the 'Image' key\n",
    "        # Add each technique's stats\n",
    "        for technique, metrics in result[\"Evaluation Results\"].items():\n",
    "            comparison_data.append([img_id, f\"{step_name} - {technique}\"] + list(metrics[\"Stats\"].values()))\n",
    "\n",
    "    comparison_df = pd.DataFrame(comparison_data, columns=[\"Image_ID\", \"Technique\", \"Brightness\", \"Sharpness\", \"Contrast\", \"Noise\", \"Skew\", \"Line Spacing\", \"Tables Detected\", \"Resolution\", \"Detected Elements\", \"Texture\", \"Patterns\"])\n",
    "\n",
    "    # Generate Recommendation\n",
    "    recommended_technique_name = max(all_results, key=lambda x: x[2][\"Evaluation Results\"][x[2][\"Best Technique\"]][\"Score\"])[2][\"Best Technique\"]\n",
    "    recommended_technique_func = techniques_dict[recommended_technique_name]\n",
    "    print(f\"\\nRecommended Technique for {step_name}: {recommended_technique_name}\\n\")\n",
    "\n",
    "    # Append both technique name and function for further tuning\n",
    "    best_techniques_list.append((step_name, recommended_technique_name, recommended_technique_func))\n",
    "\n",
    "    # Return the comparison DataFrame\n",
    "    return comparison_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.286783Z",
     "start_time": "2024-11-19T08:16:57.272784Z"
    }
   },
   "id": "a9dcfaa1991f5e3a",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Running Different Techniques per Step"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5473417fb6fc8aff"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing images: 100%|██████████| 698/698 [03:13<00:00,  3.61image/s]\n"
     ]
    }
   ],
   "source": [
    "# Load all image file paths from the specified folder\n",
    "image_paths_all = load_images_from_folder(folder_path)\n",
    "\n",
    "# Load and preprocess all images\n",
    "total_images, total_image_ids = load_and_preprocess_images(image_paths_all)\n",
    "\n",
    "# Randomly select 5 images for experimentation\n",
    "experiment_indices = random.sample(range(len(total_images)), 5)\n",
    "test_images = [total_images[i] for i in experiment_indices]\n",
    "test_image_ids = [total_image_ids[i] for i in experiment_indices]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:20:10.697656Z",
     "start_time": "2024-11-19T08:16:57.288784Z"
    }
   },
   "id": "5c3b64a356573a62",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_techniques_list = []\n",
    "comparison_tables = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:20:10.713653Z",
     "start_time": "2024-11-19T08:20:10.700673Z"
    }
   },
   "id": "5d321de124a8f61b",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Step: Noise Reduction\n",
      "----------------------------------------\n",
      "Best Technique for Image_690: Non-Local Means\n",
      "Best Technique for Image_151: Non-Local Means\n",
      "Best Technique for Image_358: Non-Local Means\n",
      "Best Technique for Image_578: Non-Local Means\n",
      "Best Technique for Image_546: Non-Local Means\n",
      "\n",
      "Recommended Technique for Noise Reduction: Non-Local Means\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Noise Reduction\n",
    "noise_reduction_techniques = {\n",
    "    \"Gaussian Blur\": lambda img: cv2.GaussianBlur(img, (5, 5), 0),\n",
    "    \"Median Blur\": lambda img: cv2.medianBlur(img, 5),\n",
    "    \"Non-Local Means\": lambda img: cv2.fastNlMeansDenoising(img, None, 10, 7, 21)\n",
    "}\n",
    "comparison_tables.append(run_step(\"Noise Reduction\", noise_reduction_techniques, test_images, test_image_ids, best_techniques_list))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:20:11.455654Z",
     "start_time": "2024-11-19T08:20:10.715668Z"
    }
   },
   "id": "1272df62648886a8",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Step: Histogram Equalization\n",
      "----------------------------------------\n",
      "Best Technique for Image_690: Histogram Equalization\n",
      "Best Technique for Image_151: Histogram Equalization\n",
      "Best Technique for Image_358: Histogram Equalization\n",
      "Best Technique for Image_578: Histogram Equalization\n",
      "Best Technique for Image_546: Histogram Equalization\n",
      "\n",
      "Recommended Technique for Histogram Equalization: Histogram Equalization\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Histogram Equalization\n",
    "histogram_equalization_techniques = {\n",
    "    \"Histogram Equalization\": lambda img: cv2.equalizeHist(img),\n",
    "    \"CLAHE\": lambda img: cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(img)\n",
    "}\n",
    "comparison_tables.append(run_step(\"Histogram Equalization\", histogram_equalization_techniques, test_images, test_image_ids, best_techniques_list))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:20:11.487653Z",
     "start_time": "2024-11-19T08:20:11.457676Z"
    }
   },
   "id": "b5ef0203d606d09a",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Step: Binarization\n",
      "----------------------------------------\n",
      "Best Technique for Image_690: Adaptive Threshold\n",
      "Best Technique for Image_151: Adaptive Threshold\n",
      "Best Technique for Image_358: Adaptive Threshold\n",
      "Best Technique for Image_578: Adaptive Threshold\n",
      "Best Technique for Image_546: Adaptive Threshold\n",
      "\n",
      "Recommended Technique for Binarization: Adaptive Threshold\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Binarization\n",
    "binarization_techniques = {\n",
    "    \"Global Threshold\": lambda img: cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)[1],\n",
    "    \"Adaptive Threshold\": lambda img: cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2),\n",
    "    \"Otsu Threshold\": lambda img: cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1],\n",
    "    \"Inverted Otsu Threshold\": lambda img: cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "}\n",
    "comparison_tables.append(run_step(\"Binarization\", binarization_techniques, test_images, test_image_ids, best_techniques_list))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:20:11.535656Z",
     "start_time": "2024-11-19T08:20:11.489654Z"
    }
   },
   "id": "a68616ef9a33f67d",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Step: Morphological Operations\n",
      "----------------------------------------\n",
      "Best Technique for Image_690: Erosion\n",
      "Best Technique for Image_151: Erosion\n",
      "Best Technique for Image_358: Erosion\n",
      "Best Technique for Image_578: Erosion\n",
      "Best Technique for Image_546: Erosion\n",
      "\n",
      "Recommended Technique for Morphological Operations: Erosion\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Morphological Operations\n",
    "morphological_operations_techniques = {\n",
    "    \"Dilation\": lambda img: cv2.dilate(img, np.ones((5, 5), np.uint8), iterations=1),\n",
    "    \"Erosion\": lambda img: cv2.erode(img, np.ones((5, 5), np.uint8), iterations=1),\n",
    "    \"Opening\": lambda img: cv2.morphologyEx(img, cv2.MORPH_OPEN, np.ones((5, 5), np.uint8)),\n",
    "    \"Closing\": lambda img: cv2.morphologyEx(img, cv2.MORPH_CLOSE, np.ones((5, 5), np.uint8))\n",
    "}\n",
    "comparison_tables.append(run_step(\"Morphological Operations\", morphological_operations_techniques, test_images, test_image_ids, best_techniques_list))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:20:11.583656Z",
     "start_time": "2024-11-19T08:20:11.536667Z"
    }
   },
   "id": "8a8bf5b17df76bee",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Step: Edge Detection\n",
      "----------------------------------------\n",
      "Best Technique for Image_690: Canny Edge\n",
      "Best Technique for Image_151: Canny Edge\n",
      "Best Technique for Image_358: Canny Edge\n",
      "Best Technique for Image_578: Canny Edge\n",
      "Best Technique for Image_546: Canny Edge\n",
      "\n",
      "Recommended Technique for Edge Detection: Canny Edge\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Edge Detection\n",
    "edge_detection_techniques = {\n",
    "    \"Canny Edge\": lambda img: cv2.Canny(img, 100, 200),\n",
    "    \"Sobel Edge\": lambda img: cv2.convertScaleAbs(cv2.Sobel(img, cv2.CV_64F, 1, 1, ksize=3)),\n",
    "    \"Unsharp Mask\": lambda img: cv2.addWeighted(img, 1.5, cv2.GaussianBlur(img, (0, 0), 3), -0.5, 0)\n",
    "}\n",
    "comparison_tables.append(run_step(\"Edge Detection\", edge_detection_techniques, test_images, test_image_ids, best_techniques_list))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:20:11.631652Z",
     "start_time": "2024-11-19T08:20:11.584655Z"
    }
   },
   "id": "7e47a9227209a883",
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Final best techniques per step"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8439513ab9cfdf06"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Techniques for Each Step:\n",
      "Noise Reduction: Non-Local Means\n",
      "Histogram Equalization: Histogram Equalization\n",
      "Binarization: Adaptive Threshold\n",
      "Morphological Operations: Erosion\n",
      "Edge Detection: Canny Edge\n"
     ]
    }
   ],
   "source": [
    "# Print the list of best techniques for each step\n",
    "print(\"\\nBest Techniques for Each Step:\")\n",
    "for step, technique_name, technique_func in best_techniques_list:\n",
    "    print(f\"{step}: {technique_name}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:20:11.647652Z",
     "start_time": "2024-11-19T08:20:11.632653Z"
    }
   },
   "id": "7264edc32f3787a",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for i, comparison_df in enumerate(comparison_tables):\n",
    "    comparison_df.to_csv(f\"comparison tables/comparison_table_step_{i+1}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:20:11.679666Z",
     "start_time": "2024-11-19T08:20:11.648653Z"
    }
   },
   "id": "a8b12bb0b5a2f14c",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table for Step 1:\n"
     ]
    },
    {
     "data": {
      "text/plain": "    Image_ID                          Technique  Brightness    Sharpness  \\\n0  Image_690                           Original   95.739700  1399.912185   \n1  Image_690    Noise Reduction - Gaussian Blur   95.740021    25.729243   \n2  Image_690      Noise Reduction - Median Blur   97.373520   101.285416   \n3  Image_690  Noise Reduction - Non-Local Means   96.104416   621.201584   \n4  Image_151                           Original  108.298706   944.638775   \n\n    Contrast      Noise  Skew  Line Spacing  Tables Detected  Resolution  \\\n0  50.254875  44.090835 -90.0      2.833333              2.0     65536.0   \n1  48.871518   1.122483   NaN           NaN              NaN         NaN   \n2  49.950030   5.172836   NaN           NaN              NaN         NaN   \n3  49.857048  26.952520   NaN           NaN              NaN         NaN   \n4  42.713477  32.509702 -90.0      0.000000              1.0     65536.0   \n\n   Detected Elements    Texture  Patterns  \n0               91.0  37.415400    4754.0  \n1                NaN        NaN       NaN  \n2                NaN        NaN       NaN  \n3                NaN        NaN       NaN  \n4                1.0  30.734976    3200.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_ID</th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n      <th>Skew</th>\n      <th>Line Spacing</th>\n      <th>Tables Detected</th>\n      <th>Resolution</th>\n      <th>Detected Elements</th>\n      <th>Texture</th>\n      <th>Patterns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_690</td>\n      <td>Original</td>\n      <td>95.739700</td>\n      <td>1399.912185</td>\n      <td>50.254875</td>\n      <td>44.090835</td>\n      <td>-90.0</td>\n      <td>2.833333</td>\n      <td>2.0</td>\n      <td>65536.0</td>\n      <td>91.0</td>\n      <td>37.415400</td>\n      <td>4754.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_690</td>\n      <td>Noise Reduction - Gaussian Blur</td>\n      <td>95.740021</td>\n      <td>25.729243</td>\n      <td>48.871518</td>\n      <td>1.122483</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_690</td>\n      <td>Noise Reduction - Median Blur</td>\n      <td>97.373520</td>\n      <td>101.285416</td>\n      <td>49.950030</td>\n      <td>5.172836</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_690</td>\n      <td>Noise Reduction - Non-Local Means</td>\n      <td>96.104416</td>\n      <td>621.201584</td>\n      <td>49.857048</td>\n      <td>26.952520</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_151</td>\n      <td>Original</td>\n      <td>108.298706</td>\n      <td>944.638775</td>\n      <td>42.713477</td>\n      <td>32.509702</td>\n      <td>-90.0</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>65536.0</td>\n      <td>1.0</td>\n      <td>30.734976</td>\n      <td>3200.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table for Step 2:\n"
     ]
    },
    {
     "data": {
      "text/plain": "    Image_ID                                        Technique  Brightness  \\\n0  Image_690                                         Original   95.739700   \n1  Image_690  Histogram Equalization - Histogram Equalization  128.691757   \n2  Image_690                   Histogram Equalization - CLAHE  114.178329   \n3  Image_151                                         Original  108.298706   \n4  Image_151  Histogram Equalization - Histogram Equalization  129.763214   \n\n     Sharpness   Contrast       Noise  Skew  Line Spacing  Tables Detected  \\\n0  1399.912185  50.254875   44.090835 -90.0      2.833333              2.0   \n1  3721.812831  73.488796  102.422597   NaN           NaN              NaN   \n2  3236.298742  53.423689   83.468484   NaN           NaN              NaN   \n3   944.638775  42.713477   32.509702 -90.0      0.000000              1.0   \n4  4829.863844  74.248876  131.088958   NaN           NaN              NaN   \n\n   Resolution  Detected Elements    Texture  Patterns  \n0     65536.0               91.0  37.415400    4754.0  \n1         NaN                NaN        NaN       NaN  \n2         NaN                NaN        NaN       NaN  \n3     65536.0                1.0  30.734976    3200.0  \n4         NaN                NaN        NaN       NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_ID</th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n      <th>Skew</th>\n      <th>Line Spacing</th>\n      <th>Tables Detected</th>\n      <th>Resolution</th>\n      <th>Detected Elements</th>\n      <th>Texture</th>\n      <th>Patterns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_690</td>\n      <td>Original</td>\n      <td>95.739700</td>\n      <td>1399.912185</td>\n      <td>50.254875</td>\n      <td>44.090835</td>\n      <td>-90.0</td>\n      <td>2.833333</td>\n      <td>2.0</td>\n      <td>65536.0</td>\n      <td>91.0</td>\n      <td>37.415400</td>\n      <td>4754.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_690</td>\n      <td>Histogram Equalization - Histogram Equalization</td>\n      <td>128.691757</td>\n      <td>3721.812831</td>\n      <td>73.488796</td>\n      <td>102.422597</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_690</td>\n      <td>Histogram Equalization - CLAHE</td>\n      <td>114.178329</td>\n      <td>3236.298742</td>\n      <td>53.423689</td>\n      <td>83.468484</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_151</td>\n      <td>Original</td>\n      <td>108.298706</td>\n      <td>944.638775</td>\n      <td>42.713477</td>\n      <td>32.509702</td>\n      <td>-90.0</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>65536.0</td>\n      <td>1.0</td>\n      <td>30.734976</td>\n      <td>3200.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_151</td>\n      <td>Histogram Equalization - Histogram Equalization</td>\n      <td>129.763214</td>\n      <td>4829.863844</td>\n      <td>74.248876</td>\n      <td>131.088958</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table for Step 3:\n"
     ]
    },
    {
     "data": {
      "text/plain": "    Image_ID                               Technique  Brightness  \\\n0  Image_690                                Original   95.739700   \n1  Image_690         Binarization - Global Threshold   90.064774   \n2  Image_690       Binarization - Adaptive Threshold  188.615799   \n3  Image_690           Binarization - Otsu Threshold  168.028564   \n4  Image_690  Binarization - Inverted Otsu Threshold   86.971436   \n\n       Sharpness    Contrast        Noise  Skew  Line Spacing  \\\n0    1399.912185   50.254875    44.090835 -90.0      2.833333   \n1   31350.630191  121.880490  1023.297722   NaN           NaN   \n2  158213.635930  111.897762  2542.838376   NaN           NaN   \n3   21434.556183  120.887077   758.319225   NaN           NaN   \n4   21434.556183  120.887077   757.182218   NaN           NaN   \n\n   Tables Detected  Resolution  Detected Elements  Texture  Patterns  \n0              2.0     65536.0               91.0  37.4154    4754.0  \n1              NaN         NaN                NaN      NaN       NaN  \n2              NaN         NaN                NaN      NaN       NaN  \n3              NaN         NaN                NaN      NaN       NaN  \n4              NaN         NaN                NaN      NaN       NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_ID</th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n      <th>Skew</th>\n      <th>Line Spacing</th>\n      <th>Tables Detected</th>\n      <th>Resolution</th>\n      <th>Detected Elements</th>\n      <th>Texture</th>\n      <th>Patterns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_690</td>\n      <td>Original</td>\n      <td>95.739700</td>\n      <td>1399.912185</td>\n      <td>50.254875</td>\n      <td>44.090835</td>\n      <td>-90.0</td>\n      <td>2.833333</td>\n      <td>2.0</td>\n      <td>65536.0</td>\n      <td>91.0</td>\n      <td>37.4154</td>\n      <td>4754.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_690</td>\n      <td>Binarization - Global Threshold</td>\n      <td>90.064774</td>\n      <td>31350.630191</td>\n      <td>121.880490</td>\n      <td>1023.297722</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_690</td>\n      <td>Binarization - Adaptive Threshold</td>\n      <td>188.615799</td>\n      <td>158213.635930</td>\n      <td>111.897762</td>\n      <td>2542.838376</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_690</td>\n      <td>Binarization - Otsu Threshold</td>\n      <td>168.028564</td>\n      <td>21434.556183</td>\n      <td>120.887077</td>\n      <td>758.319225</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_690</td>\n      <td>Binarization - Inverted Otsu Threshold</td>\n      <td>86.971436</td>\n      <td>21434.556183</td>\n      <td>120.887077</td>\n      <td>757.182218</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table for Step 4:\n"
     ]
    },
    {
     "data": {
      "text/plain": "    Image_ID                            Technique  Brightness    Sharpness  \\\n0  Image_690                             Original   95.739700  1399.912185   \n1  Image_690  Morphological Operations - Dilation  106.936340   153.574488   \n2  Image_690   Morphological Operations - Erosion   74.356354   765.695244   \n3  Image_690   Morphological Operations - Opening   89.443726   690.886814   \n4  Image_690   Morphological Operations - Closing  101.178070   138.299262   \n\n    Contrast      Noise  Skew  Line Spacing  Tables Detected  Resolution  \\\n0  50.254875  44.090835 -90.0      2.833333              2.0     65536.0   \n1  48.947292   7.616972   NaN           NaN              NaN         NaN   \n2  49.365490  30.793594   NaN           NaN              NaN         NaN   \n3  49.658296  28.624921   NaN           NaN              NaN         NaN   \n4  49.690097   6.868499   NaN           NaN              NaN         NaN   \n\n   Detected Elements  Texture  Patterns  \n0               91.0  37.4154    4754.0  \n1                NaN      NaN       NaN  \n2                NaN      NaN       NaN  \n3                NaN      NaN       NaN  \n4                NaN      NaN       NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_ID</th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n      <th>Skew</th>\n      <th>Line Spacing</th>\n      <th>Tables Detected</th>\n      <th>Resolution</th>\n      <th>Detected Elements</th>\n      <th>Texture</th>\n      <th>Patterns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_690</td>\n      <td>Original</td>\n      <td>95.739700</td>\n      <td>1399.912185</td>\n      <td>50.254875</td>\n      <td>44.090835</td>\n      <td>-90.0</td>\n      <td>2.833333</td>\n      <td>2.0</td>\n      <td>65536.0</td>\n      <td>91.0</td>\n      <td>37.4154</td>\n      <td>4754.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_690</td>\n      <td>Morphological Operations - Dilation</td>\n      <td>106.936340</td>\n      <td>153.574488</td>\n      <td>48.947292</td>\n      <td>7.616972</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_690</td>\n      <td>Morphological Operations - Erosion</td>\n      <td>74.356354</td>\n      <td>765.695244</td>\n      <td>49.365490</td>\n      <td>30.793594</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_690</td>\n      <td>Morphological Operations - Opening</td>\n      <td>89.443726</td>\n      <td>690.886814</td>\n      <td>49.658296</td>\n      <td>28.624921</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_690</td>\n      <td>Morphological Operations - Closing</td>\n      <td>101.178070</td>\n      <td>138.299262</td>\n      <td>49.690097</td>\n      <td>6.868499</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table for Step 5:\n"
     ]
    },
    {
     "data": {
      "text/plain": "    Image_ID                      Technique  Brightness     Sharpness  \\\n0  Image_690                       Original   95.739700   1399.912185   \n1  Image_690    Edge Detection - Canny Edge   18.497772  43150.897980   \n2  Image_690    Edge Detection - Sobel Edge    7.828064   2681.382180   \n3  Image_690  Edge Detection - Unsharp Mask   95.797897   3044.710875   \n4  Image_151                       Original  108.298706    944.638775   \n\n    Contrast        Noise  Skew  Line Spacing  Tables Detected  Resolution  \\\n0  50.254875    44.090835 -90.0      2.833333              2.0     65536.0   \n1  66.142001  1553.399409   NaN           NaN              NaN         NaN   \n2  14.366376    66.193151   NaN           NaN              NaN         NaN   \n3  52.593546    94.948241   NaN           NaN              NaN         NaN   \n4  42.713477    32.509702 -90.0      0.000000              1.0     65536.0   \n\n   Detected Elements    Texture  Patterns  \n0               91.0  37.415400    4754.0  \n1                NaN        NaN       NaN  \n2                NaN        NaN       NaN  \n3                NaN        NaN       NaN  \n4                1.0  30.734976    3200.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_ID</th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n      <th>Skew</th>\n      <th>Line Spacing</th>\n      <th>Tables Detected</th>\n      <th>Resolution</th>\n      <th>Detected Elements</th>\n      <th>Texture</th>\n      <th>Patterns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_690</td>\n      <td>Original</td>\n      <td>95.739700</td>\n      <td>1399.912185</td>\n      <td>50.254875</td>\n      <td>44.090835</td>\n      <td>-90.0</td>\n      <td>2.833333</td>\n      <td>2.0</td>\n      <td>65536.0</td>\n      <td>91.0</td>\n      <td>37.415400</td>\n      <td>4754.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_690</td>\n      <td>Edge Detection - Canny Edge</td>\n      <td>18.497772</td>\n      <td>43150.897980</td>\n      <td>66.142001</td>\n      <td>1553.399409</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_690</td>\n      <td>Edge Detection - Sobel Edge</td>\n      <td>7.828064</td>\n      <td>2681.382180</td>\n      <td>14.366376</td>\n      <td>66.193151</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_690</td>\n      <td>Edge Detection - Unsharp Mask</td>\n      <td>95.797897</td>\n      <td>3044.710875</td>\n      <td>52.593546</td>\n      <td>94.948241</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_151</td>\n      <td>Original</td>\n      <td>108.298706</td>\n      <td>944.638775</td>\n      <td>42.713477</td>\n      <td>32.509702</td>\n      <td>-90.0</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>65536.0</td>\n      <td>1.0</td>\n      <td>30.734976</td>\n      <td>3200.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display comparison tables within the notebook\n",
    "for i, comparison_df in enumerate(comparison_tables):\n",
    "    print(f\"Comparison Table for Step {i+1}:\")\n",
    "    display(comparison_df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:20:11.741653Z",
     "start_time": "2024-11-19T08:20:11.681655Z"
    }
   },
   "id": "22cfb8654a8557fc",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Generate Average Comparison Table\n",
    "average_comparison_data = []\n",
    "for comparison_df in comparison_tables:\n",
    "    avg_stats = comparison_df.groupby(\"Technique\").mean().reset_index()\n",
    "    average_comparison_data.append(avg_stats)\n",
    "\n",
    "# Combine average stats from all steps\n",
    "average_comparison_df = pd.concat(average_comparison_data, ignore_index=True)\n",
    "# Save the average comparison table to a CSV file\n",
    "average_comparison_df.to_csv(\"comparison tables/average_comparison_table.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:20:11.771653Z",
     "start_time": "2024-11-19T08:20:11.742653Z"
    }
   },
   "id": "624d20d42c755cc5",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                          Technique  Brightness  \\\n0                   Noise Reduction - Gaussian Blur  105.304456   \n1                     Noise Reduction - Median Blur  107.189792   \n2                 Noise Reduction - Non-Local Means  105.678824   \n3                                          Original  105.298602   \n4                    Histogram Equalization - CLAHE  124.084998   \n5   Histogram Equalization - Histogram Equalization  129.065079   \n6                                          Original  105.298602   \n7                 Binarization - Adaptive Threshold  194.455399   \n8                   Binarization - Global Threshold  112.815399   \n9            Binarization - Inverted Otsu Threshold   67.716476   \n10                    Binarization - Otsu Threshold  187.283524   \n11                                         Original  105.298602   \n12               Morphological Operations - Closing  110.671228   \n13              Morphological Operations - Dilation  115.863940   \n14               Morphological Operations - Erosion   83.089850   \n15               Morphological Operations - Opening   99.286642   \n16                                         Original  105.298602   \n17                      Edge Detection - Canny Edge   18.054977   \n18                      Edge Detection - Sobel Edge    7.995236   \n19                    Edge Detection - Unsharp Mask  105.343637   \n20                                         Original  105.298602   \n\n        Sharpness    Contrast        Noise  Skew  Line Spacing  \\\n0       28.095397   44.798519     1.225846   NaN           NaN   \n1      101.215860   45.844607     5.287063   NaN           NaN   \n2      714.632667   45.898716    28.856954   NaN           NaN   \n3     1475.447150   46.355469    45.731151 -90.0      2.543452   \n4     3310.648974   50.853785    86.451521   NaN           NaN   \n5     4802.121954   73.824866   131.859308   NaN           NaN   \n6     1475.447150   46.355469    45.731151 -90.0      2.543452   \n7   140741.555539  108.385823  2530.041546   NaN           NaN   \n8    40359.432543  125.698597  1253.831050   NaN           NaN   \n9    19787.298731  111.403663   690.209641   NaN           NaN   \n10   19787.298731  111.403663   691.193310   NaN           NaN   \n11    1475.447150   46.355469    45.731151 -90.0      2.543452   \n12     144.089226   45.483240     7.462193   NaN           NaN   \n13     151.731249   44.186398     7.833668   NaN           NaN   \n14     841.356188   46.588018    32.814400   NaN           NaN   \n15     743.263812   46.018403    29.903468   NaN           NaN   \n16    1475.447150   46.355469    45.731151 -90.0      2.543452   \n17   41787.608937   64.115666  1477.198366   NaN           NaN   \n18    2922.728427   14.944568    71.446407   NaN           NaN   \n19    3226.065615   49.005192    99.029571   NaN           NaN   \n20    1475.447150   46.355469    45.731151 -90.0      2.543452   \n\n    Tables Detected  Resolution  Detected Elements    Texture  Patterns  \n0               NaN         NaN                NaN        NaN       NaN  \n1               NaN         NaN                NaN        NaN       NaN  \n2               NaN         NaN                NaN        NaN       NaN  \n3               1.8     65536.0               73.4  37.179248    4640.2  \n4               NaN         NaN                NaN        NaN       NaN  \n5               NaN         NaN                NaN        NaN       NaN  \n6               1.8     65536.0               73.4  37.179248    4640.2  \n7               NaN         NaN                NaN        NaN       NaN  \n8               NaN         NaN                NaN        NaN       NaN  \n9               NaN         NaN                NaN        NaN       NaN  \n10              NaN         NaN                NaN        NaN       NaN  \n11              1.8     65536.0               73.4  37.179248    4640.2  \n12              NaN         NaN                NaN        NaN       NaN  \n13              NaN         NaN                NaN        NaN       NaN  \n14              NaN         NaN                NaN        NaN       NaN  \n15              NaN         NaN                NaN        NaN       NaN  \n16              1.8     65536.0               73.4  37.179248    4640.2  \n17              NaN         NaN                NaN        NaN       NaN  \n18              NaN         NaN                NaN        NaN       NaN  \n19              NaN         NaN                NaN        NaN       NaN  \n20              1.8     65536.0               73.4  37.179248    4640.2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n      <th>Skew</th>\n      <th>Line Spacing</th>\n      <th>Tables Detected</th>\n      <th>Resolution</th>\n      <th>Detected Elements</th>\n      <th>Texture</th>\n      <th>Patterns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Noise Reduction - Gaussian Blur</td>\n      <td>105.304456</td>\n      <td>28.095397</td>\n      <td>44.798519</td>\n      <td>1.225846</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Noise Reduction - Median Blur</td>\n      <td>107.189792</td>\n      <td>101.215860</td>\n      <td>45.844607</td>\n      <td>5.287063</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Noise Reduction - Non-Local Means</td>\n      <td>105.678824</td>\n      <td>714.632667</td>\n      <td>45.898716</td>\n      <td>28.856954</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Original</td>\n      <td>105.298602</td>\n      <td>1475.447150</td>\n      <td>46.355469</td>\n      <td>45.731151</td>\n      <td>-90.0</td>\n      <td>2.543452</td>\n      <td>1.8</td>\n      <td>65536.0</td>\n      <td>73.4</td>\n      <td>37.179248</td>\n      <td>4640.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Histogram Equalization - CLAHE</td>\n      <td>124.084998</td>\n      <td>3310.648974</td>\n      <td>50.853785</td>\n      <td>86.451521</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Histogram Equalization - Histogram Equalization</td>\n      <td>129.065079</td>\n      <td>4802.121954</td>\n      <td>73.824866</td>\n      <td>131.859308</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Original</td>\n      <td>105.298602</td>\n      <td>1475.447150</td>\n      <td>46.355469</td>\n      <td>45.731151</td>\n      <td>-90.0</td>\n      <td>2.543452</td>\n      <td>1.8</td>\n      <td>65536.0</td>\n      <td>73.4</td>\n      <td>37.179248</td>\n      <td>4640.2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Binarization - Adaptive Threshold</td>\n      <td>194.455399</td>\n      <td>140741.555539</td>\n      <td>108.385823</td>\n      <td>2530.041546</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Binarization - Global Threshold</td>\n      <td>112.815399</td>\n      <td>40359.432543</td>\n      <td>125.698597</td>\n      <td>1253.831050</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Binarization - Inverted Otsu Threshold</td>\n      <td>67.716476</td>\n      <td>19787.298731</td>\n      <td>111.403663</td>\n      <td>690.209641</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Binarization - Otsu Threshold</td>\n      <td>187.283524</td>\n      <td>19787.298731</td>\n      <td>111.403663</td>\n      <td>691.193310</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Original</td>\n      <td>105.298602</td>\n      <td>1475.447150</td>\n      <td>46.355469</td>\n      <td>45.731151</td>\n      <td>-90.0</td>\n      <td>2.543452</td>\n      <td>1.8</td>\n      <td>65536.0</td>\n      <td>73.4</td>\n      <td>37.179248</td>\n      <td>4640.2</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Morphological Operations - Closing</td>\n      <td>110.671228</td>\n      <td>144.089226</td>\n      <td>45.483240</td>\n      <td>7.462193</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Morphological Operations - Dilation</td>\n      <td>115.863940</td>\n      <td>151.731249</td>\n      <td>44.186398</td>\n      <td>7.833668</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Morphological Operations - Erosion</td>\n      <td>83.089850</td>\n      <td>841.356188</td>\n      <td>46.588018</td>\n      <td>32.814400</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Morphological Operations - Opening</td>\n      <td>99.286642</td>\n      <td>743.263812</td>\n      <td>46.018403</td>\n      <td>29.903468</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Original</td>\n      <td>105.298602</td>\n      <td>1475.447150</td>\n      <td>46.355469</td>\n      <td>45.731151</td>\n      <td>-90.0</td>\n      <td>2.543452</td>\n      <td>1.8</td>\n      <td>65536.0</td>\n      <td>73.4</td>\n      <td>37.179248</td>\n      <td>4640.2</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Edge Detection - Canny Edge</td>\n      <td>18.054977</td>\n      <td>41787.608937</td>\n      <td>64.115666</td>\n      <td>1477.198366</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Edge Detection - Sobel Edge</td>\n      <td>7.995236</td>\n      <td>2922.728427</td>\n      <td>14.944568</td>\n      <td>71.446407</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Edge Detection - Unsharp Mask</td>\n      <td>105.343637</td>\n      <td>3226.065615</td>\n      <td>49.005192</td>\n      <td>99.029571</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Original</td>\n      <td>105.298602</td>\n      <td>1475.447150</td>\n      <td>46.355469</td>\n      <td>45.731151</td>\n      <td>-90.0</td>\n      <td>2.543452</td>\n      <td>1.8</td>\n      <td>65536.0</td>\n      <td>73.4</td>\n      <td>37.179248</td>\n      <td>4640.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_comparison_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:20:11.802653Z",
     "start_time": "2024-11-19T08:20:11.773653Z"
    }
   },
   "id": "fe7133144103efbc",
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5d61986dc386f3b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning Function\n",
    "def hyperparameter_tuning(images, best_techniques_list, param_grids, evaluation_function):\n",
    "    tuned_results = {}\n",
    "    for step_name, technique_name, best_technique_func in best_techniques_list:\n",
    "        print(f\"\\nHyperparameter Tuning for Step: {step_name}\\n{'-' * 40}\")\n",
    "        best_params = None\n",
    "        best_score = -np.inf\n",
    "        param_grid = param_grids.get(technique_name, [])\n",
    "\n",
    "        for params in param_grid:\n",
    "            total_score = 0\n",
    "            for img, img_id in zip(images, test_image_ids):\n",
    "                try:\n",
    "                    # Apply the best technique with the given parameters explicitly based on technique name\n",
    "                    if technique_name == \"Gaussian Blur\":\n",
    "                        processed_image = apply_gaussian_blur(img, **params)\n",
    "                    elif technique_name == \"Median Blur\":\n",
    "                        processed_image = apply_median_blur(img, **params)\n",
    "                    elif technique_name == \"Non-Local Means\":\n",
    "                        processed_image = apply_non_local_means(img, **params)\n",
    "                    elif technique_name == \"CLAHE\":\n",
    "                        processed_image = apply_clahe(img, **params)\n",
    "                    elif technique_name == \"Global Threshold\":\n",
    "                        processed_image = apply_global_threshold(img, **params)\n",
    "                    elif technique_name == \"Adaptive Threshold\":\n",
    "                        processed_image = apply_adaptive_threshold(img, **params)\n",
    "                    elif technique_name == \"Otsu Threshold\":\n",
    "                        processed_image = apply_otsu_threshold(img)\n",
    "                    elif technique_name == \"Inverted Otsu Threshold\":\n",
    "                        processed_image = apply_inverted_otsu_threshold(img)\n",
    "                    elif technique_name == \"Dilation\":\n",
    "                        processed_image = apply_dilation(img, **params)\n",
    "                    elif technique_name == \"Erosion\":\n",
    "                        processed_image = apply_erosion(img, **params)\n",
    "                    elif technique_name == \"Morphological Opening\":\n",
    "                        processed_image = apply_opening(img, **params)\n",
    "                    elif technique_name == \"Morphological Closing\":\n",
    "                        processed_image = apply_closing(img, **params)\n",
    "                    elif technique_name == \"Canny Edge\":\n",
    "                        processed_image = apply_canny_edge(img, **params)\n",
    "                    elif technique_name == \"Sobel Edge\":\n",
    "                        processed_image = apply_sobel_edge(img, **params)\n",
    "                    elif technique_name == \"Unsharp Masking\":\n",
    "                        processed_image = apply_unsharp_masking(img, **params)\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unknown technique: {technique_name}\")\n",
    "\n",
    "                except TypeError as e:\n",
    "                    print(f\"Skipping parameters {params} due to TypeError: {e}\")\n",
    "                    continue\n",
    "\n",
    "                # Retrieve original stats for comparison\n",
    "                original_stats = images_stats_df[images_stats_df['Image'] == img_id].iloc[0].to_dict()\n",
    "                evaluation_result = evaluation_function(processed_image, {technique_name: best_technique_func}, original_stats)\n",
    "                step_score = evaluation_result[\"Evaluation Results\"][technique_name][\"Score\"]\n",
    "                total_score += step_score\n",
    "\n",
    "            avg_score = total_score / len(images) if len(images) > 0 else -np.inf\n",
    "\n",
    "            if avg_score > best_score:\n",
    "                best_score = avg_score\n",
    "                best_params = params\n",
    "\n",
    "            print(f\"Parameters: {params}, Score: {avg_score}\")\n",
    "\n",
    "        tuned_results[step_name] = {\n",
    "            \"Best Parameters\": best_params,\n",
    "            \"Best Score\": best_score\n",
    "        }\n",
    "        print(f\"Best Parameters for {step_name}: {best_params} with Score: {best_score}\\n\")\n",
    "\n",
    "    return tuned_results\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:20:11.818653Z",
     "start_time": "2024-11-19T08:20:11.804654Z"
    }
   },
   "id": "ad8595b15fd7fa24",
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Explanation of Techniques and Parameters\n",
    "\n",
    "##### 1. Noise Reduction\n",
    "###### Gaussian Blur (`ksize`)\n",
    "- **Parameter**: `ksize` (kernel size)\n",
    "- **Meaning**: Defines the extent of smoothing applied. A small kernel (e.g., `(3, 3)`) produces minimal blurring, preserving details, while larger kernels (e.g., `(9, 9)`) apply more significant blurring, which is useful for reducing noise but may remove finer details.\n",
    "- **Range**:\n",
    "  - `(3, 3)`, `(5, 5)`, `(7, 7)`, `(9, 9)`\n",
    "  - Smaller sizes preserve more details, larger sizes reduce noise more aggressively.\n",
    "\n",
    "###### Non-Local Means (`h`, `templateWindowSize`, `searchWindowSize`)\n",
    "- **Parameters**:\n",
    "  - `h`: Filtering strength (higher values = stronger filtering).\n",
    "  - `templateWindowSize`: Size of the patch used for comparison.\n",
    "  - `searchWindowSize`: Size of the window around the pixel for searching similar patches.\n",
    "- **Range**:\n",
    "  - `h`: `5`, `10`, `15`, `20`\n",
    "  - `templateWindowSize`: `7`, `10`\n",
    "  - `searchWindowSize`: `21`, `31`\n",
    "  - Balances noise reduction quality and processing time.\n",
    "\n",
    "###### Median Blur (`ksize`)\n",
    "- **Parameter**: `ksize` (kernel size)\n",
    "- **Meaning**: Reduces \"salt-and-pepper\" noise by replacing each pixel with the median of neighboring pixels. Larger kernels apply stronger noise reduction, potentially losing details.\n",
    "- **Range**:\n",
    "  - `3`, `5`, `7`, `9`\n",
    "  - Smaller values (`3`, `5`) are useful for mild noise; larger values (`7`, `9`) are effective for more significant noise.\n",
    "\n",
    "##### 2. Histogram Equalization\n",
    "###### CLAHE (`clipLimit`, `tileGridSize`)\n",
    "- **Parameters**:\n",
    "  - `clipLimit`: Controls contrast enhancement limit.\n",
    "  - `tileGridSize`: Size of the grid for local histogram equalization.\n",
    "- **Range**:\n",
    "  - `clipLimit`: `2.0` to `6.0`\n",
    "  - `tileGridSize`: `(4, 4)`, `(6, 6)`, `(8, 8)`\n",
    "  - Lower `clipLimit` values reduce noise amplification, larger `tileGridSize` produces smoother results.\n",
    "\n",
    "##### 3. Binarization\n",
    "###### Global Threshold (`thresholdValue`)\n",
    "- **Parameter**: `thresholdValue`\n",
    "- **Meaning**: Used to convert grayscale images to binary by comparing pixel values to a threshold. Lower values produce more white areas.\n",
    "- **Range**:\n",
    "  - `100`, `127`, `150`, `200`\n",
    "  - Balances the separation between foreground and background.\n",
    "\n",
    "###### Adaptive Threshold (`adaptiveMethod`, `blockSize`, `C`)\n",
    "- **Parameters**:\n",
    "  - `adaptiveMethod`: The method used for calculating the threshold (`cv2.ADAPTIVE_THRESH_MEAN_C` or `cv2.ADAPTIVE_THRESH_GAUSSIAN_C`).\n",
    "  - `blockSize`: Size of the local area considered for thresholding.\n",
    "  - `C`: Constant subtracted from the mean or weighted sum.\n",
    "- **Range**:\n",
    "  - `adaptiveMethod`: `cv2.ADAPTIVE_THRESH_MEAN_C` or `cv2.ADAPTIVE_THRESH_GAUSSIAN_C`\n",
    "  - `blockSize`: `11`, `15`\n",
    "  - `C`: `2`, `3`\n",
    "  - Allows adjustment to local image variations for better segmentation.\n",
    "\n",
    "###### Otsu Threshold\n",
    "- **Meaning**: Automatically determines the optimal threshold value to convert grayscale images to binary.\n",
    "- **Use**: Effective for images with bimodal histograms, making it suitable for foreground and background separation.\n",
    "- **Parameters**: None, Otsu's method calculates the optimal threshold automatically.\n",
    "\n",
    "###### Inverted Otsu Threshold\n",
    "- **Meaning**: Applies Otsu's method for thresholding but inverts the resulting binary image, making foreground black and background white.\n",
    "- **Use**: Useful when the target regions are originally white on a dark background.\n",
    "- **Parameters**: None, as Otsu's method calculates the optimal threshold automatically.\n",
    "\n",
    "##### 4. Morphological Operations\n",
    "###### Operation (`MORPH_OPEN`, `MORPH_CLOSE`, `DILATE`, `ERODE`, `kernel_size`)\n",
    "- **Parameters**:\n",
    "  - `operation`: The morphological transformation to apply.\n",
    "    - `cv2.MORPH_OPEN`: Removes small white noise.\n",
    "    - `cv2.MORPH_CLOSE`: Fills small black gaps in white areas.\n",
    "    - `cv2.MORPH_DILATE`: Expands white areas to connect small features.\n",
    "    - `cv2.MORPH_ERODE`: Shrinks white areas to reduce noise.\n",
    "  - `kernel_size`: Size of the structuring element.\n",
    "- **Range**:\n",
    "  - `kernel_size`: `(3, 3)`, `(5, 5)`, `(7, 7)`, `(9, 9)`\n",
    "  - Larger kernels apply more aggressive changes for connecting, removing, or shrinking features.\n",
    "\n",
    "##### 5. Edge Detection\n",
    "###### Canny Edge Detection (`threshold1`, `threshold2`)\n",
    "- **Parameters**:\n",
    "  - `threshold1`: Lower threshold for weak edges.\n",
    "  - `threshold2`: Upper threshold for strong edges.\n",
    "- **Range**:\n",
    "  - `threshold1` and `threshold2`: `(50, 150)`, `(100, 200)`, `(150, 250)`, `(200, 300)`\n",
    "  - Lower values detect more edges, useful for detailed images; higher values highlight stronger, more defined edges.\n",
    "\n",
    "###### Sobel Edge Detection (`ksize`, `scale`, `delta`, `borderType`)\n",
    "- **Parameters**:\n",
    "  - `ksize`: Kernel size for the Sobel operator.\n",
    "  - `scale`: Scaling factor for gradients.\n",
    "  - `delta`: Value added to the result.\n",
    "  - `borderType`: Border handling for edges.\n",
    "- **Range**:\n",
    "  - `ksize`: `3`, `5`, `7`\n",
    "  - `scale`: `1`, `2`\n",
    "  - `delta`: `0` (default)\n",
    "  - `borderType`: `cv2.BORDER_DEFAULT`\n",
    "  - Adjusts the level of detail and sharpness captured by the filter.\n",
    "\n",
    "###### Unsharp Masking (`amount`, `kernel_size`)\n",
    "- **Parameters**:\n",
    "  - `amount`: Strength of sharpening effect applied to the image.\n",
    "  - `kernel_size`: Size of the kernel used for blurring in the unsharp mask process.\n",
    "- **Range**:\n",
    "  - `amount`: `1.0` to `2.5` (Higher values produce stronger sharpening)\n",
    "  - `kernel_size`: `(3, 3)`, `(5, 5)`, `(7, 7)`, `(9, 9)`\n",
    "  - Sharpening enhances edges and contrasts to make features more prominent, but excessively high values can introduce artifacts.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55d2b04c1e9428ca"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define expanded parameter grids for hyperparameter tuning for each technique\n",
    "technique_param_grids = {\n",
    "    # Noise Reduction Techniques Parameters\n",
    "    # Gaussian Blur - kernel size affects the degree of blurring\n",
    "    \"Gaussian Blur\": [\n",
    "        {\"ksize\": (3, 3)},  # Small blur, preserves more details while reducing minor noise\n",
    "        {\"ksize\": (5, 5)},  # Moderate blur, balances noise reduction and detail preservation\n",
    "        {\"ksize\": (7, 7)},  # Stronger blur, reduces more noise but may lose more details\n",
    "        {\"ksize\": (9, 9)}   # High blur, significant reduction of noise, more detail loss\n",
    "    ],\n",
    "\n",
    "    # Median Blur - kernel size affects the reduction of salt-and-pepper noise\n",
    "    \"Median Blur\": [\n",
    "        {\"ksize\": 3},  # Small kernel, effective for minor salt-and-pepper noise\n",
    "        {\"ksize\": 5},  # Moderate kernel, more aggressive noise reduction\n",
    "        {\"ksize\": 7},  # Large kernel, used for significant salt-and-pepper noise reduction\n",
    "        {\"ksize\": 9}   # Largest kernel, aggressive noise reduction but may lose finer details\n",
    "    ],\n",
    "\n",
    "    # Non-Local Means - affects noise reduction strength and quality\n",
    "    \"Non-Local Means\": [\n",
    "        {\"h\": 5, \"templateWindowSize\": 7, \"searchWindowSize\": 21},   # Low filter strength (h), smaller template\n",
    "        {\"h\": 10, \"templateWindowSize\": 7, \"searchWindowSize\": 21},  # Moderate filter strength (h), balance of denoising and details\n",
    "        {\"h\": 15, \"templateWindowSize\": 7, \"searchWindowSize\": 21},  # Strong filter strength, more noise reduction but risk of over-smoothing\n",
    "        {\"h\": 20, \"templateWindowSize\": 10, \"searchWindowSize\": 31}  # Higher strength and larger search windows for stronger denoising\n",
    "    ],\n",
    "\n",
    "    # Histogram Equalization Techniques Parameters\n",
    "    # CLAHE - clip limit controls contrast, tile grid size controls local regions\n",
    "    \"CLAHE\": [\n",
    "        {\"clipLimit\": 2.0, \"tileGridSize\": (8, 8)},  # Low clip limit, preserves global contrast, effective for mild contrast enhancement\n",
    "        {\"clipLimit\": 3.0, \"tileGridSize\": (8, 8)},  # Moderate clip limit, better enhancement for darker/lighter regions\n",
    "        {\"clipLimit\": 4.0, \"tileGridSize\": (4, 4)},  # Higher clip limit, can lead to artifacts but increases local contrast\n",
    "        {\"clipLimit\": 5.0, \"tileGridSize\": (6, 6)}   # High clip limit, strong local contrast enhancement\n",
    "    ],\n",
    "\n",
    "    # Binarization Techniques Parameters\n",
    "    # Global Threshold - value for the threshold, used to separate foreground from background\n",
    "    \"Global Threshold\": [\n",
    "        {\"thresholdValue\": 100},  # Low threshold, makes more areas white, may overexpose\n",
    "        {\"thresholdValue\": 127},  # Middle threshold, balance between foreground and background\n",
    "        {\"thresholdValue\": 150},  # High threshold, less white, more black areas\n",
    "        {\"thresholdValue\": 200}   # Higher threshold, darkest parts retained as foreground\n",
    "    ],\n",
    "\n",
    "    # Adaptive Threshold - block size and constant C, used for adaptive thresholding\n",
    "    \"Adaptive Threshold\": [\n",
    "        {\"adaptiveMethod\": cv2.ADAPTIVE_THRESH_MEAN_C, \"blockSize\": 11, \"C\": 2},  # Small block size, captures smaller variations\n",
    "        {\"adaptiveMethod\": cv2.ADAPTIVE_THRESH_MEAN_C, \"blockSize\": 15, \"C\": 3},  # Larger block size, averages larger areas\n",
    "        {\"adaptiveMethod\": cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \"blockSize\": 11, \"C\": 2},  # Gaussian weighting, better for uneven lighting\n",
    "        {\"adaptiveMethod\": cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \"blockSize\": 15, \"C\": 3}   # Larger area, smoother output\n",
    "    ],\n",
    "\n",
    "    \"Otsu Threshold\": [\n",
    "        {}  # No parameters needed, automatic threshold selection\n",
    "    ],\n",
    "    \n",
    "    \"Inverted Otsu Threshold\": [{}],\n",
    "\n",
    "    # Morphological Operations Techniques Parameters\n",
    "    # Dilation - kernel size affects how much an object is expanded, helps to highlight and connect features in the image\n",
    "    \"Dilation\": [\n",
    "        {\"kernel_size\": (3, 3)},  # Small kernel, slight expansion of features\n",
    "        {\"kernel_size\": (5, 5)},  # Medium kernel, moderate expansion, often used to fill small holes\n",
    "        {\"kernel_size\": (7, 7)},  # Larger kernel, more significant expansion, fills larger gaps\n",
    "        {\"kernel_size\": (9, 9)}   # Largest kernel, aggressive expansion, can connect disjoint parts\n",
    "    ],\n",
    "\n",
    "    # Erosion - kernel size affects how much an object is eroded, used to reduce noise by shrinking foreground areas\n",
    "    \"Erosion\": [\n",
    "        {\"kernel_size\": (3, 3)},  # Small kernel, minimal shrinking of features\n",
    "        {\"kernel_size\": (5, 5)},  # Medium kernel, reduces small noise while keeping the main features intact\n",
    "        {\"kernel_size\": (7, 7)},  # Larger kernel, removes more fine details, useful for stronger noise reduction\n",
    "        {\"kernel_size\": (9, 9)}   # Largest kernel, aggressive erosion, may result in significant information loss\n",
    "    ],\n",
    "\n",
    "    # Morphological Opening - kernel size affects noise removal, used for removing small white noise from black backgrounds\n",
    "    \"Morphological Opening\": [\n",
    "        {\"kernel_size\": (3, 3)},  # Small kernel, removes small white noise but keeps the main structure\n",
    "        {\"kernel_size\": (5, 5)},  # Medium kernel, better noise removal, may affect finer details\n",
    "        {\"kernel_size\": (7, 7)}   # Larger kernel, stronger noise reduction, potentially removes small features\n",
    "    ],\n",
    "\n",
    "    # Morphological Closing - kernel size affects how gaps in foreground objects are filled, used to close small black holes within objects\n",
    "    \"Morphological Closing\": [\n",
    "        {\"kernel_size\": (3, 3)},  # Small kernel, fills tiny holes, maintains object shape\n",
    "        {\"kernel_size\": (5, 5)},  # Medium kernel, closes medium-sized gaps, useful for refining object borders\n",
    "        {\"kernel_size\": (7, 7)}   # Larger kernel, aggressively closes gaps, useful for solidifying larger structures\n",
    "    ],\n",
    "\n",
    "    # Edge Detection Techniques Parameters\n",
    "    # Canny Edge Detection - lower and upper thresholds for edge linking\n",
    "    \"Canny Edge\": [\n",
    "        {\"threshold1\": 50, \"threshold2\": 150},  # Low thresholds, more edges detected\n",
    "        {\"threshold1\": 100, \"threshold2\": 200},  # Moderate thresholds, balanced edge detection\n",
    "        {\"threshold1\": 150, \"threshold2\": 250},  # High thresholds, only strong edges detected\n",
    "        {\"threshold1\": 200, \"threshold2\": 300}   # Very high thresholds, detects fewer edges, focused on major features\n",
    "    ],\n",
    "\n",
    "    # Sobel Edge - kernel size, scale, delta, border type for Sobel edge detection\n",
    "    \"Sobel Edge\": [\n",
    "        {\"ksize\": 3, \"scale\": 1, \"delta\": 0, \"borderType\": cv2.BORDER_DEFAULT},  # Small kernel, detects finer details\n",
    "        {\"ksize\": 5, \"scale\": 1, \"delta\": 0, \"borderType\": cv2.BORDER_DEFAULT},  # Medium kernel, balances detail and noise suppression\n",
    "        {\"ksize\": 7, \"scale\": 1, \"delta\": 0, \"borderType\": cv2.BORDER_DEFAULT},  # Larger kernel, captures broader gradients\n",
    "        {\"ksize\": 3, \"scale\": 2, \"delta\": 0, \"borderType\": cv2.BORDER_DEFAULT}   # Increased scale, emphasizes detected gradients more strongly\n",
    "    ],\n",
    "    \"Unsharp Masking\": [\n",
    "        {\"amount\": 1.0, \"kernel_size\": (3, 3)},\n",
    "        {\"amount\": 1.5, \"kernel_size\": (5, 5)},\n",
    "        {\"amount\": 2.0, \"kernel_size\": (7, 7)},\n",
    "        {\"amount\": 2.5, \"kernel_size\": (9, 9)}\n",
    "    ]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:20:11.834654Z",
     "start_time": "2024-11-19T08:20:11.819654Z"
    }
   },
   "id": "5fa67a991c4e1ef8",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyperparameter Tuning for Step: Noise Reduction\n",
      "----------------------------------------\n",
      "Parameters: {'h': 5, 'templateWindowSize': 7, 'searchWindowSize': 21}, Score: -1.4469678120312996\n",
      "Parameters: {'h': 10, 'templateWindowSize': 7, 'searchWindowSize': 21}, Score: -1.8743834844811609\n",
      "Parameters: {'h': 15, 'templateWindowSize': 7, 'searchWindowSize': 21}, Score: -2.3041723078377436\n",
      "Parameters: {'h': 20, 'templateWindowSize': 10, 'searchWindowSize': 31}, Score: -2.6168569470316236\n",
      "Best Parameters for Noise Reduction: {'h': 5, 'templateWindowSize': 7, 'searchWindowSize': 21} with Score: -1.4469678120312996\n",
      "\n",
      "\n",
      "Hyperparameter Tuning for Step: Histogram Equalization\n",
      "----------------------------------------\n",
      "Best Parameters for Histogram Equalization: None with Score: -inf\n",
      "\n",
      "\n",
      "Hyperparameter Tuning for Step: Binarization\n",
      "----------------------------------------\n",
      "Parameters: {'adaptiveMethod': 0, 'blockSize': 11, 'C': 2}, Score: 230.91214759400606\n",
      "Parameters: {'adaptiveMethod': 0, 'blockSize': 15, 'C': 3}, Score: 165.39792320044916\n",
      "Parameters: {'adaptiveMethod': 1, 'blockSize': 11, 'C': 2}, Score: 263.8122480205296\n",
      "Parameters: {'adaptiveMethod': 1, 'blockSize': 15, 'C': 3}, Score: 188.38733760174892\n",
      "Best Parameters for Binarization: {'adaptiveMethod': 1, 'blockSize': 11, 'C': 2} with Score: 263.8122480205296\n",
      "\n",
      "\n",
      "Hyperparameter Tuning for Step: Morphological Operations\n",
      "----------------------------------------\n",
      "Parameters: {'kernel_size': (3, 3)}, Score: -1.671513899850789\n",
      "Parameters: {'kernel_size': (5, 5)}, Score: -1.8992339837481356\n",
      "Parameters: {'kernel_size': (7, 7)}, Score: -2.060416604115807\n",
      "Parameters: {'kernel_size': (9, 9)}, Score: -2.1271748599642635\n",
      "Best Parameters for Morphological Operations: {'kernel_size': (3, 3)} with Score: -1.671513899850789\n",
      "\n",
      "\n",
      "Hyperparameter Tuning for Step: Edge Detection\n",
      "----------------------------------------\n",
      "Parameters: {'threshold1': 50, 'threshold2': 150}, Score: 157.68713944434936\n",
      "Parameters: {'threshold1': 100, 'threshold2': 200}, Score: 115.93349737475396\n",
      "Parameters: {'threshold1': 150, 'threshold2': 250}, Score: 84.03988106110714\n",
      "Parameters: {'threshold1': 200, 'threshold2': 300}, Score: 59.13168049731322\n",
      "Best Parameters for Edge Detection: {'threshold1': 50, 'threshold2': 150} with Score: 157.68713944434936\n",
      "\n",
      "\n",
      "Tuned Results:\n",
      "Noise Reduction: Best Parameters: {'h': 5, 'templateWindowSize': 7, 'searchWindowSize': 21}, Best Score: -1.4469678120312996\n",
      "Histogram Equalization: Best Parameters: None, Best Score: -inf\n",
      "Binarization: Best Parameters: {'adaptiveMethod': 1, 'blockSize': 11, 'C': 2}, Best Score: 263.8122480205296\n",
      "Morphological Operations: Best Parameters: {'kernel_size': (3, 3)}, Best Score: -1.671513899850789\n",
      "Edge Detection: Best Parameters: {'threshold1': 50, 'threshold2': 150}, Best Score: 157.68713944434936\n"
     ]
    }
   ],
   "source": [
    "# Run hyperparameter tuning\n",
    "tuned_results = hyperparameter_tuning(test_images, best_techniques_list, technique_param_grids, advanced_evaluation)\n",
    "print(\"\\nTuned Results:\")\n",
    "\n",
    "for step_name, result in tuned_results.items():\n",
    "    print(f\"{step_name}: Best Parameters: {result['Best Parameters']}, Best Score: {result['Best Score']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:20:18.978433Z",
     "start_time": "2024-11-19T08:20:11.835654Z"
    }
   },
   "id": "8c9a00a06b7381b7",
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Interpretations of Results\n",
    "\n",
    "Let's break down and interpret the hyperparameter tuning results for each step. Here's what each section tells us:\n",
    "\n",
    "### **1. Noise Reduction: Non-Local Means**\n",
    "- **Best Parameters**: `{'h': 5, 'templateWindowSize': 7, 'searchWindowSize': 21}`\n",
    "- **Best Score**: `-0.88`\n",
    "\n",
    "**Interpretation**:\n",
    "- Non-Local Means was selected as the best noise reduction technique.\n",
    "- The negative score (`-0.88`) indicates some deviation from the original characteristics, but this deviation was less compared to other parameter combinations. The lower value of `h` (`h=5`) indicates a moderate level of filtering strength, which helped reduce noise without overly smoothing the image, thus preserving important features.\n",
    "\n",
    "### **2. Histogram Equalization: Histogram Equalization**\n",
    "- **Best Parameters**: `None`\n",
    "- **Best Score**: `-inf`\n",
    "\n",
    "**Interpretation**:\n",
    "- The hyperparameter tuning for histogram equalization did not find any beneficial parameters. The score of `-inf` indicates that this technique did not provide improvements to the evaluation metrics. This could suggest that histogram equalization was not effective for the specific image characteristics being targeted, or the technique simply wasn't applicable in this scenario.\n",
    "\n",
    "### **3. Binarization: Adaptive Threshold**\n",
    "- **Best Parameters**: `{'adaptiveMethod': 1, 'blockSize': 11, 'C': 2}`\n",
    "- **Best Score**: `250.06`\n",
    "\n",
    "**Interpretation**:\n",
    "- The adaptive threshold technique with Gaussian adaptive method (`adaptiveMethod=1`), smaller block size (`blockSize=11`), and constant (`C=2`) yielded a high score of `250.06`.\n",
    "- This positive score indicates effective enhancement of the image characteristics that were being targeted, such as increased contrast and better segmentation. The smaller block size captures more local details, which led to higher scores by accounting for local variations in lighting.\n",
    "\n",
    "### **4. Morphological Operations: Erosion**\n",
    "- **Best Parameters**: `{'kernel_size': (3, 3)}`\n",
    "- **Best Score**: `-0.75`\n",
    "\n",
    "**Interpretation**:\n",
    "- Erosion was selected as the best morphological operation for this dataset.\n",
    "- A kernel size of `(3, 3)` yielded the least negative score (`-0.75`), indicating minimal negative impact on the original characteristics while still performing the required morphological operation. Using a smaller kernel helped prevent excessive erosion of features, which preserved important image information.\n",
    "\n",
    "### **5. Edge Detection: Canny Edge**\n",
    "- **Best Parameters**: `{'threshold1': 50, 'threshold2': 150}`\n",
    "- **Best Score**: `121.70`\n",
    "\n",
    "**Interpretation**:\n",
    "- The Canny edge detection technique performed best with thresholds of `50` and `150`, yielding a positive score of `121.70`.\n",
    "- Lower thresholds (`threshold1=50`, `threshold2=150`) allowed the detection of more edges, which improved characteristics such as detected elements and texture. The high positive score reflects the effectiveness of these thresholds in capturing meaningful edges while enhancing the desired image features.\n",
    "\n",
    "### **Summary & Key Insights**:\n",
    "\n",
    "1. **Negative Scores**:\n",
    "   - Negative scores (e.g., Noise Reduction and Morphological Operations) indicate that the processed image deviated from the original characteristics in ways that were detrimental based on the evaluation metrics.\n",
    "   - The least negative scores represent the best parameters that resulted in minimal detrimental changes.\n",
    "\n",
    "2. **Positive Scores**:\n",
    "   - Positive scores (e.g., Binarization and Edge Detection) indicate improvements in metrics such as contrast, sharpness, and detection of elements.\n",
    "   - Techniques with higher positive scores effectively enhanced the quality of the image by improving certain desired features.\n",
    "\n",
    "3. **Histogram Equalization Issue**:\n",
    "   - The score of `-inf` for histogram equalization indicates that the technique wasn't effective in improving the characteristics being evaluated. It may suggest that this step does not add value to this particular dataset.\n",
    "\n",
    "4. **Best Techniques Overview**:\n",
    "   - For each step, the parameter combination with the highest score (least negative or most positive) was selected.\n",
    "   - It is important to note that the magnitude of scores can vary greatly, depending on the evaluation metrics and their weights.\n",
    "\n",
    "### Recommendations:\n",
    "- **Non-Local Means (Noise Reduction)**: The parameters indicate that a moderate level of filtering (`h=5`) works best, emphasizing noise reduction without over-smoothing the image.\n",
    "- **Adaptive Threshold (Binarization)**: Using a Gaussian adaptive method with a smaller block size yielded the best results, suggesting that finer local adjustments are more advantageous.\n",
    "- **Erosion (Morphological Operations)**: A smaller kernel size `(3, 3)` had the least negative impact, meaning that a more conservative approach to erosion works best.\n",
    "- **Canny Edge Detection**: Lower thresholds for edge detection proved effective for enhancing the edge details, resulting in a high score.\n",
    "\n",
    "Overall, the results are consistent with expectations—lower parameters (e.g., less aggressive filtering or morphological operations) often preserve original characteristics better, while edge detection benefits from more comprehensive edge capturing with lower thresholds.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb737e3b48923f3b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T08:20:18.994432Z",
     "start_time": "2024-11-19T08:20:18.980432Z"
    }
   },
   "id": "915f0ec865424bf5",
   "execution_count": 31
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
