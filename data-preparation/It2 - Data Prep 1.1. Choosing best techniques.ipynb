{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preparation - IT2 - Choosing |best techniques per step in the flow "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6679ab839dfc599"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a6db9fa264159cd5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T13:23:21.939509Z",
     "start_time": "2024-11-13T13:23:21.918510Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the path to the folder containing the images to be processed\n",
    "folder_path = '../data/original'  # Update this path to point to your specific folder containing images\n",
    "\n",
    "# Define the path to the folder where the processed images will be saved\n",
    "output_folder = '../data/processed'  # Update this path to the desired output folder"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T13:23:22.123514Z",
     "start_time": "2024-11-13T13:23:22.106510Z"
    }
   },
   "id": "d0b8bdef35d1e5da",
   "execution_count": 110
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Images and stats"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a22a19fd22d2b9a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder_path, extensions=('.png', '.jpg', '.jpeg', '.JPG')):\n",
    "    \"\"\"\n",
    "    Load all image file paths from a specified folder that match the given file extensions.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing the images.\n",
    "    extensions (tuple of str): A tuple of file extensions to filter the images by. \n",
    "                               Default is ('.png', '.jpg', '.jpeg', '.JPG').\n",
    "\n",
    "    Returns:\n",
    "    list: A list of full file paths to images in the folder that match the specified extensions.\n",
    "    \n",
    "    Raises:\n",
    "    FileNotFoundError: If the specified folder does not exist.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        raise FileNotFoundError(f\"The specified folder does not exist: {folder_path}\")\n",
    "\n",
    "    # List comprehension to gather all image paths with the specified extensions\n",
    "    image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(extensions)]\n",
    "\n",
    "    return image_paths"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T13:23:22.138510Z",
     "start_time": "2024-11-13T13:23:22.126511Z"
    }
   },
   "id": "703777edb6b6cb6b",
   "execution_count": 111
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to convert to gray scale\n",
    "def load_and_preprocess_images(image_paths, resize_dim=(256, 256)):\n",
    "    images = []\n",
    "    image_ids = []\n",
    "\n",
    "    # Initialize tqdm progress bar\n",
    "    for path in tqdm(image_paths, desc=\"Loading and preprocessing images\", unit=\"image\"):\n",
    "        img = cv2.imread(path)\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "        img_resized = cv2.resize(img_gray, resize_dim)  # Resize for consistency\n",
    "        images.append(img_resized)\n",
    "        image_ids.append(f'Image_{len(images)}')  # Assign image ID as Image_1, Image_2, etc.\n",
    "\n",
    "    return images, image_ids"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T13:23:22.153511Z",
     "start_time": "2024-11-13T13:23:22.140511Z"
    }
   },
   "id": "8097d12ed08ed95c",
   "execution_count": 112
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the CSV file with the image statistics\n",
    "images_stats_path = \"../data-understanding/images_stats.csv\"  \n",
    "images_stats_df = pd.read_csv(images_stats_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T13:23:22.245513Z",
     "start_time": "2024-11-13T13:23:22.155512Z"
    }
   },
   "id": "f0024219894c26ef",
   "execution_count": 113
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Image', 'Brightness', 'Sharpness', 'Contrast', 'Noise', 'Skew',\n       'Line Spacing', 'Tables Detected', 'Resolution', 'Detected Elements',\n       'Texture', 'Patterns'],\n      dtype='object')"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_stats_df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T13:23:22.275510Z",
     "start_time": "2024-11-13T13:23:22.247516Z"
    }
   },
   "id": "db335d32477016cb",
   "execution_count": 114
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions per step"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12f7addce2a50971"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 1: Noise Reduction Techniques"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cf7d2143725450b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Noise Reduction Functions\n",
    "def apply_gaussian_blur(image, ksize=(5, 5)):\n",
    "    \"\"\"Apply Gaussian Blur to reduce noise with the specified kernel size.\"\"\"\n",
    "    return cv2.GaussianBlur(image, ksize, 0)\n",
    "\n",
    "def apply_median_blur(image, ksize=5):\n",
    "    \"\"\"Apply Median Blur to reduce salt-and-pepper noise with the specified kernel size.\"\"\"\n",
    "    return cv2.medianBlur(image, ksize)\n",
    "\n",
    "def apply_non_local_means(image, h=10, templateWindowSize=7, searchWindowSize=21):\n",
    "    \"\"\"Apply Non-Local Means Denoising with specified parameters.\"\"\"\n",
    "    return cv2.fastNlMeansDenoising(image, None, h, templateWindowSize, searchWindowSize)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T13:44:25.282379Z",
     "start_time": "2024-11-13T13:44:25.261376Z"
    }
   },
   "id": "8fe3ee9d85584a63",
   "execution_count": 139
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2: Histogram Equalization Techniques"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b6cdd42d07d1c96"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Histogram Equalization Functions\n",
    "def apply_histogram_equalization(image):\n",
    "    return cv2.equalizeHist(image)\n",
    "\n",
    "def apply_clahe(image, clipLimit=2.0, tileGridSize=(8, 8)):\n",
    "    \"\"\"Apply CLAHE to enhance image contrast with specified parameters.\"\"\"\n",
    "    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n",
    "    return clahe.apply(image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T13:44:25.906375Z",
     "start_time": "2024-11-13T13:44:25.889376Z"
    }
   },
   "id": "44c99f9c5258c6f3",
   "execution_count": 140
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3: Binarization Techniques"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29e647d0a546cb82"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Binarization Functions\n",
    "def apply_global_threshold(image, thresholdValue=127):\n",
    "    \"\"\"Apply Global Thresholding with the specified threshold value.\"\"\"\n",
    "    _, binary_image = cv2.threshold(image, thresholdValue, 255, cv2.THRESH_BINARY)\n",
    "    return binary_image\n",
    "\n",
    "def apply_adaptive_threshold(image, adaptiveMethod=cv2.ADAPTIVE_THRESH_MEAN_C, blockSize=11, C=2):\n",
    "    \"\"\"Apply Adaptive Thresholding with the specified method, block size, and constant C.\"\"\"\n",
    "    return cv2.adaptiveThreshold(image, 255, adaptiveMethod, cv2.THRESH_BINARY, blockSize, C)\n",
    "\n",
    "def apply_otsu_threshold(image):\n",
    "    \"\"\"Apply Otsu Thresholding.\"\"\"\n",
    "    _, binary_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return binary_image\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T13:44:26.610656Z",
     "start_time": "2024-11-13T13:44:26.600657Z"
    }
   },
   "id": "3b2691be436fc225",
   "execution_count": 141
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 4: Morphological Operations Techniques"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3c7a336f8c8b717"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Morphological Operations Functions\n",
    "def apply_dilation(image, kernel_size=(5, 5)):\n",
    "    \"\"\"Apply Dilation with the specified kernel size.\"\"\"\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations=1)\n",
    "\n",
    "def apply_erosion(image, kernel_size=(5, 5)):\n",
    "    \"\"\"Apply Erosion with the specified kernel size.\"\"\"\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations=1)\n",
    "\n",
    "def apply_opening(image, kernel_size=(5, 5)):\n",
    "    \"\"\"Apply Morphological Opening with the specified kernel size.\"\"\"\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "def apply_closing(image, kernel_size=(5, 5)):\n",
    "    \"\"\"Apply Morphological Closing with the specified kernel size.\"\"\"\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T13:44:27.301038Z",
     "start_time": "2024-11-13T13:44:27.284048Z"
    }
   },
   "id": "da08a64db428ad4a",
   "execution_count": 142
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 5: Edge Detection Techniques"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5596f364429dda1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Edge Detection Functions\n",
    "def apply_canny_edge(image, threshold1=50, threshold2=150):\n",
    "    \"\"\"Apply Canny Edge Detection with specified thresholds.\"\"\"\n",
    "    return cv2.Canny(image, threshold1, threshold2)\n",
    "\n",
    "def apply_sobel_edge(image, ksize=3, scale=1, delta=0, borderType=cv2.BORDER_DEFAULT):\n",
    "    \"\"\"Apply Sobel Edge Detection with specified parameters.\"\"\"\n",
    "    return cv2.Sobel(image, cv2.CV_64F, 1, 1, ksize=ksize, scale=scale, delta=delta, borderType=borderType)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T13:44:28.184117Z",
     "start_time": "2024-11-13T13:44:28.178118Z"
    }
   },
   "id": "76e5c83f8a5c9bc8",
   "execution_count": 143
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Characteristics Calculation for testing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e79e5c4a578b19f5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Image Characteristics Calculation Functions - from data understanding it2\n",
    "def calculate_brightness(image):\n",
    "    return np.mean(image)\n",
    "\n",
    "def calculate_sharpness(image):\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\n",
    "def calculate_contrast(image):\n",
    "    return image.std()\n",
    "\n",
    "def calculate_noise(image):\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    noise = cv2.absdiff(image, blurred)\n",
    "    return np.var(noise)\n",
    "\n",
    "def calculate_skew(image):\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "    _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    coords = np.column_stack(np.where(binary > 0))\n",
    "    if coords.size == 0:\n",
    "        return 0\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    if abs(angle) < 1e-2:\n",
    "        angle = 0\n",
    "    return round(angle, 2)\n",
    "\n",
    "def calculate_line_spacing(image):\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "    _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    heights = [cv2.boundingRect(contour)[3] for contour in contours]\n",
    "    if len(heights) > 1:\n",
    "        line_spacing = np.mean(np.diff(sorted(heights)))\n",
    "    else:\n",
    "        line_spacing = 0\n",
    "    return line_spacing\n",
    "\n",
    "def detect_tables(image):\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "    _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    binary = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    table_contours = [contour for contour in contours if cv2.contourArea(contour) > 1000]\n",
    "    return len(table_contours)\n",
    "\n",
    "def calculate_resolution(image):\n",
    "    height, width = image.shape[:2]\n",
    "    return height * width\n",
    "\n",
    "def calculate_elements_detection(image):\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "    _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return len(contours)\n",
    "\n",
    "def calculate_texture(image):\n",
    "    laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "    return laplacian.std()\n",
    "\n",
    "def calculate_patterns(image):\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "    edges = cv2.Canny(image, 100, 200)\n",
    "    return np.sum(edges > 0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T13:23:22.385518Z",
     "start_time": "2024-11-13T13:23:22.354512Z"
    }
   },
   "id": "aec243807f00da68",
   "execution_count": 120
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation per step"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "203cff1e1647315b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code evaluates multiple techniques in each step of the image processing pipeline and selects the best technique based on a scoring system. Here's how it works:\n",
    "\n",
    "Technique Evaluation:\n",
    "\n",
    "Each technique for a specific step (e.g., Gaussian Blur, Median Blur for Noise Reduction) is applied to the test images.\n",
    "After applying the technique, the characteristics of the processed image are calculated (e.g., Brightness, Sharpness, Noise, etc.).\n",
    "Scoring Mechanism:\n",
    "\n",
    "The scoring function is designed to minimize noise while maximizing positive characteristics like sharpness and contrast.\n",
    "The score calculation takes into account changes in image characteristics compared to the original image.\n",
    "Noise is treated negatively (-stats[\"Noise\"]), whereas characteristics like Sharpness, Contrast, and other features are treated positively (score += stats[key] - original_stats[key]).\n",
    "After evaluating all techniques, the one with the highest score is selected as the \"best technique\" for that step.\n",
    "Best Technique Selection:\n",
    "\n",
    "The technique with the highest score is selected and printed, and this is repeated for each step in the pipeline."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61ca8cdd80754f23"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Function of evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6dafdc80cafbb5f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Basic Evaluation Function\n",
    "# -------------------------\n",
    "# def basic_evaluation(image, techniques_dict, original_stats):\n",
    "#     evaluation_results = {}\n",
    "#     for technique_name, technique_func in techniques_dict.items():\n",
    "#         processed_image = technique_func(image)\n",
    "#         stats = {\n",
    "#             \"Brightness\": calculate_brightness(processed_image),\n",
    "#             \"Sharpness\": calculate_sharpness(processed_image),\n",
    "#             \"Contrast\": calculate_contrast(processed_image),\n",
    "#             \"Noise\": calculate_noise(processed_image)\n",
    "#         }\n",
    "# \n",
    "#         # Basic scoring function - prioritizing sharpness, contrast, and minimized noise\n",
    "#         score = stats[\"Sharpness\"] + stats[\"Contrast\"] - stats[\"Noise\"]\n",
    "#         evaluation_results[technique_name] = {\"Score\": score, \"Stats\": stats}\n",
    "# \n",
    "#     best_technique = max(evaluation_results, key=lambda x: evaluation_results[x][\"Score\"])\n",
    "#     return {\"Best Technique\": best_technique, \"Evaluation Results\": evaluation_results}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T13:23:22.401511Z",
     "start_time": "2024-11-13T13:23:22.388512Z"
    }
   },
   "id": "ce72107041cb13b3",
   "execution_count": 121
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Advanced Evaluation Function\n",
    "# # ----------------------------\n",
    "# def advanced_evaluation(image, techniques_dict,original_stats):\n",
    "#     evaluation_results = {}\n",
    "#     for technique_name, technique_func in techniques_dict.items():\n",
    "#         processed_image = technique_func(image)\n",
    "#         stats = {\n",
    "#             \"Brightness\": calculate_brightness(processed_image),\n",
    "#             \"Sharpness\": calculate_sharpness(processed_image),\n",
    "#             \"Contrast\": calculate_contrast(processed_image),\n",
    "#             \"Noise\": calculate_noise(processed_image),\n",
    "#             \"Skew\": calculate_skew(processed_image),\n",
    "#             \"Line Spacing\": calculate_line_spacing(processed_image),\n",
    "#             \"Tables Detected\": detect_tables(processed_image),\n",
    "#             \"Resolution\": calculate_resolution(processed_image),\n",
    "#             \"Detected Elements\": calculate_elements_detection(processed_image),\n",
    "#             \"Texture\": calculate_texture(processed_image),\n",
    "#             \"Patterns\": calculate_patterns(processed_image)\n",
    "#         }\n",
    "# \n",
    "#         # Compare with original characteristics and calculate score\n",
    "#         score = 0\n",
    "#         score -= abs(stats[\"Brightness\"] - original_stats[\"Brightness\"])  # Closer brightness to original is better\n",
    "#         score += stats[\"Sharpness\"] - original_stats[\"Sharpness\"]  # Higher sharpness is better, relative improvement\n",
    "#         score += stats[\"Contrast\"] - original_stats[\"Contrast\"]  # Higher contrast is better, relative improvement\n",
    "#         score -= abs(stats[\"Noise\"] - original_stats[\"Noise\"])  # Lower noise difference compared to original is better\n",
    "#         score -= abs(stats[\"Skew\"] - original_stats[\"Skew\"])  # Less skew difference is better\n",
    "#         score -= abs(stats[\"Line Spacing\"] - original_stats[\"Line Spacing\"])  # Closer line spacing to original is better\n",
    "#         score += stats[\"Tables Detected\"] - original_stats[\"Tables Detected\"]  # More tables detected is better\n",
    "#         score += stats[\"Resolution\"] - original_stats[\"Resolution\"]  # Higher resolution is better\n",
    "#         score += stats[\"Detected Elements\"] - original_stats[\"Detected Elements\"]  # More elements detected is better\n",
    "#         score += stats[\"Texture\"] - original_stats[\"Texture\"]  # Higher texture complexity is better, relative improvement\n",
    "#         score += stats[\"Patterns\"] - original_stats[\"Patterns\"]  # More patterns detected is better\n",
    "# \n",
    "#         evaluation_results[technique_name] = {\"Score\": score, \"Stats\": stats}\n",
    "# \n",
    "#     best_technique = max(evaluation_results, key=lambda x: evaluation_results[x][\"Score\"])\n",
    "#     return {\"Best Technique\": best_technique, \"Evaluation Results\": evaluation_results}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T13:23:22.417509Z",
     "start_time": "2024-11-13T13:23:22.403511Z"
    }
   },
   "id": "3067606c27e5a0cd",
   "execution_count": 122
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def advanced_evaluation(image, techniques_dict, original_stats):\n",
    "    evaluation_results = {}\n",
    "\n",
    "    for technique_name, technique_func in techniques_dict.items():\n",
    "        # Apply the technique\n",
    "        processed_image = technique_func(image)\n",
    "\n",
    "        # Calculate characteristics for the processed image\n",
    "        stats = {\n",
    "            \"Brightness\": calculate_brightness(processed_image),\n",
    "            \"Sharpness\": calculate_sharpness(processed_image),\n",
    "            \"Contrast\": calculate_contrast(processed_image),\n",
    "            \"Noise\": calculate_noise(processed_image),\n",
    "            \"Skew\": calculate_skew(processed_image),\n",
    "            \"Line Spacing\": calculate_line_spacing(processed_image),\n",
    "            \"Tables Detected\": detect_tables(processed_image),\n",
    "            \"Resolution\": calculate_resolution(processed_image),\n",
    "            \"Detected Elements\": calculate_elements_detection(processed_image),\n",
    "            \"Texture\": calculate_texture(processed_image),\n",
    "            \"Patterns\": calculate_patterns(processed_image)\n",
    "        }\n",
    "\n",
    "        # Normalize metrics to comparable ranges (between 0 and 1, roughly)\n",
    "        stats_normalized = {\n",
    "            \"Brightness\": stats[\"Brightness\"] / 255,\n",
    "            \"Sharpness\": stats[\"Sharpness\"] / 1000,\n",
    "            \"Contrast\": stats[\"Contrast\"] / 255,\n",
    "            \"Noise\": stats[\"Noise\"] / 255,\n",
    "            \"Skew\": stats[\"Skew\"] / 45,\n",
    "            \"Line Spacing\": stats[\"Line Spacing\"] / 100,\n",
    "            \"Tables Detected\": stats[\"Tables Detected\"] / 10,\n",
    "            \"Resolution\": stats[\"Resolution\"] / (512 * 512),\n",
    "            \"Detected Elements\": stats[\"Detected Elements\"] / 100,\n",
    "            \"Texture\": stats[\"Texture\"] / 100,\n",
    "            \"Patterns\": stats[\"Patterns\"] / 1000\n",
    "        }\n",
    "\n",
    "        # Normalize the original stats for comparison\n",
    "        original_stats_normalized = {\n",
    "            \"Brightness\": original_stats[\"Brightness\"] / 255,\n",
    "            \"Sharpness\": original_stats[\"Sharpness\"] / 1000,\n",
    "            \"Contrast\": original_stats[\"Contrast\"] / 255,\n",
    "            \"Noise\": original_stats[\"Noise\"] / 255,\n",
    "            \"Skew\": original_stats[\"Skew\"] / 45,\n",
    "            \"Line Spacing\": original_stats[\"Line Spacing\"] / 100,\n",
    "            \"Tables Detected\": original_stats[\"Tables Detected\"] / 10,\n",
    "            \"Resolution\": original_stats[\"Resolution\"] / (512 * 512),\n",
    "            \"Detected Elements\": original_stats[\"Detected Elements\"] / 100,\n",
    "            \"Texture\": original_stats[\"Texture\"] / 100,\n",
    "            \"Patterns\": original_stats[\"Patterns\"] / 1000\n",
    "        }\n",
    "\n",
    "        # Weights for each characteristic (to determine their importance)\n",
    "        weights = {\n",
    "            \"Brightness\": -1.0,  # Closer to original is better (penalized if different)\n",
    "            \"Sharpness\": 2.0,    # Higher is better (rewarded if improved)\n",
    "            \"Contrast\": 1.0,     # Higher is better (rewarded if improved)\n",
    "            \"Noise\": -1.5,       # Lower is better (penalized if increased)\n",
    "            \"Skew\": -0.5,        # Closer to original is better (penalized if different)\n",
    "            \"Line Spacing\": -0.5,  # Closer to original is better (penalized if different)\n",
    "            \"Tables Detected\": 1.0,  # More tables detected is better\n",
    "            \"Resolution\": 1.0,    # Higher is better\n",
    "            \"Detected Elements\": 1.0,  # More elements detected is better\n",
    "            \"Texture\": 1.0,       # Higher texture complexity is better\n",
    "            \"Patterns\": 1.0       # More patterns detected is better\n",
    "        }\n",
    "\n",
    "        # Calculate score using normalized metrics and weights\n",
    "        score = 0\n",
    "        for metric, value in stats_normalized.items():\n",
    "            original_value = original_stats_normalized.get(metric, 0)\n",
    "            score += weights[metric] * (value - original_value)\n",
    "\n",
    "        evaluation_results[technique_name] = {\"Score\": score, \"Stats\": stats}\n",
    "\n",
    "    # Determine the best technique based on the highest score\n",
    "    best_technique = max(evaluation_results, key=lambda x: evaluation_results[x][\"Score\"])\n",
    "    return {\"Best Technique\": best_technique, \"Evaluation Results\": evaluation_results}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T14:13:21.950247Z",
     "start_time": "2024-11-13T14:13:21.931249Z"
    }
   },
   "id": "6bf4a8b130aa7d7f",
   "execution_count": 170
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function for Each Step testing\n",
    "def run_step(step_name, techniques_dict, test_images, test_image_ids, best_techniques_list):\n",
    "    print(f\"\\nRunning Step: {step_name}\\n{'-' * 40}\")\n",
    "    all_results = []\n",
    "    for img, img_id in zip(test_images, test_image_ids):\n",
    "        # Retrieve original stats from the dataset\n",
    "        original_stats = images_stats_df[images_stats_df['Image'] == img_id].iloc[0].to_dict()\n",
    "\n",
    "        step_result = advanced_evaluation(img, techniques_dict,original_stats)\n",
    "        all_results.append((img_id, original_stats, step_result))\n",
    "        print(f\"Best Technique for {img_id}: {step_result['Best Technique']}\")\n",
    "\n",
    "    # Generate Comparison Table\n",
    "    comparison_data = []\n",
    "    for img_id, original_stats, result in all_results:\n",
    "        # Add original stats row\n",
    "        comparison_data.append([img_id, \"Original\"] + list(original_stats.values())[1:])  # Skip the 'Image' key\n",
    "        # Add each technique's stats\n",
    "        for technique, metrics in result[\"Evaluation Results\"].items():\n",
    "            comparison_data.append([img_id, f\"{step_name} - {technique}\"] + list(metrics[\"Stats\"].values()))\n",
    "\n",
    "    comparison_df = pd.DataFrame(comparison_data, columns=[\"Image_ID\", \"Technique\", \"Brightness\", \"Sharpness\", \"Contrast\", \"Noise\", \"Skew\", \"Line Spacing\", \"Tables Detected\", \"Resolution\", \"Detected Elements\", \"Texture\", \"Patterns\"])\n",
    "\n",
    "    # Generate Recommendation\n",
    "    recommended_technique_name = max(all_results, key=lambda x: x[2][\"Evaluation Results\"][x[2][\"Best Technique\"]][\"Score\"])[2][\"Best Technique\"]\n",
    "    recommended_technique_func = techniques_dict[recommended_technique_name]\n",
    "    print(f\"\\nRecommended Technique for {step_name}: {recommended_technique_name}\\n\")\n",
    "\n",
    "    # Append both technique name and function for further tuning\n",
    "    best_techniques_list.append((step_name, recommended_technique_name, recommended_technique_func))\n",
    "\n",
    "    # Return the comparison DataFrame\n",
    "    return comparison_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T13:23:22.433510Z",
     "start_time": "2024-11-13T13:23:22.419510Z"
    }
   },
   "id": "a9dcfaa1991f5e3a",
   "execution_count": 123
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Running Different Techniques per Step"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5473417fb6fc8aff"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing images: 100%|██████████| 698/698 [02:44<00:00,  4.24image/s]\n"
     ]
    }
   ],
   "source": [
    "# Load all image file paths from the specified folder\n",
    "image_paths_all = load_images_from_folder(folder_path)\n",
    "\n",
    "# Load and preprocess all images\n",
    "total_images, total_image_ids = load_and_preprocess_images(image_paths_all)\n",
    "\n",
    "# Randomly select 5 images for experimentation\n",
    "experiment_indices = random.sample(range(len(total_images)), 5)\n",
    "test_images = [total_images[i] for i in experiment_indices]\n",
    "test_image_ids = [total_image_ids[i] for i in experiment_indices]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T13:26:07.111340Z",
     "start_time": "2024-11-13T13:23:22.436518Z"
    }
   },
   "id": "5c3b64a356573a62",
   "execution_count": 124
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_techniques_list = []\n",
    "comparison_tables = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T14:13:30.122101Z",
     "start_time": "2024-11-13T14:13:30.109115Z"
    }
   },
   "id": "5d321de124a8f61b",
   "execution_count": 171
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Step: Noise Reduction\n",
      "----------------------------------------\n",
      "Best Technique for Image_168: Non-Local Means\n",
      "Best Technique for Image_642: Non-Local Means\n",
      "Best Technique for Image_288: Non-Local Means\n",
      "Best Technique for Image_185: Non-Local Means\n",
      "Best Technique for Image_372: Non-Local Means\n",
      "\n",
      "Recommended Technique for Noise Reduction: Non-Local Means\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Noise Reduction\n",
    "noise_reduction_techniques = {\n",
    "    \"Gaussian Blur\": lambda img: cv2.GaussianBlur(img, (5, 5), 0),\n",
    "    \"Median Blur\": lambda img: cv2.medianBlur(img, 5),\n",
    "    \"Non-Local Means\": lambda img: cv2.fastNlMeansDenoising(img, None, 10, 7, 21)\n",
    "}\n",
    "comparison_tables.append(run_step(\"Noise Reduction\", noise_reduction_techniques, test_images, test_image_ids, best_techniques_list))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T14:13:31.244392Z",
     "start_time": "2024-11-13T14:13:30.504417Z"
    }
   },
   "id": "1272df62648886a8",
   "execution_count": 172
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Step: Histogram Equalization\n",
      "----------------------------------------\n",
      "Best Technique for Image_168: Histogram Equalization\n",
      "Best Technique for Image_642: CLAHE\n",
      "Best Technique for Image_288: Histogram Equalization\n",
      "Best Technique for Image_185: Histogram Equalization\n",
      "Best Technique for Image_372: Histogram Equalization\n",
      "\n",
      "Recommended Technique for Histogram Equalization: Histogram Equalization\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Histogram Equalization\n",
    "histogram_equalization_techniques = {\n",
    "    \"Histogram Equalization\": lambda img: cv2.equalizeHist(img),\n",
    "    \"CLAHE\": lambda img: cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(img)\n",
    "}\n",
    "comparison_tables.append(run_step(\"Histogram Equalization\", histogram_equalization_techniques, test_images, test_image_ids, best_techniques_list))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T14:13:31.368393Z",
     "start_time": "2024-11-13T14:13:31.247393Z"
    }
   },
   "id": "b5ef0203d606d09a",
   "execution_count": 173
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Step: Binarization\n",
      "----------------------------------------\n",
      "Best Technique for Image_168: Adaptive Threshold\n",
      "Best Technique for Image_642: Adaptive Threshold\n",
      "Best Technique for Image_288: Adaptive Threshold\n",
      "Best Technique for Image_185: Adaptive Threshold\n",
      "Best Technique for Image_372: Adaptive Threshold\n",
      "\n",
      "Recommended Technique for Binarization: Adaptive Threshold\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Binarization\n",
    "binarization_techniques = {\n",
    "    \"Global Threshold\": lambda img: cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)[1],\n",
    "    \"Adaptive Threshold\": lambda img: cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2),\n",
    "    \"Otsu Threshold\": lambda img: cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "}\n",
    "comparison_tables.append(run_step(\"Binarization\", binarization_techniques, test_images, test_image_ids, best_techniques_list))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T14:13:32.132749Z",
     "start_time": "2024-11-13T14:13:31.951911Z"
    }
   },
   "id": "a68616ef9a33f67d",
   "execution_count": 174
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Step: Morphological Operations\n",
      "----------------------------------------\n",
      "Best Technique for Image_168: Erosion\n",
      "Best Technique for Image_642: Erosion\n",
      "Best Technique for Image_288: Erosion\n",
      "Best Technique for Image_185: Erosion\n",
      "Best Technique for Image_372: Erosion\n",
      "\n",
      "Recommended Technique for Morphological Operations: Erosion\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Morphological Operations\n",
    "morphological_operations_techniques = {\n",
    "    \"Dilation\": lambda img: cv2.dilate(img, np.ones((5, 5), np.uint8), iterations=1),\n",
    "    \"Erosion\": lambda img: cv2.erode(img, np.ones((5, 5), np.uint8), iterations=1),\n",
    "    \"Opening\": lambda img: cv2.morphologyEx(img, cv2.MORPH_OPEN, np.ones((5, 5), np.uint8)),\n",
    "    \"Closing\": lambda img: cv2.morphologyEx(img, cv2.MORPH_CLOSE, np.ones((5, 5), np.uint8))\n",
    "}\n",
    "comparison_tables.append(run_step(\"Morphological Operations\", morphological_operations_techniques, test_images, test_image_ids, best_techniques_list))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T14:13:34.387473Z",
     "start_time": "2024-11-13T14:13:34.251466Z"
    }
   },
   "id": "8a8bf5b17df76bee",
   "execution_count": 175
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Step: Edge Detection\n",
      "----------------------------------------\n",
      "Best Technique for Image_168: Canny Edge\n",
      "Best Technique for Image_642: Canny Edge\n",
      "Best Technique for Image_288: Canny Edge\n",
      "Best Technique for Image_185: Canny Edge\n",
      "Best Technique for Image_372: Canny Edge\n",
      "\n",
      "Recommended Technique for Edge Detection: Canny Edge\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Edge Detection\n",
    "edge_detection_techniques = {\n",
    "    \"Canny Edge\": lambda img: cv2.Canny(img, 100, 200),\n",
    "    \"Sobel Edge\": lambda img: cv2.convertScaleAbs(cv2.Sobel(img, cv2.CV_64F, 1, 1, ksize=3))\n",
    "}\n",
    "comparison_tables.append(run_step(\"Edge Detection\", edge_detection_techniques, test_images, test_image_ids, best_techniques_list))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T14:13:35.606465Z",
     "start_time": "2024-11-13T14:13:35.503465Z"
    }
   },
   "id": "7e47a9227209a883",
   "execution_count": 176
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Final best techniques per step"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8439513ab9cfdf06"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Techniques for Each Step:\n",
      "Noise Reduction: Non-Local Means\n",
      "Histogram Equalization: Histogram Equalization\n",
      "Binarization: Adaptive Threshold\n",
      "Morphological Operations: Erosion\n",
      "Edge Detection: Canny Edge\n"
     ]
    }
   ],
   "source": [
    "# Print the list of best techniques for each step\n",
    "print(\"\\nBest Techniques for Each Step:\")\n",
    "for step, technique_name, technique_func in best_techniques_list:\n",
    "    print(f\"{step}: {technique_name}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T14:13:47.673699Z",
     "start_time": "2024-11-13T14:13:47.653709Z"
    }
   },
   "id": "7264edc32f3787a",
   "execution_count": 177
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for i, comparison_df in enumerate(comparison_tables):\n",
    "    comparison_df.to_csv(f\"comparison tables/comparison_table_step_{i+1}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T14:13:49.738800Z",
     "start_time": "2024-11-13T14:13:49.716798Z"
    }
   },
   "id": "a8b12bb0b5a2f14c",
   "execution_count": 178
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table for Step 1:\n"
     ]
    },
    {
     "data": {
      "text/plain": "    Image_ID                          Technique  Brightness    Sharpness  \\\n0  Image_168                           Original  102.072388   978.061044   \n1  Image_168    Noise Reduction - Gaussian Blur  102.101547    23.812057   \n2  Image_168      Noise Reduction - Median Blur  103.508911   111.742331   \n3  Image_168  Noise Reduction - Non-Local Means  102.519684   363.663595   \n4  Image_642                           Original  109.358383  1760.960945   \n\n    Contrast      Noise  Skew  Line Spacing  Tables Detected  Resolution  \\\n0  43.181213  32.850364 -90.0       0.00000                1       65536   \n1  41.874337   1.118163 -90.0       0.00000                2       65536   \n2  42.719517   5.970850 -90.0       0.00000                1       65536   \n3  42.825398  17.555627 -90.0       0.00000                1       65536   \n4  52.015105  56.500502 -90.0       1.59375                2       65536   \n\n   Detected Elements    Texture  Patterns  \n0                  1  31.273968      3863  \n1                  1   4.879760      1103  \n2                  1  10.570825       992  \n3                  1  19.069966      1884  \n4                161  41.963805      4931  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_ID</th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n      <th>Skew</th>\n      <th>Line Spacing</th>\n      <th>Tables Detected</th>\n      <th>Resolution</th>\n      <th>Detected Elements</th>\n      <th>Texture</th>\n      <th>Patterns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_168</td>\n      <td>Original</td>\n      <td>102.072388</td>\n      <td>978.061044</td>\n      <td>43.181213</td>\n      <td>32.850364</td>\n      <td>-90.0</td>\n      <td>0.00000</td>\n      <td>1</td>\n      <td>65536</td>\n      <td>1</td>\n      <td>31.273968</td>\n      <td>3863</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_168</td>\n      <td>Noise Reduction - Gaussian Blur</td>\n      <td>102.101547</td>\n      <td>23.812057</td>\n      <td>41.874337</td>\n      <td>1.118163</td>\n      <td>-90.0</td>\n      <td>0.00000</td>\n      <td>2</td>\n      <td>65536</td>\n      <td>1</td>\n      <td>4.879760</td>\n      <td>1103</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_168</td>\n      <td>Noise Reduction - Median Blur</td>\n      <td>103.508911</td>\n      <td>111.742331</td>\n      <td>42.719517</td>\n      <td>5.970850</td>\n      <td>-90.0</td>\n      <td>0.00000</td>\n      <td>1</td>\n      <td>65536</td>\n      <td>1</td>\n      <td>10.570825</td>\n      <td>992</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_168</td>\n      <td>Noise Reduction - Non-Local Means</td>\n      <td>102.519684</td>\n      <td>363.663595</td>\n      <td>42.825398</td>\n      <td>17.555627</td>\n      <td>-90.0</td>\n      <td>0.00000</td>\n      <td>1</td>\n      <td>65536</td>\n      <td>1</td>\n      <td>19.069966</td>\n      <td>1884</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_642</td>\n      <td>Original</td>\n      <td>109.358383</td>\n      <td>1760.960945</td>\n      <td>52.015105</td>\n      <td>56.500502</td>\n      <td>-90.0</td>\n      <td>1.59375</td>\n      <td>2</td>\n      <td>65536</td>\n      <td>161</td>\n      <td>41.963805</td>\n      <td>4931</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table for Step 2:\n"
     ]
    },
    {
     "data": {
      "text/plain": "    Image_ID                                        Technique  Brightness  \\\n0  Image_168                                         Original  102.072388   \n1  Image_168  Histogram Equalization - Histogram Equalization  130.006622   \n2  Image_168                   Histogram Equalization - CLAHE  120.380508   \n3  Image_642                                         Original  109.358383   \n4  Image_642  Histogram Equalization - Histogram Equalization  128.542160   \n\n     Sharpness   Contrast       Noise  Skew  Line Spacing  Tables Detected  \\\n0   978.061044  43.181213   32.850364 -90.0      0.000000                1   \n1  5328.425232  74.273891  138.782599 -90.0      0.605701                3   \n2  2234.628612  48.583296   61.975004 -90.0      0.927273                2   \n3  1760.960945  52.015105   56.500502 -90.0      1.593750                2   \n4  3610.248460  73.686047  107.169441 -90.0      0.861486                2   \n\n   Resolution  Detected Elements    Texture  Patterns  \n0       65536                  1  31.273968      3863  \n1       65536                422  72.996063      8332  \n2       65536                276  47.271859      5905  \n3       65536                161  41.963805      4931  \n4       65536                297  60.085343      6574  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_ID</th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n      <th>Skew</th>\n      <th>Line Spacing</th>\n      <th>Tables Detected</th>\n      <th>Resolution</th>\n      <th>Detected Elements</th>\n      <th>Texture</th>\n      <th>Patterns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_168</td>\n      <td>Original</td>\n      <td>102.072388</td>\n      <td>978.061044</td>\n      <td>43.181213</td>\n      <td>32.850364</td>\n      <td>-90.0</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>65536</td>\n      <td>1</td>\n      <td>31.273968</td>\n      <td>3863</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_168</td>\n      <td>Histogram Equalization - Histogram Equalization</td>\n      <td>130.006622</td>\n      <td>5328.425232</td>\n      <td>74.273891</td>\n      <td>138.782599</td>\n      <td>-90.0</td>\n      <td>0.605701</td>\n      <td>3</td>\n      <td>65536</td>\n      <td>422</td>\n      <td>72.996063</td>\n      <td>8332</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_168</td>\n      <td>Histogram Equalization - CLAHE</td>\n      <td>120.380508</td>\n      <td>2234.628612</td>\n      <td>48.583296</td>\n      <td>61.975004</td>\n      <td>-90.0</td>\n      <td>0.927273</td>\n      <td>2</td>\n      <td>65536</td>\n      <td>276</td>\n      <td>47.271859</td>\n      <td>5905</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_642</td>\n      <td>Original</td>\n      <td>109.358383</td>\n      <td>1760.960945</td>\n      <td>52.015105</td>\n      <td>56.500502</td>\n      <td>-90.0</td>\n      <td>1.593750</td>\n      <td>2</td>\n      <td>65536</td>\n      <td>161</td>\n      <td>41.963805</td>\n      <td>4931</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_642</td>\n      <td>Histogram Equalization - Histogram Equalization</td>\n      <td>128.542160</td>\n      <td>3610.248460</td>\n      <td>73.686047</td>\n      <td>107.169441</td>\n      <td>-90.0</td>\n      <td>0.861486</td>\n      <td>2</td>\n      <td>65536</td>\n      <td>297</td>\n      <td>60.085343</td>\n      <td>6574</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table for Step 3:\n"
     ]
    },
    {
     "data": {
      "text/plain": "    Image_ID                          Technique  Brightness      Sharpness  \\\n0  Image_168                           Original  102.072388     978.061044   \n1  Image_168    Binarization - Global Threshold   99.049072   44951.731438   \n2  Image_168  Binarization - Adaptive Threshold  201.448288  132966.082076   \n3  Image_168      Binarization - Otsu Threshold  189.689713   16191.738274   \n4  Image_642                           Original  109.358383    1760.960945   \n\n     Contrast        Noise  Skew  Line Spacing  Tables Detected  Resolution  \\\n0   43.181213    32.850364 -90.0      0.000000                1       65536   \n1  124.285135  1352.177491 -90.0      0.639098                1       65536   \n2  103.864819  2584.828339 -90.0      0.087496                1       65536   \n3  111.304491   577.710957 -90.0      0.620438                2       65536   \n4   52.015105    56.500502 -90.0      1.593750                2       65536   \n\n   Detected Elements     Texture  Patterns  \n0                  1   31.273968      3863  \n1                400  212.018234      6651  \n2               2824  364.645145     17617  \n3                412  127.246761      3830  \n4                161   41.963805      4931  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_ID</th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n      <th>Skew</th>\n      <th>Line Spacing</th>\n      <th>Tables Detected</th>\n      <th>Resolution</th>\n      <th>Detected Elements</th>\n      <th>Texture</th>\n      <th>Patterns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_168</td>\n      <td>Original</td>\n      <td>102.072388</td>\n      <td>978.061044</td>\n      <td>43.181213</td>\n      <td>32.850364</td>\n      <td>-90.0</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>65536</td>\n      <td>1</td>\n      <td>31.273968</td>\n      <td>3863</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_168</td>\n      <td>Binarization - Global Threshold</td>\n      <td>99.049072</td>\n      <td>44951.731438</td>\n      <td>124.285135</td>\n      <td>1352.177491</td>\n      <td>-90.0</td>\n      <td>0.639098</td>\n      <td>1</td>\n      <td>65536</td>\n      <td>400</td>\n      <td>212.018234</td>\n      <td>6651</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_168</td>\n      <td>Binarization - Adaptive Threshold</td>\n      <td>201.448288</td>\n      <td>132966.082076</td>\n      <td>103.864819</td>\n      <td>2584.828339</td>\n      <td>-90.0</td>\n      <td>0.087496</td>\n      <td>1</td>\n      <td>65536</td>\n      <td>2824</td>\n      <td>364.645145</td>\n      <td>17617</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_168</td>\n      <td>Binarization - Otsu Threshold</td>\n      <td>189.689713</td>\n      <td>16191.738274</td>\n      <td>111.304491</td>\n      <td>577.710957</td>\n      <td>-90.0</td>\n      <td>0.620438</td>\n      <td>2</td>\n      <td>65536</td>\n      <td>412</td>\n      <td>127.246761</td>\n      <td>3830</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_642</td>\n      <td>Original</td>\n      <td>109.358383</td>\n      <td>1760.960945</td>\n      <td>52.015105</td>\n      <td>56.500502</td>\n      <td>-90.0</td>\n      <td>1.593750</td>\n      <td>2</td>\n      <td>65536</td>\n      <td>161</td>\n      <td>41.963805</td>\n      <td>4931</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table for Step 4:\n"
     ]
    },
    {
     "data": {
      "text/plain": "    Image_ID                            Technique  Brightness   Sharpness  \\\n0  Image_168                             Original  102.072388  978.061044   \n1  Image_168  Morphological Operations - Dilation  110.889069  128.098141   \n2  Image_168   Morphological Operations - Erosion   84.292847  588.418070   \n3  Image_168   Morphological Operations - Opening   97.500473  518.894563   \n4  Image_168   Morphological Operations - Closing  106.481705  128.957677   \n\n    Contrast      Noise  Skew  Line Spacing  Tables Detected  Resolution  \\\n0  43.181213  32.850364 -90.0           0.0                1       65536   \n1  41.176608   6.784680 -90.0           0.0                1       65536   \n2  44.491891  24.163212 -90.0           0.0                1       65536   \n3  43.276082  22.217615 -90.0           0.0                2       65536   \n4  42.070947   6.950182 -90.0           0.0                1       65536   \n\n   Detected Elements    Texture  Patterns  \n0                  1  31.273968      3863  \n1                  1  11.318045      1011  \n2                  1  24.257330      5870  \n3                  1  22.779257      4182  \n4                  1  11.355953      1010  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_ID</th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n      <th>Skew</th>\n      <th>Line Spacing</th>\n      <th>Tables Detected</th>\n      <th>Resolution</th>\n      <th>Detected Elements</th>\n      <th>Texture</th>\n      <th>Patterns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_168</td>\n      <td>Original</td>\n      <td>102.072388</td>\n      <td>978.061044</td>\n      <td>43.181213</td>\n      <td>32.850364</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>65536</td>\n      <td>1</td>\n      <td>31.273968</td>\n      <td>3863</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_168</td>\n      <td>Morphological Operations - Dilation</td>\n      <td>110.889069</td>\n      <td>128.098141</td>\n      <td>41.176608</td>\n      <td>6.784680</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>65536</td>\n      <td>1</td>\n      <td>11.318045</td>\n      <td>1011</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_168</td>\n      <td>Morphological Operations - Erosion</td>\n      <td>84.292847</td>\n      <td>588.418070</td>\n      <td>44.491891</td>\n      <td>24.163212</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>65536</td>\n      <td>1</td>\n      <td>24.257330</td>\n      <td>5870</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_168</td>\n      <td>Morphological Operations - Opening</td>\n      <td>97.500473</td>\n      <td>518.894563</td>\n      <td>43.276082</td>\n      <td>22.217615</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>65536</td>\n      <td>1</td>\n      <td>22.779257</td>\n      <td>4182</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_168</td>\n      <td>Morphological Operations - Closing</td>\n      <td>106.481705</td>\n      <td>128.957677</td>\n      <td>42.070947</td>\n      <td>6.950182</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>65536</td>\n      <td>1</td>\n      <td>11.355953</td>\n      <td>1010</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table for Step 5:\n"
     ]
    },
    {
     "data": {
      "text/plain": "    Image_ID                    Technique  Brightness     Sharpness  \\\n0  Image_168                     Original  102.072388    978.061044   \n1  Image_168  Edge Detection - Canny Edge   15.030899  34312.304874   \n2  Image_168  Edge Detection - Sobel Edge    6.434784   1951.784930   \n3  Image_642                     Original  109.358383   1760.960945   \n4  Image_642  Edge Detection - Canny Edge   19.186478  43328.501895   \n\n    Contrast        Noise  Skew  Line Spacing  Tables Detected  Resolution  \\\n0  43.181213    32.850364 -90.0       0.00000                1       65536   \n1  60.057900  1323.056184 -90.0       0.00000                1       65536   \n2  12.957535    50.027596 -90.0       0.00000                1       65536   \n3  52.015105    56.500502 -90.0       1.59375                2       65536   \n4  67.263890  1583.965897 -90.0       0.00000                1       65536   \n\n   Detected Elements     Texture  Patterns  \n0                  1   31.273968      3863  \n1                  1  185.235809      5242  \n2                  1   44.179010      3702  \n3                161   41.963805      4931  \n4                  1  208.154995      6268  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_ID</th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n      <th>Skew</th>\n      <th>Line Spacing</th>\n      <th>Tables Detected</th>\n      <th>Resolution</th>\n      <th>Detected Elements</th>\n      <th>Texture</th>\n      <th>Patterns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_168</td>\n      <td>Original</td>\n      <td>102.072388</td>\n      <td>978.061044</td>\n      <td>43.181213</td>\n      <td>32.850364</td>\n      <td>-90.0</td>\n      <td>0.00000</td>\n      <td>1</td>\n      <td>65536</td>\n      <td>1</td>\n      <td>31.273968</td>\n      <td>3863</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_168</td>\n      <td>Edge Detection - Canny Edge</td>\n      <td>15.030899</td>\n      <td>34312.304874</td>\n      <td>60.057900</td>\n      <td>1323.056184</td>\n      <td>-90.0</td>\n      <td>0.00000</td>\n      <td>1</td>\n      <td>65536</td>\n      <td>1</td>\n      <td>185.235809</td>\n      <td>5242</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_168</td>\n      <td>Edge Detection - Sobel Edge</td>\n      <td>6.434784</td>\n      <td>1951.784930</td>\n      <td>12.957535</td>\n      <td>50.027596</td>\n      <td>-90.0</td>\n      <td>0.00000</td>\n      <td>1</td>\n      <td>65536</td>\n      <td>1</td>\n      <td>44.179010</td>\n      <td>3702</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_642</td>\n      <td>Original</td>\n      <td>109.358383</td>\n      <td>1760.960945</td>\n      <td>52.015105</td>\n      <td>56.500502</td>\n      <td>-90.0</td>\n      <td>1.59375</td>\n      <td>2</td>\n      <td>65536</td>\n      <td>161</td>\n      <td>41.963805</td>\n      <td>4931</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_642</td>\n      <td>Edge Detection - Canny Edge</td>\n      <td>19.186478</td>\n      <td>43328.501895</td>\n      <td>67.263890</td>\n      <td>1583.965897</td>\n      <td>-90.0</td>\n      <td>0.00000</td>\n      <td>1</td>\n      <td>65536</td>\n      <td>1</td>\n      <td>208.154995</td>\n      <td>6268</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display comparison tables within the notebook\n",
    "for i, comparison_df in enumerate(comparison_tables):\n",
    "    print(f\"Comparison Table for Step {i+1}:\")\n",
    "    display(comparison_df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T14:13:50.177025Z",
     "start_time": "2024-11-13T14:13:50.123026Z"
    }
   },
   "id": "22cfb8654a8557fc",
   "execution_count": 179
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Generate Average Comparison Table\n",
    "average_comparison_data = []\n",
    "for comparison_df in comparison_tables:\n",
    "    avg_stats = comparison_df.groupby(\"Technique\").mean().reset_index()\n",
    "    average_comparison_data.append(avg_stats)\n",
    "\n",
    "# Combine average stats from all steps\n",
    "average_comparison_df = pd.concat(average_comparison_data, ignore_index=True)\n",
    "# Save the average comparison table to a CSV file\n",
    "average_comparison_df.to_csv(\"average_comparison_table.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T14:13:51.204468Z",
     "start_time": "2024-11-13T14:13:51.177466Z"
    }
   },
   "id": "624d20d42c755cc5",
   "execution_count": 180
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                          Technique  Brightness  \\\n0                   Noise Reduction - Gaussian Blur  107.162756   \n1                     Noise Reduction - Median Blur  108.618152   \n2                 Noise Reduction - Non-Local Means  107.536963   \n3                                          Original  107.149319   \n4                    Histogram Equalization - CLAHE  126.506528   \n5   Histogram Equalization - Histogram Equalization  129.341000   \n6                                          Original  107.149319   \n7                 Binarization - Adaptive Threshold  196.684158   \n8                   Binarization - Global Threshold  107.262177   \n9                     Binarization - Otsu Threshold  195.659271   \n10                                         Original  107.149319   \n11               Morphological Operations - Closing  111.718808   \n12              Morphological Operations - Dilation  116.659772   \n13               Morphological Operations - Erosion   89.189844   \n14               Morphological Operations - Opening  102.595728   \n15                                         Original  107.149319   \n16                      Edge Detection - Canny Edge   15.276031   \n17                      Edge Detection - Sobel Edge    6.441840   \n18                                         Original  107.149319   \n\n        Sharpness    Contrast        Noise  Skew  Line Spacing  \\\n0       24.681440   41.958559     1.128670 -90.0      8.009615   \n1       95.788121   42.708486     4.916750 -90.0     11.079617   \n2      482.279009   42.909078    21.262351 -90.0     19.660569   \n3     1042.807841   43.318449    34.524881 -90.0     52.286640   \n4     2404.716668   47.830540    66.324622 -72.0      0.704711   \n5     4132.136154   74.116035   118.173999 -90.0      0.801573   \n6     1042.807841   43.318449    34.524881 -90.0     52.286640   \n7   130853.866491  107.010438  2507.259614 -36.0      0.102801   \n8    37629.083617  125.651187  1189.211578 -90.0      0.779416   \n9    17345.278201  107.277268   623.156986 -72.0      0.902003   \n10    1042.807841   43.318449    34.524881 -90.0     52.286640   \n11     130.919410   42.198184     6.766485 -90.0     42.570000   \n12     138.736504   40.394424     7.203136 -90.0     16.635714   \n13     639.030252   45.984433    26.183838 -90.0     27.610000   \n14     559.835454   43.509737    23.678647 -90.0     27.388889   \n15    1042.807841   43.318449    34.524881 -90.0     52.286640   \n16   34669.139811   59.988003  1314.548009 -90.0      0.000000   \n17    2017.968337   13.094296    52.659723 -90.0      0.000000   \n18    1042.807841   43.318449    34.524881 -90.0     52.286640   \n\n    Tables Detected  Resolution  Detected Elements     Texture  Patterns  \n0               2.0     65536.0               13.6    4.926009    1221.8  \n1               1.4     65536.0               14.6    9.712208    1176.2  \n2               1.6     65536.0               11.8   21.061042    2284.2  \n3               1.8     65536.0               75.4   31.465931    3926.0  \n4               2.2     65536.0              379.8   48.158238    6535.8  \n5               2.4     65536.0              331.4   63.944852    7529.8  \n6               1.8     65536.0               75.4   31.465931    3926.0  \n7               1.8     65536.0             2512.6  361.378629   18201.2  \n8               1.4     65536.0              340.0  193.481037    5701.0  \n9               1.8     65536.0              369.6  129.692905    3767.0  \n10              1.8     65536.0               75.4   31.465931    3926.0  \n11              0.8     65536.0                4.2   11.404722    1171.8  \n12              1.8     65536.0                6.8   11.721110    1181.6  \n13              2.0     65536.0                5.4   24.620653    5177.0  \n14              2.2     65536.0                6.8   23.014468    3837.0  \n15              1.8     65536.0               75.4   31.465931    3926.0  \n16              1.6     65536.0                1.0  184.431175    5411.4  \n17              1.8     65536.0                1.0   43.540198    3451.8  \n18              1.8     65536.0               75.4   31.465931    3926.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n      <th>Skew</th>\n      <th>Line Spacing</th>\n      <th>Tables Detected</th>\n      <th>Resolution</th>\n      <th>Detected Elements</th>\n      <th>Texture</th>\n      <th>Patterns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Noise Reduction - Gaussian Blur</td>\n      <td>107.162756</td>\n      <td>24.681440</td>\n      <td>41.958559</td>\n      <td>1.128670</td>\n      <td>-90.0</td>\n      <td>8.009615</td>\n      <td>2.0</td>\n      <td>65536.0</td>\n      <td>13.6</td>\n      <td>4.926009</td>\n      <td>1221.8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Noise Reduction - Median Blur</td>\n      <td>108.618152</td>\n      <td>95.788121</td>\n      <td>42.708486</td>\n      <td>4.916750</td>\n      <td>-90.0</td>\n      <td>11.079617</td>\n      <td>1.4</td>\n      <td>65536.0</td>\n      <td>14.6</td>\n      <td>9.712208</td>\n      <td>1176.2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Noise Reduction - Non-Local Means</td>\n      <td>107.536963</td>\n      <td>482.279009</td>\n      <td>42.909078</td>\n      <td>21.262351</td>\n      <td>-90.0</td>\n      <td>19.660569</td>\n      <td>1.6</td>\n      <td>65536.0</td>\n      <td>11.8</td>\n      <td>21.061042</td>\n      <td>2284.2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Original</td>\n      <td>107.149319</td>\n      <td>1042.807841</td>\n      <td>43.318449</td>\n      <td>34.524881</td>\n      <td>-90.0</td>\n      <td>52.286640</td>\n      <td>1.8</td>\n      <td>65536.0</td>\n      <td>75.4</td>\n      <td>31.465931</td>\n      <td>3926.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Histogram Equalization - CLAHE</td>\n      <td>126.506528</td>\n      <td>2404.716668</td>\n      <td>47.830540</td>\n      <td>66.324622</td>\n      <td>-72.0</td>\n      <td>0.704711</td>\n      <td>2.2</td>\n      <td>65536.0</td>\n      <td>379.8</td>\n      <td>48.158238</td>\n      <td>6535.8</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Histogram Equalization - Histogram Equalization</td>\n      <td>129.341000</td>\n      <td>4132.136154</td>\n      <td>74.116035</td>\n      <td>118.173999</td>\n      <td>-90.0</td>\n      <td>0.801573</td>\n      <td>2.4</td>\n      <td>65536.0</td>\n      <td>331.4</td>\n      <td>63.944852</td>\n      <td>7529.8</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Original</td>\n      <td>107.149319</td>\n      <td>1042.807841</td>\n      <td>43.318449</td>\n      <td>34.524881</td>\n      <td>-90.0</td>\n      <td>52.286640</td>\n      <td>1.8</td>\n      <td>65536.0</td>\n      <td>75.4</td>\n      <td>31.465931</td>\n      <td>3926.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Binarization - Adaptive Threshold</td>\n      <td>196.684158</td>\n      <td>130853.866491</td>\n      <td>107.010438</td>\n      <td>2507.259614</td>\n      <td>-36.0</td>\n      <td>0.102801</td>\n      <td>1.8</td>\n      <td>65536.0</td>\n      <td>2512.6</td>\n      <td>361.378629</td>\n      <td>18201.2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Binarization - Global Threshold</td>\n      <td>107.262177</td>\n      <td>37629.083617</td>\n      <td>125.651187</td>\n      <td>1189.211578</td>\n      <td>-90.0</td>\n      <td>0.779416</td>\n      <td>1.4</td>\n      <td>65536.0</td>\n      <td>340.0</td>\n      <td>193.481037</td>\n      <td>5701.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Binarization - Otsu Threshold</td>\n      <td>195.659271</td>\n      <td>17345.278201</td>\n      <td>107.277268</td>\n      <td>623.156986</td>\n      <td>-72.0</td>\n      <td>0.902003</td>\n      <td>1.8</td>\n      <td>65536.0</td>\n      <td>369.6</td>\n      <td>129.692905</td>\n      <td>3767.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Original</td>\n      <td>107.149319</td>\n      <td>1042.807841</td>\n      <td>43.318449</td>\n      <td>34.524881</td>\n      <td>-90.0</td>\n      <td>52.286640</td>\n      <td>1.8</td>\n      <td>65536.0</td>\n      <td>75.4</td>\n      <td>31.465931</td>\n      <td>3926.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Morphological Operations - Closing</td>\n      <td>111.718808</td>\n      <td>130.919410</td>\n      <td>42.198184</td>\n      <td>6.766485</td>\n      <td>-90.0</td>\n      <td>42.570000</td>\n      <td>0.8</td>\n      <td>65536.0</td>\n      <td>4.2</td>\n      <td>11.404722</td>\n      <td>1171.8</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Morphological Operations - Dilation</td>\n      <td>116.659772</td>\n      <td>138.736504</td>\n      <td>40.394424</td>\n      <td>7.203136</td>\n      <td>-90.0</td>\n      <td>16.635714</td>\n      <td>1.8</td>\n      <td>65536.0</td>\n      <td>6.8</td>\n      <td>11.721110</td>\n      <td>1181.6</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Morphological Operations - Erosion</td>\n      <td>89.189844</td>\n      <td>639.030252</td>\n      <td>45.984433</td>\n      <td>26.183838</td>\n      <td>-90.0</td>\n      <td>27.610000</td>\n      <td>2.0</td>\n      <td>65536.0</td>\n      <td>5.4</td>\n      <td>24.620653</td>\n      <td>5177.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Morphological Operations - Opening</td>\n      <td>102.595728</td>\n      <td>559.835454</td>\n      <td>43.509737</td>\n      <td>23.678647</td>\n      <td>-90.0</td>\n      <td>27.388889</td>\n      <td>2.2</td>\n      <td>65536.0</td>\n      <td>6.8</td>\n      <td>23.014468</td>\n      <td>3837.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Original</td>\n      <td>107.149319</td>\n      <td>1042.807841</td>\n      <td>43.318449</td>\n      <td>34.524881</td>\n      <td>-90.0</td>\n      <td>52.286640</td>\n      <td>1.8</td>\n      <td>65536.0</td>\n      <td>75.4</td>\n      <td>31.465931</td>\n      <td>3926.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Edge Detection - Canny Edge</td>\n      <td>15.276031</td>\n      <td>34669.139811</td>\n      <td>59.988003</td>\n      <td>1314.548009</td>\n      <td>-90.0</td>\n      <td>0.000000</td>\n      <td>1.6</td>\n      <td>65536.0</td>\n      <td>1.0</td>\n      <td>184.431175</td>\n      <td>5411.4</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Edge Detection - Sobel Edge</td>\n      <td>6.441840</td>\n      <td>2017.968337</td>\n      <td>13.094296</td>\n      <td>52.659723</td>\n      <td>-90.0</td>\n      <td>0.000000</td>\n      <td>1.8</td>\n      <td>65536.0</td>\n      <td>1.0</td>\n      <td>43.540198</td>\n      <td>3451.8</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Original</td>\n      <td>107.149319</td>\n      <td>1042.807841</td>\n      <td>43.318449</td>\n      <td>34.524881</td>\n      <td>-90.0</td>\n      <td>52.286640</td>\n      <td>1.8</td>\n      <td>65536.0</td>\n      <td>75.4</td>\n      <td>31.465931</td>\n      <td>3926.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_comparison_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T14:13:52.057687Z",
     "start_time": "2024-11-13T14:13:52.022682Z"
    }
   },
   "id": "fe7133144103efbc",
   "execution_count": 181
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5d61986dc386f3b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning Function\n",
    "def hyperparameter_tuning(images, best_techniques_list, param_grids, evaluation_function):\n",
    "    tuned_results = {}\n",
    "    for step_name, technique_name, best_technique_func in best_techniques_list:\n",
    "        print(f\"\\nHyperparameter Tuning for Step: {step_name}\\n{'-' * 40}\")\n",
    "        best_params = None\n",
    "        best_score = -np.inf\n",
    "        param_grid = param_grids.get(technique_name, [])\n",
    "\n",
    "        for params in param_grid:\n",
    "            total_score = 0\n",
    "            for img, img_id in zip(images, test_image_ids):\n",
    "                try:\n",
    "                    # Apply the best technique with the given parameters explicitly based on technique name\n",
    "                    if technique_name == \"Gaussian Blur\":\n",
    "                        processed_image = apply_gaussian_blur(img, **params)\n",
    "                    elif technique_name == \"Median Blur\":\n",
    "                        processed_image = apply_median_blur(img, **params)\n",
    "                    elif technique_name == \"Non-Local Means\":\n",
    "                        processed_image = apply_non_local_means(img, **params)\n",
    "                    elif technique_name == \"CLAHE\":\n",
    "                        processed_image = apply_clahe(img, **params)\n",
    "                    elif technique_name == \"Global Threshold\":\n",
    "                        processed_image = apply_global_threshold(img, **params)\n",
    "                    elif technique_name == \"Adaptive Threshold\":\n",
    "                        processed_image = apply_adaptive_threshold(img, **params)\n",
    "                    elif technique_name == \"Otsu Threshold\":\n",
    "                        processed_image = apply_otsu_threshold(img)\n",
    "                    elif technique_name == \"Dilation\":\n",
    "                        processed_image = apply_dilation(img, **params)\n",
    "                    elif technique_name == \"Erosion\":\n",
    "                        processed_image = apply_erosion(img, **params)\n",
    "                    elif technique_name == \"Morphological Opening\":\n",
    "                        processed_image = apply_opening(img, **params)\n",
    "                    elif technique_name == \"Morphological Closing\":\n",
    "                        processed_image = apply_closing(img, **params)\n",
    "                    elif technique_name == \"Canny Edge\":\n",
    "                        processed_image = apply_canny_edge(img, **params)\n",
    "                    elif technique_name == \"Sobel Edge\":\n",
    "                        processed_image = apply_sobel_edge(img, **params)\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unknown technique: {technique_name}\")\n",
    "\n",
    "                except TypeError as e:\n",
    "                    print(f\"Skipping parameters {params} due to TypeError: {e}\")\n",
    "                    continue\n",
    "\n",
    "                # Retrieve original stats for comparison\n",
    "                original_stats = images_stats_df[images_stats_df['Image'] == img_id].iloc[0].to_dict()\n",
    "                evaluation_result = evaluation_function(processed_image, {technique_name: best_technique_func}, original_stats)\n",
    "                step_score = evaluation_result[\"Evaluation Results\"][technique_name][\"Score\"]\n",
    "                total_score += step_score\n",
    "\n",
    "            avg_score = total_score / len(images) if len(images) > 0 else -np.inf\n",
    "\n",
    "            if avg_score > best_score:\n",
    "                best_score = avg_score\n",
    "                best_params = params\n",
    "\n",
    "            print(f\"Parameters: {params}, Score: {avg_score}\")\n",
    "\n",
    "        tuned_results[step_name] = {\n",
    "            \"Best Parameters\": best_params,\n",
    "            \"Best Score\": best_score\n",
    "        }\n",
    "        print(f\"Best Parameters for {step_name}: {best_params} with Score: {best_score}\\n\")\n",
    "\n",
    "    return tuned_results\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T14:13:53.526683Z",
     "start_time": "2024-11-13T14:13:53.503683Z"
    }
   },
   "id": "ad8595b15fd7fa24",
   "execution_count": 182
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Explanation of Techniques and Parameters\n",
    "\n",
    "##### 1. Noise Reduction\n",
    "###### Gaussian Blur (`ksize`)\n",
    "- **Parameter**: `ksize` (kernel size)\n",
    "- **Meaning**: Defines the extent of smoothing applied. A small kernel (e.g., `(3, 3)`) produces minimal blurring, preserving details, while larger kernels (e.g., `(9, 9)`) apply more significant blurring, which is useful for reducing noise but may remove finer details.\n",
    "- **Range**:\n",
    "  - `(3, 3)`, `(5, 5)`, `(7, 7)`, `(9, 9)`\n",
    "  - Smaller sizes preserve more details, larger sizes reduce noise more aggressively.\n",
    "\n",
    "###### Non-Local Means (`h`, `templateWindowSize`, `searchWindowSize`)\n",
    "- **Parameters**:\n",
    "  - `h`: Filtering strength (higher values = stronger filtering).\n",
    "  - `templateWindowSize`: Size of the patch used for comparison.\n",
    "  - `searchWindowSize`: Size of the window around the pixel for searching similar patches.\n",
    "- **Range**:\n",
    "  - `h`: `5`, `10`, `15`, `20`\n",
    "  - `templateWindowSize`: `7`, `10`\n",
    "  - `searchWindowSize`: `21`, `31`\n",
    "  - Balances noise reduction quality and processing time.\n",
    "\n",
    "###### Median Blur (`ksize`)\n",
    "- **Parameter**: `ksize` (kernel size)\n",
    "- **Meaning**: Reduces \"salt-and-pepper\" noise by replacing each pixel with the median of neighboring pixels. Larger kernels apply stronger noise reduction, potentially losing details.\n",
    "- **Range**:\n",
    "  - `3`, `5`, `7`, `9`\n",
    "  - Smaller values (`3`, `5`) are useful for mild noise; larger values (`7`, `9`) are effective for more significant noise.\n",
    "\n",
    "##### 2. Histogram Equalization\n",
    "###### CLAHE (`clipLimit`, `tileGridSize`)\n",
    "- **Parameters**:\n",
    "  - `clipLimit`: Controls contrast enhancement limit.\n",
    "  - `tileGridSize`: Size of the grid for local histogram equalization.\n",
    "- **Range**:\n",
    "  - `clipLimit`: `2.0` to `6.0`\n",
    "  - `tileGridSize`: `(4, 4)`, `(6, 6)`, `(8, 8)`\n",
    "  - Lower `clipLimit` values reduce noise amplification, larger `tileGridSize` produces smoother results.\n",
    "\n",
    "##### 3. Binarization\n",
    "###### Global Threshold (`thresholdValue`)\n",
    "- **Parameter**: `thresholdValue`\n",
    "- **Meaning**: Used to convert grayscale images to binary by comparing pixel values to a threshold. Lower values produce more white areas.\n",
    "- **Range**:\n",
    "  - `100`, `127`, `150`, `200`\n",
    "  - Balances the separation between foreground and background.\n",
    "\n",
    "###### Adaptive Threshold (`adaptiveMethod`, `blockSize`, `C`)\n",
    "- **Parameters**:\n",
    "  - `adaptiveMethod`: The method used for calculating the threshold (`cv2.ADAPTIVE_THRESH_MEAN_C` or `cv2.ADAPTIVE_THRESH_GAUSSIAN_C`).\n",
    "  - `blockSize`: Size of the local area considered for thresholding.\n",
    "  - `C`: Constant subtracted from the mean or weighted sum.\n",
    "- **Range**:\n",
    "  - `adaptiveMethod`: `cv2.ADAPTIVE_THRESH_MEAN_C` or `cv2.ADAPTIVE_THRESH_GAUSSIAN_C`\n",
    "  - `blockSize`: `11`, `15`\n",
    "  - `C`: `2`, `3`\n",
    "  - Allows adjustment to local image variations for better segmentation.\n",
    "\n",
    "##### 4. Morphological Operations\n",
    "###### Operation (`MORPH_OPEN`, `MORPH_CLOSE`, `DILATE`, `ERODE`, `kernel_size`)\n",
    "- **Parameters**:\n",
    "  - `operation`: The morphological transformation to apply.\n",
    "    - `cv2.MORPH_OPEN`: Removes small white noise.\n",
    "    - `cv2.MORPH_CLOSE`: Fills small black gaps in white areas.\n",
    "    - `cv2.MORPH_DILATE`: Expands white areas to connect small features.\n",
    "    - `cv2.MORPH_ERODE`: Shrinks white areas to reduce noise.\n",
    "  - `kernel_size`: Size of the structuring element.\n",
    "- **Range**:\n",
    "  - `kernel_size`: `(3, 3)`, `(5, 5)`, `(7, 7)`, `(9, 9)`\n",
    "  - Larger kernels apply more aggressive changes for connecting, removing, or shrinking features.\n",
    "\n",
    "##### 5. Edge Detection\n",
    "###### Canny Edge Detection (`threshold1`, `threshold2`)\n",
    "- **Parameters**:\n",
    "  - `threshold1`: Lower threshold for weak edges.\n",
    "  - `threshold2`: Upper threshold for strong edges.\n",
    "- **Range**:\n",
    "  - `threshold1` and `threshold2`: `(50, 150)`, `(100, 200)`, `(150, 250)`, `(200, 300)`\n",
    "  - Lower values detect more edges, useful for detailed images; higher values highlight stronger, more defined edges.\n",
    "\n",
    "###### Sobel Edge Detection (`ksize`, `scale`, `delta`, `borderType`)\n",
    "- **Parameters**:\n",
    "  - `ksize`: Kernel size for the Sobel operator.\n",
    "  - `scale`: Scaling factor for gradients.\n",
    "  - `delta`: Value added to the result.\n",
    "  - `borderType`: Border handling for edges.\n",
    "- **Range**:\n",
    "  - `ksize`: `3`, `5`, `7`\n",
    "  - `scale`: `1`, `2`\n",
    "  - `delta`: `0` (default)\n",
    "  - `borderType`: `cv2.BORDER_DEFAULT`\n",
    "  - Adjusts the level of detail and sharpness captured by the filter.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55d2b04c1e9428ca"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define expanded parameter grids for hyperparameter tuning for each technique\n",
    "technique_param_grids = {\n",
    "    # Noise Reduction Techniques Parameters\n",
    "    # Gaussian Blur - kernel size affects the degree of blurring\n",
    "    \"Gaussian Blur\": [\n",
    "        {\"ksize\": (3, 3)},  # Small blur, preserves more details while reducing minor noise\n",
    "        {\"ksize\": (5, 5)},  # Moderate blur, balances noise reduction and detail preservation\n",
    "        {\"ksize\": (7, 7)},  # Stronger blur, reduces more noise but may lose more details\n",
    "        {\"ksize\": (9, 9)}   # High blur, significant reduction of noise, more detail loss\n",
    "    ],\n",
    "\n",
    "    # Median Blur - kernel size affects the reduction of salt-and-pepper noise\n",
    "    \"Median Blur\": [\n",
    "        {\"ksize\": 3},  # Small kernel, effective for minor salt-and-pepper noise\n",
    "        {\"ksize\": 5},  # Moderate kernel, more aggressive noise reduction\n",
    "        {\"ksize\": 7},  # Large kernel, used for significant salt-and-pepper noise reduction\n",
    "        {\"ksize\": 9}   # Largest kernel, aggressive noise reduction but may lose finer details\n",
    "    ],\n",
    "\n",
    "    # Non-Local Means - affects noise reduction strength and quality\n",
    "    \"Non-Local Means\": [\n",
    "        {\"h\": 5, \"templateWindowSize\": 7, \"searchWindowSize\": 21},   # Low filter strength (h), smaller template\n",
    "        {\"h\": 10, \"templateWindowSize\": 7, \"searchWindowSize\": 21},  # Moderate filter strength (h), balance of denoising and details\n",
    "        {\"h\": 15, \"templateWindowSize\": 7, \"searchWindowSize\": 21},  # Strong filter strength, more noise reduction but risk of over-smoothing\n",
    "        {\"h\": 20, \"templateWindowSize\": 10, \"searchWindowSize\": 31}  # Higher strength and larger search windows for stronger denoising\n",
    "    ],\n",
    "\n",
    "    # Histogram Equalization Techniques Parameters\n",
    "    # CLAHE - clip limit controls contrast, tile grid size controls local regions\n",
    "    \"CLAHE\": [\n",
    "        {\"clipLimit\": 2.0, \"tileGridSize\": (8, 8)},  # Low clip limit, preserves global contrast, effective for mild contrast enhancement\n",
    "        {\"clipLimit\": 3.0, \"tileGridSize\": (8, 8)},  # Moderate clip limit, better enhancement for darker/lighter regions\n",
    "        {\"clipLimit\": 4.0, \"tileGridSize\": (4, 4)},  # Higher clip limit, can lead to artifacts but increases local contrast\n",
    "        {\"clipLimit\": 5.0, \"tileGridSize\": (6, 6)}   # High clip limit, strong local contrast enhancement\n",
    "    ],\n",
    "\n",
    "    # Binarization Techniques Parameters\n",
    "    # Global Threshold - value for the threshold, used to separate foreground from background\n",
    "    \"Global Threshold\": [\n",
    "        {\"thresholdValue\": 100},  # Low threshold, makes more areas white, may overexpose\n",
    "        {\"thresholdValue\": 127},  # Middle threshold, balance between foreground and background\n",
    "        {\"thresholdValue\": 150},  # High threshold, less white, more black areas\n",
    "        {\"thresholdValue\": 200}   # Higher threshold, darkest parts retained as foreground\n",
    "    ],\n",
    "\n",
    "    # Adaptive Threshold - block size and constant C, used for adaptive thresholding\n",
    "    \"Adaptive Threshold\": [\n",
    "        {\"adaptiveMethod\": cv2.ADAPTIVE_THRESH_MEAN_C, \"blockSize\": 11, \"C\": 2},  # Small block size, captures smaller variations\n",
    "        {\"adaptiveMethod\": cv2.ADAPTIVE_THRESH_MEAN_C, \"blockSize\": 15, \"C\": 3},  # Larger block size, averages larger areas\n",
    "        {\"adaptiveMethod\": cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \"blockSize\": 11, \"C\": 2},  # Gaussian weighting, better for uneven lighting\n",
    "        {\"adaptiveMethod\": cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \"blockSize\": 15, \"C\": 3}   # Larger area, smoother output\n",
    "    ],\n",
    "\n",
    "    \"Otsu Threshold\": [\n",
    "        {}  # No parameters needed, automatic threshold selection\n",
    "    ],\n",
    "\n",
    "    # Morphological Operations Techniques Parameters\n",
    "    # Dilation - kernel size affects how much an object is expanded, helps to highlight and connect features in the image\n",
    "    \"Dilation\": [\n",
    "        {\"kernel_size\": (3, 3)},  # Small kernel, slight expansion of features\n",
    "        {\"kernel_size\": (5, 5)},  # Medium kernel, moderate expansion, often used to fill small holes\n",
    "        {\"kernel_size\": (7, 7)},  # Larger kernel, more significant expansion, fills larger gaps\n",
    "        {\"kernel_size\": (9, 9)}   # Largest kernel, aggressive expansion, can connect disjoint parts\n",
    "    ],\n",
    "\n",
    "    # Erosion - kernel size affects how much an object is eroded, used to reduce noise by shrinking foreground areas\n",
    "    \"Erosion\": [\n",
    "        {\"kernel_size\": (3, 3)},  # Small kernel, minimal shrinking of features\n",
    "        {\"kernel_size\": (5, 5)},  # Medium kernel, reduces small noise while keeping the main features intact\n",
    "        {\"kernel_size\": (7, 7)},  # Larger kernel, removes more fine details, useful for stronger noise reduction\n",
    "        {\"kernel_size\": (9, 9)}   # Largest kernel, aggressive erosion, may result in significant information loss\n",
    "    ],\n",
    "\n",
    "    # Morphological Opening - kernel size affects noise removal, used for removing small white noise from black backgrounds\n",
    "    \"Morphological Opening\": [\n",
    "        {\"kernel_size\": (3, 3)},  # Small kernel, removes small white noise but keeps the main structure\n",
    "        {\"kernel_size\": (5, 5)},  # Medium kernel, better noise removal, may affect finer details\n",
    "        {\"kernel_size\": (7, 7)}   # Larger kernel, stronger noise reduction, potentially removes small features\n",
    "    ],\n",
    "\n",
    "    # Morphological Closing - kernel size affects how gaps in foreground objects are filled, used to close small black holes within objects\n",
    "    \"Morphological Closing\": [\n",
    "        {\"kernel_size\": (3, 3)},  # Small kernel, fills tiny holes, maintains object shape\n",
    "        {\"kernel_size\": (5, 5)},  # Medium kernel, closes medium-sized gaps, useful for refining object borders\n",
    "        {\"kernel_size\": (7, 7)}   # Larger kernel, aggressively closes gaps, useful for solidifying larger structures\n",
    "    ],\n",
    "\n",
    "    # Edge Detection Techniques Parameters\n",
    "    # Canny Edge Detection - lower and upper thresholds for edge linking\n",
    "    \"Canny Edge\": [\n",
    "        {\"threshold1\": 50, \"threshold2\": 150},  # Low thresholds, more edges detected\n",
    "        {\"threshold1\": 100, \"threshold2\": 200},  # Moderate thresholds, balanced edge detection\n",
    "        {\"threshold1\": 150, \"threshold2\": 250},  # High thresholds, only strong edges detected\n",
    "        {\"threshold1\": 200, \"threshold2\": 300}   # Very high thresholds, detects fewer edges, focused on major features\n",
    "    ],\n",
    "\n",
    "    # Sobel Edge - kernel size, scale, delta, border type for Sobel edge detection\n",
    "    \"Sobel Edge\": [\n",
    "        {\"ksize\": 3, \"scale\": 1, \"delta\": 0, \"borderType\": cv2.BORDER_DEFAULT},  # Small kernel, detects finer details\n",
    "        {\"ksize\": 5, \"scale\": 1, \"delta\": 0, \"borderType\": cv2.BORDER_DEFAULT},  # Medium kernel, balances detail and noise suppression\n",
    "        {\"ksize\": 7, \"scale\": 1, \"delta\": 0, \"borderType\": cv2.BORDER_DEFAULT},  # Larger kernel, captures broader gradients\n",
    "        {\"ksize\": 3, \"scale\": 2, \"delta\": 0, \"borderType\": cv2.BORDER_DEFAULT}   # Increased scale, emphasizes detected gradients more strongly\n",
    "    ]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T14:13:55.698685Z",
     "start_time": "2024-11-13T14:13:55.672685Z"
    }
   },
   "id": "5fa67a991c4e1ef8",
   "execution_count": 185
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyperparameter Tuning for Step: Noise Reduction\n",
      "----------------------------------------\n",
      "Parameters: {'h': 5, 'templateWindowSize': 7, 'searchWindowSize': 21}, Score: -3.394338295790815\n",
      "Parameters: {'h': 10, 'templateWindowSize': 7, 'searchWindowSize': 21}, Score: -4.059359032202847\n",
      "Parameters: {'h': 15, 'templateWindowSize': 7, 'searchWindowSize': 21}, Score: -5.247716101937137\n",
      "Parameters: {'h': 20, 'templateWindowSize': 10, 'searchWindowSize': 31}, Score: -5.834622915628669\n",
      "Best Parameters for Noise Reduction: {'h': 5, 'templateWindowSize': 7, 'searchWindowSize': 21} with Score: -3.394338295790815\n",
      "\n",
      "\n",
      "Hyperparameter Tuning for Step: Histogram Equalization\n",
      "----------------------------------------\n",
      "Best Parameters for Histogram Equalization: None with Score: -inf\n",
      "\n",
      "\n",
      "Hyperparameter Tuning for Step: Binarization\n",
      "----------------------------------------\n",
      "Parameters: {'adaptiveMethod': 0, 'blockSize': 11, 'C': 2}, Score: 248.50167325414412\n",
      "Parameters: {'adaptiveMethod': 0, 'blockSize': 15, 'C': 3}, Score: 173.1955192069313\n",
      "Parameters: {'adaptiveMethod': 1, 'blockSize': 11, 'C': 2}, Score: 286.5825205340362\n",
      "Parameters: {'adaptiveMethod': 1, 'blockSize': 15, 'C': 3}, Score: 197.5142192539035\n",
      "Best Parameters for Binarization: {'adaptiveMethod': 1, 'blockSize': 11, 'C': 2} with Score: 286.5825205340362\n",
      "\n",
      "\n",
      "Hyperparameter Tuning for Step: Morphological Operations\n",
      "----------------------------------------\n",
      "Parameters: {'kernel_size': (3, 3)}, Score: -1.0354956534619517\n",
      "Parameters: {'kernel_size': (5, 5)}, Score: -2.106134089004875\n",
      "Parameters: {'kernel_size': (7, 7)}, Score: -2.895634749213236\n",
      "Parameters: {'kernel_size': (9, 9)}, Score: -3.1034133778044732\n",
      "Best Parameters for Morphological Operations: {'kernel_size': (3, 3)} with Score: -1.0354956534619517\n",
      "\n",
      "\n",
      "Hyperparameter Tuning for Step: Edge Detection\n",
      "----------------------------------------\n",
      "Parameters: {'threshold1': 50, 'threshold2': 150}, Score: 139.47192053196855\n",
      "Parameters: {'threshold1': 100, 'threshold2': 200}, Score: 102.07115287545972\n",
      "Parameters: {'threshold1': 150, 'threshold2': 250}, Score: 69.69583429895621\n",
      "Parameters: {'threshold1': 200, 'threshold2': 300}, Score: 43.41511256013517\n",
      "Best Parameters for Edge Detection: {'threshold1': 50, 'threshold2': 150} with Score: 139.47192053196855\n",
      "\n",
      "\n",
      "Tuned Results:\n",
      "Noise Reduction: Best Parameters: {'h': 5, 'templateWindowSize': 7, 'searchWindowSize': 21}, Best Score: -3.394338295790815\n",
      "Histogram Equalization: Best Parameters: None, Best Score: -inf\n",
      "Binarization: Best Parameters: {'adaptiveMethod': 1, 'blockSize': 11, 'C': 2}, Best Score: 286.5825205340362\n",
      "Morphological Operations: Best Parameters: {'kernel_size': (3, 3)}, Best Score: -1.0354956534619517\n",
      "Edge Detection: Best Parameters: {'threshold1': 50, 'threshold2': 150}, Best Score: 139.47192053196855\n"
     ]
    }
   ],
   "source": [
    "# Run hyperparameter tuning\n",
    "tuned_results = hyperparameter_tuning(test_images, best_techniques_list, technique_param_grids, advanced_evaluation)\n",
    "print(\"\\nTuned Results:\")\n",
    "\n",
    "for step_name, result in tuned_results.items():\n",
    "    print(f\"{step_name}: Best Parameters: {result['Best Parameters']}, Best Score: {result['Best Score']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T14:14:04.615123Z",
     "start_time": "2024-11-13T14:13:56.837684Z"
    }
   },
   "id": "8c9a00a06b7381b7",
   "execution_count": 186
  },
  {
   "cell_type": "markdown",
   "source": [
    "Interpretations of results:\n",
    "Let's break down and interpret the hyperparameter tuning results for each step. Here's what each section tells us:\n",
    "\n",
    "### **1. Noise Reduction: Non-Local Means**\n",
    "- **Best Parameters**: `{'h': 5, 'templateWindowSize': 7, 'searchWindowSize': 21}`\n",
    "- **Best Score**: `-3.39`\n",
    "\n",
    "**Interpretation**:\n",
    "- Non-Local Means was selected as the best noise reduction technique.\n",
    "- The negative score (`-3.39`) indicates that this technique resulted in changes that deviated from the original characteristics, but this was the least deviation compared to other parameter combinations. Lower `h` values (`h=5`) seemed to perform better because stronger denoising (higher `h` values) tends to over-smooth the image, resulting in a higher deviation from the original characteristics.\n",
    "\n",
    "### **2. Histogram Equalization: Histogram Equalization**\n",
    "- **Best Parameters**: `None`\n",
    "- **Best Score**: `-inf`\n",
    "\n",
    "**Interpretation**:\n",
    "- The hyperparameter tuning for histogram equalization did not find any parameters to improve upon, which suggests that the default parameters might be unsuitable for improving the metrics used in the scoring function. The score of `-inf` means no improvement was achieved, potentially due to the technique either not being applicable or beneficial to the specific image characteristics being targeted.\n",
    "\n",
    "### **3. Binarization: Adaptive Threshold**\n",
    "- **Best Parameters**: `{'adaptiveMethod': 1, 'blockSize': 11, 'C': 2}`\n",
    "- **Best Score**: `286.58`\n",
    "\n",
    "**Interpretation**:\n",
    "- The adaptive threshold technique with Gaussian adaptive method (`adaptiveMethod=1`), smaller block size (`blockSize=11`), and constant (`C=2`) yielded the highest score of `286.58`.\n",
    "- This positive score indicates that the chosen parameter combination effectively enhanced the image in ways the evaluation function rewards, such as increased contrast, sharpness, and detection of elements. Smaller block sizes are likely capturing more local variations, leading to higher scores.\n",
    "\n",
    "### **4. Morphological Operations: Erosion**\n",
    "- **Best Parameters**: `{'kernel_size': (3, 3)}`\n",
    "- **Best Score**: `-1.03`\n",
    "\n",
    "**Interpretation**:\n",
    "- Erosion was selected as the best morphological operation.\n",
    "- A kernel size of `(3, 3)` yielded the least negative score (`-1.03`), indicating that this parameter minimally affected the original characteristics while performing the morphological operation. Larger kernel sizes (`(5, 5)`, `(7, 7)`, `(9, 9)`) resulted in more deviation, which aligns with the idea that stronger erosion could overly reduce relevant structures in the image, negatively affecting its characteristics.\n",
    "\n",
    "### **5. Edge Detection: Canny Edge**\n",
    "- **Best Parameters**: `{'threshold1': 50, 'threshold2': 150}`\n",
    "- **Best Score**: `139.47`\n",
    "\n",
    "**Interpretation**:\n",
    "- The Canny edge detection method performed best with thresholds of `50` and `150`, yielding a positive score of `139.47`.\n",
    "- Lower thresholds (`threshold1=50`, `threshold2=150`) produced a better score because more edges were detected, contributing positively to metrics such as detected elements, texture, and patterns. Increasing the thresholds tended to reduce the number of detected edges, which led to lower scores.\n",
    "\n",
    "### **Summary & Key Insights**:\n",
    "\n",
    "1. **Negative Scores**:\n",
    "   - Negative scores (e.g., Noise Reduction and Morphological Operations) indicate that the processed image deviated from the original characteristics in ways that were detrimental based on the evaluation metrics.\n",
    "   - The least negative scores represent the best parameters that resulted in minimal detrimental changes.\n",
    "\n",
    "2. **Positive Scores**:\n",
    "   - Positive scores (e.g., Binarization and Edge Detection) indicate improvements in metrics such as contrast, sharpness, and detection of elements.\n",
    "   - Techniques with higher positive scores effectively enhanced the quality of the image by improving certain desired features.\n",
    "\n",
    "3. **Histogram Equalization Issue**:\n",
    "   - The score of `-inf` for histogram equalization indicates that the technique wasn't effective, and the parameter space may need to be reconsidered. It might also be that this step doesn't add value for these particular images.\n",
    "\n",
    "4. **Best Techniques Overview**:\n",
    "   - For each step, the parameter combination that had the highest score (least negative or most positive) was selected.\n",
    "   - It is important to note that the magnitude of scores can vary greatly, depending on the evaluation metrics and their weights.\n",
    "\n",
    "### Recommendations:\n",
    "- **Non-Local Means (Noise Reduction)**: The parameters suggest that a lighter touch (`h=5`) works better, indicating that preserving details is more beneficial for these images.\n",
    "- **Adaptive Threshold (Binarization)**: The best results came from using a Gaussian adaptive method with a smaller block size, indicating that finer local adjustments are advantageous.\n",
    "- **Erosion (Morphological Operations)**: A smaller kernel size `(3, 3)` resulted in the least deviation, suggesting a lighter morphological touch is preferable.\n",
    "- **Canny Edge Detection**: Lower thresholds were effective in enhancing edge details, resulting in a higher score.\n",
    "\n",
    "Overall, the scores are consistent with an expected outcome where lower parameters (e.g., less aggressive denoising or erosion) lead to better preservation of original characteristics, while certain techniques like edge detection benefit from lower thresholds for more comprehensive edge enhancement."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb737e3b48923f3b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T13:26:08.763319Z",
     "start_time": "2024-11-13T13:26:08.748321Z"
    }
   },
   "id": "915f0ec865424bf5",
   "execution_count": 138
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
