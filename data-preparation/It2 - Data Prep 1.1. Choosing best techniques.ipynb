{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6679ab839dfc599",
   "metadata": {},
   "source": [
    "# Data Preparation - IT2 - Choosing |best techniques per step in the flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6db9fa264159cd5",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-18T16:29:25.022360Z",
     "start_time": "2024-11-18T16:29:25.015362Z"
=======
     "end_time": "2024-11-13T13:23:21.939509Z",
     "start_time": "2024-11-13T13:23:21.918510Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d0b8bdef35d1e5da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T13:23:22.123514Z",
     "start_time": "2024-11-13T13:23:22.106510Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the path to the folder containing the images to be processed\n",
    "folder_path = '../data/original'  # Update this path to point to your specific folder containing images\n",
    "\n",
    "# Define the path to the folder where the processed images will be saved\n",
    "output_folder = '../data/processed'  # Update this path to the desired output folder"
<<<<<<< HEAD
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:29:25.230361Z",
     "start_time": "2024-11-18T16:29:25.216362Z"
    }
   },
   "id": "d0b8bdef35d1e5da",
   "execution_count": 33
=======
   ]
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
  },
  {
   "cell_type": "markdown",
   "id": "3a22a19fd22d2b9a",
   "metadata": {},
   "source": [
    "## Loading Images and stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "703777edb6b6cb6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T13:23:22.138510Z",
     "start_time": "2024-11-13T13:23:22.126511Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder_path, extensions=('.png', '.jpg', '.jpeg', '.JPG')):\n",
    "    \"\"\"\n",
    "    Load all image file paths from a specified folder that match the given file extensions.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing the images.\n",
    "    extensions (tuple of str): A tuple of file extensions to filter the images by. \n",
    "                               Default is ('.png', '.jpg', '.jpeg', '.JPG').\n",
    "\n",
    "    Returns:\n",
    "    list: A list of full file paths to images in the folder that match the specified extensions.\n",
    "    \n",
    "    Raises:\n",
    "    FileNotFoundError: If the specified folder does not exist.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        raise FileNotFoundError(f\"The specified folder does not exist: {folder_path}\")\n",
    "\n",
    "    # List comprehension to gather all image paths with the specified extensions\n",
    "    image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(extensions)]\n",
    "\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8097d12ed08ed95c",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-18T16:29:25.262365Z",
     "start_time": "2024-11-18T16:29:25.248362Z"
    }
   },
   "id": "703777edb6b6cb6b",
   "execution_count": 34
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-13T13:23:22.153511Z",
     "start_time": "2024-11-13T13:23:22.140511Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
   "outputs": [],
   "source": [
    "# Function to convert to gray scale\n",
    "def load_and_preprocess_images(image_paths, resize_dim=(256, 256)):\n",
    "    images = []\n",
    "    image_ids = []\n",
    "\n",
    "    # Initialize tqdm progress bar\n",
    "    for path in tqdm(image_paths, desc=\"Loading and preprocessing images\", unit=\"image\"):\n",
    "        img = cv2.imread(path)\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "        img_resized = cv2.resize(img_gray, resize_dim)  # Resize for consistency\n",
    "        images.append(img_resized)\n",
    "        image_ids.append(f'Image_{len(images)}')  # Assign image ID as Image_1, Image_2, etc.\n",
    "\n",
    "    return images, image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f0024219894c26ef",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-18T16:29:25.294360Z",
     "start_time": "2024-11-18T16:29:25.275363Z"
    }
   },
   "id": "8097d12ed08ed95c",
   "execution_count": 35
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-13T13:23:22.245513Z",
     "start_time": "2024-11-13T13:23:22.155512Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
   "outputs": [],
   "source": [
    "# Load the CSV file with the image statistics\n",
    "images_stats_path = \"../data-understanding/images_stats.csv\"  \n",
    "images_stats_df = pd.read_csv(images_stats_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "db335d32477016cb",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-18T16:29:25.310360Z",
     "start_time": "2024-11-18T16:29:25.296362Z"
    }
   },
   "id": "f0024219894c26ef",
   "execution_count": 36
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-13T13:23:22.275510Z",
     "start_time": "2024-11-13T13:23:22.247516Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Image', 'Brightness', 'Sharpness', 'Contrast', 'Noise', 'Skew',\n",
       "       'Line Spacing', 'Tables Detected', 'Resolution', 'Detected Elements',\n",
       "       'Texture', 'Patterns'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_stats_df.columns"
<<<<<<< HEAD
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:29:25.326360Z",
     "start_time": "2024-11-18T16:29:25.312361Z"
    }
   },
   "id": "db335d32477016cb",
   "execution_count": 37
=======
   ]
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
  },
  {
   "cell_type": "markdown",
   "id": "12f7addce2a50971",
   "metadata": {},
   "source": [
    "## Functions per step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf7d2143725450b",
   "metadata": {},
   "source": [
    "### Step 1: Noise Reduction Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8fe3ee9d85584a63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T13:44:25.282379Z",
     "start_time": "2024-11-13T13:44:25.261376Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Noise Reduction Functions\n",
    "def apply_gaussian_blur(image, ksize=(5, 5)):\n",
    "    \"\"\"Apply Gaussian Blur to reduce noise with the specified kernel size.\"\"\"\n",
    "    return cv2.GaussianBlur(image, ksize, 0)\n",
    "\n",
    "def apply_median_blur(image, ksize=5):\n",
    "    \"\"\"Apply Median Blur to reduce salt-and-pepper noise with the specified kernel size.\"\"\"\n",
    "    return cv2.medianBlur(image, ksize)\n",
    "\n",
    "def apply_non_local_means(image, h=10, templateWindowSize=7, searchWindowSize=21):\n",
    "    \"\"\"Apply Non-Local Means Denoising with specified parameters.\"\"\"\n",
    "    return cv2.fastNlMeansDenoising(image, None, h, templateWindowSize, searchWindowSize)"
<<<<<<< HEAD
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:29:25.342362Z",
     "start_time": "2024-11-18T16:29:25.328361Z"
    }
   },
   "id": "8fe3ee9d85584a63",
   "execution_count": 38
=======
   ]
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
  },
  {
   "cell_type": "markdown",
   "id": "5b6cdd42d07d1c96",
   "metadata": {},
   "source": [
    "### Step 2: Histogram Equalization Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "44c99f9c5258c6f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T13:44:25.906375Z",
     "start_time": "2024-11-13T13:44:25.889376Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Histogram Equalization Functions\n",
    "def apply_histogram_equalization(image):\n",
    "    return cv2.equalizeHist(image)\n",
    "\n",
    "def apply_clahe(image, clipLimit=2.0, tileGridSize=(8, 8)):\n",
    "    \"\"\"Apply CLAHE to enhance image contrast with specified parameters.\"\"\"\n",
    "    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n",
    "    return clahe.apply(image)"
<<<<<<< HEAD
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:29:25.373361Z",
     "start_time": "2024-11-18T16:29:25.354361Z"
    }
   },
   "id": "44c99f9c5258c6f3",
   "execution_count": 39
=======
   ]
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
  },
  {
   "cell_type": "markdown",
   "id": "29e647d0a546cb82",
   "metadata": {},
   "source": [
    "### Step 3: Binarization Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3b2691be436fc225",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T13:44:26.610656Z",
     "start_time": "2024-11-13T13:44:26.600657Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Binarization Functions\n",
    "def apply_global_threshold(image, thresholdValue=127):\n",
    "    \"\"\"Apply Global Thresholding with the specified threshold value.\"\"\"\n",
    "    _, binary_image = cv2.threshold(image, thresholdValue, 255, cv2.THRESH_BINARY)\n",
    "    return binary_image\n",
    "\n",
    "def apply_adaptive_threshold(image, adaptiveMethod=cv2.ADAPTIVE_THRESH_MEAN_C, blockSize=11, C=2):\n",
    "    \"\"\"Apply Adaptive Thresholding with the specified method, block size, and constant C.\"\"\"\n",
    "    return cv2.adaptiveThreshold(image, 255, adaptiveMethod, cv2.THRESH_BINARY, blockSize, C)\n",
    "\n",
    "def apply_otsu_threshold(image):\n",
    "    \"\"\"Apply Otsu Thresholding.\"\"\"\n",
    "    _, binary_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return binary_image\n",
    "\n",
    "def apply_inverted_otsu_threshold(image):\n",
    "    \"\"\"Apply Inverted Otsu Thresholding.\"\"\"\n",
    "    _, binary_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    return binary_image\n"
<<<<<<< HEAD
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:29:25.420360Z",
     "start_time": "2024-11-18T16:29:25.407373Z"
    }
   },
   "id": "3b2691be436fc225",
   "execution_count": 40
=======
   ]
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
  },
  {
   "cell_type": "markdown",
   "id": "c3c7a336f8c8b717",
   "metadata": {},
   "source": [
    "### Step 4: Morphological Operations Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "da08a64db428ad4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T13:44:27.301038Z",
     "start_time": "2024-11-13T13:44:27.284048Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Morphological Operations Functions\n",
    "def apply_dilation(image, kernel_size=(5, 5)):\n",
    "    \"\"\"Apply Dilation with the specified kernel size.\"\"\"\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations=1)\n",
    "\n",
    "def apply_erosion(image, kernel_size=(5, 5)):\n",
    "    \"\"\"Apply Erosion with the specified kernel size.\"\"\"\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations=1)\n",
    "\n",
    "def apply_opening(image, kernel_size=(5, 5)):\n",
    "    \"\"\"Apply Morphological Opening with the specified kernel size.\"\"\"\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "def apply_closing(image, kernel_size=(5, 5)):\n",
    "    \"\"\"Apply Morphological Closing with the specified kernel size.\"\"\"\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n"
<<<<<<< HEAD
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:29:25.451360Z",
     "start_time": "2024-11-18T16:29:25.431361Z"
    }
   },
   "id": "da08a64db428ad4a",
   "execution_count": 41
=======
   ]
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
  },
  {
   "cell_type": "markdown",
   "id": "e5596f364429dda1",
   "metadata": {},
   "source": [
    "### Step 5: Edge Detection Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "76e5c83f8a5c9bc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T13:44:28.184117Z",
     "start_time": "2024-11-13T13:44:28.178118Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Edge Detection Functions\n",
    "def apply_canny_edge(image, threshold1=50, threshold2=150):\n",
    "    \"\"\"Apply Canny Edge Detection with specified thresholds.\"\"\"\n",
    "    return cv2.Canny(image, threshold1, threshold2)\n",
    "\n",
    "def apply_sobel_edge(image, ksize=3, scale=1, delta=0, borderType=cv2.BORDER_DEFAULT):\n",
    "    \"\"\"Apply Sobel Edge Detection with specified parameters.\"\"\"\n",
<<<<<<< HEAD
    "    return cv2.Sobel(image, cv2.CV_64F, 1, 1, ksize=ksize, scale=scale, delta=delta, borderType=borderType)\n",
    "\n",
    "def apply_unsharp_masking(image, amount=1.5, kernel_size=(0, 0)):\n",
    "    \"\"\"Apply Unsharp Masking to sharpen the image.\"\"\"\n",
    "    blurred = cv2.GaussianBlur(image, kernel_size, 0)\n",
    "    sharpened = cv2.addWeighted(image, 1 + amount, blurred, -amount, 0)\n",
    "    return sharpened"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:29:25.498406Z",
     "start_time": "2024-11-18T16:29:25.492407Z"
    }
   },
   "id": "76e5c83f8a5c9bc8",
   "execution_count": 42
=======
    "    return cv2.Sobel(image, cv2.CV_64F, 1, 1, ksize=ksize, scale=scale, delta=delta, borderType=borderType)"
   ]
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
  },
  {
   "cell_type": "markdown",
   "id": "e79e5c4a578b19f5",
   "metadata": {},
   "source": [
    "## Characteristics Calculation for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "aec243807f00da68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T13:23:22.385518Z",
     "start_time": "2024-11-13T13:23:22.354512Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Image Characteristics Calculation Functions - from data understanding it2\n",
    "def calculate_brightness(image):\n",
    "    return np.mean(image)\n",
    "\n",
    "def calculate_sharpness(image):\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\n",
    "def calculate_contrast(image):\n",
    "    return image.std()\n",
    "\n",
    "def calculate_noise(image):\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    noise = cv2.absdiff(image, blurred)\n",
    "    return np.var(noise)\n",
    "\n",
<<<<<<< HEAD
    "# def calculate_skew(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "#     _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "#     coords = np.column_stack(np.where(binary > 0))\n",
    "#     if coords.size == 0:\n",
    "#         return 0\n",
    "#     angle = cv2.minAreaRect(coords)[-1]\n",
    "#     if angle < -45:\n",
    "#         angle = -(90 + angle)\n",
    "#     else:\n",
    "#         angle = -angle\n",
    "#     if abs(angle) < 1e-2:\n",
    "#         angle = 0\n",
    "#     return round(angle, 2)\n",
    "# \n",
    "# def calculate_line_spacing(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "#     _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "#     contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     heights = [cv2.boundingRect(contour)[3] for contour in contours]\n",
    "#     if len(heights) > 1:\n",
    "#         line_spacing = np.mean(np.diff(sorted(heights)))\n",
    "#     else:\n",
    "#         line_spacing = 0\n",
    "#     return line_spacing\n",
    "# \n",
    "# def detect_tables(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "#     _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "#     binary = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "#     contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     table_contours = [contour for contour in contours if cv2.contourArea(contour) > 1000]\n",
    "#     return len(table_contours)\n",
    "# \n",
    "# def calculate_resolution(image):\n",
    "#     height, width = image.shape[:2]\n",
    "#     return height * width\n",
    "# \n",
    "# def calculate_elements_detection(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "#     _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "#     contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     return len(contours)\n",
    "# \n",
    "# def calculate_texture(image):\n",
    "#     laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "#     return laplacian.std()\n",
    "# \n",
    "# def calculate_patterns(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "#     edges = cv2.Canny(image, 100, 200)\n",
    "#     return np.sum(edges > 0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-11-18T16:29:25.501405Z"
    }
   },
   "id": "aec243807f00da68",
   "execution_count": null
=======
    "def calculate_skew(image):\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "    _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    coords = np.column_stack(np.where(binary > 0))\n",
    "    if coords.size == 0:\n",
    "        return 0\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    if abs(angle) < 1e-2:\n",
    "        angle = 0\n",
    "    return round(angle, 2)\n",
    "\n",
    "def calculate_line_spacing(image):\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "    _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    heights = [cv2.boundingRect(contour)[3] for contour in contours]\n",
    "    if len(heights) > 1:\n",
    "        line_spacing = np.mean(np.diff(sorted(heights)))\n",
    "    else:\n",
    "        line_spacing = 0\n",
    "    return line_spacing\n",
    "\n",
    "def detect_tables(image):\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "    _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    binary = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    table_contours = [contour for contour in contours if cv2.contourArea(contour) > 1000]\n",
    "    return len(table_contours)\n",
    "\n",
    "def calculate_resolution(image):\n",
    "    height, width = image.shape[:2]\n",
    "    return height * width\n",
    "\n",
    "def calculate_elements_detection(image):\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "    _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return len(contours)\n",
    "\n",
    "def calculate_texture(image):\n",
    "    laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "    return laplacian.std()\n",
    "\n",
    "def calculate_patterns(image):\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "    edges = cv2.Canny(image, 100, 200)\n",
    "    return np.sum(edges > 0)\n"
   ]
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
  },
  {
   "cell_type": "markdown",
   "id": "203cff1e1647315b",
   "metadata": {},
   "source": [
    "## Evaluation per step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ca8cdd80754f23",
   "metadata": {},
   "source": [
<<<<<<< HEAD
=======
    "The code evaluates multiple techniques in each step of the image processing pipeline and selects the best technique based on a scoring system. Here's how it works:\n",
    "\n",
    "Technique Evaluation:\n",
    "\n",
    "Each technique for a specific step (e.g., Gaussian Blur, Median Blur for Noise Reduction) is applied to the test images.\n",
    "After applying the technique, the characteristics of the processed image are calculated (e.g., Brightness, Sharpness, Noise, etc.).\n",
    "Scoring Mechanism:\n",
    "\n",
    "The scoring function is designed to minimize noise while maximizing positive characteristics like sharpness and contrast.\n",
    "The score calculation takes into account changes in image characteristics compared to the original image.\n",
    "Noise is treated negatively (-stats[\"Noise\"]), whereas characteristics like Sharpness, Contrast, and other features are treated positively (score += stats[key] - original_stats[key]).\n",
    "After evaluating all techniques, the one with the highest score is selected as the \"best technique\" for that step.\n",
    "Best Technique Selection:\n",
    "\n",
    "The technique with the highest score is selected and printed, and this is repeated for each step in the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dafdc80cafbb5f",
   "metadata": {},
   "source": [
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
    "### Function of evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ce72107041cb13b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T13:23:22.401511Z",
     "start_time": "2024-11-13T13:23:22.388512Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Basic Evaluation Function\n",
    "# -------------------------\n",
    "# def basic_evaluation(image, techniques_dict, original_stats):\n",
    "#     evaluation_results = {}\n",
    "#     for technique_name, technique_func in techniques_dict.items():\n",
    "#         processed_image = technique_func(image)\n",
    "#         stats = {\n",
    "#             \"Brightness\": calculate_brightness(processed_image),\n",
    "#             \"Sharpness\": calculate_sharpness(processed_image),\n",
    "#             \"Contrast\": calculate_contrast(processed_image),\n",
    "#             \"Noise\": calculate_noise(processed_image)\n",
    "#         }\n",
    "# \n",
    "#         # Basic scoring function - prioritizing sharpness, contrast, and minimized noise\n",
    "#         score = stats[\"Sharpness\"] + stats[\"Contrast\"] - stats[\"Noise\"]\n",
    "#         evaluation_results[technique_name] = {\"Score\": score, \"Stats\": stats}\n",
    "# \n",
    "#     best_technique = max(evaluation_results, key=lambda x: evaluation_results[x][\"Score\"])\n",
    "#     return {\"Best Technique\": best_technique, \"Evaluation Results\": evaluation_results}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3067606c27e5a0cd",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-18T16:29:26.092708Z",
     "start_time": "2024-11-18T16:29:26.073712Z"
    }
   },
   "id": "ce72107041cb13b3",
   "execution_count": 44
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-13T13:23:22.417509Z",
     "start_time": "2024-11-13T13:23:22.403511Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
   "outputs": [],
   "source": [
    "# def advanced_evaluation(image, techniques_dict, original_stats):\n",
    "#     evaluation_results = {}\n",
    "# \n",
    "#     for technique_name, technique_func in techniques_dict.items():\n",
    "#         # Apply the technique\n",
    "#         processed_image = technique_func(image)\n",
    "# \n",
    "#         # Calculate characteristics for the processed image\n",
    "#         stats = {\n",
    "#             \"Brightness\": calculate_brightness(processed_image),\n",
    "#             \"Sharpness\": calculate_sharpness(processed_image),\n",
    "#             \"Contrast\": calculate_contrast(processed_image),\n",
    "#             \"Noise\": calculate_noise(processed_image),\n",
    "#             \"Skew\": calculate_skew(processed_image),\n",
    "#             \"Line Spacing\": calculate_line_spacing(processed_image),\n",
    "#             \"Tables Detected\": detect_tables(processed_image),\n",
    "#             \"Resolution\": calculate_resolution(processed_image),\n",
    "#             \"Detected Elements\": calculate_elements_detection(processed_image),\n",
    "#             \"Texture\": calculate_texture(processed_image),\n",
    "#             \"Patterns\": calculate_patterns(processed_image)\n",
    "#         }\n",
    "# \n",
    "#         # Normalize metrics to comparable ranges (between 0 and 1, roughly)\n",
    "#         stats_normalized = {\n",
    "#             \"Brightness\": stats[\"Brightness\"] / 255,\n",
    "#             \"Sharpness\": stats[\"Sharpness\"] / 1000,\n",
    "#             \"Contrast\": stats[\"Contrast\"] / 255,\n",
    "#             \"Noise\": stats[\"Noise\"] / 255,\n",
    "#             \"Skew\": stats[\"Skew\"] / 45,\n",
    "#             \"Line Spacing\": stats[\"Line Spacing\"] / 100,\n",
    "#             \"Tables Detected\": stats[\"Tables Detected\"] / 10,\n",
    "#             \"Resolution\": stats[\"Resolution\"] / (512 * 512),\n",
    "#             \"Detected Elements\": stats[\"Detected Elements\"] / 100,\n",
    "#             \"Texture\": stats[\"Texture\"] / 100,\n",
    "#             \"Patterns\": stats[\"Patterns\"] / 1000\n",
    "#         }\n",
    "# \n",
    "#         # Normalize the original stats for comparison\n",
    "#         original_stats_normalized = {\n",
    "#             \"Brightness\": original_stats[\"Brightness\"] / 255,\n",
    "#             \"Sharpness\": original_stats[\"Sharpness\"] / 1000,\n",
    "#             \"Contrast\": original_stats[\"Contrast\"] / 255,\n",
    "#             \"Noise\": original_stats[\"Noise\"] / 255,\n",
    "#             \"Skew\": original_stats[\"Skew\"] / 45,\n",
    "#             \"Line Spacing\": original_stats[\"Line Spacing\"] / 100,\n",
    "#             \"Tables Detected\": original_stats[\"Tables Detected\"] / 10,\n",
    "#             \"Resolution\": original_stats[\"Resolution\"] / (512 * 512),\n",
    "#             \"Detected Elements\": original_stats[\"Detected Elements\"] / 100,\n",
    "#             \"Texture\": original_stats[\"Texture\"] / 100,\n",
    "#             \"Patterns\": original_stats[\"Patterns\"] / 1000\n",
    "#         }\n",
    "# \n",
    "#         # Weights for each characteristic (to determine their importance)\n",
    "#         weights = {\n",
    "#             \"Brightness\": -1.0,  # Closer to original is better (penalized if different)\n",
    "#             \"Sharpness\": 2.0,    # Higher is better (rewarded if improved)\n",
    "#             \"Contrast\": 1.0,     # Higher is better (rewarded if improved)\n",
    "#             \"Noise\": -1.5,       # Lower is better (penalized if increased)\n",
    "#             \"Skew\": -0.5,        # Closer to original is better (penalized if different)\n",
    "#             \"Line Spacing\": -0.5,  # Closer to original is better (penalized if different)\n",
    "#             \"Tables Detected\": 1.0,  # More tables detected is better\n",
    "#             \"Resolution\": 1.0,    # Higher is better\n",
    "#             \"Detected Elements\": 1.0,  # More elements detected is better\n",
    "#             \"Texture\": 1.0,       # Higher texture complexity is better\n",
    "#             \"Patterns\": 1.0       # More patterns detected is better\n",
    "#         }\n",
    "# \n",
    "#         # Calculate score using normalized metrics and weights\n",
    "#         score = 0\n",
    "#         for metric, value in stats_normalized.items():\n",
    "#             original_value = original_stats_normalized.get(metric, 0)\n",
    "#             score += weights[metric] * (value - original_value)\n",
    "# \n",
    "#         evaluation_results[technique_name] = {\"Score\": score, \"Stats\": stats}\n",
    "# \n",
    "#     # Determine the best technique based on the highest score\n",
    "#     best_technique = max(evaluation_results, key=lambda x: evaluation_results[x][\"Score\"])\n",
<<<<<<< HEAD
    "#     return {\"Best Technique\": best_technique, \"Evaluation Results\": evaluation_results}\n"
   ],
=======
    "#     return {\"Best Technique\": best_technique, \"Evaluation Results\": evaluation_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6bf4a8b130aa7d7f",
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-18T16:29:26.108700Z",
     "start_time": "2024-11-18T16:29:26.094702Z"
    }
   },
   "id": "3067606c27e5a0cd",
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Normalization Process\n",
    "\n",
    "**Normalization** is crucial for ensuring that the values of different characteristics (`Brightness`, `Sharpness`, `Contrast`, `Noise`) are on a similar scale. Without normalization, these characteristics might have vastly different ranges, which could skew the evaluation. Here's what happens in the function:\n",
    "\n",
    "1. **Brightness Normalization**:\n",
    "   - The brightness of an image is typically represented on a scale from 0 to 255 (as an 8-bit grayscale value).\n",
    "   - To normalize brightness, we divide it by 255, which brings its range between 0 and 1.\n",
    "\n",
    "2. **Sharpness Normalization**:\n",
    "   - Sharpness is measured as the variance of the Laplacian, which often has larger values than brightness.\n",
    "   - Dividing by `1000` helps normalize it to roughly between 0 and 1. The choice of `1000` is made to ensure that sharpness values are comparable to the other metrics.\n",
    "\n",
    "3. **Contrast Normalization**:\n",
    "   - Contrast is calculated using the standard deviation of pixel values, which usually falls between 0 and 255 for 8-bit images.\n",
    "   - Dividing by 255 brings contrast into the range between 0 and 1.\n",
    "\n",
    "4. **Noise Normalization**:\n",
    "   - The noise measure is the variance of the difference between the original and a blurred version of the image.\n",
    "   - Dividing by 255 brings it to a similar range as the other characteristics, ensuring comparability.\n",
    "\n",
    "By normalizing all metrics to a range between 0 and 1, we ensure that each characteristic has equal weight in the evaluation, preventing one metric from dominating due to a larger numeric range.\n",
    "\n",
    "##### Scoring Calculation\n",
    "\n",
    "Once all metrics are normalized, a score is calculated to determine how well the processed image improves compared to the original. Here's the breakdown of the scoring process:\n",
    "\n",
    "1. **Weights for Characteristics**:\n",
    "   - We assign **weights** to each metric based on its importance:\n",
    "     - **Brightness**: Weight of `-1.0` means that deviation from the original value is penalized.\n",
    "     - **Sharpness**: Weight of `2.0` rewards increased sharpness.\n",
    "     - **Contrast**: Weight of `1.0` rewards increased contrast.\n",
    "     - **Noise**: Weight of `-1.5` penalizes increased noise.\n",
    "\n",
    "2. **Score Calculation**:\n",
    "   - The difference between the normalized processed value and the normalized original value is multiplied by the respective weight.\n",
    "   - If a **positively weighted metric** (like sharpness or contrast) **improves**, it contributes positively to the score.\n",
    "   - If a **negatively weighted metric** (like noise or brightness deviation) **increases**, it contributes negatively, penalizing the score.\n",
    "\n",
    "3. **Best Technique Selection**:\n",
    "   - After calculating the score for each technique, the function selects the one with the **highest score**.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14621ade3e0e3283"
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-13T14:13:21.950247Z",
     "start_time": "2024-11-13T14:13:21.931249Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
   "outputs": [],
   "source": [
    "def advanced_evaluation(image, techniques_dict, original_stats):\n",
    "    evaluation_results = {}\n",
    "\n",
    "    for technique_name, technique_func in techniques_dict.items():\n",
    "        # Apply the technique\n",
    "        processed_image = technique_func(image)\n",
    "\n",
    "        # Calculate characteristics for the processed image\n",
    "        stats = {\n",
    "            \"Brightness\": calculate_brightness(processed_image),\n",
    "            \"Sharpness\": calculate_sharpness(processed_image),\n",
    "            \"Contrast\": calculate_contrast(processed_image),\n",
    "            \"Noise\": calculate_noise(processed_image),\n",
    "        }\n",
    "\n",
    "        # Normalize metrics to comparable ranges (between 0 and 1, roughly)\n",
    "        stats_normalized = {\n",
    "            \"Brightness\": stats[\"Brightness\"] / 255,\n",
    "            \"Sharpness\": stats[\"Sharpness\"] / 1000,\n",
    "            \"Contrast\": stats[\"Contrast\"] / 255,\n",
    "            \"Noise\": stats[\"Noise\"] / 255,\n",
    "        }\n",
    "\n",
    "        # Normalize the original stats for comparison\n",
    "        original_stats_normalized = {\n",
    "            \"Brightness\": original_stats[\"Brightness\"] / 255,\n",
    "            \"Sharpness\": original_stats[\"Sharpness\"] / 1000,\n",
    "            \"Contrast\": original_stats[\"Contrast\"] / 255,\n",
    "            \"Noise\": original_stats[\"Noise\"] / 255,\n",
    "        }\n",
    "\n",
    "        # Weights for each characteristic (to determine their importance)\n",
    "        weights = {\n",
    "            \"Brightness\": -1.0,  # Closer to original is better (penalized if different) as they were in a good level before\n",
    "            \"Sharpness\": 2.0,    # Higher is better (rewarded if improved)\n",
    "            \"Contrast\": 1.0,     # Higher is better (rewarded if improved)\n",
    "            \"Noise\": -1.5,       # Lower is better (penalized if increased)\n",
    "        }\n",
    "\n",
    "        # Calculate score using normalized metrics and weights\n",
    "        score = 0\n",
    "        for metric, value in stats_normalized.items():\n",
    "            original_value = original_stats_normalized.get(metric, 0)\n",
    "            score += weights[metric] * (value - original_value)\n",
    "\n",
    "        evaluation_results[technique_name] = {\"Score\": score, \"Stats\": stats}\n",
    "\n",
    "    # Determine the best technique based on the highest score\n",
    "    best_technique = max(evaluation_results, key=lambda x: evaluation_results[x][\"Score\"])\n",
    "    return {\"Best Technique\": best_technique, \"Evaluation Results\": evaluation_results}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a9dcfaa1991f5e3a",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-18T16:29:26.124701Z",
     "start_time": "2024-11-18T16:29:26.110701Z"
    }
   },
   "id": "6bf4a8b130aa7d7f",
   "execution_count": 46
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-13T13:23:22.433510Z",
     "start_time": "2024-11-13T13:23:22.419510Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
   "outputs": [],
   "source": [
    "# Function for Each Step testing\n",
    "def run_step(step_name, techniques_dict, test_images, test_image_ids, best_techniques_list):\n",
    "    print(f\"\\nRunning Step: {step_name}\\n{'-' * 40}\")\n",
    "    all_results = []\n",
    "    for img, img_id in zip(test_images, test_image_ids):\n",
    "        # Retrieve original stats from the dataset\n",
    "        original_stats = images_stats_df[images_stats_df['Image'] == img_id].iloc[0].to_dict()\n",
    "\n",
    "        step_result = advanced_evaluation(img, techniques_dict,original_stats)\n",
    "        all_results.append((img_id, original_stats, step_result))\n",
    "        print(f\"Best Technique for {img_id}: {step_result['Best Technique']}\")\n",
    "\n",
    "    # Generate Comparison Table\n",
    "    comparison_data = []\n",
    "    for img_id, original_stats, result in all_results:\n",
    "        # Add original stats row\n",
    "        comparison_data.append([img_id, \"Original\"] + list(original_stats.values())[1:])  # Skip the 'Image' key\n",
    "        # Add each technique's stats\n",
    "        for technique, metrics in result[\"Evaluation Results\"].items():\n",
    "            comparison_data.append([img_id, f\"{step_name} - {technique}\"] + list(metrics[\"Stats\"].values()))\n",
    "\n",
    "    comparison_df = pd.DataFrame(comparison_data, columns=[\"Image_ID\", \"Technique\", \"Brightness\", \"Sharpness\", \"Contrast\", \"Noise\", \"Skew\", \"Line Spacing\", \"Tables Detected\", \"Resolution\", \"Detected Elements\", \"Texture\", \"Patterns\"])\n",
    "\n",
    "    # Generate Recommendation\n",
    "    recommended_technique_name = max(all_results, key=lambda x: x[2][\"Evaluation Results\"][x[2][\"Best Technique\"]][\"Score\"])[2][\"Best Technique\"]\n",
    "    recommended_technique_func = techniques_dict[recommended_technique_name]\n",
    "    print(f\"\\nRecommended Technique for {step_name}: {recommended_technique_name}\\n\")\n",
    "\n",
    "    # Append both technique name and function for further tuning\n",
    "    best_techniques_list.append((step_name, recommended_technique_name, recommended_technique_func))\n",
    "\n",
    "    # Return the comparison DataFrame\n",
    "    return comparison_df"
<<<<<<< HEAD
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:29:26.140700Z",
     "start_time": "2024-11-18T16:29:26.126701Z"
    }
   },
   "id": "a9dcfaa1991f5e3a",
   "execution_count": 47
=======
   ]
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
  },
  {
   "cell_type": "markdown",
   "id": "5473417fb6fc8aff",
   "metadata": {},
   "source": [
    "### Running Different Techniques per Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5c3b64a356573a62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T13:26:07.111340Z",
     "start_time": "2024-11-13T13:23:22.436518Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing images: 100%|██████████| 698/698 [02:36<00:00,  4.45image/s]\n"
     ]
    }
   ],
   "source": [
    "# Load all image file paths from the specified folder\n",
    "image_paths_all = load_images_from_folder(folder_path)\n",
    "\n",
    "# Load and preprocess all images\n",
    "total_images, total_image_ids = load_and_preprocess_images(image_paths_all)\n",
    "\n",
    "# Randomly select 5 images for experimentation\n",
    "experiment_indices = random.sample(range(len(total_images)), 5)\n",
    "test_images = [total_images[i] for i in experiment_indices]\n",
    "test_image_ids = [total_image_ids[i] for i in experiment_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5d321de124a8f61b",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-18T16:32:03.080034Z",
     "start_time": "2024-11-18T16:29:26.143701Z"
    }
   },
   "id": "5c3b64a356573a62",
   "execution_count": 48
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-13T14:13:30.122101Z",
     "start_time": "2024-11-13T14:13:30.109115Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
   "outputs": [],
   "source": [
    "best_techniques_list = []\n",
    "comparison_tables = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1272df62648886a8",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-18T16:32:03.096031Z",
     "start_time": "2024-11-18T16:32:03.082041Z"
    }
   },
   "id": "5d321de124a8f61b",
   "execution_count": 49
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-13T14:13:31.244392Z",
     "start_time": "2024-11-13T14:13:30.504417Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Step: Noise Reduction\n",
      "----------------------------------------\n",
      "Best Technique for Image_144: Non-Local Means\n",
      "Best Technique for Image_270: Non-Local Means\n",
      "Best Technique for Image_673: Non-Local Means\n",
      "Best Technique for Image_424: Non-Local Means\n",
      "Best Technique for Image_139: Non-Local Means\n",
      "\n",
      "Recommended Technique for Noise Reduction: Non-Local Means\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Noise Reduction\n",
    "noise_reduction_techniques = {\n",
    "    \"Gaussian Blur\": lambda img: cv2.GaussianBlur(img, (5, 5), 0),\n",
    "    \"Median Blur\": lambda img: cv2.medianBlur(img, 5),\n",
    "    \"Non-Local Means\": lambda img: cv2.fastNlMeansDenoising(img, None, 10, 7, 21)\n",
    "}\n",
    "comparison_tables.append(run_step(\"Noise Reduction\", noise_reduction_techniques, test_images, test_image_ids, best_techniques_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b5ef0203d606d09a",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-18T16:32:03.758032Z",
     "start_time": "2024-11-18T16:32:03.098033Z"
    }
   },
   "id": "1272df62648886a8",
   "execution_count": 50
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-13T14:13:31.368393Z",
     "start_time": "2024-11-13T14:13:31.247393Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Step: Histogram Equalization\n",
      "----------------------------------------\n",
      "Best Technique for Image_144: Histogram Equalization\n",
      "Best Technique for Image_270: Histogram Equalization\n",
      "Best Technique for Image_673: Histogram Equalization\n",
      "Best Technique for Image_424: Histogram Equalization\n",
      "Best Technique for Image_139: Histogram Equalization\n",
      "\n",
      "Recommended Technique for Histogram Equalization: Histogram Equalization\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Histogram Equalization\n",
    "histogram_equalization_techniques = {\n",
    "    \"Histogram Equalization\": lambda img: cv2.equalizeHist(img),\n",
    "    \"CLAHE\": lambda img: cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(img)\n",
    "}\n",
    "comparison_tables.append(run_step(\"Histogram Equalization\", histogram_equalization_techniques, test_images, test_image_ids, best_techniques_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a68616ef9a33f67d",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-18T16:32:03.790031Z",
     "start_time": "2024-11-18T16:32:03.759032Z"
    }
   },
   "id": "b5ef0203d606d09a",
   "execution_count": 51
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-13T14:13:32.132749Z",
     "start_time": "2024-11-13T14:13:31.951911Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Step: Binarization\n",
      "----------------------------------------\n",
      "Best Technique for Image_144: Adaptive Threshold\n",
      "Best Technique for Image_270: Adaptive Threshold\n",
      "Best Technique for Image_673: Adaptive Threshold\n",
      "Best Technique for Image_424: Adaptive Threshold\n",
      "Best Technique for Image_139: Adaptive Threshold\n",
      "\n",
      "Recommended Technique for Binarization: Adaptive Threshold\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Binarization\n",
    "binarization_techniques = {\n",
    "    \"Global Threshold\": lambda img: cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)[1],\n",
    "    \"Adaptive Threshold\": lambda img: cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2),\n",
    "    \"Otsu Threshold\": lambda img: cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "}\n",
    "comparison_tables.append(run_step(\"Binarization\", binarization_techniques, test_images, test_image_ids, best_techniques_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8a8bf5b17df76bee",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-18T16:32:03.821031Z",
     "start_time": "2024-11-18T16:32:03.792032Z"
    }
   },
   "id": "a68616ef9a33f67d",
   "execution_count": 52
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-13T14:13:34.387473Z",
     "start_time": "2024-11-13T14:13:34.251466Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Step: Morphological Operations\n",
      "----------------------------------------\n",
      "Best Technique for Image_144: Erosion\n",
      "Best Technique for Image_270: Erosion\n",
      "Best Technique for Image_673: Erosion\n",
      "Best Technique for Image_424: Erosion\n",
      "Best Technique for Image_139: Erosion\n",
      "\n",
      "Recommended Technique for Morphological Operations: Erosion\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Morphological Operations\n",
    "morphological_operations_techniques = {\n",
    "    \"Dilation\": lambda img: cv2.dilate(img, np.ones((5, 5), np.uint8), iterations=1),\n",
    "    \"Erosion\": lambda img: cv2.erode(img, np.ones((5, 5), np.uint8), iterations=1),\n",
    "    \"Opening\": lambda img: cv2.morphologyEx(img, cv2.MORPH_OPEN, np.ones((5, 5), np.uint8)),\n",
    "    \"Closing\": lambda img: cv2.morphologyEx(img, cv2.MORPH_CLOSE, np.ones((5, 5), np.uint8))\n",
    "}\n",
    "comparison_tables.append(run_step(\"Morphological Operations\", morphological_operations_techniques, test_images, test_image_ids, best_techniques_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7e47a9227209a883",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-18T16:32:03.868034Z",
     "start_time": "2024-11-18T16:32:03.822031Z"
    }
   },
   "id": "8a8bf5b17df76bee",
   "execution_count": 53
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-13T14:13:35.606465Z",
     "start_time": "2024-11-13T14:13:35.503465Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Step: Edge Detection\n",
      "----------------------------------------\n",
      "Best Technique for Image_144: Canny Edge\n",
      "Best Technique for Image_270: Canny Edge\n",
      "Best Technique for Image_673: Canny Edge\n",
      "Best Technique for Image_424: Canny Edge\n",
      "Best Technique for Image_139: Canny Edge\n",
      "\n",
      "Recommended Technique for Edge Detection: Canny Edge\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Edge Detection\n",
    "edge_detection_techniques = {\n",
    "    \"Canny Edge\": lambda img: cv2.Canny(img, 100, 200),\n",
    "    \"Sobel Edge\": lambda img: cv2.convertScaleAbs(cv2.Sobel(img, cv2.CV_64F, 1, 1, ksize=3))\n",
    "}\n",
    "comparison_tables.append(run_step(\"Edge Detection\", edge_detection_techniques, test_images, test_image_ids, best_techniques_list))"
<<<<<<< HEAD
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:32:03.900034Z",
     "start_time": "2024-11-18T16:32:03.869034Z"
    }
   },
   "id": "7e47a9227209a883",
   "execution_count": 54
=======
   ]
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
  },
  {
   "cell_type": "markdown",
   "id": "8439513ab9cfdf06",
   "metadata": {},
   "source": [
    "## Final best techniques per step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7264edc32f3787a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T14:13:47.673699Z",
     "start_time": "2024-11-13T14:13:47.653709Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Techniques for Each Step:\n",
      "Noise Reduction: Non-Local Means\n",
      "Histogram Equalization: Histogram Equalization\n",
      "Binarization: Adaptive Threshold\n",
      "Morphological Operations: Erosion\n",
      "Edge Detection: Canny Edge\n"
     ]
    }
   ],
   "source": [
    "# Print the list of best techniques for each step\n",
    "print(\"\\nBest Techniques for Each Step:\")\n",
    "for step, technique_name, technique_func in best_techniques_list:\n",
    "    print(f\"{step}: {technique_name}\")"
<<<<<<< HEAD
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:32:03.915032Z",
     "start_time": "2024-11-18T16:32:03.901033Z"
    }
   },
   "id": "7264edc32f3787a",
   "execution_count": 55
=======
   ]
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a8b12bb0b5a2f14c",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-18T16:32:03.930032Z",
     "start_time": "2024-11-18T16:32:03.916032Z"
    }
   },
   "id": "a8b12bb0b5a2f14c",
   "execution_count": 56
=======
     "end_time": "2024-11-13T14:13:49.738800Z",
     "start_time": "2024-11-13T14:13:49.716798Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for i, comparison_df in enumerate(comparison_tables):\n",
    "    comparison_df.to_csv(f\"comparison tables/comparison_table_step_{i+1}.csv\", index=False)"
   ]
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "22cfb8654a8557fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T14:13:50.177025Z",
     "start_time": "2024-11-13T14:13:50.123026Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table for Step 1:\n"
     ]
    },
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "    Image_ID                          Technique  Brightness   Sharpness  \\\n0  Image_144                           Original  105.442551  878.783992   \n1  Image_144    Noise Reduction - Gaussian Blur  105.463882   23.060809   \n2  Image_144      Noise Reduction - Median Blur  106.882797  121.808847   \n3  Image_144  Noise Reduction - Non-Local Means  105.832642  300.302401   \n4  Image_270                           Original  104.912491  383.849415   \n\n    Contrast      Noise  Skew  Line Spacing  Tables Detected  Resolution  \\\n0  43.876493  28.044017 -90.0           0.0              1.0     65536.0   \n1  42.638656   1.053578   NaN           NaN              NaN         NaN   \n2  43.549354   6.438945   NaN           NaN              NaN         NaN   \n3  43.452878  14.151011   NaN           NaN              NaN         NaN   \n4  40.795659  14.317919 -90.0           0.0              1.0     65536.0   \n\n   Detected Elements    Texture  Patterns  \n0                1.0  29.644291    3630.0  \n1                NaN        NaN       NaN  \n2                NaN        NaN       NaN  \n3                NaN        NaN       NaN  \n4                1.0  19.592075    1979.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_ID</th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n      <th>Skew</th>\n      <th>Line Spacing</th>\n      <th>Tables Detected</th>\n      <th>Resolution</th>\n      <th>Detected Elements</th>\n      <th>Texture</th>\n      <th>Patterns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_144</td>\n      <td>Original</td>\n      <td>105.442551</td>\n      <td>878.783992</td>\n      <td>43.876493</td>\n      <td>28.044017</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>65536.0</td>\n      <td>1.0</td>\n      <td>29.644291</td>\n      <td>3630.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_144</td>\n      <td>Noise Reduction - Gaussian Blur</td>\n      <td>105.463882</td>\n      <td>23.060809</td>\n      <td>42.638656</td>\n      <td>1.053578</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_144</td>\n      <td>Noise Reduction - Median Blur</td>\n      <td>106.882797</td>\n      <td>121.808847</td>\n      <td>43.549354</td>\n      <td>6.438945</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_144</td>\n      <td>Noise Reduction - Non-Local Means</td>\n      <td>105.832642</td>\n      <td>300.302401</td>\n      <td>43.452878</td>\n      <td>14.151011</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_270</td>\n      <td>Original</td>\n      <td>104.912491</td>\n      <td>383.849415</td>\n      <td>40.795659</td>\n      <td>14.317919</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>65536.0</td>\n      <td>1.0</td>\n      <td>19.592075</td>\n      <td>1979.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
=======
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Brightness</th>\n",
       "      <th>Sharpness</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Noise</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Line Spacing</th>\n",
       "      <th>Tables Detected</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Detected Elements</th>\n",
       "      <th>Texture</th>\n",
       "      <th>Patterns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_168</td>\n",
       "      <td>Original</td>\n",
       "      <td>102.072388</td>\n",
       "      <td>978.061044</td>\n",
       "      <td>43.181213</td>\n",
       "      <td>32.850364</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>65536</td>\n",
       "      <td>1</td>\n",
       "      <td>31.273968</td>\n",
       "      <td>3863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_168</td>\n",
       "      <td>Noise Reduction - Gaussian Blur</td>\n",
       "      <td>102.101547</td>\n",
       "      <td>23.812057</td>\n",
       "      <td>41.874337</td>\n",
       "      <td>1.118163</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>65536</td>\n",
       "      <td>1</td>\n",
       "      <td>4.879760</td>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_168</td>\n",
       "      <td>Noise Reduction - Median Blur</td>\n",
       "      <td>103.508911</td>\n",
       "      <td>111.742331</td>\n",
       "      <td>42.719517</td>\n",
       "      <td>5.970850</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>65536</td>\n",
       "      <td>1</td>\n",
       "      <td>10.570825</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_168</td>\n",
       "      <td>Noise Reduction - Non-Local Means</td>\n",
       "      <td>102.519684</td>\n",
       "      <td>363.663595</td>\n",
       "      <td>42.825398</td>\n",
       "      <td>17.555627</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>65536</td>\n",
       "      <td>1</td>\n",
       "      <td>19.069966</td>\n",
       "      <td>1884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_642</td>\n",
       "      <td>Original</td>\n",
       "      <td>109.358383</td>\n",
       "      <td>1760.960945</td>\n",
       "      <td>52.015105</td>\n",
       "      <td>56.500502</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>1.59375</td>\n",
       "      <td>2</td>\n",
       "      <td>65536</td>\n",
       "      <td>161</td>\n",
       "      <td>41.963805</td>\n",
       "      <td>4931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Image_ID                          Technique  Brightness    Sharpness  \\\n",
       "0  Image_168                           Original  102.072388   978.061044   \n",
       "1  Image_168    Noise Reduction - Gaussian Blur  102.101547    23.812057   \n",
       "2  Image_168      Noise Reduction - Median Blur  103.508911   111.742331   \n",
       "3  Image_168  Noise Reduction - Non-Local Means  102.519684   363.663595   \n",
       "4  Image_642                           Original  109.358383  1760.960945   \n",
       "\n",
       "    Contrast      Noise  Skew  Line Spacing  Tables Detected  Resolution  \\\n",
       "0  43.181213  32.850364 -90.0       0.00000                1       65536   \n",
       "1  41.874337   1.118163 -90.0       0.00000                2       65536   \n",
       "2  42.719517   5.970850 -90.0       0.00000                1       65536   \n",
       "3  42.825398  17.555627 -90.0       0.00000                1       65536   \n",
       "4  52.015105  56.500502 -90.0       1.59375                2       65536   \n",
       "\n",
       "   Detected Elements    Texture  Patterns  \n",
       "0                  1  31.273968      3863  \n",
       "1                  1   4.879760      1103  \n",
       "2                  1  10.570825       992  \n",
       "3                  1  19.069966      1884  \n",
       "4                161  41.963805      4931  "
      ]
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table for Step 2:\n"
     ]
    },
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "    Image_ID                                        Technique  Brightness  \\\n0  Image_144                                         Original  105.442551   \n1  Image_144  Histogram Equalization - Histogram Equalization  129.492935   \n2  Image_144                   Histogram Equalization - CLAHE  124.683655   \n3  Image_270                                         Original  104.912491   \n4  Image_270  Histogram Equalization - Histogram Equalization  130.220413   \n\n     Sharpness   Contrast       Noise  Skew  Line Spacing  Tables Detected  \\\n0   878.783992  43.876493   28.044017 -90.0           0.0              1.0   \n1  4026.472115  74.188186  107.734846   NaN           NaN              NaN   \n2  2233.693986  49.140666   58.068508   NaN           NaN              NaN   \n3   383.849415  40.795659   14.317919 -90.0           0.0              1.0   \n4  2878.605315  74.642132   75.150072   NaN           NaN              NaN   \n\n   Resolution  Detected Elements    Texture  Patterns  \n0     65536.0                1.0  29.644291    3630.0  \n1         NaN                NaN        NaN       NaN  \n2         NaN                NaN        NaN       NaN  \n3     65536.0                1.0  19.592075    1979.0  \n4         NaN                NaN        NaN       NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_ID</th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n      <th>Skew</th>\n      <th>Line Spacing</th>\n      <th>Tables Detected</th>\n      <th>Resolution</th>\n      <th>Detected Elements</th>\n      <th>Texture</th>\n      <th>Patterns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_144</td>\n      <td>Original</td>\n      <td>105.442551</td>\n      <td>878.783992</td>\n      <td>43.876493</td>\n      <td>28.044017</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>65536.0</td>\n      <td>1.0</td>\n      <td>29.644291</td>\n      <td>3630.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_144</td>\n      <td>Histogram Equalization - Histogram Equalization</td>\n      <td>129.492935</td>\n      <td>4026.472115</td>\n      <td>74.188186</td>\n      <td>107.734846</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_144</td>\n      <td>Histogram Equalization - CLAHE</td>\n      <td>124.683655</td>\n      <td>2233.693986</td>\n      <td>49.140666</td>\n      <td>58.068508</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_270</td>\n      <td>Original</td>\n      <td>104.912491</td>\n      <td>383.849415</td>\n      <td>40.795659</td>\n      <td>14.317919</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>65536.0</td>\n      <td>1.0</td>\n      <td>19.592075</td>\n      <td>1979.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_270</td>\n      <td>Histogram Equalization - Histogram Equalization</td>\n      <td>130.220413</td>\n      <td>2878.605315</td>\n      <td>74.642132</td>\n      <td>75.150072</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
=======
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Brightness</th>\n",
       "      <th>Sharpness</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Noise</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Line Spacing</th>\n",
       "      <th>Tables Detected</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Detected Elements</th>\n",
       "      <th>Texture</th>\n",
       "      <th>Patterns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_168</td>\n",
       "      <td>Original</td>\n",
       "      <td>102.072388</td>\n",
       "      <td>978.061044</td>\n",
       "      <td>43.181213</td>\n",
       "      <td>32.850364</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>65536</td>\n",
       "      <td>1</td>\n",
       "      <td>31.273968</td>\n",
       "      <td>3863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_168</td>\n",
       "      <td>Histogram Equalization - Histogram Equalization</td>\n",
       "      <td>130.006622</td>\n",
       "      <td>5328.425232</td>\n",
       "      <td>74.273891</td>\n",
       "      <td>138.782599</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.605701</td>\n",
       "      <td>3</td>\n",
       "      <td>65536</td>\n",
       "      <td>422</td>\n",
       "      <td>72.996063</td>\n",
       "      <td>8332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_168</td>\n",
       "      <td>Histogram Equalization - CLAHE</td>\n",
       "      <td>120.380508</td>\n",
       "      <td>2234.628612</td>\n",
       "      <td>48.583296</td>\n",
       "      <td>61.975004</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>2</td>\n",
       "      <td>65536</td>\n",
       "      <td>276</td>\n",
       "      <td>47.271859</td>\n",
       "      <td>5905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_642</td>\n",
       "      <td>Original</td>\n",
       "      <td>109.358383</td>\n",
       "      <td>1760.960945</td>\n",
       "      <td>52.015105</td>\n",
       "      <td>56.500502</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>1.593750</td>\n",
       "      <td>2</td>\n",
       "      <td>65536</td>\n",
       "      <td>161</td>\n",
       "      <td>41.963805</td>\n",
       "      <td>4931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_642</td>\n",
       "      <td>Histogram Equalization - Histogram Equalization</td>\n",
       "      <td>128.542160</td>\n",
       "      <td>3610.248460</td>\n",
       "      <td>73.686047</td>\n",
       "      <td>107.169441</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.861486</td>\n",
       "      <td>2</td>\n",
       "      <td>65536</td>\n",
       "      <td>297</td>\n",
       "      <td>60.085343</td>\n",
       "      <td>6574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Image_ID                                        Technique  Brightness  \\\n",
       "0  Image_168                                         Original  102.072388   \n",
       "1  Image_168  Histogram Equalization - Histogram Equalization  130.006622   \n",
       "2  Image_168                   Histogram Equalization - CLAHE  120.380508   \n",
       "3  Image_642                                         Original  109.358383   \n",
       "4  Image_642  Histogram Equalization - Histogram Equalization  128.542160   \n",
       "\n",
       "     Sharpness   Contrast       Noise  Skew  Line Spacing  Tables Detected  \\\n",
       "0   978.061044  43.181213   32.850364 -90.0      0.000000                1   \n",
       "1  5328.425232  74.273891  138.782599 -90.0      0.605701                3   \n",
       "2  2234.628612  48.583296   61.975004 -90.0      0.927273                2   \n",
       "3  1760.960945  52.015105   56.500502 -90.0      1.593750                2   \n",
       "4  3610.248460  73.686047  107.169441 -90.0      0.861486                2   \n",
       "\n",
       "   Resolution  Detected Elements    Texture  Patterns  \n",
       "0       65536                  1  31.273968      3863  \n",
       "1       65536                422  72.996063      8332  \n",
       "2       65536                276  47.271859      5905  \n",
       "3       65536                161  41.963805      4931  \n",
       "4       65536                297  60.085343      6574  "
      ]
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table for Step 3:\n"
     ]
    },
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "    Image_ID                          Technique  Brightness      Sharpness  \\\n0  Image_144                           Original  105.442551     878.783992   \n1  Image_144    Binarization - Global Threshold  116.756973   39926.230293   \n2  Image_144  Binarization - Adaptive Threshold  196.238251  133066.293419   \n3  Image_144      Binarization - Otsu Threshold  191.479568   14748.088181   \n4  Image_270                           Original  104.912491     383.849415   \n\n     Contrast        Noise  Skew  Line Spacing  Tables Detected  Resolution  \\\n0   43.876493    28.044017 -90.0           0.0              1.0     65536.0   \n1  127.046595  1272.351242   NaN           NaN              NaN         NaN   \n2  107.383904  2545.865893   NaN           NaN              NaN         NaN   \n3  110.285379   543.256054   NaN           NaN              NaN         NaN   \n4   40.795659    14.317919 -90.0           0.0              1.0     65536.0   \n\n   Detected Elements    Texture  Patterns  \n0                1.0  29.644291    3630.0  \n1                NaN        NaN       NaN  \n2                NaN        NaN       NaN  \n3                NaN        NaN       NaN  \n4                1.0  19.592075    1979.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_ID</th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n      <th>Skew</th>\n      <th>Line Spacing</th>\n      <th>Tables Detected</th>\n      <th>Resolution</th>\n      <th>Detected Elements</th>\n      <th>Texture</th>\n      <th>Patterns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_144</td>\n      <td>Original</td>\n      <td>105.442551</td>\n      <td>878.783992</td>\n      <td>43.876493</td>\n      <td>28.044017</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>65536.0</td>\n      <td>1.0</td>\n      <td>29.644291</td>\n      <td>3630.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_144</td>\n      <td>Binarization - Global Threshold</td>\n      <td>116.756973</td>\n      <td>39926.230293</td>\n      <td>127.046595</td>\n      <td>1272.351242</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_144</td>\n      <td>Binarization - Adaptive Threshold</td>\n      <td>196.238251</td>\n      <td>133066.293419</td>\n      <td>107.383904</td>\n      <td>2545.865893</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_144</td>\n      <td>Binarization - Otsu Threshold</td>\n      <td>191.479568</td>\n      <td>14748.088181</td>\n      <td>110.285379</td>\n      <td>543.256054</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_270</td>\n      <td>Original</td>\n      <td>104.912491</td>\n      <td>383.849415</td>\n      <td>40.795659</td>\n      <td>14.317919</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>65536.0</td>\n      <td>1.0</td>\n      <td>19.592075</td>\n      <td>1979.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
=======
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Brightness</th>\n",
       "      <th>Sharpness</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Noise</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Line Spacing</th>\n",
       "      <th>Tables Detected</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Detected Elements</th>\n",
       "      <th>Texture</th>\n",
       "      <th>Patterns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_168</td>\n",
       "      <td>Original</td>\n",
       "      <td>102.072388</td>\n",
       "      <td>978.061044</td>\n",
       "      <td>43.181213</td>\n",
       "      <td>32.850364</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>65536</td>\n",
       "      <td>1</td>\n",
       "      <td>31.273968</td>\n",
       "      <td>3863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_168</td>\n",
       "      <td>Binarization - Global Threshold</td>\n",
       "      <td>99.049072</td>\n",
       "      <td>44951.731438</td>\n",
       "      <td>124.285135</td>\n",
       "      <td>1352.177491</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.639098</td>\n",
       "      <td>1</td>\n",
       "      <td>65536</td>\n",
       "      <td>400</td>\n",
       "      <td>212.018234</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_168</td>\n",
       "      <td>Binarization - Adaptive Threshold</td>\n",
       "      <td>201.448288</td>\n",
       "      <td>132966.082076</td>\n",
       "      <td>103.864819</td>\n",
       "      <td>2584.828339</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.087496</td>\n",
       "      <td>1</td>\n",
       "      <td>65536</td>\n",
       "      <td>2824</td>\n",
       "      <td>364.645145</td>\n",
       "      <td>17617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_168</td>\n",
       "      <td>Binarization - Otsu Threshold</td>\n",
       "      <td>189.689713</td>\n",
       "      <td>16191.738274</td>\n",
       "      <td>111.304491</td>\n",
       "      <td>577.710957</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.620438</td>\n",
       "      <td>2</td>\n",
       "      <td>65536</td>\n",
       "      <td>412</td>\n",
       "      <td>127.246761</td>\n",
       "      <td>3830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_642</td>\n",
       "      <td>Original</td>\n",
       "      <td>109.358383</td>\n",
       "      <td>1760.960945</td>\n",
       "      <td>52.015105</td>\n",
       "      <td>56.500502</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>1.593750</td>\n",
       "      <td>2</td>\n",
       "      <td>65536</td>\n",
       "      <td>161</td>\n",
       "      <td>41.963805</td>\n",
       "      <td>4931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Image_ID                          Technique  Brightness      Sharpness  \\\n",
       "0  Image_168                           Original  102.072388     978.061044   \n",
       "1  Image_168    Binarization - Global Threshold   99.049072   44951.731438   \n",
       "2  Image_168  Binarization - Adaptive Threshold  201.448288  132966.082076   \n",
       "3  Image_168      Binarization - Otsu Threshold  189.689713   16191.738274   \n",
       "4  Image_642                           Original  109.358383    1760.960945   \n",
       "\n",
       "     Contrast        Noise  Skew  Line Spacing  Tables Detected  Resolution  \\\n",
       "0   43.181213    32.850364 -90.0      0.000000                1       65536   \n",
       "1  124.285135  1352.177491 -90.0      0.639098                1       65536   \n",
       "2  103.864819  2584.828339 -90.0      0.087496                1       65536   \n",
       "3  111.304491   577.710957 -90.0      0.620438                2       65536   \n",
       "4   52.015105    56.500502 -90.0      1.593750                2       65536   \n",
       "\n",
       "   Detected Elements     Texture  Patterns  \n",
       "0                  1   31.273968      3863  \n",
       "1                400  212.018234      6651  \n",
       "2               2824  364.645145     17617  \n",
       "3                412  127.246761      3830  \n",
       "4                161   41.963805      4931  "
      ]
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table for Step 4:\n"
     ]
    },
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "    Image_ID                            Technique  Brightness   Sharpness  \\\n0  Image_144                             Original  105.442551  878.783992   \n1  Image_144  Morphological Operations - Dilation  114.804138  141.685569   \n2  Image_144   Morphological Operations - Erosion   87.088043  621.414689   \n3  Image_144   Morphological Operations - Opening  101.126312  514.909845   \n4  Image_144   Morphological Operations - Closing  109.990479  134.373209   \n\n    Contrast      Noise  Skew  Line Spacing  Tables Detected  Resolution  \\\n0  43.876493  28.044017 -90.0           0.0              1.0     65536.0   \n1  41.295956   7.386752   NaN           NaN              NaN         NaN   \n2  44.944366  24.778242   NaN           NaN              NaN         NaN   \n3  44.036324  21.316685   NaN           NaN              NaN         NaN   \n4  42.887003   7.023791   NaN           NaN              NaN         NaN   \n\n   Detected Elements    Texture  Patterns  \n0                1.0  29.644291    3630.0  \n1                NaN        NaN       NaN  \n2                NaN        NaN       NaN  \n3                NaN        NaN       NaN  \n4                NaN        NaN       NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_ID</th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n      <th>Skew</th>\n      <th>Line Spacing</th>\n      <th>Tables Detected</th>\n      <th>Resolution</th>\n      <th>Detected Elements</th>\n      <th>Texture</th>\n      <th>Patterns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_144</td>\n      <td>Original</td>\n      <td>105.442551</td>\n      <td>878.783992</td>\n      <td>43.876493</td>\n      <td>28.044017</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>65536.0</td>\n      <td>1.0</td>\n      <td>29.644291</td>\n      <td>3630.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_144</td>\n      <td>Morphological Operations - Dilation</td>\n      <td>114.804138</td>\n      <td>141.685569</td>\n      <td>41.295956</td>\n      <td>7.386752</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_144</td>\n      <td>Morphological Operations - Erosion</td>\n      <td>87.088043</td>\n      <td>621.414689</td>\n      <td>44.944366</td>\n      <td>24.778242</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_144</td>\n      <td>Morphological Operations - Opening</td>\n      <td>101.126312</td>\n      <td>514.909845</td>\n      <td>44.036324</td>\n      <td>21.316685</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_144</td>\n      <td>Morphological Operations - Closing</td>\n      <td>109.990479</td>\n      <td>134.373209</td>\n      <td>42.887003</td>\n      <td>7.023791</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
=======
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Brightness</th>\n",
       "      <th>Sharpness</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Noise</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Line Spacing</th>\n",
       "      <th>Tables Detected</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Detected Elements</th>\n",
       "      <th>Texture</th>\n",
       "      <th>Patterns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_168</td>\n",
       "      <td>Original</td>\n",
       "      <td>102.072388</td>\n",
       "      <td>978.061044</td>\n",
       "      <td>43.181213</td>\n",
       "      <td>32.850364</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>65536</td>\n",
       "      <td>1</td>\n",
       "      <td>31.273968</td>\n",
       "      <td>3863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_168</td>\n",
       "      <td>Morphological Operations - Dilation</td>\n",
       "      <td>110.889069</td>\n",
       "      <td>128.098141</td>\n",
       "      <td>41.176608</td>\n",
       "      <td>6.784680</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>65536</td>\n",
       "      <td>1</td>\n",
       "      <td>11.318045</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_168</td>\n",
       "      <td>Morphological Operations - Erosion</td>\n",
       "      <td>84.292847</td>\n",
       "      <td>588.418070</td>\n",
       "      <td>44.491891</td>\n",
       "      <td>24.163212</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>65536</td>\n",
       "      <td>1</td>\n",
       "      <td>24.257330</td>\n",
       "      <td>5870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_168</td>\n",
       "      <td>Morphological Operations - Opening</td>\n",
       "      <td>97.500473</td>\n",
       "      <td>518.894563</td>\n",
       "      <td>43.276082</td>\n",
       "      <td>22.217615</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>65536</td>\n",
       "      <td>1</td>\n",
       "      <td>22.779257</td>\n",
       "      <td>4182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_168</td>\n",
       "      <td>Morphological Operations - Closing</td>\n",
       "      <td>106.481705</td>\n",
       "      <td>128.957677</td>\n",
       "      <td>42.070947</td>\n",
       "      <td>6.950182</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>65536</td>\n",
       "      <td>1</td>\n",
       "      <td>11.355953</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Image_ID                            Technique  Brightness   Sharpness  \\\n",
       "0  Image_168                             Original  102.072388  978.061044   \n",
       "1  Image_168  Morphological Operations - Dilation  110.889069  128.098141   \n",
       "2  Image_168   Morphological Operations - Erosion   84.292847  588.418070   \n",
       "3  Image_168   Morphological Operations - Opening   97.500473  518.894563   \n",
       "4  Image_168   Morphological Operations - Closing  106.481705  128.957677   \n",
       "\n",
       "    Contrast      Noise  Skew  Line Spacing  Tables Detected  Resolution  \\\n",
       "0  43.181213  32.850364 -90.0           0.0                1       65536   \n",
       "1  41.176608   6.784680 -90.0           0.0                1       65536   \n",
       "2  44.491891  24.163212 -90.0           0.0                1       65536   \n",
       "3  43.276082  22.217615 -90.0           0.0                2       65536   \n",
       "4  42.070947   6.950182 -90.0           0.0                1       65536   \n",
       "\n",
       "   Detected Elements    Texture  Patterns  \n",
       "0                  1  31.273968      3863  \n",
       "1                  1  11.318045      1011  \n",
       "2                  1  24.257330      5870  \n",
       "3                  1  22.779257      4182  \n",
       "4                  1  11.355953      1010  "
      ]
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table for Step 5:\n"
     ]
    },
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "    Image_ID                    Technique  Brightness     Sharpness  \\\n0  Image_144                     Original  105.442551    878.783992   \n1  Image_144  Edge Detection - Canny Edge   14.124298  31950.901369   \n2  Image_144  Edge Detection - Sobel Edge    6.361526   1739.862594   \n3  Image_270                     Original  104.912491    383.849415   \n4  Image_270  Edge Detection - Canny Edge    7.700272  16235.413727   \n\n    Contrast        Noise  Skew  Line Spacing  Tables Detected  Resolution  \\\n0  43.876493    28.044017 -90.0           0.0              1.0     65536.0   \n1  58.328383  1242.833447   NaN           NaN              NaN         NaN   \n2  12.156799    43.992756   NaN           NaN              NaN         NaN   \n3  40.795659    14.317919 -90.0           0.0              1.0     65536.0   \n4  43.638000   695.878102   NaN           NaN              NaN         NaN   \n\n   Detected Elements    Texture  Patterns  \n0                1.0  29.644291    3630.0  \n1                NaN        NaN       NaN  \n2                NaN        NaN       NaN  \n3                1.0  19.592075    1979.0  \n4                NaN        NaN       NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_ID</th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n      <th>Skew</th>\n      <th>Line Spacing</th>\n      <th>Tables Detected</th>\n      <th>Resolution</th>\n      <th>Detected Elements</th>\n      <th>Texture</th>\n      <th>Patterns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_144</td>\n      <td>Original</td>\n      <td>105.442551</td>\n      <td>878.783992</td>\n      <td>43.876493</td>\n      <td>28.044017</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>65536.0</td>\n      <td>1.0</td>\n      <td>29.644291</td>\n      <td>3630.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_144</td>\n      <td>Edge Detection - Canny Edge</td>\n      <td>14.124298</td>\n      <td>31950.901369</td>\n      <td>58.328383</td>\n      <td>1242.833447</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_144</td>\n      <td>Edge Detection - Sobel Edge</td>\n      <td>6.361526</td>\n      <td>1739.862594</td>\n      <td>12.156799</td>\n      <td>43.992756</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_270</td>\n      <td>Original</td>\n      <td>104.912491</td>\n      <td>383.849415</td>\n      <td>40.795659</td>\n      <td>14.317919</td>\n      <td>-90.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>65536.0</td>\n      <td>1.0</td>\n      <td>19.592075</td>\n      <td>1979.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_270</td>\n      <td>Edge Detection - Canny Edge</td>\n      <td>7.700272</td>\n      <td>16235.413727</td>\n      <td>43.638000</td>\n      <td>695.878102</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
=======
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Brightness</th>\n",
       "      <th>Sharpness</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Noise</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Line Spacing</th>\n",
       "      <th>Tables Detected</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Detected Elements</th>\n",
       "      <th>Texture</th>\n",
       "      <th>Patterns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_168</td>\n",
       "      <td>Original</td>\n",
       "      <td>102.072388</td>\n",
       "      <td>978.061044</td>\n",
       "      <td>43.181213</td>\n",
       "      <td>32.850364</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>65536</td>\n",
       "      <td>1</td>\n",
       "      <td>31.273968</td>\n",
       "      <td>3863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_168</td>\n",
       "      <td>Edge Detection - Canny Edge</td>\n",
       "      <td>15.030899</td>\n",
       "      <td>34312.304874</td>\n",
       "      <td>60.057900</td>\n",
       "      <td>1323.056184</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>65536</td>\n",
       "      <td>1</td>\n",
       "      <td>185.235809</td>\n",
       "      <td>5242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_168</td>\n",
       "      <td>Edge Detection - Sobel Edge</td>\n",
       "      <td>6.434784</td>\n",
       "      <td>1951.784930</td>\n",
       "      <td>12.957535</td>\n",
       "      <td>50.027596</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>65536</td>\n",
       "      <td>1</td>\n",
       "      <td>44.179010</td>\n",
       "      <td>3702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_642</td>\n",
       "      <td>Original</td>\n",
       "      <td>109.358383</td>\n",
       "      <td>1760.960945</td>\n",
       "      <td>52.015105</td>\n",
       "      <td>56.500502</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>1.59375</td>\n",
       "      <td>2</td>\n",
       "      <td>65536</td>\n",
       "      <td>161</td>\n",
       "      <td>41.963805</td>\n",
       "      <td>4931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_642</td>\n",
       "      <td>Edge Detection - Canny Edge</td>\n",
       "      <td>19.186478</td>\n",
       "      <td>43328.501895</td>\n",
       "      <td>67.263890</td>\n",
       "      <td>1583.965897</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>65536</td>\n",
       "      <td>1</td>\n",
       "      <td>208.154995</td>\n",
       "      <td>6268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Image_ID                    Technique  Brightness     Sharpness  \\\n",
       "0  Image_168                     Original  102.072388    978.061044   \n",
       "1  Image_168  Edge Detection - Canny Edge   15.030899  34312.304874   \n",
       "2  Image_168  Edge Detection - Sobel Edge    6.434784   1951.784930   \n",
       "3  Image_642                     Original  109.358383   1760.960945   \n",
       "4  Image_642  Edge Detection - Canny Edge   19.186478  43328.501895   \n",
       "\n",
       "    Contrast        Noise  Skew  Line Spacing  Tables Detected  Resolution  \\\n",
       "0  43.181213    32.850364 -90.0       0.00000                1       65536   \n",
       "1  60.057900  1323.056184 -90.0       0.00000                1       65536   \n",
       "2  12.957535    50.027596 -90.0       0.00000                1       65536   \n",
       "3  52.015105    56.500502 -90.0       1.59375                2       65536   \n",
       "4  67.263890  1583.965897 -90.0       0.00000                1       65536   \n",
       "\n",
       "   Detected Elements     Texture  Patterns  \n",
       "0                  1   31.273968      3863  \n",
       "1                  1  185.235809      5242  \n",
       "2                  1   44.179010      3702  \n",
       "3                161   41.963805      4931  \n",
       "4                  1  208.154995      6268  "
      ]
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display comparison tables within the notebook\n",
    "for i, comparison_df in enumerate(comparison_tables):\n",
    "    print(f\"Comparison Table for Step {i+1}:\")\n",
    "    display(comparison_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "624d20d42c755cc5",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-18T16:32:03.992031Z",
     "start_time": "2024-11-18T16:32:03.933031Z"
    }
   },
   "id": "22cfb8654a8557fc",
   "execution_count": 57
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-13T14:13:51.204468Z",
     "start_time": "2024-11-13T14:13:51.177466Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
   "outputs": [],
   "source": [
    "# Generate Average Comparison Table\n",
    "average_comparison_data = []\n",
    "for comparison_df in comparison_tables:\n",
    "    avg_stats = comparison_df.groupby(\"Technique\").mean().reset_index()\n",
    "    average_comparison_data.append(avg_stats)\n",
    "\n",
    "# Combine average stats from all steps\n",
    "average_comparison_df = pd.concat(average_comparison_data, ignore_index=True)\n",
    "# Save the average comparison table to a CSV file\n",
    "average_comparison_df.to_csv(\"average_comparison_table.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "fe7133144103efbc",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-18T16:32:04.008034Z",
     "start_time": "2024-11-18T16:32:03.993033Z"
    }
   },
   "id": "624d20d42c755cc5",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                          Technique  Brightness  \\\n0                   Noise Reduction - Gaussian Blur  105.260486   \n1                     Noise Reduction - Median Blur  106.605545   \n2                 Noise Reduction - Non-Local Means  105.587057   \n3                                          Original  105.248325   \n4                    Histogram Equalization - CLAHE  124.179880   \n5   Histogram Equalization - Histogram Equalization  129.451764   \n6                                          Original  105.248325   \n7                 Binarization - Adaptive Threshold  196.267044   \n8                   Binarization - Global Threshold  104.832642   \n9                     Binarization - Otsu Threshold  193.930893   \n10                                         Original  105.248325   \n11               Morphological Operations - Closing  109.818475   \n12              Morphological Operations - Dilation  114.813745   \n13               Morphological Operations - Erosion   88.407144   \n14               Morphological Operations - Opening  101.118991   \n15                                         Original  105.248325   \n16                      Edge Detection - Canny Edge   14.432465   \n17                      Edge Detection - Sobel Edge    6.034091   \n18                                         Original  105.248325   \n\n        Sharpness    Contrast        Noise  Skew  Line Spacing  \\\n0       23.487330   41.371877     1.076727   NaN           NaN   \n1      113.463440   42.131764     5.681749   NaN           NaN   \n2      431.954884   42.287182    19.247578   NaN           NaN   \n3      894.339739   42.690301    29.998493 -90.0      1.378378   \n4     2165.506656   47.297139    59.393571   NaN           NaN   \n5     3898.946640   74.137555   109.654599   NaN           NaN   \n6      894.339739   42.690301    29.998493 -90.0      1.378378   \n7   133350.445271  107.269969  2537.248577   NaN           NaN   \n8    36790.479047  124.970479  1187.282099   NaN           NaN   \n9    15110.048065  108.142238   566.560188   NaN           NaN   \n10     894.339739   42.690301    29.998493 -90.0      1.378378   \n11     135.725370   41.451581     6.952975   NaN           NaN   \n12     148.426479   39.910699     7.659574   NaN           NaN   \n13     560.211693   45.080016    23.199851   NaN           NaN   \n14     495.635609   42.972709    21.303621   NaN           NaN   \n15     894.339739   42.690301    29.998493 -90.0      1.378378   \n16   32049.523613   58.170604  1252.863327   NaN           NaN   \n17    1607.648709   12.114073    42.199061   NaN           NaN   \n18     894.339739   42.690301    29.998493 -90.0      1.378378   \n\n    Tables Detected  Resolution  Detected Elements    Texture  Patterns  \n0               NaN         NaN                NaN        NaN       NaN  \n1               NaN         NaN                NaN        NaN       NaN  \n2               NaN         NaN                NaN        NaN       NaN  \n3               1.4     65536.0                8.4  29.438506    3709.2  \n4               NaN         NaN                NaN        NaN       NaN  \n5               NaN         NaN                NaN        NaN       NaN  \n6               1.4     65536.0                8.4  29.438506    3709.2  \n7               NaN         NaN                NaN        NaN       NaN  \n8               NaN         NaN                NaN        NaN       NaN  \n9               NaN         NaN                NaN        NaN       NaN  \n10              1.4     65536.0                8.4  29.438506    3709.2  \n11              NaN         NaN                NaN        NaN       NaN  \n12              NaN         NaN                NaN        NaN       NaN  \n13              NaN         NaN                NaN        NaN       NaN  \n14              NaN         NaN                NaN        NaN       NaN  \n15              1.4     65536.0                8.4  29.438506    3709.2  \n16              NaN         NaN                NaN        NaN       NaN  \n17              NaN         NaN                NaN        NaN       NaN  \n18              1.4     65536.0                8.4  29.438506    3709.2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n      <th>Skew</th>\n      <th>Line Spacing</th>\n      <th>Tables Detected</th>\n      <th>Resolution</th>\n      <th>Detected Elements</th>\n      <th>Texture</th>\n      <th>Patterns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Noise Reduction - Gaussian Blur</td>\n      <td>105.260486</td>\n      <td>23.487330</td>\n      <td>41.371877</td>\n      <td>1.076727</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Noise Reduction - Median Blur</td>\n      <td>106.605545</td>\n      <td>113.463440</td>\n      <td>42.131764</td>\n      <td>5.681749</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Noise Reduction - Non-Local Means</td>\n      <td>105.587057</td>\n      <td>431.954884</td>\n      <td>42.287182</td>\n      <td>19.247578</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Original</td>\n      <td>105.248325</td>\n      <td>894.339739</td>\n      <td>42.690301</td>\n      <td>29.998493</td>\n      <td>-90.0</td>\n      <td>1.378378</td>\n      <td>1.4</td>\n      <td>65536.0</td>\n      <td>8.4</td>\n      <td>29.438506</td>\n      <td>3709.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Histogram Equalization - CLAHE</td>\n      <td>124.179880</td>\n      <td>2165.506656</td>\n      <td>47.297139</td>\n      <td>59.393571</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Histogram Equalization - Histogram Equalization</td>\n      <td>129.451764</td>\n      <td>3898.946640</td>\n      <td>74.137555</td>\n      <td>109.654599</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Original</td>\n      <td>105.248325</td>\n      <td>894.339739</td>\n      <td>42.690301</td>\n      <td>29.998493</td>\n      <td>-90.0</td>\n      <td>1.378378</td>\n      <td>1.4</td>\n      <td>65536.0</td>\n      <td>8.4</td>\n      <td>29.438506</td>\n      <td>3709.2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Binarization - Adaptive Threshold</td>\n      <td>196.267044</td>\n      <td>133350.445271</td>\n      <td>107.269969</td>\n      <td>2537.248577</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Binarization - Global Threshold</td>\n      <td>104.832642</td>\n      <td>36790.479047</td>\n      <td>124.970479</td>\n      <td>1187.282099</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Binarization - Otsu Threshold</td>\n      <td>193.930893</td>\n      <td>15110.048065</td>\n      <td>108.142238</td>\n      <td>566.560188</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Original</td>\n      <td>105.248325</td>\n      <td>894.339739</td>\n      <td>42.690301</td>\n      <td>29.998493</td>\n      <td>-90.0</td>\n      <td>1.378378</td>\n      <td>1.4</td>\n      <td>65536.0</td>\n      <td>8.4</td>\n      <td>29.438506</td>\n      <td>3709.2</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Morphological Operations - Closing</td>\n      <td>109.818475</td>\n      <td>135.725370</td>\n      <td>41.451581</td>\n      <td>6.952975</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Morphological Operations - Dilation</td>\n      <td>114.813745</td>\n      <td>148.426479</td>\n      <td>39.910699</td>\n      <td>7.659574</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Morphological Operations - Erosion</td>\n      <td>88.407144</td>\n      <td>560.211693</td>\n      <td>45.080016</td>\n      <td>23.199851</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Morphological Operations - Opening</td>\n      <td>101.118991</td>\n      <td>495.635609</td>\n      <td>42.972709</td>\n      <td>21.303621</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Original</td>\n      <td>105.248325</td>\n      <td>894.339739</td>\n      <td>42.690301</td>\n      <td>29.998493</td>\n      <td>-90.0</td>\n      <td>1.378378</td>\n      <td>1.4</td>\n      <td>65536.0</td>\n      <td>8.4</td>\n      <td>29.438506</td>\n      <td>3709.2</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Edge Detection - Canny Edge</td>\n      <td>14.432465</td>\n      <td>32049.523613</td>\n      <td>58.170604</td>\n      <td>1252.863327</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Edge Detection - Sobel Edge</td>\n      <td>6.034091</td>\n      <td>1607.648709</td>\n      <td>12.114073</td>\n      <td>42.199061</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Original</td>\n      <td>105.248325</td>\n      <td>894.339739</td>\n      <td>42.690301</td>\n      <td>29.998493</td>\n      <td>-90.0</td>\n      <td>1.378378</td>\n      <td>1.4</td>\n      <td>65536.0</td>\n      <td>8.4</td>\n      <td>29.438506</td>\n      <td>3709.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
=======
     "end_time": "2024-11-13T14:13:52.057687Z",
     "start_time": "2024-11-13T14:13:52.022682Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Technique</th>\n",
       "      <th>Brightness</th>\n",
       "      <th>Sharpness</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Noise</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Line Spacing</th>\n",
       "      <th>Tables Detected</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Detected Elements</th>\n",
       "      <th>Texture</th>\n",
       "      <th>Patterns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Noise Reduction - Gaussian Blur</td>\n",
       "      <td>107.162756</td>\n",
       "      <td>24.681440</td>\n",
       "      <td>41.958559</td>\n",
       "      <td>1.128670</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>8.009615</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>4.926009</td>\n",
       "      <td>1221.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Noise Reduction - Median Blur</td>\n",
       "      <td>108.618152</td>\n",
       "      <td>95.788121</td>\n",
       "      <td>42.708486</td>\n",
       "      <td>4.916750</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>11.079617</td>\n",
       "      <td>1.4</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>9.712208</td>\n",
       "      <td>1176.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Noise Reduction - Non-Local Means</td>\n",
       "      <td>107.536963</td>\n",
       "      <td>482.279009</td>\n",
       "      <td>42.909078</td>\n",
       "      <td>21.262351</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>19.660569</td>\n",
       "      <td>1.6</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>21.061042</td>\n",
       "      <td>2284.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Original</td>\n",
       "      <td>107.149319</td>\n",
       "      <td>1042.807841</td>\n",
       "      <td>43.318449</td>\n",
       "      <td>34.524881</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>52.286640</td>\n",
       "      <td>1.8</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>75.4</td>\n",
       "      <td>31.465931</td>\n",
       "      <td>3926.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Histogram Equalization - CLAHE</td>\n",
       "      <td>126.506528</td>\n",
       "      <td>2404.716668</td>\n",
       "      <td>47.830540</td>\n",
       "      <td>66.324622</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>0.704711</td>\n",
       "      <td>2.2</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>379.8</td>\n",
       "      <td>48.158238</td>\n",
       "      <td>6535.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Histogram Equalization - Histogram Equalization</td>\n",
       "      <td>129.341000</td>\n",
       "      <td>4132.136154</td>\n",
       "      <td>74.116035</td>\n",
       "      <td>118.173999</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.801573</td>\n",
       "      <td>2.4</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>331.4</td>\n",
       "      <td>63.944852</td>\n",
       "      <td>7529.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Original</td>\n",
       "      <td>107.149319</td>\n",
       "      <td>1042.807841</td>\n",
       "      <td>43.318449</td>\n",
       "      <td>34.524881</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>52.286640</td>\n",
       "      <td>1.8</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>75.4</td>\n",
       "      <td>31.465931</td>\n",
       "      <td>3926.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Binarization - Adaptive Threshold</td>\n",
       "      <td>196.684158</td>\n",
       "      <td>130853.866491</td>\n",
       "      <td>107.010438</td>\n",
       "      <td>2507.259614</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>0.102801</td>\n",
       "      <td>1.8</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>2512.6</td>\n",
       "      <td>361.378629</td>\n",
       "      <td>18201.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Binarization - Global Threshold</td>\n",
       "      <td>107.262177</td>\n",
       "      <td>37629.083617</td>\n",
       "      <td>125.651187</td>\n",
       "      <td>1189.211578</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.779416</td>\n",
       "      <td>1.4</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>193.481037</td>\n",
       "      <td>5701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Binarization - Otsu Threshold</td>\n",
       "      <td>195.659271</td>\n",
       "      <td>17345.278201</td>\n",
       "      <td>107.277268</td>\n",
       "      <td>623.156986</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>0.902003</td>\n",
       "      <td>1.8</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>369.6</td>\n",
       "      <td>129.692905</td>\n",
       "      <td>3767.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Original</td>\n",
       "      <td>107.149319</td>\n",
       "      <td>1042.807841</td>\n",
       "      <td>43.318449</td>\n",
       "      <td>34.524881</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>52.286640</td>\n",
       "      <td>1.8</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>75.4</td>\n",
       "      <td>31.465931</td>\n",
       "      <td>3926.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Morphological Operations - Closing</td>\n",
       "      <td>111.718808</td>\n",
       "      <td>130.919410</td>\n",
       "      <td>42.198184</td>\n",
       "      <td>6.766485</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>42.570000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>11.404722</td>\n",
       "      <td>1171.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Morphological Operations - Dilation</td>\n",
       "      <td>116.659772</td>\n",
       "      <td>138.736504</td>\n",
       "      <td>40.394424</td>\n",
       "      <td>7.203136</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>16.635714</td>\n",
       "      <td>1.8</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>11.721110</td>\n",
       "      <td>1181.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Morphological Operations - Erosion</td>\n",
       "      <td>89.189844</td>\n",
       "      <td>639.030252</td>\n",
       "      <td>45.984433</td>\n",
       "      <td>26.183838</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>27.610000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>24.620653</td>\n",
       "      <td>5177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Morphological Operations - Opening</td>\n",
       "      <td>102.595728</td>\n",
       "      <td>559.835454</td>\n",
       "      <td>43.509737</td>\n",
       "      <td>23.678647</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>27.388889</td>\n",
       "      <td>2.2</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>23.014468</td>\n",
       "      <td>3837.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Original</td>\n",
       "      <td>107.149319</td>\n",
       "      <td>1042.807841</td>\n",
       "      <td>43.318449</td>\n",
       "      <td>34.524881</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>52.286640</td>\n",
       "      <td>1.8</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>75.4</td>\n",
       "      <td>31.465931</td>\n",
       "      <td>3926.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Edge Detection - Canny Edge</td>\n",
       "      <td>15.276031</td>\n",
       "      <td>34669.139811</td>\n",
       "      <td>59.988003</td>\n",
       "      <td>1314.548009</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.6</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>184.431175</td>\n",
       "      <td>5411.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Edge Detection - Sobel Edge</td>\n",
       "      <td>6.441840</td>\n",
       "      <td>2017.968337</td>\n",
       "      <td>13.094296</td>\n",
       "      <td>52.659723</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.8</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.540198</td>\n",
       "      <td>3451.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Original</td>\n",
       "      <td>107.149319</td>\n",
       "      <td>1042.807841</td>\n",
       "      <td>43.318449</td>\n",
       "      <td>34.524881</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>52.286640</td>\n",
       "      <td>1.8</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>75.4</td>\n",
       "      <td>31.465931</td>\n",
       "      <td>3926.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Technique  Brightness  \\\n",
       "0                   Noise Reduction - Gaussian Blur  107.162756   \n",
       "1                     Noise Reduction - Median Blur  108.618152   \n",
       "2                 Noise Reduction - Non-Local Means  107.536963   \n",
       "3                                          Original  107.149319   \n",
       "4                    Histogram Equalization - CLAHE  126.506528   \n",
       "5   Histogram Equalization - Histogram Equalization  129.341000   \n",
       "6                                          Original  107.149319   \n",
       "7                 Binarization - Adaptive Threshold  196.684158   \n",
       "8                   Binarization - Global Threshold  107.262177   \n",
       "9                     Binarization - Otsu Threshold  195.659271   \n",
       "10                                         Original  107.149319   \n",
       "11               Morphological Operations - Closing  111.718808   \n",
       "12              Morphological Operations - Dilation  116.659772   \n",
       "13               Morphological Operations - Erosion   89.189844   \n",
       "14               Morphological Operations - Opening  102.595728   \n",
       "15                                         Original  107.149319   \n",
       "16                      Edge Detection - Canny Edge   15.276031   \n",
       "17                      Edge Detection - Sobel Edge    6.441840   \n",
       "18                                         Original  107.149319   \n",
       "\n",
       "        Sharpness    Contrast        Noise  Skew  Line Spacing  \\\n",
       "0       24.681440   41.958559     1.128670 -90.0      8.009615   \n",
       "1       95.788121   42.708486     4.916750 -90.0     11.079617   \n",
       "2      482.279009   42.909078    21.262351 -90.0     19.660569   \n",
       "3     1042.807841   43.318449    34.524881 -90.0     52.286640   \n",
       "4     2404.716668   47.830540    66.324622 -72.0      0.704711   \n",
       "5     4132.136154   74.116035   118.173999 -90.0      0.801573   \n",
       "6     1042.807841   43.318449    34.524881 -90.0     52.286640   \n",
       "7   130853.866491  107.010438  2507.259614 -36.0      0.102801   \n",
       "8    37629.083617  125.651187  1189.211578 -90.0      0.779416   \n",
       "9    17345.278201  107.277268   623.156986 -72.0      0.902003   \n",
       "10    1042.807841   43.318449    34.524881 -90.0     52.286640   \n",
       "11     130.919410   42.198184     6.766485 -90.0     42.570000   \n",
       "12     138.736504   40.394424     7.203136 -90.0     16.635714   \n",
       "13     639.030252   45.984433    26.183838 -90.0     27.610000   \n",
       "14     559.835454   43.509737    23.678647 -90.0     27.388889   \n",
       "15    1042.807841   43.318449    34.524881 -90.0     52.286640   \n",
       "16   34669.139811   59.988003  1314.548009 -90.0      0.000000   \n",
       "17    2017.968337   13.094296    52.659723 -90.0      0.000000   \n",
       "18    1042.807841   43.318449    34.524881 -90.0     52.286640   \n",
       "\n",
       "    Tables Detected  Resolution  Detected Elements     Texture  Patterns  \n",
       "0               2.0     65536.0               13.6    4.926009    1221.8  \n",
       "1               1.4     65536.0               14.6    9.712208    1176.2  \n",
       "2               1.6     65536.0               11.8   21.061042    2284.2  \n",
       "3               1.8     65536.0               75.4   31.465931    3926.0  \n",
       "4               2.2     65536.0              379.8   48.158238    6535.8  \n",
       "5               2.4     65536.0              331.4   63.944852    7529.8  \n",
       "6               1.8     65536.0               75.4   31.465931    3926.0  \n",
       "7               1.8     65536.0             2512.6  361.378629   18201.2  \n",
       "8               1.4     65536.0              340.0  193.481037    5701.0  \n",
       "9               1.8     65536.0              369.6  129.692905    3767.0  \n",
       "10              1.8     65536.0               75.4   31.465931    3926.0  \n",
       "11              0.8     65536.0                4.2   11.404722    1171.8  \n",
       "12              1.8     65536.0                6.8   11.721110    1181.6  \n",
       "13              2.0     65536.0                5.4   24.620653    5177.0  \n",
       "14              2.2     65536.0                6.8   23.014468    3837.0  \n",
       "15              1.8     65536.0               75.4   31.465931    3926.0  \n",
       "16              1.6     65536.0                1.0  184.431175    5411.4  \n",
       "17              1.8     65536.0                1.0   43.540198    3451.8  \n",
       "18              1.8     65536.0               75.4   31.465931    3926.0  "
      ]
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_comparison_df"
<<<<<<< HEAD
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:32:04.040035Z",
     "start_time": "2024-11-18T16:32:04.009033Z"
    }
   },
   "id": "fe7133144103efbc",
   "execution_count": 59
=======
   ]
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
  },
  {
   "cell_type": "markdown",
   "id": "c5d61986dc386f3b",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ad8595b15fd7fa24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T14:13:53.526683Z",
     "start_time": "2024-11-13T14:13:53.503683Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning Function\n",
    "def hyperparameter_tuning(images, best_techniques_list, param_grids, evaluation_function):\n",
    "    tuned_results = {}\n",
    "    for step_name, technique_name, best_technique_func in best_techniques_list:\n",
    "        print(f\"\\nHyperparameter Tuning for Step: {step_name}\\n{'-' * 40}\")\n",
    "        best_params = None\n",
    "        best_score = -np.inf\n",
    "        param_grid = param_grids.get(technique_name, [])\n",
    "\n",
    "        for params in param_grid:\n",
    "            total_score = 0\n",
    "            for img, img_id in zip(images, test_image_ids):\n",
    "                try:\n",
    "                    # Apply the best technique with the given parameters explicitly based on technique name\n",
    "                    if technique_name == \"Gaussian Blur\":\n",
    "                        processed_image = apply_gaussian_blur(img, **params)\n",
    "                    elif technique_name == \"Median Blur\":\n",
    "                        processed_image = apply_median_blur(img, **params)\n",
    "                    elif technique_name == \"Non-Local Means\":\n",
    "                        processed_image = apply_non_local_means(img, **params)\n",
    "                    elif technique_name == \"CLAHE\":\n",
    "                        processed_image = apply_clahe(img, **params)\n",
    "                    elif technique_name == \"Global Threshold\":\n",
    "                        processed_image = apply_global_threshold(img, **params)\n",
    "                    elif technique_name == \"Adaptive Threshold\":\n",
    "                        processed_image = apply_adaptive_threshold(img, **params)\n",
    "                    elif technique_name == \"Otsu Threshold\":\n",
    "                        processed_image = apply_otsu_threshold(img)\n",
    "                    elif technique_name == \"Inverted Otsu Threshold\":\n",
    "                        processed_image = apply_inverted_otsu_threshold(img)\n",
    "                    elif technique_name == \"Dilation\":\n",
    "                        processed_image = apply_dilation(img, **params)\n",
    "                    elif technique_name == \"Erosion\":\n",
    "                        processed_image = apply_erosion(img, **params)\n",
    "                    elif technique_name == \"Morphological Opening\":\n",
    "                        processed_image = apply_opening(img, **params)\n",
    "                    elif technique_name == \"Morphological Closing\":\n",
    "                        processed_image = apply_closing(img, **params)\n",
    "                    elif technique_name == \"Canny Edge\":\n",
    "                        processed_image = apply_canny_edge(img, **params)\n",
    "                    elif technique_name == \"Sobel Edge\":\n",
    "                        processed_image = apply_sobel_edge(img, **params)\n",
    "                    elif technique_name == \"Unsharp Masking\":\n",
    "                        processed_image = apply_unsharp_masking(img, **params)\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unknown technique: {technique_name}\")\n",
    "\n",
    "                except TypeError as e:\n",
    "                    print(f\"Skipping parameters {params} due to TypeError: {e}\")\n",
    "                    continue\n",
    "\n",
    "                # Retrieve original stats for comparison\n",
    "                original_stats = images_stats_df[images_stats_df['Image'] == img_id].iloc[0].to_dict()\n",
    "                evaluation_result = evaluation_function(processed_image, {technique_name: best_technique_func}, original_stats)\n",
    "                step_score = evaluation_result[\"Evaluation Results\"][technique_name][\"Score\"]\n",
    "                total_score += step_score\n",
    "\n",
    "            avg_score = total_score / len(images) if len(images) > 0 else -np.inf\n",
    "\n",
    "            if avg_score > best_score:\n",
    "                best_score = avg_score\n",
    "                best_params = params\n",
    "\n",
    "            print(f\"Parameters: {params}, Score: {avg_score}\")\n",
    "\n",
    "        tuned_results[step_name] = {\n",
    "            \"Best Parameters\": best_params,\n",
    "            \"Best Score\": best_score\n",
    "        }\n",
    "        print(f\"Best Parameters for {step_name}: {best_params} with Score: {best_score}\\n\")\n",
    "\n",
    "    return tuned_results\n"
<<<<<<< HEAD
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:32:04.056035Z",
     "start_time": "2024-11-18T16:32:04.041034Z"
    }
   },
   "id": "ad8595b15fd7fa24",
   "execution_count": 60
=======
   ]
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
  },
  {
   "cell_type": "markdown",
   "id": "55d2b04c1e9428ca",
   "metadata": {},
   "source": [
    "#### Explanation of Techniques and Parameters\n",
    "\n",
    "##### 1. Noise Reduction\n",
    "###### Gaussian Blur (`ksize`)\n",
    "- **Parameter**: `ksize` (kernel size)\n",
    "- **Meaning**: Defines the extent of smoothing applied. A small kernel (e.g., `(3, 3)`) produces minimal blurring, preserving details, while larger kernels (e.g., `(9, 9)`) apply more significant blurring, which is useful for reducing noise but may remove finer details.\n",
    "- **Range**:\n",
    "  - `(3, 3)`, `(5, 5)`, `(7, 7)`, `(9, 9)`\n",
    "  - Smaller sizes preserve more details, larger sizes reduce noise more aggressively.\n",
    "\n",
    "###### Non-Local Means (`h`, `templateWindowSize`, `searchWindowSize`)\n",
    "- **Parameters**:\n",
    "  - `h`: Filtering strength (higher values = stronger filtering).\n",
    "  - `templateWindowSize`: Size of the patch used for comparison.\n",
    "  - `searchWindowSize`: Size of the window around the pixel for searching similar patches.\n",
    "- **Range**:\n",
    "  - `h`: `5`, `10`, `15`, `20`\n",
    "  - `templateWindowSize`: `7`, `10`\n",
    "  - `searchWindowSize`: `21`, `31`\n",
    "  - Balances noise reduction quality and processing time.\n",
    "\n",
    "###### Median Blur (`ksize`)\n",
    "- **Parameter**: `ksize` (kernel size)\n",
    "- **Meaning**: Reduces \"salt-and-pepper\" noise by replacing each pixel with the median of neighboring pixels. Larger kernels apply stronger noise reduction, potentially losing details.\n",
    "- **Range**:\n",
    "  - `3`, `5`, `7`, `9`\n",
    "  - Smaller values (`3`, `5`) are useful for mild noise; larger values (`7`, `9`) are effective for more significant noise.\n",
    "\n",
    "##### 2. Histogram Equalization\n",
    "###### CLAHE (`clipLimit`, `tileGridSize`)\n",
    "- **Parameters**:\n",
    "  - `clipLimit`: Controls contrast enhancement limit.\n",
    "  - `tileGridSize`: Size of the grid for local histogram equalization.\n",
    "- **Range**:\n",
    "  - `clipLimit`: `2.0` to `6.0`\n",
    "  - `tileGridSize`: `(4, 4)`, `(6, 6)`, `(8, 8)`\n",
    "  - Lower `clipLimit` values reduce noise amplification, larger `tileGridSize` produces smoother results.\n",
    "\n",
    "##### 3. Binarization\n",
    "###### Global Threshold (`thresholdValue`)\n",
    "- **Parameter**: `thresholdValue`\n",
    "- **Meaning**: Used to convert grayscale images to binary by comparing pixel values to a threshold. Lower values produce more white areas.\n",
    "- **Range**:\n",
    "  - `100`, `127`, `150`, `200`\n",
    "  - Balances the separation between foreground and background.\n",
    "\n",
    "###### Adaptive Threshold (`adaptiveMethod`, `blockSize`, `C`)\n",
    "- **Parameters**:\n",
    "  - `adaptiveMethod`: The method used for calculating the threshold (`cv2.ADAPTIVE_THRESH_MEAN_C` or `cv2.ADAPTIVE_THRESH_GAUSSIAN_C`).\n",
    "  - `blockSize`: Size of the local area considered for thresholding.\n",
    "  - `C`: Constant subtracted from the mean or weighted sum.\n",
    "- **Range**:\n",
    "  - `adaptiveMethod`: `cv2.ADAPTIVE_THRESH_MEAN_C` or `cv2.ADAPTIVE_THRESH_GAUSSIAN_C`\n",
    "  - `blockSize`: `11`, `15`\n",
    "  - `C`: `2`, `3`\n",
    "  - Allows adjustment to local image variations for better segmentation.\n",
    "\n",
    "###### Otsu Threshold\n",
    "- **Meaning**: Automatically determines the optimal threshold value to convert grayscale images to binary.\n",
    "- **Use**: Effective for images with bimodal histograms, making it suitable for foreground and background separation.\n",
    "- **Parameters**: None, Otsu's method calculates the optimal threshold automatically.\n",
    "\n",
    "###### Inverted Otsu Threshold\n",
    "- **Meaning**: Applies Otsu's method for thresholding but inverts the resulting binary image, making foreground black and background white.\n",
    "- **Use**: Useful when the target regions are originally white on a dark background.\n",
    "- **Parameters**: None, as Otsu's method calculates the optimal threshold automatically.\n",
    "\n",
    "##### 4. Morphological Operations\n",
    "###### Operation (`MORPH_OPEN`, `MORPH_CLOSE`, `DILATE`, `ERODE`, `kernel_size`)\n",
    "- **Parameters**:\n",
    "  - `operation`: The morphological transformation to apply.\n",
    "    - `cv2.MORPH_OPEN`: Removes small white noise.\n",
    "    - `cv2.MORPH_CLOSE`: Fills small black gaps in white areas.\n",
    "    - `cv2.MORPH_DILATE`: Expands white areas to connect small features.\n",
    "    - `cv2.MORPH_ERODE`: Shrinks white areas to reduce noise.\n",
    "  - `kernel_size`: Size of the structuring element.\n",
    "- **Range**:\n",
    "  - `kernel_size`: `(3, 3)`, `(5, 5)`, `(7, 7)`, `(9, 9)`\n",
    "  - Larger kernels apply more aggressive changes for connecting, removing, or shrinking features.\n",
    "\n",
    "##### 5. Edge Detection\n",
    "###### Canny Edge Detection (`threshold1`, `threshold2`)\n",
    "- **Parameters**:\n",
    "  - `threshold1`: Lower threshold for weak edges.\n",
    "  - `threshold2`: Upper threshold for strong edges.\n",
    "- **Range**:\n",
    "  - `threshold1` and `threshold2`: `(50, 150)`, `(100, 200)`, `(150, 250)`, `(200, 300)`\n",
    "  - Lower values detect more edges, useful for detailed images; higher values highlight stronger, more defined edges.\n",
    "\n",
    "###### Sobel Edge Detection (`ksize`, `scale`, `delta`, `borderType`)\n",
    "- **Parameters**:\n",
    "  - `ksize`: Kernel size for the Sobel operator.\n",
    "  - `scale`: Scaling factor for gradients.\n",
    "  - `delta`: Value added to the result.\n",
    "  - `borderType`: Border handling for edges.\n",
    "- **Range**:\n",
    "  - `ksize`: `3`, `5`, `7`\n",
    "  - `scale`: `1`, `2`\n",
    "  - `delta`: `0` (default)\n",
    "  - `borderType`: `cv2.BORDER_DEFAULT`\n",
<<<<<<< HEAD
    "  - Adjusts the level of detail and sharpness captured by the filter.\n",
    "\n",
    "###### Unsharp Masking (`amount`, `kernel_size`)\n",
    "- **Parameters**:\n",
    "  - `amount`: Strength of sharpening effect applied to the image.\n",
    "  - `kernel_size`: Size of the kernel used for blurring in the unsharp mask process.\n",
    "- **Range**:\n",
    "  - `amount`: `1.0` to `2.5` (Higher values produce stronger sharpening)\n",
    "  - `kernel_size`: `(3, 3)`, `(5, 5)`, `(7, 7)`, `(9, 9)`\n",
    "  - Sharpening enhances edges and contrasts to make features more prominent, but excessively high values can introduce artifacts.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55d2b04c1e9428ca"
=======
    "  - Adjusts the level of detail and sharpness captured by the filter.\n"
   ]
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5fa67a991c4e1ef8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T14:13:55.698685Z",
     "start_time": "2024-11-13T14:13:55.672685Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define expanded parameter grids for hyperparameter tuning for each technique\n",
    "technique_param_grids = {\n",
    "    # Noise Reduction Techniques Parameters\n",
    "    # Gaussian Blur - kernel size affects the degree of blurring\n",
    "    \"Gaussian Blur\": [\n",
    "        {\"ksize\": (3, 3)},  # Small blur, preserves more details while reducing minor noise\n",
    "        {\"ksize\": (5, 5)},  # Moderate blur, balances noise reduction and detail preservation\n",
    "        {\"ksize\": (7, 7)},  # Stronger blur, reduces more noise but may lose more details\n",
    "        {\"ksize\": (9, 9)}   # High blur, significant reduction of noise, more detail loss\n",
    "    ],\n",
    "\n",
    "    # Median Blur - kernel size affects the reduction of salt-and-pepper noise\n",
    "    \"Median Blur\": [\n",
    "        {\"ksize\": 3},  # Small kernel, effective for minor salt-and-pepper noise\n",
    "        {\"ksize\": 5},  # Moderate kernel, more aggressive noise reduction\n",
    "        {\"ksize\": 7},  # Large kernel, used for significant salt-and-pepper noise reduction\n",
    "        {\"ksize\": 9}   # Largest kernel, aggressive noise reduction but may lose finer details\n",
    "    ],\n",
    "\n",
    "    # Non-Local Means - affects noise reduction strength and quality\n",
    "    \"Non-Local Means\": [\n",
    "        {\"h\": 5, \"templateWindowSize\": 7, \"searchWindowSize\": 21},   # Low filter strength (h), smaller template\n",
    "        {\"h\": 10, \"templateWindowSize\": 7, \"searchWindowSize\": 21},  # Moderate filter strength (h), balance of denoising and details\n",
    "        {\"h\": 15, \"templateWindowSize\": 7, \"searchWindowSize\": 21},  # Strong filter strength, more noise reduction but risk of over-smoothing\n",
    "        {\"h\": 20, \"templateWindowSize\": 10, \"searchWindowSize\": 31}  # Higher strength and larger search windows for stronger denoising\n",
    "    ],\n",
    "\n",
    "    # Histogram Equalization Techniques Parameters\n",
    "    # CLAHE - clip limit controls contrast, tile grid size controls local regions\n",
    "    \"CLAHE\": [\n",
    "        {\"clipLimit\": 2.0, \"tileGridSize\": (8, 8)},  # Low clip limit, preserves global contrast, effective for mild contrast enhancement\n",
    "        {\"clipLimit\": 3.0, \"tileGridSize\": (8, 8)},  # Moderate clip limit, better enhancement for darker/lighter regions\n",
    "        {\"clipLimit\": 4.0, \"tileGridSize\": (4, 4)},  # Higher clip limit, can lead to artifacts but increases local contrast\n",
    "        {\"clipLimit\": 5.0, \"tileGridSize\": (6, 6)}   # High clip limit, strong local contrast enhancement\n",
    "    ],\n",
    "\n",
    "    # Binarization Techniques Parameters\n",
    "    # Global Threshold - value for the threshold, used to separate foreground from background\n",
    "    \"Global Threshold\": [\n",
    "        {\"thresholdValue\": 100},  # Low threshold, makes more areas white, may overexpose\n",
    "        {\"thresholdValue\": 127},  # Middle threshold, balance between foreground and background\n",
    "        {\"thresholdValue\": 150},  # High threshold, less white, more black areas\n",
    "        {\"thresholdValue\": 200}   # Higher threshold, darkest parts retained as foreground\n",
    "    ],\n",
    "\n",
    "    # Adaptive Threshold - block size and constant C, used for adaptive thresholding\n",
    "    \"Adaptive Threshold\": [\n",
    "        {\"adaptiveMethod\": cv2.ADAPTIVE_THRESH_MEAN_C, \"blockSize\": 11, \"C\": 2},  # Small block size, captures smaller variations\n",
    "        {\"adaptiveMethod\": cv2.ADAPTIVE_THRESH_MEAN_C, \"blockSize\": 15, \"C\": 3},  # Larger block size, averages larger areas\n",
    "        {\"adaptiveMethod\": cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \"blockSize\": 11, \"C\": 2},  # Gaussian weighting, better for uneven lighting\n",
    "        {\"adaptiveMethod\": cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \"blockSize\": 15, \"C\": 3}   # Larger area, smoother output\n",
    "    ],\n",
    "\n",
    "    \"Otsu Threshold\": [\n",
    "        {}  # No parameters needed, automatic threshold selection\n",
    "    ],\n",
    "    \n",
    "    \"Inverted Otsu Threshold\": [{}],\n",
    "\n",
    "    # Morphological Operations Techniques Parameters\n",
    "    # Dilation - kernel size affects how much an object is expanded, helps to highlight and connect features in the image\n",
    "    \"Dilation\": [\n",
    "        {\"kernel_size\": (3, 3)},  # Small kernel, slight expansion of features\n",
    "        {\"kernel_size\": (5, 5)},  # Medium kernel, moderate expansion, often used to fill small holes\n",
    "        {\"kernel_size\": (7, 7)},  # Larger kernel, more significant expansion, fills larger gaps\n",
    "        {\"kernel_size\": (9, 9)}   # Largest kernel, aggressive expansion, can connect disjoint parts\n",
    "    ],\n",
    "\n",
    "    # Erosion - kernel size affects how much an object is eroded, used to reduce noise by shrinking foreground areas\n",
    "    \"Erosion\": [\n",
    "        {\"kernel_size\": (3, 3)},  # Small kernel, minimal shrinking of features\n",
    "        {\"kernel_size\": (5, 5)},  # Medium kernel, reduces small noise while keeping the main features intact\n",
    "        {\"kernel_size\": (7, 7)},  # Larger kernel, removes more fine details, useful for stronger noise reduction\n",
    "        {\"kernel_size\": (9, 9)}   # Largest kernel, aggressive erosion, may result in significant information loss\n",
    "    ],\n",
    "\n",
    "    # Morphological Opening - kernel size affects noise removal, used for removing small white noise from black backgrounds\n",
    "    \"Morphological Opening\": [\n",
    "        {\"kernel_size\": (3, 3)},  # Small kernel, removes small white noise but keeps the main structure\n",
    "        {\"kernel_size\": (5, 5)},  # Medium kernel, better noise removal, may affect finer details\n",
    "        {\"kernel_size\": (7, 7)}   # Larger kernel, stronger noise reduction, potentially removes small features\n",
    "    ],\n",
    "\n",
    "    # Morphological Closing - kernel size affects how gaps in foreground objects are filled, used to close small black holes within objects\n",
    "    \"Morphological Closing\": [\n",
    "        {\"kernel_size\": (3, 3)},  # Small kernel, fills tiny holes, maintains object shape\n",
    "        {\"kernel_size\": (5, 5)},  # Medium kernel, closes medium-sized gaps, useful for refining object borders\n",
    "        {\"kernel_size\": (7, 7)}   # Larger kernel, aggressively closes gaps, useful for solidifying larger structures\n",
    "    ],\n",
    "\n",
    "    # Edge Detection Techniques Parameters\n",
    "    # Canny Edge Detection - lower and upper thresholds for edge linking\n",
    "    \"Canny Edge\": [\n",
    "        {\"threshold1\": 50, \"threshold2\": 150},  # Low thresholds, more edges detected\n",
    "        {\"threshold1\": 100, \"threshold2\": 200},  # Moderate thresholds, balanced edge detection\n",
    "        {\"threshold1\": 150, \"threshold2\": 250},  # High thresholds, only strong edges detected\n",
    "        {\"threshold1\": 200, \"threshold2\": 300}   # Very high thresholds, detects fewer edges, focused on major features\n",
    "    ],\n",
    "\n",
    "    # Sobel Edge - kernel size, scale, delta, border type for Sobel edge detection\n",
    "    \"Sobel Edge\": [\n",
    "        {\"ksize\": 3, \"scale\": 1, \"delta\": 0, \"borderType\": cv2.BORDER_DEFAULT},  # Small kernel, detects finer details\n",
    "        {\"ksize\": 5, \"scale\": 1, \"delta\": 0, \"borderType\": cv2.BORDER_DEFAULT},  # Medium kernel, balances detail and noise suppression\n",
    "        {\"ksize\": 7, \"scale\": 1, \"delta\": 0, \"borderType\": cv2.BORDER_DEFAULT},  # Larger kernel, captures broader gradients\n",
    "        {\"ksize\": 3, \"scale\": 2, \"delta\": 0, \"borderType\": cv2.BORDER_DEFAULT}   # Increased scale, emphasizes detected gradients more strongly\n",
    "    ],\n",
    "    \"Unsharp Masking\": [\n",
    "        {\"amount\": 1.0, \"kernel_size\": (3, 3)},\n",
    "        {\"amount\": 1.5, \"kernel_size\": (5, 5)},\n",
    "        {\"amount\": 2.0, \"kernel_size\": (7, 7)},\n",
    "        {\"amount\": 2.5, \"kernel_size\": (9, 9)}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8c9a00a06b7381b7",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-18T16:32:04.087034Z",
     "start_time": "2024-11-18T16:32:04.058036Z"
    }
   },
   "id": "5fa67a991c4e1ef8",
   "execution_count": 61
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-13T14:14:04.615123Z",
     "start_time": "2024-11-13T14:13:56.837684Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyperparameter Tuning for Step: Noise Reduction\n",
      "----------------------------------------\n",
      "Parameters: {'h': 5, 'templateWindowSize': 7, 'searchWindowSize': 21}, Score: -0.8756000282606307\n",
      "Parameters: {'h': 10, 'templateWindowSize': 7, 'searchWindowSize': 21}, Score: -1.048609090061881\n",
      "Parameters: {'h': 15, 'templateWindowSize': 7, 'searchWindowSize': 21}, Score: -1.3339050847269525\n",
      "Parameters: {'h': 20, 'templateWindowSize': 10, 'searchWindowSize': 31}, Score: -1.5823083039238486\n",
      "Best Parameters for Noise Reduction: {'h': 5, 'templateWindowSize': 7, 'searchWindowSize': 21} with Score: -0.8756000282606307\n",
      "\n",
      "\n",
      "Hyperparameter Tuning for Step: Histogram Equalization\n",
      "----------------------------------------\n",
      "Best Parameters for Histogram Equalization: None with Score: -inf\n",
      "\n",
      "\n",
      "Hyperparameter Tuning for Step: Binarization\n",
      "----------------------------------------\n",
      "Parameters: {'adaptiveMethod': 0, 'blockSize': 11, 'C': 2}, Score: 218.99982792368874\n",
      "Parameters: {'adaptiveMethod': 0, 'blockSize': 15, 'C': 3}, Score: 148.36517914336235\n",
      "Parameters: {'adaptiveMethod': 1, 'blockSize': 11, 'C': 2}, Score: 250.05999860004553\n",
      "Parameters: {'adaptiveMethod': 1, 'blockSize': 15, 'C': 3}, Score: 168.10308598579735\n",
      "Best Parameters for Binarization: {'adaptiveMethod': 1, 'blockSize': 11, 'C': 2} with Score: 250.05999860004553\n",
      "\n",
      "\n",
      "Hyperparameter Tuning for Step: Morphological Operations\n",
      "----------------------------------------\n",
      "Parameters: {'kernel_size': (3, 3)}, Score: -0.7486110828519064\n",
      "Parameters: {'kernel_size': (5, 5)}, Score: -0.9257783780037417\n",
      "Parameters: {'kernel_size': (7, 7)}, Score: -1.0104417971740403\n",
      "Parameters: {'kernel_size': (9, 9)}, Score: -1.0749282063290426\n",
      "Best Parameters for Morphological Operations: {'kernel_size': (3, 3)} with Score: -0.7486110828519064\n",
      "\n",
      "\n",
      "Hyperparameter Tuning for Step: Edge Detection\n",
      "----------------------------------------\n",
      "Parameters: {'threshold1': 50, 'threshold2': 150}, Score: 121.69775826219777\n",
      "Parameters: {'threshold1': 100, 'threshold2': 200}, Score: 89.15266956778746\n",
      "Parameters: {'threshold1': 150, 'threshold2': 250}, Score: 67.03868170281513\n",
      "Parameters: {'threshold1': 200, 'threshold2': 300}, Score: 47.98164405584032\n",
      "Best Parameters for Edge Detection: {'threshold1': 50, 'threshold2': 150} with Score: 121.69775826219777\n",
      "\n",
      "\n",
      "Tuned Results:\n",
      "Noise Reduction: Best Parameters: {'h': 5, 'templateWindowSize': 7, 'searchWindowSize': 21}, Best Score: -0.8756000282606307\n",
      "Histogram Equalization: Best Parameters: None, Best Score: -inf\n",
      "Binarization: Best Parameters: {'adaptiveMethod': 1, 'blockSize': 11, 'C': 2}, Best Score: 250.05999860004553\n",
      "Morphological Operations: Best Parameters: {'kernel_size': (3, 3)}, Best Score: -0.7486110828519064\n",
      "Edge Detection: Best Parameters: {'threshold1': 50, 'threshold2': 150}, Best Score: 121.69775826219777\n"
     ]
    }
   ],
   "source": [
    "# Run hyperparameter tuning\n",
    "tuned_results = hyperparameter_tuning(test_images, best_techniques_list, technique_param_grids, advanced_evaluation)\n",
    "print(\"\\nTuned Results:\")\n",
    "\n",
    "for step_name, result in tuned_results.items():\n",
    "    print(f\"{step_name}: Best Parameters: {result['Best Parameters']}, Best Score: {result['Best Score']}\")"
<<<<<<< HEAD
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:32:10.530033Z",
     "start_time": "2024-11-18T16:32:04.088034Z"
    }
   },
   "id": "8c9a00a06b7381b7",
   "execution_count": 62
=======
   ]
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
  },
  {
   "cell_type": "markdown",
   "id": "bb737e3b48923f3b",
   "metadata": {},
   "source": [
    "#### Interpretations of Results\n",
    "\n",
    "Let's break down and interpret the hyperparameter tuning results for each step. Here's what each section tells us:\n",
    "\n",
    "### **1. Noise Reduction: Non-Local Means**\n",
    "- **Best Parameters**: `{'h': 5, 'templateWindowSize': 7, 'searchWindowSize': 21}`\n",
    "- **Best Score**: `-0.88`\n",
    "\n",
    "**Interpretation**:\n",
    "- Non-Local Means was selected as the best noise reduction technique.\n",
    "- The negative score (`-0.88`) indicates some deviation from the original characteristics, but this deviation was less compared to other parameter combinations. The lower value of `h` (`h=5`) indicates a moderate level of filtering strength, which helped reduce noise without overly smoothing the image, thus preserving important features.\n",
    "\n",
    "### **2. Histogram Equalization: Histogram Equalization**\n",
    "- **Best Parameters**: `None`\n",
    "- **Best Score**: `-inf`\n",
    "\n",
    "**Interpretation**:\n",
    "- The hyperparameter tuning for histogram equalization did not find any beneficial parameters. The score of `-inf` indicates that this technique did not provide improvements to the evaluation metrics. This could suggest that histogram equalization was not effective for the specific image characteristics being targeted, or the technique simply wasn't applicable in this scenario.\n",
    "\n",
    "### **3. Binarization: Adaptive Threshold**\n",
    "- **Best Parameters**: `{'adaptiveMethod': 1, 'blockSize': 11, 'C': 2}`\n",
    "- **Best Score**: `250.06`\n",
    "\n",
    "**Interpretation**:\n",
    "- The adaptive threshold technique with Gaussian adaptive method (`adaptiveMethod=1`), smaller block size (`blockSize=11`), and constant (`C=2`) yielded a high score of `250.06`.\n",
    "- This positive score indicates effective enhancement of the image characteristics that were being targeted, such as increased contrast and better segmentation. The smaller block size captures more local details, which led to higher scores by accounting for local variations in lighting.\n",
    "\n",
    "### **4. Morphological Operations: Erosion**\n",
    "- **Best Parameters**: `{'kernel_size': (3, 3)}`\n",
    "- **Best Score**: `-0.75`\n",
    "\n",
    "**Interpretation**:\n",
    "- Erosion was selected as the best morphological operation for this dataset.\n",
    "- A kernel size of `(3, 3)` yielded the least negative score (`-0.75`), indicating minimal negative impact on the original characteristics while still performing the required morphological operation. Using a smaller kernel helped prevent excessive erosion of features, which preserved important image information.\n",
    "\n",
    "### **5. Edge Detection: Canny Edge**\n",
    "- **Best Parameters**: `{'threshold1': 50, 'threshold2': 150}`\n",
    "- **Best Score**: `121.70`\n",
    "\n",
    "**Interpretation**:\n",
    "- The Canny edge detection technique performed best with thresholds of `50` and `150`, yielding a positive score of `121.70`.\n",
    "- Lower thresholds (`threshold1=50`, `threshold2=150`) allowed the detection of more edges, which improved characteristics such as detected elements and texture. The high positive score reflects the effectiveness of these thresholds in capturing meaningful edges while enhancing the desired image features.\n",
    "\n",
    "### **Summary & Key Insights**:\n",
    "\n",
    "1. **Negative Scores**:\n",
    "   - Negative scores (e.g., Noise Reduction and Morphological Operations) indicate that the processed image deviated from the original characteristics in ways that were detrimental based on the evaluation metrics.\n",
    "   - The least negative scores represent the best parameters that resulted in minimal detrimental changes.\n",
    "\n",
    "2. **Positive Scores**:\n",
    "   - Positive scores (e.g., Binarization and Edge Detection) indicate improvements in metrics such as contrast, sharpness, and detection of elements.\n",
    "   - Techniques with higher positive scores effectively enhanced the quality of the image by improving certain desired features.\n",
    "\n",
    "3. **Histogram Equalization Issue**:\n",
    "   - The score of `-inf` for histogram equalization indicates that the technique wasn't effective in improving the characteristics being evaluated. It may suggest that this step does not add value to this particular dataset.\n",
    "\n",
    "4. **Best Techniques Overview**:\n",
    "   - For each step, the parameter combination with the highest score (least negative or most positive) was selected.\n",
    "   - It is important to note that the magnitude of scores can vary greatly, depending on the evaluation metrics and their weights.\n",
    "\n",
    "### Recommendations:\n",
    "- **Non-Local Means (Noise Reduction)**: The parameters indicate that a moderate level of filtering (`h=5`) works best, emphasizing noise reduction without over-smoothing the image.\n",
    "- **Adaptive Threshold (Binarization)**: Using a Gaussian adaptive method with a smaller block size yielded the best results, suggesting that finer local adjustments are more advantageous.\n",
    "- **Erosion (Morphological Operations)**: A smaller kernel size `(3, 3)` had the least negative impact, meaning that a more conservative approach to erosion works best.\n",
    "- **Canny Edge Detection**: Lower thresholds for edge detection proved effective for enhancing the edge details, resulting in a high score.\n",
    "\n",
<<<<<<< HEAD
    "Overall, the results are consistent with expectations—lower parameters (e.g., less aggressive filtering or morphological operations) often preserve original characteristics better, while edge detection benefits from more comprehensive edge capturing with lower thresholds.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb737e3b48923f3b"
=======
    "Overall, the scores are consistent with an expected outcome where lower parameters (e.g., less aggressive denoising or erosion) lead to better preservation of original characteristics, while certain techniques like edge detection benefit from lower thresholds for more comprehensive edge enhancement."
   ]
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "915f0ec865424bf5",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-18T16:32:10.546141Z",
     "start_time": "2024-11-18T16:32:10.532033Z"
    }
   },
   "id": "915f0ec865424bf5",
   "execution_count": 62
=======
     "end_time": "2024-11-13T13:26:08.763319Z",
     "start_time": "2024-11-13T13:26:08.748321Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
>>>>>>> 747268b5d9af586f9b785aa79d3df27938b4a0cd
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
