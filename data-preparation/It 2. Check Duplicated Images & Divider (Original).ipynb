{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 2 - Remove Duplicated Images and Dividers (Original)\n",
    "\n",
    "> **Creator**: Ryo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder path\n",
    "source_folder = '../data/original'\n",
    "target_folder = '../data/data-understanding/1. Non Divider (Original)'\n",
    "target_folder_2 = '../data/data-understanding/2. Non Duplicated (Original)'\n",
    "\n",
    "file_prefix = ''\n",
    "\n",
    "# Divider file numbers\n",
    "divider_file_numbers = [\n",
    "    '00915', '00951', '01077', '01292', '01540'\n",
    "]\n",
    "\n",
    "# Non-divider file numbers\n",
    "non_divider_file_numbers = [\n",
    "    '00914', '01018', '01139', '01366', '01396', '01429', '01612'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Divider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Visualize Histogram Peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "import os\n",
    "\n",
    "def show_image_intensity_distribution_with_peaks(image_path, prominence, distance):\n",
    "    \"\"\"\n",
    "    Display an image along with its pixel intensity distribution (histogram) and highlight peaks.\n",
    "    Includes a horizontal line at frequency 50000 for reference.\n",
    "\n",
    "    Parameters:\n",
    "        image_path (str): Path to the image file.\n",
    "        prominence (int): Minimum prominence of each peak (controls peak sensitivity).\n",
    "        distance (int): Minimum horizontal distance in bins between peaks.\n",
    "    \"\"\"\n",
    "    # Extract filename for title\n",
    "    filename = os.path.basename(image_path)\n",
    "    \n",
    "    # Load image in grayscale\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Calculate histogram and find peaks\n",
    "    hist_values, _ = np.histogram(image.ravel(), bins=256, range=(0, 256))\n",
    "    peaks, _ = find_peaks(hist_values, prominence=prominence, distance=distance)\n",
    "    \n",
    "    # Plot image and intensity histogram with peaks\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    # Display the image without axis\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')  # Remove axis for the image display\n",
    "    plt.title(f\"Image: {filename}\")  # Title includes filename\n",
    "    \n",
    "    # Display the pixel intensity histogram\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(hist_values, color='blue')\n",
    "    plt.plot(peaks, hist_values[peaks], \"x\", color='red')  # Mark peaks with red 'x'\n",
    "    plt.axhline(y=50000, color='green', linestyle='--', label=\"Frequency 50000\")  # Add horizontal line at 50000\n",
    "    plt.title(f\"Pixel Intensity Distribution\\nTotal Peaks: {len(peaks)}\")\n",
    "    plt.xlabel(\"Pixel Intensity (0-255)\")  # X-axis: intensity levels from 0 to 255\n",
    "    plt.ylabel(\"Frequency\")  # Y-axis: frequency of each intensity level\n",
    "    plt.legend()  # Show legend for the horizontal line\n",
    "    \n",
    "    # Adjust layout for better spacing\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Histogram Peaks - Multi Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_multiple_images_hist_peaks(folder_path, file_numbers, prominence=50000, distance=50):\n",
    "    \"\"\"\n",
    "    Analyze multiple images for pixel intensity distribution and peak detection.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str): Path to the folder containing images.\n",
    "        file_numbers (list): List of numeric parts of filenames to analyze.\n",
    "        prominence (int): Minimum prominence of each peak (controls peak sensitivity).\n",
    "        distance (int): Minimum horizontal distance in bins between peaks.\n",
    "    \"\"\"     \n",
    "    for num in file_numbers:\n",
    "        # Construct the full file path\n",
    "        image_path = os.path.join(folder_path, f\"{file_prefix}DSC{num}.JPG\")\n",
    "        if os.path.exists(image_path):\n",
    "            print(f\"Analyzing image: {image_path}\")\n",
    "            show_image_intensity_distribution_with_peaks(image_path, prominence=prominence, distance=distance)\n",
    "        else:\n",
    "            print(f\"File not found: {image_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the images\n",
    "analyze_multiple_images_hist_peaks(source_folder, divider_file_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the images\n",
    "analyze_multiple_images_hist_peaks(source_folder, non_divider_file_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Divider Pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_divider_page(image_path):\n",
    "    \"\"\"\n",
    "    Determine if an image is likely a divider page by checking for two peaks in pixel intensity above 125.\n",
    "\n",
    "    Parameters:\n",
    "        image_path (str): Path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if at least two peaks above intensity 125 are found, False otherwise.\n",
    "    \"\"\"\n",
    "    # Load image in grayscale\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Calculate histogram\n",
    "    hist_values, _ = np.histogram(image.ravel(), bins=256, range=(0, 256))\n",
    "    \n",
    "    # Find peaks in the histogram\n",
    "    peaks, _ = find_peaks(hist_values, prominence=50000, distance=50)\n",
    "\n",
    "    # Count peaks with intensity above 100\n",
    "    high_peaks_count = sum(peak >= 100 for peak in peaks)\n",
    "\n",
    "    # Check if there are at least two peaks above 125\n",
    "    return high_peaks_count >= 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Divider Pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_divider_pages(folder_path):\n",
    "    \"\"\"\n",
    "    Find all images in a folder that are likely divider pages, print their numeric suffixes\n",
    "    along with a total count, and return the list of numeric suffixes.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str): Path to the folder containing images.\n",
    "\n",
    "    Returns:\n",
    "        list: Numeric suffixes of divider pages.\n",
    "    \"\"\"\n",
    "    divider_files = []  # List to store numeric suffixes of divider pages\n",
    "    valid_extensions = ('.png', '.jpg', '.jpeg', '.JPG', '.JPEG')  # Support various image extensions\n",
    "    \n",
    "    # Loop through each file in the folder with tqdm for a loading bar\n",
    "    for filename in tqdm(os.listdir(folder_path), desc=\"Processing images\", leave=True):\n",
    "        if filename.endswith(valid_extensions):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            # Check if the image is a divider page\n",
    "            if is_divider_page(image_path):\n",
    "                # Extract the numeric part of the filename\n",
    "                number = ''.join(filter(str.isdigit, filename.split('_')[-1]))\n",
    "                divider_files.append(number)  # Add only the numeric part\n",
    "    \n",
    "    # Print out all divider page numeric suffixes after processing\n",
    "    print(\"\\nDivider pages found:\")\n",
    "    for i, divider in enumerate(divider_files, start=1):\n",
    "        print(f\"{i}. {divider}\")\n",
    "    \n",
    "    # Print the total count of divider pages\n",
    "    print(f\"\\nTotal divider pages found: {len(divider_files)}\")\n",
    "    \n",
    "    return divider_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to find divider files\n",
    "divider_files = find_divider_pages(source_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy Non Divider Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_non_divider_images(source_folder, target_folder, divider_files):\n",
    "    \"\"\"\n",
    "    Copy all non-divider images from the source folder to the target folder.\n",
    "\n",
    "    Parameters:\n",
    "        source_folder (str): Path to the folder containing original images.\n",
    "        target_folder (str): Path to the folder where non-divider images will be copied.\n",
    "        divider_files (list): List of numeric suffixes of divider images.\n",
    "    \"\"\"\n",
    "    # Ensure target folder exists\n",
    "    os.makedirs(target_folder, exist_ok=True)\n",
    "    \n",
    "    valid_extensions = ('.png', '.jpg', '.jpeg', '.JPG', '.JPEG')\n",
    "    \n",
    "    # Loop through each file in the source folder with tqdm for a loading bar\n",
    "    for filename in tqdm(os.listdir(source_folder), desc=\"Copying non-divider images\", leave=True):\n",
    "        if filename.endswith(valid_extensions):\n",
    "            # Extract the numeric part of the filename\n",
    "            number = ''.join(filter(str.isdigit, filename.split('_')[-1]))\n",
    "            \n",
    "            # Check if the file is NOT a divider image\n",
    "            if number not in divider_files:\n",
    "                source_path = os.path.join(source_folder, filename)\n",
    "                target_path = os.path.join(target_folder, filename)\n",
    "                \n",
    "                # Copy the file to the target folder\n",
    "                shutil.copy(source_path, target_path)\n",
    "\n",
    "    print(f\"Non-divider images copied to {target_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to copy non-divider images\n",
    "divider_pages = [\n",
    "    '00915', '00951', '00998', '01077', '01138', '01183', '01195', '01240', \n",
    "    '01247', '01292', '01329', '01350', '01365', '01397', '01418', '01422', \n",
    "    '01428', '01434', '01440', '01445', '01455', '01461', '01531', '01540', \n",
    "    '01549', '01557', '01611', '01618', '01622', '01623', '01627', '01633'\n",
    "]\n",
    "\n",
    "copy_non_divider_images(source_folder, target_folder, divider_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Information Pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_information_files_from_dividers(divider_files):\n",
    "    \"\"\"\n",
    "    Generate a list of file numbers by taking each divider file and subtracting 1.\n",
    "    If the resulting number is also in divider_files, subtract 1 again.\n",
    "\n",
    "    Parameters:\n",
    "        divider_files (list of str): List of divider file suffixes (e.g., ['00915', '01077']).\n",
    "\n",
    "    Returns:\n",
    "        list of str: Adjusted list of file numbers.\n",
    "    \"\"\"\n",
    "    adjusted_files = []\n",
    "    \n",
    "    for file in divider_files:\n",
    "        # Convert file number to integer, subtract 1, and format back to 5-digit string\n",
    "        adjusted_number = int(file) - 1\n",
    "        adjusted_file = f\"{adjusted_number:05d}\"\n",
    "        \n",
    "        # Check if the adjusted file is in divider_files, subtract 1 again if necessary\n",
    "        if adjusted_file in divider_files:\n",
    "            adjusted_number -= 1\n",
    "            adjusted_file = f\"{adjusted_number:05d}\"\n",
    "        \n",
    "        # Append the adjusted file to the result list\n",
    "        adjusted_files.append(adjusted_file)\n",
    "    \n",
    "    return adjusted_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the information_files list by adjusting divider files\n",
    "information_files = generate_information_files_from_dividers(divider_pages)\n",
    "\n",
    "# Print the resulting file numbers\n",
    "print(\"Adjusted file numbers for analysis:\")\n",
    "print(information_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_matching_score(reference_image_path, target_image_path):\n",
    "    \"\"\"\n",
    "    Calculate the template matching score between a reference image and a target image.\n",
    "    \n",
    "    Parameters:\n",
    "        reference_image_path (str): Path to the reference image.\n",
    "        target_image_path (str): Path to the target image.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (float, str) The maximum matching score (between 0 and 1) or None if image loading fails, and an error message if any.\n",
    "    \"\"\"\n",
    "    # Load the reference and target images in grayscale\n",
    "    reference_image = cv2.imread(reference_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    target_image = cv2.imread(target_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Check if images are loaded properly\n",
    "    if reference_image is None:\n",
    "        return None, f\"Error loading reference image: {reference_image_path}\"\n",
    "    if target_image is None:\n",
    "        return None, f\"Error loading target image: {target_image_path}\"\n",
    "    \n",
    "    # Use template matching\n",
    "    res = cv2.matchTemplate(target_image, reference_image, cv2.TM_CCOEFF_NORMED)\n",
    "    _, max_val, _, _ = cv2.minMaxLoc(res)\n",
    "    return max_val, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_with_template_and_delete(reference_image_path, target_folder, file_numbers, score_threshold=0.75):\n",
    "    \"\"\"\n",
    "    Compare multiple images in a folder with a reference image using template matching,\n",
    "    print files with scores above a threshold, and delete them from the target folder.\n",
    "\n",
    "    Parameters:\n",
    "        reference_image_path (str): Path to the reference image.\n",
    "        target_folder (str): Path to the folder containing target images and from which files will be deleted.\n",
    "        file_numbers (list): List of numeric parts of filenames to analyze.\n",
    "        score_threshold (float): Minimum score required to consider an image as matching.\n",
    "    \"\"\"\n",
    "    results_to_delete = []  # List to store files that match criteria for deletion\n",
    "    error_messages = []  # List to store error messages\n",
    "\n",
    "    # Loop through each file and compute template matching score\n",
    "    for file_num in tqdm(file_numbers, desc=\"Comparing images\"):\n",
    "        image_path = os.path.join(target_folder, f\"{file_prefix}DSC{file_num}.JPG\")\n",
    "        \n",
    "        # Calculate similarity score\n",
    "        similarity, error = template_matching_score(reference_image_path, image_path)\n",
    "        \n",
    "        # Store error messages if any\n",
    "        if error:\n",
    "            error_messages.append(error)\n",
    "            continue\n",
    "        \n",
    "        # Only process if similarity is successfully calculated and above threshold\n",
    "        if similarity is not None and similarity >= score_threshold:\n",
    "            results_to_delete.append((file_num, similarity, image_path))\n",
    "\n",
    "    # Print results above threshold\n",
    "    print(\"\\nImages with matching score above threshold:\")\n",
    "    for file_num, score, image_path in results_to_delete:\n",
    "        print(f\"{file_prefix}DSC{file_num}.JPG - Score: {score * 100:.2f}%\")\n",
    "        \n",
    "        # Delete the file from the target folder\n",
    "        if os.path.exists(image_path):\n",
    "            os.remove(image_path)\n",
    "            print(f\"Deleted file: {image_path}\")\n",
    "        else:\n",
    "            print(f\"File not found: {image_path}\")\n",
    "    \n",
    "    # Print any errors that occurred after loading is complete\n",
    "    if error_messages:\n",
    "        print(\"\\nErrors encountered during processing:\")\n",
    "        for error in error_messages:\n",
    "            print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the reference image path using the predefined variables\n",
    "reference_image_number = '00914'  # Replace with any desired file number from non_divider_file_numbers\n",
    "reference_image_path = f\"{target_folder}/{file_prefix}DSC{reference_image_number}.JPG\"\n",
    "\n",
    "# Run the comparison\n",
    "compare_with_template_and_delete(reference_image_path, target_folder, information_files, score_threshold=0.82)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Duplicated Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Image and Check Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_and_visualize_image_similarity(folder_path, file_num1, file_num2, threshold=0.4):\n",
    "    \"\"\"\n",
    "    Compare two images to determine if they are similar based on ORB feature matching and visualize the matches.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str): Path to the folder containing images.\n",
    "        file_num1 (int): Numeric suffix of the first image file.\n",
    "        file_num2 (int): Numeric suffix of the second image file.\n",
    "        threshold (float): Similarity threshold (between 0 and 1). Higher means more similarity required.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if images are similar based on the threshold, False otherwise.\n",
    "    \"\"\"\n",
    "    # Construct the full file paths\n",
    "    image_path1 = f\"{folder_path}/{file_prefix}DSC00{file_num1}.JPG\"\n",
    "    image_path2 = f\"{folder_path}/{file_prefix}DSC00{file_num2}.JPG\"\n",
    "    \n",
    "    # Load the two images in grayscale\n",
    "    image1 = cv2.imread(image_path1, cv2.IMREAD_GRAYSCALE)\n",
    "    image2 = cv2.imread(image_path2, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Check if images loaded correctly\n",
    "    if image1 is None or image2 is None:\n",
    "        print(f\"Error: Unable to load one or both images: {image_path1}, {image_path2}\")\n",
    "        return False\n",
    "\n",
    "    # Initialize ORB detector\n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "    # Detect and compute ORB features for both images\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(image1, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(image2, None)\n",
    "\n",
    "    # Use BFMatcher to find matches between the descriptors\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "\n",
    "    # Sort matches by distance (lower distance is better)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    # Calculate the number of good matches\n",
    "    num_matches = len(matches)\n",
    "    num_keypoints = min(len(keypoints1), len(keypoints2))\n",
    "    match_ratio = num_matches / num_keypoints if num_keypoints > 0 else 0\n",
    "    match_percentage = match_ratio * 100\n",
    "\n",
    "    print(f\"Match percentage for images {file_num1} and {file_num2}: {match_percentage:.2f}%\")\n",
    "\n",
    "    # Determine if images are similar based on the match ratio\n",
    "    are_similar = match_ratio >= threshold\n",
    "\n",
    "    # Visualize the matches with space between the images\n",
    "    matched_image = cv2.drawMatches(\n",
    "        image1, keypoints1, image2, keypoints2, matches[:50], None,\n",
    "        flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(matched_image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Comparison of DSC00{file_num1} and DSC00{file_num2} - Match: {match_percentage:.2f}%\")\n",
    "    \n",
    "    # Add spacing between the images\n",
    "    plt.subplots_adjust(left=0.05, right=0.95, top=0.9, bottom=0.1, wspace=0.5)\n",
    "    plt.show()\n",
    "\n",
    "    return are_similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_num1 = 960\n",
    "file_num2 = 961 \n",
    "file_num3 = 962 \n",
    "file_num4 = 963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the images are similar\n",
    "if compare_and_visualize_image_similarity(target_folder, file_num1, file_num2):\n",
    "    print(\"Images are similar (likely duplicates).\")\n",
    "else:\n",
    "    print(\"Images are not similar (not duplicates).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the images are similar\n",
    "if compare_and_visualize_image_similarity(target_folder, file_num2, file_num3):\n",
    "    print(\"Images are similar (likely duplicates).\")\n",
    "else:\n",
    "    print(\"Images are not similar (not duplicates).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure Similarity (ORB + SSIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_images_similar_orb_ssim(folder_path, file1, file2, orb_threshold=0.4, ssim_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Compare two images to determine if they are similar based on ORB feature matching and SSIM validation.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str): Path to the folder containing images.\n",
    "        file1 (str): Filename of the first image.\n",
    "        file2 (str): Filename of the second image.\n",
    "        orb_threshold (float): ORB similarity threshold (between 0 and 1).\n",
    "        ssim_threshold (float): SSIM similarity threshold (between 0 and 1).\n",
    "\n",
    "    Returns:\n",
    "        float: Combined match percentage if similar, else None.\n",
    "    \"\"\"\n",
    "    image_path1 = os.path.join(folder_path, file1)\n",
    "    image_path2 = os.path.join(folder_path, file2)\n",
    "    \n",
    "    # Load images in grayscale\n",
    "    image1 = cv2.imread(image_path1, cv2.IMREAD_GRAYSCALE)\n",
    "    image2 = cv2.imread(image_path2, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Check if images loaded correctly\n",
    "    if image1 is None or image2 is None:\n",
    "        print(f\"Error loading images: {image_path1}, {image_path2}\")\n",
    "        return None\n",
    "\n",
    "    # Step 1: ORB feature matching\n",
    "    orb = cv2.ORB_create()\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(image1, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(image2, None)\n",
    "\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "    num_matches = len(matches)\n",
    "    num_keypoints = min(len(keypoints1), len(keypoints2))\n",
    "    orb_match_ratio = num_matches / num_keypoints if num_keypoints > 0 else 0\n",
    "    orb_match_percentage = orb_match_ratio * 100\n",
    "\n",
    "    # Only proceed with SSIM if ORB match percentage is above threshold\n",
    "    if orb_match_ratio >= orb_threshold:\n",
    "        # Step 2: SSIM validation\n",
    "        ssim_score, _ = ssim(image1, image2, full=True)\n",
    "        \n",
    "        # Determine final similarity based on SSIM score\n",
    "        if ssim_score >= ssim_threshold:\n",
    "            combined_score = (orb_match_percentage + ssim_score * 100) / 2\n",
    "            return (file1, file2, combined_score)  # Return files with combined score\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Duplicated Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_images_for_duplicates_orb_ssim(folder_path, orb_threshold=0.35, ssim_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Check images in a folder for duplicates using a combination of ORB and SSIM.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str): Path to the folder containing images.\n",
    "        orb_threshold (float): ORB similarity threshold.\n",
    "        ssim_threshold (float): SSIM similarity threshold.\n",
    "\n",
    "    Returns:\n",
    "        list: List of duplicate pairs with match percentage.\n",
    "    \"\"\"\n",
    "    valid_extensions = ('.png', '.jpg', '.jpeg', '.JPG', '.JPEG')\n",
    "    image_files = sorted([f for f in os.listdir(folder_path) if f.endswith(valid_extensions)])\n",
    "    duplicate_pairs = []\n",
    "\n",
    "    # Add tqdm progress bar here\n",
    "    for i in tqdm(range(len(image_files) - 1), desc=\"Checking images for duplicates\"):\n",
    "        file1 = image_files[i]\n",
    "        file2 = image_files[i + 1]\n",
    "        \n",
    "        result = are_images_similar_orb_ssim(folder_path, file1, file2, orb_threshold, ssim_threshold)\n",
    "        \n",
    "        if result is not None:\n",
    "            duplicate_pairs.append(result)\n",
    "    \n",
    "    return duplicate_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort Duplicated Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_and_print_duplicates(duplicate_pairs, descending=True):\n",
    "    \"\"\"\n",
    "    Sort and print duplicate pairs by match percentage.\n",
    "\n",
    "    Parameters:\n",
    "        duplicate_pairs (list): List of tuples (file1, file2, match_percentage).\n",
    "        descending (bool): If True, sort from highest to lowest match percentage.\n",
    "    \"\"\"\n",
    "    # Sort duplicate pairs by match percentage in specified order\n",
    "    sorted_pairs = sorted(duplicate_pairs, key=lambda x: x[2], reverse=descending)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nDuplicate pairs found (sorted by match percentage):\")\n",
    "    for file1, file2, match_percentage in sorted_pairs:\n",
    "        print(f\"{file1} and {file2} - Match: {match_percentage:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_pairs = check_images_for_duplicates_orb_ssim(target_folder, orb_threshold=0.35, ssim_threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort and print results\n",
    "sort_and_print_duplicates(duplicate_pairs, descending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Non Duplicated Images to New Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_and_copy_unique_images(source_folder, target_folder, duplicated_file_list):\n",
    "    \"\"\"\n",
    "    Copy unique images from the source folder to the target folder, excluding images listed for deletion.\n",
    "\n",
    "    Parameters:\n",
    "        source_folder (str): Path to the folder containing original images.\n",
    "        target_folder (str): Path to the folder where unique images will be copied.\n",
    "        duplicated_file_list (list): List of numeric suffixes of images to delete from the source folder.\n",
    "    \"\"\"\n",
    "    # Ensure the target folder exists\n",
    "    os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "    # Build delete_set with full filenames\n",
    "    delete_set = {f\"{file_prefix}DSC{suffix}.JPG\" for suffix in duplicated_file_list}\n",
    "    skipped_files = []  # List to store skipped filenames for later printing\n",
    "\n",
    "    # Process each file in the source folder with tqdm progress bar\n",
    "    for filename in tqdm(os.listdir(source_folder), desc=\"Processing images\", leave=True):\n",
    "        # Only process image files with expected prefix and extension\n",
    "        if filename in delete_set:\n",
    "            skipped_files.append(filename)  # Store filename if it is skipped\n",
    "            continue  # Skip this file\n",
    "        else:\n",
    "            # Copy the unique file to the target folder\n",
    "            source_path = os.path.join(source_folder, filename)\n",
    "            destination_path = os.path.join(target_folder, filename)\n",
    "            shutil.copy2(source_path, destination_path)\n",
    "\n",
    "    # Print skipped files after progress bar completes\n",
    "    if skipped_files:\n",
    "        print(\"\\nSkipped duplicate files:\")\n",
    "        for idx, skipped_file in enumerate(skipped_files, start=1):\n",
    "            print(f\"{idx}. {skipped_file}\")\n",
    "        print(f\"\\nTotal skipped files: {len(skipped_files)}\")\n",
    "\n",
    "    # Confirmation message\n",
    "    print(\"\\nProcess complete. All unique files have been copied to:\", target_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of specific file suffixes to delete with 5-character format\n",
    "duplicated_file_list = [\n",
    "    \"00960\", \"01011\", \"01033\", \"01037\", \"01050\", \"01051\", \"01080\", \"01098\", \"01100\", \"01108\",\n",
    "    \"01117\", \"01127\", \"01221\", \"01244\", \"01257\", \"01258\", \"01259\", \"01268\", \"01293\", \"01319\",\n",
    "    \"01324\", \"01358\", \"01366\", \"01450\", \"01467\", \"01482\", \"01518\", \"01554\", \"01596\"\n",
    "]\n",
    "\n",
    "# Run the function\n",
    "remove_and_copy_unique_images(target_folder, target_folder_2, duplicated_file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Finalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing Different Images Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_resize_images(folder_path, file_names, target_ratio=0.75, target_size=(1536, 2048)):\n",
    "    \"\"\"\n",
    "    Crop specific images to match a target aspect ratio and resize them to a specific dimension.\n",
    "    \n",
    "    Parameters:\n",
    "    folder_path (str): Path to the folder containing the images to crop and resize.\n",
    "    file_names (list): List of specific file names to process.\n",
    "    target_ratio (float): Target aspect ratio (width/height).\n",
    "    target_size (tuple): Target size (height, width) for the output images.\n",
    "    \n",
    "    Returns:\n",
    "    None: Overwrites cropped and resized images in the same folder.\n",
    "    \"\"\"\n",
    "    for filename in file_names:\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File not found: {file_path}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.imread(file_path)\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"Could not read {filename}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        height, width = image.shape[:2]\n",
    "        current_ratio = width / height\n",
    "\n",
    "        # Step 1: Crop the image to match the target ratio\n",
    "        if current_ratio > target_ratio:  # Image is too wide\n",
    "            new_width = int(height * target_ratio)\n",
    "            x_start = (width - new_width) // 2\n",
    "            cropped_image = image[:, x_start:x_start + new_width]\n",
    "        elif current_ratio < target_ratio:  # Image is too tall\n",
    "            new_height = int(width / target_ratio)\n",
    "            y_start = 0  # Start from the top\n",
    "            cropped_image = image[y_start:y_start + new_height, :]\n",
    "        else:\n",
    "            cropped_image = image  # No cropping needed if ratios match\n",
    "\n",
    "        # Step 2: Resize the image to the target size\n",
    "        resized_image = cv2.resize(cropped_image, (target_size[1], target_size[0]), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Overwrite the original image with the cropped and resized version\n",
    "        cv2.imwrite(file_path, resized_image)\n",
    "        print(f\"Cropped, resized, and saved: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_and_resize_images(\n",
    "    folder_path='../data/data-understanding/2. Non Duplicated (Original)',\n",
    "    file_names=['DSC01640.JPG', 'DSC01641.JPG', 'DSC01642.JPG', 'DSC01643.JPG'],\n",
    "    target_ratio=0.75,\n",
    "    target_size=(1536, 2048)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Total Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images_in_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Count the total number of image files in a specified folder.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str): Path to the folder containing images.\n",
    "\n",
    "    Returns:\n",
    "        int: The total number of images in the folder.\n",
    "    \"\"\"\n",
    "    # Valid image extensions\n",
    "    valid_extensions = ('.png', '.jpg', '.jpeg', '.JPG', '.JPEG')\n",
    "    \n",
    "    # Count files with valid extensions\n",
    "    image_count = sum(1 for filename in os.listdir(folder_path) if filename.endswith(valid_extensions))\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Total number of images in '{folder_path}': {image_count}\")\n",
    "    \n",
    "    return image_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to count images\n",
    "count_images_in_folder(target_folder_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alessandroryo",
   "language": "python",
   "name": "alessandroryo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
