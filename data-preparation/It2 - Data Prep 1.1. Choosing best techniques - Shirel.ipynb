{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6679ab839dfc599",
   "metadata": {},
   "source": [
    "# Data Preparation - IT2 - Choosing |best techniques per step in the flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a6db9fa264159cd5",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-19T14:42:50.146242Z",
     "start_time": "2024-11-19T14:42:50.118245Z"
=======
     "end_time": "2024-11-19T08:16:57.033783Z",
     "start_time": "2024-11-19T08:16:55.376784Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b8bdef35d1e5da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.048784Z",
     "start_time": "2024-11-19T08:16:57.035784Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the path to the folder containing the images to be processed\n",
<<<<<<< HEAD
    "folder_path = '../data/subset'  # Update this path to point to your specific folder containing images"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:42:50.459159Z",
     "start_time": "2024-11-19T14:42:50.440161Z"
    }
   },
   "id": "d0b8bdef35d1e5da",
   "execution_count": 137
=======
    "folder_path = '../data/original'  # Update this path to point to your specific folder containing images\n",
    "\n",
    "# Define the path to the folder where the processed images will be saved\n",
    "output_folder = '../data/processed'  # Update this path to the desired output folder"
   ]
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
  },
  {
   "cell_type": "markdown",
   "id": "3a22a19fd22d2b9a",
   "metadata": {},
   "source": [
    "## Loading Images and stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "703777edb6b6cb6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.064784Z",
     "start_time": "2024-11-19T08:16:57.049784Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder_path, extensions=('.png', '.jpg', '.jpeg', '.JPG')):\n",
    "    \"\"\"\n",
    "    Load all image file paths from a specified folder that match the given file extensions.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing the images.\n",
    "    extensions (tuple of str): A tuple of file extensions to filter the images by. \n",
    "                               Default is ('.png', '.jpg', '.jpeg', '.JPG').\n",
    "\n",
    "    Returns:\n",
    "    list: A list of full file paths to images in the folder that match the specified extensions.\n",
    "    \n",
    "    Raises:\n",
    "    FileNotFoundError: If the specified folder does not exist.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        raise FileNotFoundError(f\"The specified folder does not exist: {folder_path}\")\n",
    "\n",
    "    # List comprehension to gather all image paths with the specified extensions\n",
    "    image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(extensions)]\n",
    "\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8097d12ed08ed95c",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-19T14:42:51.145735Z",
     "start_time": "2024-11-19T14:42:51.128732Z"
    }
   },
   "id": "703777edb6b6cb6b",
   "execution_count": 138
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-19T08:16:57.080784Z",
     "start_time": "2024-11-19T08:16:57.065784Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
   "outputs": [],
   "source": [
    "# Function to convert to gray scale\n",
    "def load_and_preprocess_images(image_paths, resize_dim=(256, 256)):\n",
    "    images = []\n",
    "    image_ids = []\n",
    "\n",
    "    # Initialize tqdm progress bar\n",
    "    for path in tqdm(image_paths, desc=\"Loading and preprocessing images\", unit=\"image\"):\n",
    "        img = cv2.imread(path)\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "        # img_resized = cv2.resize(img_gray, resize_dim)  # Resize for consistency\n",
    "        images.append(img_gray)\n",
    "        image_ids.append(f'Image_{len(images)}')  # Assign image ID as Image_1, Image_2, etc.\n",
    "\n",
    "    return images, image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0024219894c26ef",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-19T14:42:51.687238Z",
     "start_time": "2024-11-19T14:42:51.674241Z"
    }
   },
   "id": "8097d12ed08ed95c",
   "execution_count": 139
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Actual Loading of the images and processing them to grayscale"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c60103865226067"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing images: 100%|██████████| 12/12 [00:02<00:00,  5.21image/s]\n"
     ]
    }
   ],
   "source": [
    "# Load all image file paths from the specified folder\n",
    "image_paths_all = load_images_from_folder(folder_path)\n",
    "\n",
    "# Load and preprocess all images\n",
    "total_images, total_image_ids = load_and_preprocess_images(image_paths_all)\n",
    "\n",
    "# Randomly select 5 images for experimentation\n",
    "# experiment_indices = random.sample(range(len(total_images)), 5)\n",
    "# test_images = [total_images[i] for i in experiment_indices]\n",
    "# test_image_ids = [total_image_ids[i] for i in experiment_indices]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:42:55.122132Z",
     "start_time": "2024-11-19T14:42:52.792117Z"
    }
   },
   "id": "5c3b64a356573a62",
   "execution_count": 140
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Characteristics Calculation for testing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e79e5c4a578b19f5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Image Characteristics Calculation Functions - from data understanding it2\n",
    "def calculate_brightness(image):\n",
    "    return np.mean(image)\n",
    "\n",
    "def calculate_sharpness(image):\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\n",
    "def calculate_contrast(image):\n",
    "    return image.std()\n",
    "\n",
    "def calculate_noise(image):\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    noise = cv2.absdiff(image, blurred)\n",
    "    return np.var(noise)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:42:57.107798Z",
     "start_time": "2024-11-19T14:42:57.100746Z"
    }
   },
   "id": "b95f3ecf5f853310",
   "execution_count": 141
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculating Original Stats"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbe62b54c62f02f4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### If from the original dataframe created"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76e19884ba4667b2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the CSV file with the image statistics\n",
    "# images_stats_path = \"../data-understanding/images_stats.csv\"  \n",
    "# images_stats_df = pd.read_csv(images_stats_path)"
   ],
=======
     "end_time": "2024-11-19T08:16:57.112784Z",
     "start_time": "2024-11-19T08:16:57.083788Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the CSV file with the image statistics\n",
    "images_stats_path = \"../data-understanding/images_stats.csv\"  \n",
    "images_stats_df = pd.read_csv(images_stats_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db335d32477016cb",
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-19T14:42:58.442514Z",
     "start_time": "2024-11-19T14:42:58.434508Z"
    }
   },
   "id": "f0024219894c26ef",
   "execution_count": 142
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# images_stats_df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:42:58.811915Z",
     "start_time": "2024-11-19T14:42:58.800932Z"
    }
   },
   "id": "db335d32477016cb",
   "execution_count": 143
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# images_stats_df.drop(['Skew','Line Spacing', 'Tables Detected', 'Resolution', 'Detected Elements','Texture', 'Patterns'],axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:42:59.385477Z",
     "start_time": "2024-11-19T14:42:59.371478Z"
    }
   },
   "id": "980d4dec5e2d0514",
   "execution_count": 144
  },
  {
   "cell_type": "markdown",
   "source": [
    "### From the subset "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cef047960471803c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def image_statistics_table(images, imagesId):\n",
    "    stats_data = {'Image': [],\n",
    "                  'Brightness': [],\n",
    "                  'Sharpness': [],\n",
    "                  'Contrast': [],\n",
    "                  'Noise': [],}\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        stats_data['Image'].append(imagesId[i])\n",
    "        stats_data['Brightness'].append(calculate_brightness(img))\n",
    "        stats_data['Sharpness'].append(calculate_sharpness(img))\n",
    "        stats_data['Contrast'].append(calculate_contrast(img))\n",
    "        stats_data['Noise'].append(calculate_noise(img))\n",
    "    # Create a DataFrame to store per-image statistics\n",
    "    df = pd.DataFrame(stats_data)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:43:00.547478Z",
     "start_time": "2024-11-19T14:43:00.535480Z"
    }
   },
   "id": "42c57776b0f74758",
   "execution_count": 145
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-19T08:16:57.128786Z",
     "start_time": "2024-11-19T08:16:57.113784Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Statistics Table:\n"
     ]
    },
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "       Image  Brightness   Sharpness   Contrast     Noise\n0    Image_1  100.038606   19.325682  49.248767  0.611743\n1    Image_2   98.179438   25.128856  45.808319  0.793025\n2    Image_3  102.128122   20.476350  44.327512  0.670412\n3    Image_4  103.643973   26.898489  40.046309  0.955973\n4    Image_5  109.058805   24.906567  42.498071  0.730254\n5    Image_6  111.614181   24.875000  37.462779  0.757413\n6    Image_7  106.277182   19.551871  36.462511  0.697440\n7    Image_8  102.769224   67.817982  38.631583  1.579164\n8    Image_9   95.099688   87.266055  51.179098  2.935492\n9   Image_10   95.865772   62.674985  50.360914  2.025381\n10  Image_11   88.401153   79.075827  29.147155  3.275595\n11  Image_12   87.842252  157.765130  27.883001  6.804315",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_1</td>\n      <td>100.038606</td>\n      <td>19.325682</td>\n      <td>49.248767</td>\n      <td>0.611743</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_2</td>\n      <td>98.179438</td>\n      <td>25.128856</td>\n      <td>45.808319</td>\n      <td>0.793025</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_3</td>\n      <td>102.128122</td>\n      <td>20.476350</td>\n      <td>44.327512</td>\n      <td>0.670412</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_4</td>\n      <td>103.643973</td>\n      <td>26.898489</td>\n      <td>40.046309</td>\n      <td>0.955973</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_5</td>\n      <td>109.058805</td>\n      <td>24.906567</td>\n      <td>42.498071</td>\n      <td>0.730254</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Image_6</td>\n      <td>111.614181</td>\n      <td>24.875000</td>\n      <td>37.462779</td>\n      <td>0.757413</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Image_7</td>\n      <td>106.277182</td>\n      <td>19.551871</td>\n      <td>36.462511</td>\n      <td>0.697440</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Image_8</td>\n      <td>102.769224</td>\n      <td>67.817982</td>\n      <td>38.631583</td>\n      <td>1.579164</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Image_9</td>\n      <td>95.099688</td>\n      <td>87.266055</td>\n      <td>51.179098</td>\n      <td>2.935492</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Image_10</td>\n      <td>95.865772</td>\n      <td>62.674985</td>\n      <td>50.360914</td>\n      <td>2.025381</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Image_11</td>\n      <td>88.401153</td>\n      <td>79.075827</td>\n      <td>29.147155</td>\n      <td>3.275595</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Image_12</td>\n      <td>87.842252</td>\n      <td>157.765130</td>\n      <td>27.883001</td>\n      <td>6.804315</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
=======
      "text/plain": [
       "Index(['Image', 'Brightness', 'Sharpness', 'Contrast', 'Noise', 'Skew',\n",
       "       'Line Spacing', 'Tables Detected', 'Resolution', 'Detected Elements',\n",
       "       'Texture', 'Patterns'],\n",
       "      dtype='object')"
      ]
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "images_stats_df = image_statistics_table(total_images, total_image_ids)\n",
    "print(\"Image Statistics Table:\")\n",
    "images_stats_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:43:32.788405Z",
     "start_time": "2024-11-19T14:43:28.289291Z"
    }
   },
   "id": "33e78dcc9e5758c2",
   "execution_count": 147
=======
    "images_stats_df.columns"
   ]
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
  },
  {
   "cell_type": "markdown",
   "id": "12f7addce2a50971",
   "metadata": {},
   "source": [
    "## Functions per step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf7d2143725450b",
   "metadata": {},
   "source": [
    "### Step 1: Noise Reduction Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fe3ee9d85584a63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.144785Z",
     "start_time": "2024-11-19T08:16:57.130784Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Noise Reduction Functions\n",
    "def apply_gaussian_blur(image, ksize=(5, 5)):\n",
    "    \"\"\"Apply Gaussian Blur to reduce noise with the specified kernel size.\"\"\"\n",
    "    return cv2.GaussianBlur(image, ksize, 0)\n",
    "\n",
    "def apply_median_blur(image, ksize=5):\n",
    "    \"\"\"Apply Median Blur to reduce salt-and-pepper noise with the specified kernel size.\"\"\"\n",
    "    return cv2.medianBlur(image, ksize)\n",
    "\n",
    "def apply_non_local_means(image, h=10, templateWindowSize=7, searchWindowSize=21):\n",
    "    \"\"\"Apply Non-Local Means Denoising with specified parameters.\"\"\"\n",
    "    return cv2.fastNlMeansDenoising(image, None, h, templateWindowSize, searchWindowSize)"
<<<<<<< HEAD
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:43:42.873450Z",
     "start_time": "2024-11-19T14:43:42.847407Z"
    }
   },
   "id": "8fe3ee9d85584a63",
   "execution_count": 148
=======
   ]
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
  },
  {
   "cell_type": "markdown",
   "id": "5b6cdd42d07d1c96",
   "metadata": {},
   "source": [
    "### Step 2: Histogram Equalization Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44c99f9c5258c6f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.160784Z",
     "start_time": "2024-11-19T08:16:57.146787Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Histogram Equalization Functions\n",
    "def apply_histogram_equalization(image):\n",
    "    return cv2.equalizeHist(image)\n",
    "\n",
    "def apply_clahe(image, clipLimit=2.0, tileGridSize=(8, 8)):\n",
    "    \"\"\"Apply CLAHE to enhance image contrast with specified parameters.\"\"\"\n",
    "    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n",
    "    return clahe.apply(image)"
<<<<<<< HEAD
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:43:43.936792Z",
     "start_time": "2024-11-19T14:43:43.922793Z"
    }
   },
   "id": "44c99f9c5258c6f3",
   "execution_count": 149
=======
   ]
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
  },
  {
   "cell_type": "markdown",
   "id": "29e647d0a546cb82",
   "metadata": {},
   "source": [
    "### Step 3: Binarization Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b2691be436fc225",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.176784Z",
     "start_time": "2024-11-19T08:16:57.162784Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Binarization Functions\n",
    "def apply_global_threshold(image, thresholdValue=127):\n",
    "    \"\"\"Apply Global Thresholding with the specified threshold value.\"\"\"\n",
    "    _, binary_image = cv2.threshold(image, thresholdValue, 255, cv2.THRESH_BINARY)\n",
    "    return binary_image\n",
    "\n",
    "def apply_adaptive_threshold(image, adaptiveMethod=cv2.ADAPTIVE_THRESH_MEAN_C, blockSize=11, C=2):\n",
    "    \"\"\"Apply Adaptive Thresholding with the specified method, block size, and constant C.\"\"\"\n",
    "    return cv2.adaptiveThreshold(image, 255, adaptiveMethod, cv2.THRESH_BINARY, blockSize, C)\n",
    "\n",
    "def apply_otsu_threshold(image):\n",
    "    \"\"\"Apply Otsu Thresholding.\"\"\"\n",
    "    _, binary_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return binary_image\n",
    "\n",
    "def apply_inverted_otsu_threshold(image):\n",
    "    \"\"\"Apply Inverted Otsu Thresholding.\"\"\"\n",
    "    _, binary_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    return binary_image\n"
<<<<<<< HEAD
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:43:44.800256Z",
     "start_time": "2024-11-19T14:43:44.784252Z"
    }
   },
   "id": "3b2691be436fc225",
   "execution_count": 150
=======
   ]
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
  },
  {
   "cell_type": "markdown",
   "id": "c3c7a336f8c8b717",
   "metadata": {},
   "source": [
    "### Step 4: Morphological Operations Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da08a64db428ad4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.192786Z",
     "start_time": "2024-11-19T08:16:57.177784Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Morphological Operations Functions\n",
    "def apply_dilation(image, kernel_size=(5, 5)):\n",
    "    \"\"\"Apply Dilation with the specified kernel size.\"\"\"\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations=1)\n",
    "\n",
    "def apply_erosion(image, kernel_size=(5, 5)):\n",
    "    \"\"\"Apply Erosion with the specified kernel size.\"\"\"\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations=1)\n",
    "\n",
    "def apply_opening(image, kernel_size=(5, 5)):\n",
    "    \"\"\"Apply Morphological Opening with the specified kernel size.\"\"\"\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "def apply_closing(image, kernel_size=(5, 5)):\n",
    "    \"\"\"Apply Morphological Closing with the specified kernel size.\"\"\"\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n"
<<<<<<< HEAD
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:43:46.614262Z",
     "start_time": "2024-11-19T14:43:46.579264Z"
    }
   },
   "id": "da08a64db428ad4a",
   "execution_count": 151
=======
   ]
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
  },
  {
   "cell_type": "markdown",
   "id": "e5596f364429dda1",
   "metadata": {},
   "source": [
    "### Step 5: Edge Detection Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76e5c83f8a5c9bc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.208784Z",
     "start_time": "2024-11-19T08:16:57.193784Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Edge Detection Functions\n",
    "def apply_canny_edge(image, threshold1=50, threshold2=150):\n",
    "    \"\"\"Apply Canny Edge Detection with specified thresholds.\"\"\"\n",
    "    return cv2.Canny(image, threshold1, threshold2)\n",
    "\n",
    "def apply_sobel_edge(image, ksize=3, scale=1, delta=0, borderType=cv2.BORDER_DEFAULT):\n",
    "    \"\"\"Apply Sobel Edge Detection with specified parameters.\"\"\"\n",
    "    return cv2.Sobel(image, cv2.CV_64F, 1, 1, ksize=ksize, scale=scale, delta=delta, borderType=borderType)\n",
    "\n",
    "def apply_unsharp_masking(image, amount=1.5, kernel_size=(0, 0)):\n",
    "    \"\"\"Apply Unsharp Masking to sharpen the image.\"\"\"\n",
    "    blurred = cv2.GaussianBlur(image, kernel_size, 0)\n",
    "    sharpened = cv2.addWeighted(image, 1 + amount, blurred, -amount, 0)\n",
    "    return sharpened"
<<<<<<< HEAD
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:43:47.837359Z",
     "start_time": "2024-11-19T14:43:47.823360Z"
    }
   },
   "id": "76e5c83f8a5c9bc8",
   "execution_count": 152
=======
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79e5c4a578b19f5",
   "metadata": {},
   "source": [
    "## Characteristics Calculation for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aec243807f00da68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.224783Z",
     "start_time": "2024-11-19T08:16:57.209784Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Image Characteristics Calculation Functions - from data understanding it2\n",
    "def calculate_brightness(image):\n",
    "    return np.mean(image)\n",
    "\n",
    "def calculate_sharpness(image):\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\n",
    "def calculate_contrast(image):\n",
    "    return image.std()\n",
    "\n",
    "def calculate_noise(image):\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    noise = cv2.absdiff(image, blurred)\n",
    "    return np.var(noise)\n",
    "\n",
    "# def calculate_skew(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "#     _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "#     coords = np.column_stack(np.where(binary > 0))\n",
    "#     if coords.size == 0:\n",
    "#         return 0\n",
    "#     angle = cv2.minAreaRect(coords)[-1]\n",
    "#     if angle < -45:\n",
    "#         angle = -(90 + angle)\n",
    "#     else:\n",
    "#         angle = -angle\n",
    "#     if abs(angle) < 1e-2:\n",
    "#         angle = 0\n",
    "#     return round(angle, 2)\n",
    "# \n",
    "# def calculate_line_spacing(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "#     _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "#     contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     heights = [cv2.boundingRect(contour)[3] for contour in contours]\n",
    "#     if len(heights) > 1:\n",
    "#         line_spacing = np.mean(np.diff(sorted(heights)))\n",
    "#     else:\n",
    "#         line_spacing = 0\n",
    "#     return line_spacing\n",
    "# \n",
    "# def detect_tables(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "#     _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "#     binary = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "#     contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     table_contours = [contour for contour in contours if cv2.contourArea(contour) > 1000]\n",
    "#     return len(table_contours)\n",
    "# \n",
    "# def calculate_resolution(image):\n",
    "#     height, width = image.shape[:2]\n",
    "#     return height * width\n",
    "# \n",
    "# def calculate_elements_detection(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "#     _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "#     contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     return len(contours)\n",
    "# \n",
    "# def calculate_texture(image):\n",
    "#     laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "#     return laplacian.std()\n",
    "# \n",
    "# def calculate_patterns(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "#     edges = cv2.Canny(image, 100, 200)\n",
    "#     return np.sum(edges > 0)\n"
   ]
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
  },
  {
   "cell_type": "markdown",
   "id": "203cff1e1647315b",
   "metadata": {},
   "source": [
    "## Evaluation per step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dafdc80cafbb5f",
   "metadata": {},
   "source": [
    "### Function of evaluation"
   ]
  },
  {
<<<<<<< HEAD
=======
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce72107041cb13b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.240784Z",
     "start_time": "2024-11-19T08:16:57.226786Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Basic Evaluation Function\n",
    "# -------------------------\n",
    "# def basic_evaluation(image, techniques_dict, original_stats):\n",
    "#     evaluation_results = {}\n",
    "#     for technique_name, technique_func in techniques_dict.items():\n",
    "#         processed_image = technique_func(image)\n",
    "#         stats = {\n",
    "#             \"Brightness\": calculate_brightness(processed_image),\n",
    "#             \"Sharpness\": calculate_sharpness(processed_image),\n",
    "#             \"Contrast\": calculate_contrast(processed_image),\n",
    "#             \"Noise\": calculate_noise(processed_image)\n",
    "#         }\n",
    "# \n",
    "#         # Basic scoring function - prioritizing sharpness, contrast, and minimized noise\n",
    "#         score = stats[\"Sharpness\"] + stats[\"Contrast\"] - stats[\"Noise\"]\n",
    "#         evaluation_results[technique_name] = {\"Score\": score, \"Stats\": stats}\n",
    "# \n",
    "#     best_technique = max(evaluation_results, key=lambda x: evaluation_results[x][\"Score\"])\n",
    "#     return {\"Best Technique\": best_technique, \"Evaluation Results\": evaluation_results}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3067606c27e5a0cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.255784Z",
     "start_time": "2024-11-19T08:16:57.244783Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# def advanced_evaluation(image, techniques_dict, original_stats):\n",
    "#     evaluation_results = {}\n",
    "# \n",
    "#     for technique_name, technique_func in techniques_dict.items():\n",
    "#         # Apply the technique\n",
    "#         processed_image = technique_func(image)\n",
    "# \n",
    "#         # Calculate characteristics for the processed image\n",
    "#         stats = {\n",
    "#             \"Brightness\": calculate_brightness(processed_image),\n",
    "#             \"Sharpness\": calculate_sharpness(processed_image),\n",
    "#             \"Contrast\": calculate_contrast(processed_image),\n",
    "#             \"Noise\": calculate_noise(processed_image),\n",
    "#             \"Skew\": calculate_skew(processed_image),\n",
    "#             \"Line Spacing\": calculate_line_spacing(processed_image),\n",
    "#             \"Tables Detected\": detect_tables(processed_image),\n",
    "#             \"Resolution\": calculate_resolution(processed_image),\n",
    "#             \"Detected Elements\": calculate_elements_detection(processed_image),\n",
    "#             \"Texture\": calculate_texture(processed_image),\n",
    "#             \"Patterns\": calculate_patterns(processed_image)\n",
    "#         }\n",
    "# \n",
    "#         # Normalize metrics to comparable ranges (between 0 and 1, roughly)\n",
    "#         stats_normalized = {\n",
    "#             \"Brightness\": stats[\"Brightness\"] / 255,\n",
    "#             \"Sharpness\": stats[\"Sharpness\"] / 1000,\n",
    "#             \"Contrast\": stats[\"Contrast\"] / 255,\n",
    "#             \"Noise\": stats[\"Noise\"] / 255,\n",
    "#             \"Skew\": stats[\"Skew\"] / 45,\n",
    "#             \"Line Spacing\": stats[\"Line Spacing\"] / 100,\n",
    "#             \"Tables Detected\": stats[\"Tables Detected\"] / 10,\n",
    "#             \"Resolution\": stats[\"Resolution\"] / (512 * 512),\n",
    "#             \"Detected Elements\": stats[\"Detected Elements\"] / 100,\n",
    "#             \"Texture\": stats[\"Texture\"] / 100,\n",
    "#             \"Patterns\": stats[\"Patterns\"] / 1000\n",
    "#         }\n",
    "# \n",
    "#         # Normalize the original stats for comparison\n",
    "#         original_stats_normalized = {\n",
    "#             \"Brightness\": original_stats[\"Brightness\"] / 255,\n",
    "#             \"Sharpness\": original_stats[\"Sharpness\"] / 1000,\n",
    "#             \"Contrast\": original_stats[\"Contrast\"] / 255,\n",
    "#             \"Noise\": original_stats[\"Noise\"] / 255,\n",
    "#             \"Skew\": original_stats[\"Skew\"] / 45,\n",
    "#             \"Line Spacing\": original_stats[\"Line Spacing\"] / 100,\n",
    "#             \"Tables Detected\": original_stats[\"Tables Detected\"] / 10,\n",
    "#             \"Resolution\": original_stats[\"Resolution\"] / (512 * 512),\n",
    "#             \"Detected Elements\": original_stats[\"Detected Elements\"] / 100,\n",
    "#             \"Texture\": original_stats[\"Texture\"] / 100,\n",
    "#             \"Patterns\": original_stats[\"Patterns\"] / 1000\n",
    "#         }\n",
    "# \n",
    "#         # Weights for each characteristic (to determine their importance)\n",
    "#         weights = {\n",
    "#             \"Brightness\": -1.0,  # Closer to original is better (penalized if different)\n",
    "#             \"Sharpness\": 2.0,    # Higher is better (rewarded if improved)\n",
    "#             \"Contrast\": 1.0,     # Higher is better (rewarded if improved)\n",
    "#             \"Noise\": -1.5,       # Lower is better (penalized if increased)\n",
    "#             \"Skew\": -0.5,        # Closer to original is better (penalized if different)\n",
    "#             \"Line Spacing\": -0.5,  # Closer to original is better (penalized if different)\n",
    "#             \"Tables Detected\": 1.0,  # More tables detected is better\n",
    "#             \"Resolution\": 1.0,    # Higher is better\n",
    "#             \"Detected Elements\": 1.0,  # More elements detected is better\n",
    "#             \"Texture\": 1.0,       # Higher texture complexity is better\n",
    "#             \"Patterns\": 1.0       # More patterns detected is better\n",
    "#         }\n",
    "# \n",
    "#         # Calculate score using normalized metrics and weights\n",
    "#         score = 0\n",
    "#         for metric, value in stats_normalized.items():\n",
    "#             original_value = original_stats_normalized.get(metric, 0)\n",
    "#             score += weights[metric] * (value - original_value)\n",
    "# \n",
    "#         evaluation_results[technique_name] = {\"Score\": score, \"Stats\": stats}\n",
    "# \n",
    "#     # Determine the best technique based on the highest score\n",
    "#     best_technique = max(evaluation_results, key=lambda x: evaluation_results[x][\"Score\"])\n",
    "#     return {\"Best Technique\": best_technique, \"Evaluation Results\": evaluation_results}\n"
   ]
  },
  {
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
   "cell_type": "markdown",
   "id": "14621ade3e0e3283",
   "metadata": {},
   "source": [
    "##### Normalization Process\n",
    "\n",
    "**Normalization** is crucial for ensuring that the values of different characteristics (`Brightness`, `Sharpness`, `Contrast`, `Noise`) are on a similar scale. Without normalization, these characteristics might have vastly different ranges, which could skew the evaluation. Here's what happens in the function:\n",
    "\n",
    "1. **Brightness Normalization**:\n",
    "   - The brightness of an image is typically represented on a scale from 0 to 255 (as an 8-bit grayscale value).\n",
    "   - To normalize brightness, we divide it by 255, which brings its range between 0 and 1.\n",
    "\n",
    "2. **Sharpness Normalization**:\n",
    "   - Sharpness is measured as the variance of the Laplacian, which often has larger values than brightness.\n",
    "   - Dividing by `1000` helps normalize it to roughly between 0 and 1. The choice of `1000` is made to ensure that sharpness values are comparable to the other metrics.\n",
    "\n",
    "3. **Contrast Normalization**:\n",
    "   - Contrast is calculated using the standard deviation of pixel values, which usually falls between 0 and 255 for 8-bit images.\n",
    "   - Dividing by 255 brings contrast into the range between 0 and 1.\n",
    "\n",
    "4. **Noise Normalization**:\n",
    "   - The noise measure is the variance of the difference between the original and a blurred version of the image.\n",
    "   - Dividing by 255 brings it to a similar range as the other characteristics, ensuring comparability.\n",
    "\n",
    "By normalizing all metrics to a range between 0 and 1, we ensure that each characteristic has equal weight in the evaluation, preventing one metric from dominating due to a larger numeric range.\n",
    "\n",
    "##### Scoring Calculation\n",
    "\n",
    "Once all metrics are normalized, a score is calculated to determine how well the processed image improves compared to the original. Here's the breakdown of the scoring process:\n",
    "\n",
    "1. **Weights for Characteristics**:\n",
    "   - We assign **weights** to each metric based on its importance:\n",
    "     - **Brightness**: Weight of `-1.0` means that deviation from the original value is penalized.\n",
    "     - **Sharpness**: Weight of `2.0` rewards increased sharpness.\n",
    "     - **Contrast**: Weight of `1.0` rewards increased contrast.\n",
    "     - **Noise**: Weight of `-1.5` penalizes increased noise.\n",
    "\n",
    "2. **Score Calculation**:\n",
    "   - The difference between the normalized processed value and the normalized original value is multiplied by the respective weight.\n",
    "   - If a **positively weighted metric** (like sharpness or contrast) **improves**, it contributes positively to the score.\n",
    "   - If a **negatively weighted metric** (like noise or brightness deviation) **increases**, it contributes negatively, penalizing the score.\n",
    "\n",
    "3. **Best Technique Selection**:\n",
    "   - After calculating the score for each technique, the function selects the one with the **highest score**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bf4a8b130aa7d7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:16:57.270785Z",
     "start_time": "2024-11-19T08:16:57.257786Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def advanced_evaluation(image, techniques_dict, original_stats):\n",
    "    evaluation_results = {}\n",
    "\n",
    "    for technique_name, technique_func in techniques_dict.items():\n",
    "        # Apply the technique\n",
    "        processed_image = technique_func(image)\n",
    "\n",
    "        # Calculate characteristics for the processed image\n",
    "        stats = {\n",
    "            \"Brightness\": calculate_brightness(processed_image),\n",
    "            \"Sharpness\": calculate_sharpness(processed_image),\n",
    "            \"Contrast\": calculate_contrast(processed_image),\n",
    "            \"Noise\": calculate_noise(processed_image),\n",
    "        }\n",
    "\n",
    "        # Normalize metrics to comparable ranges (between 0 and 1, roughly)\n",
    "        stats_normalized = {\n",
    "            \"Brightness\": stats[\"Brightness\"] / 255,\n",
    "            \"Sharpness\": stats[\"Sharpness\"] / 1000,\n",
    "            \"Contrast\": stats[\"Contrast\"] / 255,\n",
    "            \"Noise\": stats[\"Noise\"] / 255,\n",
    "        }\n",
    "\n",
    "        # Normalize the original stats for comparison\n",
    "        original_stats_normalized = {\n",
    "            \"Brightness\": original_stats[\"Brightness\"] / 255,\n",
    "            \"Sharpness\": original_stats[\"Sharpness\"] / 1000,\n",
    "            \"Contrast\": original_stats[\"Contrast\"] / 255,\n",
    "            \"Noise\": original_stats[\"Noise\"] / 255,\n",
    "        }\n",
    "\n",
    "        # Weights for each characteristic (to determine their importance)\n",
    "        weights = {\n",
    "            \"Brightness\": 1.0,  # Higher is better (rewarded if improved)\n",
    "            \"Sharpness\": 1.0,    # Higher is better (rewarded if improved) but images were generally sharp already \n",
    "            \"Contrast\": 2.0,     # Higher is better (rewarded if improved) the levels of contrast were lower and obstructed details\n",
    "            \"Noise\": -1.5,       # Lower is better (penalized if increased)\n",
    "        }\n",
    "\n",
    "        # Calculate score using normalized metrics and weights\n",
    "        score = 0\n",
    "        for metric, value in stats_normalized.items():\n",
    "            original_value = original_stats_normalized.get(metric, 0)\n",
    "            score += weights[metric] * (value - original_value)\n",
    "\n",
    "        evaluation_results[technique_name] = {\"Score\": score, \"Stats\": stats}\n",
    "\n",
    "    # Determine the best technique based on the highest score\n",
    "    best_technique = max(evaluation_results, key=lambda x: evaluation_results[x][\"Score\"])\n",
    "    return {\"Best Technique\": best_technique, \"Evaluation Results\": evaluation_results}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9dcfaa1991f5e3a",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-19T14:43:50.223436Z",
     "start_time": "2024-11-19T14:43:50.207438Z"
    }
   },
   "id": "6bf4a8b130aa7d7f",
   "execution_count": 153
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-19T08:16:57.286783Z",
     "start_time": "2024-11-19T08:16:57.272784Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
   "outputs": [],
   "source": [
    "# Function for Each Step testing\n",
    "def run_step(step_name, techniques_dict, test_images, test_image_ids, best_techniques_list):\n",
    "    print(f\"\\nRunning Step: {step_name}\\n{'-' * 40}\")\n",
    "    all_results = []\n",
    "\n",
    "    # Folder to save images from this step\n",
    "    output_folder_step = f\"./Data/It2/{step_name}\"\n",
    "    os.makedirs(output_folder_step, exist_ok=True)\n",
    "\n",
    "    # Image ID to be saved for comparison (using the first image ID consistently for all techniques)\n",
    "    save_image_id = test_image_ids[0] if len(test_image_ids) > 0 else None\n",
    "\n",
    "    for img, img_id in zip(test_images, test_image_ids):\n",
    "        # Retrieve original stats from the dataset for the specific image being processed\n",
    "        original_stats = images_stats_df[images_stats_df['Image'] == img_id].iloc[0].to_dict()\n",
    "\n",
    "        # Evaluate each technique on the current image\n",
    "        step_result = advanced_evaluation(img, techniques_dict, original_stats)\n",
    "        all_results.append((img_id, original_stats, step_result))\n",
    "        print(f\"Best Technique for {img_id}: {step_result['Best Technique']}\")\n",
    "\n",
    "        # Save one processed image per technique per step (consistent image ID across all techniques)\n",
    "        if img_id == save_image_id:\n",
    "            for technique_name, technique_func in techniques_dict.items():\n",
    "                # Apply the technique to the image\n",
    "                processed_image = technique_func(img)\n",
    "\n",
    "                # Save the processed image\n",
    "                image_save_path = f\"{output_folder_step}/{technique_name}_Image_{img_id}.jpg\"\n",
    "                cv2.imwrite(image_save_path, processed_image)\n",
    "\n",
    "    # Generate Comparison Table\n",
    "    comparison_data = []\n",
    "    for img_id, original_stats, result in all_results:\n",
    "        # Add original stats row\n",
    "        comparison_data.append([img_id, \"Original\"] + list(original_stats.values())[1:])  # Skip the 'Image' key\n",
    "        # Add each technique's stats\n",
    "        for technique, metrics in result[\"Evaluation Results\"].items():\n",
    "            comparison_data.append([img_id, f\"{step_name} - {technique}\"] + list(metrics[\"Stats\"].values()))\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    comparison_df = pd.DataFrame(comparison_data, columns=[\n",
    "        \"Image_ID\", \"Technique\", \"Brightness\", \"Sharpness\", \"Contrast\", \"Noise\"\n",
    "    ])\n",
    "\n",
    "    # Generate Recommendation\n",
    "    recommended_technique_name = max(all_results, key=lambda x: x[2][\"Evaluation Results\"][x[2][\"Best Technique\"]][\"Score\"])[2][\"Best Technique\"]\n",
    "    recommended_technique_func = techniques_dict[recommended_technique_name]\n",
    "    print(f\"\\nRecommended Technique for {step_name}: {recommended_technique_name}\\n\")\n",
    "\n",
    "    # Append both technique name and function for further tuning\n",
    "    best_techniques_list.append((step_name, recommended_technique_name, recommended_technique_func))\n",
    "\n",
    "    # Return the comparison DataFrame\n",
<<<<<<< HEAD
    "    return comparison_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:43:50.911750Z",
     "start_time": "2024-11-19T14:43:50.893755Z"
    }
   },
   "id": "a9dcfaa1991f5e3a",
   "execution_count": 154
=======
    "    return comparison_df"
   ]
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
  },
  {
   "cell_type": "markdown",
   "id": "5473417fb6fc8aff",
   "metadata": {},
   "source": [
    "### Running Different Techniques per Step"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
=======
   "execution_count": 17,
   "id": "5c3b64a356573a62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:20:10.697656Z",
     "start_time": "2024-11-19T08:16:57.288784Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing images: 100%|██████████| 698/698 [03:13<00:00,  3.61image/s]\n"
     ]
    }
   ],
   "source": [
    "# Load all image file paths from the specified folder\n",
    "image_paths_all = load_images_from_folder(folder_path)\n",
    "\n",
    "# Load and preprocess all images\n",
    "total_images, total_image_ids = load_and_preprocess_images(image_paths_all)\n",
    "\n",
    "# Randomly select 5 images for experimentation\n",
    "experiment_indices = random.sample(range(len(total_images)), 5)\n",
    "test_images = [total_images[i] for i in experiment_indices]\n",
    "test_image_ids = [total_image_ids[i] for i in experiment_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d321de124a8f61b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:20:10.713653Z",
     "start_time": "2024-11-19T08:20:10.700673Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
   "outputs": [],
   "source": [
    "best_techniques_list = []\n",
    "comparison_tables = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1272df62648886a8",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-19T14:43:51.976583Z",
     "start_time": "2024-11-19T14:43:51.961581Z"
    }
   },
   "id": "5d321de124a8f61b",
   "execution_count": 155
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-19T08:20:11.455654Z",
     "start_time": "2024-11-19T08:20:10.715668Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Step: Noise Reduction\n",
      "----------------------------------------\n",
      "Best Technique for Image_1: Median Blur\n",
      "Best Technique for Image_2: Median Blur\n",
      "Best Technique for Image_3: Median Blur\n",
      "Best Technique for Image_4: Median Blur\n",
      "Best Technique for Image_5: Median Blur\n",
      "Best Technique for Image_6: Median Blur\n",
      "Best Technique for Image_7: Median Blur\n",
      "Best Technique for Image_8: Median Blur\n",
      "Best Technique for Image_9: Median Blur\n",
      "Best Technique for Image_10: Median Blur\n",
      "Best Technique for Image_11: Non-Local Means\n",
      "Best Technique for Image_12: Non-Local Means\n",
      "\n",
      "Recommended Technique for Noise Reduction: Median Blur\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Noise Reduction\n",
    "noise_reduction_techniques = {\n",
    "    \"Gaussian Blur\": lambda img: cv2.GaussianBlur(img, (5, 5), 0),\n",
    "    \"Median Blur\": lambda img: cv2.medianBlur(img, 5),\n",
    "    \"Non-Local Means\": lambda img: cv2.fastNlMeansDenoising(img, None, 10, 7, 21)\n",
    "}\n",
<<<<<<< HEAD
    "comparison_tables.append(run_step(\"Noise Reduction\", noise_reduction_techniques, total_images, total_image_ids, best_techniques_list))"
   ],
=======
    "comparison_tables.append(run_step(\"Noise Reduction\", noise_reduction_techniques, test_images, test_image_ids, best_techniques_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5ef0203d606d09a",
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-19T14:45:25.191166Z",
     "start_time": "2024-11-19T14:43:52.359889Z"
    }
   },
   "id": "1272df62648886a8",
   "execution_count": 156
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-19T08:20:11.487653Z",
     "start_time": "2024-11-19T08:20:11.457676Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Step: Histogram Equalization\n",
      "----------------------------------------\n",
      "Best Technique for Image_1: Histogram Equalization\n",
      "Best Technique for Image_2: Histogram Equalization\n",
      "Best Technique for Image_3: Histogram Equalization\n",
      "Best Technique for Image_4: Histogram Equalization\n",
      "Best Technique for Image_5: Histogram Equalization\n",
      "Best Technique for Image_6: Histogram Equalization\n",
      "Best Technique for Image_7: Histogram Equalization\n",
      "Best Technique for Image_8: Histogram Equalization\n",
      "Best Technique for Image_9: Histogram Equalization\n",
      "Best Technique for Image_10: Histogram Equalization\n",
      "Best Technique for Image_11: Histogram Equalization\n",
      "Best Technique for Image_12: Histogram Equalization\n",
      "\n",
      "Recommended Technique for Histogram Equalization: Histogram Equalization\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Histogram Equalization\n",
    "histogram_equalization_techniques = {\n",
    "    \"Histogram Equalization\": lambda img: cv2.equalizeHist(img),\n",
    "    \"CLAHE\": lambda img: cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(img)\n",
    "}\n",
<<<<<<< HEAD
    "comparison_tables.append(run_step(\"Histogram Equalization\", histogram_equalization_techniques,total_images, total_image_ids, best_techniques_list))"
   ],
=======
    "comparison_tables.append(run_step(\"Histogram Equalization\", histogram_equalization_techniques, test_images, test_image_ids, best_techniques_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a68616ef9a33f67d",
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-19T14:45:41.756317Z",
     "start_time": "2024-11-19T14:45:31.740107Z"
    }
   },
   "id": "b5ef0203d606d09a",
   "execution_count": 157
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-19T08:20:11.535656Z",
     "start_time": "2024-11-19T08:20:11.489654Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Step: Binarization\n",
      "----------------------------------------\n",
      "Best Technique for Image_1: Adaptive Threshold\n",
      "Best Technique for Image_2: Adaptive Threshold\n",
      "Best Technique for Image_3: Adaptive Threshold\n",
      "Best Technique for Image_4: Adaptive Threshold\n",
      "Best Technique for Image_5: Adaptive Threshold\n",
      "Best Technique for Image_6: Adaptive Threshold\n",
      "Best Technique for Image_7: Adaptive Threshold\n",
      "Best Technique for Image_8: Adaptive Threshold\n",
      "Best Technique for Image_9: Adaptive Threshold\n",
      "Best Technique for Image_10: Adaptive Threshold\n",
      "Best Technique for Image_11: Adaptive Threshold\n",
      "Best Technique for Image_12: Adaptive Threshold\n",
      "\n",
      "Recommended Technique for Binarization: Adaptive Threshold\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Binarization\n",
    "binarization_techniques = {\n",
    "    \"Global Threshold\": lambda img: cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)[1],\n",
    "    \"Adaptive Threshold\": lambda img: cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2),\n",
    "    \"Otsu Threshold\": lambda img: cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1],\n",
    "    \"Inverted Otsu Threshold\": lambda img: cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "}\n",
<<<<<<< HEAD
    "comparison_tables.append(run_step(\"Binarization\", binarization_techniques, total_images, total_image_ids, best_techniques_list))\n"
   ],
=======
    "comparison_tables.append(run_step(\"Binarization\", binarization_techniques, test_images, test_image_ids, best_techniques_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a8bf5b17df76bee",
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-19T14:46:00.848318Z",
     "start_time": "2024-11-19T14:45:41.759319Z"
    }
   },
   "id": "a68616ef9a33f67d",
   "execution_count": 158
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-19T08:20:11.583656Z",
     "start_time": "2024-11-19T08:20:11.536667Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Step: Morphological Operations\n",
      "----------------------------------------\n",
      "Best Technique for Image_1: Dilation\n",
      "Best Technique for Image_2: Dilation\n",
      "Best Technique for Image_3: Dilation\n",
      "Best Technique for Image_4: Dilation\n",
      "Best Technique for Image_5: Dilation\n",
      "Best Technique for Image_6: Dilation\n",
      "Best Technique for Image_7: Dilation\n",
      "Best Technique for Image_8: Dilation\n",
      "Best Technique for Image_9: Dilation\n",
      "Best Technique for Image_10: Dilation\n",
      "Best Technique for Image_11: Dilation\n",
      "Best Technique for Image_12: Opening\n",
      "\n",
      "Recommended Technique for Morphological Operations: Dilation\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Morphological Operations\n",
    "morphological_operations_techniques = {\n",
    "    \"Dilation\": lambda img: cv2.dilate(img, np.ones((5, 5), np.uint8), iterations=1),\n",
    "    \"Erosion\": lambda img: cv2.erode(img, np.ones((5, 5), np.uint8), iterations=1),\n",
    "    \"Opening\": lambda img: cv2.morphologyEx(img, cv2.MORPH_OPEN, np.ones((5, 5), np.uint8)),\n",
    "    \"Closing\": lambda img: cv2.morphologyEx(img, cv2.MORPH_CLOSE, np.ones((5, 5), np.uint8))\n",
    "}\n",
<<<<<<< HEAD
    "comparison_tables.append(run_step(\"Morphological Operations\", morphological_operations_techniques, total_images, total_image_ids, best_techniques_list))"
   ],
=======
    "comparison_tables.append(run_step(\"Morphological Operations\", morphological_operations_techniques, test_images, test_image_ids, best_techniques_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e47a9227209a883",
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-19T14:46:18.256320Z",
     "start_time": "2024-11-19T14:46:00.849317Z"
    }
   },
   "id": "8a8bf5b17df76bee",
   "execution_count": 159
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-19T08:20:11.631652Z",
     "start_time": "2024-11-19T08:20:11.584655Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Step: Edge Detection\n",
      "----------------------------------------\n",
      "Best Technique for Image_1: Unsharp Mask\n",
      "Best Technique for Image_2: Canny Edge\n",
      "Best Technique for Image_3: Canny Edge\n",
      "Best Technique for Image_4: Canny Edge\n",
      "Best Technique for Image_5: Canny Edge\n",
      "Best Technique for Image_6: Canny Edge\n",
      "Best Technique for Image_7: Canny Edge\n",
      "Best Technique for Image_8: Canny Edge\n",
      "Best Technique for Image_9: Canny Edge\n",
      "Best Technique for Image_10: Canny Edge\n",
      "Best Technique for Image_11: Canny Edge\n",
      "Best Technique for Image_12: Canny Edge\n",
      "\n",
      "Recommended Technique for Edge Detection: Canny Edge\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Edge Detection\n",
    "edge_detection_techniques = {\n",
    "    \"Canny Edge\": lambda img: cv2.Canny(img, 100, 200),\n",
    "    \"Sobel Edge\": lambda img: cv2.convertScaleAbs(cv2.Sobel(img, cv2.CV_64F, 1, 1, ksize=3)),\n",
    "    \"Unsharp Mask\": lambda img: cv2.addWeighted(img, 1.5, cv2.GaussianBlur(img, (0, 0), 3), -0.5, 0)\n",
    "}\n",
<<<<<<< HEAD
    "comparison_tables.append(run_step(\"Edge Detection\", edge_detection_techniques, total_images, total_image_ids, best_techniques_list))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:46:32.489406Z",
     "start_time": "2024-11-19T14:46:18.257320Z"
    }
   },
   "id": "7e47a9227209a883",
   "execution_count": 160
=======
    "comparison_tables.append(run_step(\"Edge Detection\", edge_detection_techniques, test_images, test_image_ids, best_techniques_list))\n"
   ]
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
  },
  {
   "cell_type": "markdown",
   "id": "8439513ab9cfdf06",
   "metadata": {},
   "source": [
    "## Final best techniques per step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7264edc32f3787a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:20:11.647652Z",
     "start_time": "2024-11-19T08:20:11.632653Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Techniques for Each Step:\n",
      "Noise Reduction: Median Blur\n",
      "Histogram Equalization: Histogram Equalization\n",
      "Binarization: Adaptive Threshold\n",
      "Morphological Operations: Dilation\n",
      "Edge Detection: Canny Edge\n"
     ]
    }
   ],
   "source": [
    "# Print the list of best techniques for each step\n",
    "print(\"\\nBest Techniques for Each Step:\")\n",
    "for step, technique_name, technique_func in best_techniques_list:\n",
    "    print(f\"{step}: {technique_name}\")"
<<<<<<< HEAD
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:46:32.505405Z",
     "start_time": "2024-11-19T14:46:32.492406Z"
    }
   },
   "id": "7264edc32f3787a",
   "execution_count": 161
=======
   ]
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8b12bb0b5a2f14c",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-19T14:46:32.553405Z",
     "start_time": "2024-11-19T14:46:32.506406Z"
    }
   },
   "id": "a8b12bb0b5a2f14c",
   "execution_count": 162
=======
     "end_time": "2024-11-19T08:20:11.679666Z",
     "start_time": "2024-11-19T08:20:11.648653Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for i, comparison_df in enumerate(comparison_tables):\n",
    "    comparison_df.to_csv(f\"comparison tables/comparison_table_step_{i+1}.csv\", index=False)"
   ]
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22cfb8654a8557fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:20:11.741653Z",
     "start_time": "2024-11-19T08:20:11.681655Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table for Step 1:\n"
     ]
    },
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "  Image_ID                          Technique  Brightness  Sharpness  \\\n0  Image_1                           Original  100.038606  19.325682   \n1  Image_1    Noise Reduction - Gaussian Blur  100.040263   2.555427   \n2  Image_1      Noise Reduction - Median Blur  100.053831   3.370179   \n3  Image_1  Noise Reduction - Non-Local Means  100.122936   1.055841   \n4  Image_2                           Original   98.179438  25.128856   \n\n    Contrast     Noise  \n0  49.248767  0.611743  \n1  49.203063  0.092129  \n2  49.205378  0.131448  \n3  49.206455  0.039625  \n4  45.808319  0.793025  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_ID</th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_1</td>\n      <td>Original</td>\n      <td>100.038606</td>\n      <td>19.325682</td>\n      <td>49.248767</td>\n      <td>0.611743</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_1</td>\n      <td>Noise Reduction - Gaussian Blur</td>\n      <td>100.040263</td>\n      <td>2.555427</td>\n      <td>49.203063</td>\n      <td>0.092129</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_1</td>\n      <td>Noise Reduction - Median Blur</td>\n      <td>100.053831</td>\n      <td>3.370179</td>\n      <td>49.205378</td>\n      <td>0.131448</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_1</td>\n      <td>Noise Reduction - Non-Local Means</td>\n      <td>100.122936</td>\n      <td>1.055841</td>\n      <td>49.206455</td>\n      <td>0.039625</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_2</td>\n      <td>Original</td>\n      <td>98.179438</td>\n      <td>25.128856</td>\n      <td>45.808319</td>\n      <td>0.793025</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
=======
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Brightness</th>\n",
       "      <th>Sharpness</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Noise</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Line Spacing</th>\n",
       "      <th>Tables Detected</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Detected Elements</th>\n",
       "      <th>Texture</th>\n",
       "      <th>Patterns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_690</td>\n",
       "      <td>Original</td>\n",
       "      <td>95.739700</td>\n",
       "      <td>1399.912185</td>\n",
       "      <td>50.254875</td>\n",
       "      <td>44.090835</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>37.415400</td>\n",
       "      <td>4754.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_690</td>\n",
       "      <td>Noise Reduction - Gaussian Blur</td>\n",
       "      <td>95.740021</td>\n",
       "      <td>25.729243</td>\n",
       "      <td>48.871518</td>\n",
       "      <td>1.122483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_690</td>\n",
       "      <td>Noise Reduction - Median Blur</td>\n",
       "      <td>97.373520</td>\n",
       "      <td>101.285416</td>\n",
       "      <td>49.950030</td>\n",
       "      <td>5.172836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_690</td>\n",
       "      <td>Noise Reduction - Non-Local Means</td>\n",
       "      <td>96.104416</td>\n",
       "      <td>621.201584</td>\n",
       "      <td>49.857048</td>\n",
       "      <td>26.952520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_151</td>\n",
       "      <td>Original</td>\n",
       "      <td>108.298706</td>\n",
       "      <td>944.638775</td>\n",
       "      <td>42.713477</td>\n",
       "      <td>32.509702</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.734976</td>\n",
       "      <td>3200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Image_ID                          Technique  Brightness    Sharpness  \\\n",
       "0  Image_690                           Original   95.739700  1399.912185   \n",
       "1  Image_690    Noise Reduction - Gaussian Blur   95.740021    25.729243   \n",
       "2  Image_690      Noise Reduction - Median Blur   97.373520   101.285416   \n",
       "3  Image_690  Noise Reduction - Non-Local Means   96.104416   621.201584   \n",
       "4  Image_151                           Original  108.298706   944.638775   \n",
       "\n",
       "    Contrast      Noise  Skew  Line Spacing  Tables Detected  Resolution  \\\n",
       "0  50.254875  44.090835 -90.0      2.833333              2.0     65536.0   \n",
       "1  48.871518   1.122483   NaN           NaN              NaN         NaN   \n",
       "2  49.950030   5.172836   NaN           NaN              NaN         NaN   \n",
       "3  49.857048  26.952520   NaN           NaN              NaN         NaN   \n",
       "4  42.713477  32.509702 -90.0      0.000000              1.0     65536.0   \n",
       "\n",
       "   Detected Elements    Texture  Patterns  \n",
       "0               91.0  37.415400    4754.0  \n",
       "1                NaN        NaN       NaN  \n",
       "2                NaN        NaN       NaN  \n",
       "3                NaN        NaN       NaN  \n",
       "4                1.0  30.734976    3200.0  "
      ]
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table for Step 2:\n"
     ]
    },
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "  Image_ID                                        Technique  Brightness  \\\n0  Image_1                                         Original  100.038606   \n1  Image_1  Histogram Equalization - Histogram Equalization  129.992140   \n2  Image_1                   Histogram Equalization - CLAHE  111.881596   \n3  Image_2                                         Original   98.179438   \n4  Image_2  Histogram Equalization - Histogram Equalization  129.388226   \n\n    Sharpness   Contrast      Noise  \n0   19.325682  49.248767   0.611743  \n1  449.752451  74.197282  11.864573  \n2  108.891513  51.003822   2.387673  \n3   25.128856  45.808319   0.793025  \n4  296.483627  74.105148   7.610643  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_ID</th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_1</td>\n      <td>Original</td>\n      <td>100.038606</td>\n      <td>19.325682</td>\n      <td>49.248767</td>\n      <td>0.611743</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_1</td>\n      <td>Histogram Equalization - Histogram Equalization</td>\n      <td>129.992140</td>\n      <td>449.752451</td>\n      <td>74.197282</td>\n      <td>11.864573</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_1</td>\n      <td>Histogram Equalization - CLAHE</td>\n      <td>111.881596</td>\n      <td>108.891513</td>\n      <td>51.003822</td>\n      <td>2.387673</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_2</td>\n      <td>Original</td>\n      <td>98.179438</td>\n      <td>25.128856</td>\n      <td>45.808319</td>\n      <td>0.793025</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_2</td>\n      <td>Histogram Equalization - Histogram Equalization</td>\n      <td>129.388226</td>\n      <td>296.483627</td>\n      <td>74.105148</td>\n      <td>7.610643</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
=======
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Brightness</th>\n",
       "      <th>Sharpness</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Noise</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Line Spacing</th>\n",
       "      <th>Tables Detected</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Detected Elements</th>\n",
       "      <th>Texture</th>\n",
       "      <th>Patterns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_690</td>\n",
       "      <td>Original</td>\n",
       "      <td>95.739700</td>\n",
       "      <td>1399.912185</td>\n",
       "      <td>50.254875</td>\n",
       "      <td>44.090835</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>37.415400</td>\n",
       "      <td>4754.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_690</td>\n",
       "      <td>Histogram Equalization - Histogram Equalization</td>\n",
       "      <td>128.691757</td>\n",
       "      <td>3721.812831</td>\n",
       "      <td>73.488796</td>\n",
       "      <td>102.422597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_690</td>\n",
       "      <td>Histogram Equalization - CLAHE</td>\n",
       "      <td>114.178329</td>\n",
       "      <td>3236.298742</td>\n",
       "      <td>53.423689</td>\n",
       "      <td>83.468484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_151</td>\n",
       "      <td>Original</td>\n",
       "      <td>108.298706</td>\n",
       "      <td>944.638775</td>\n",
       "      <td>42.713477</td>\n",
       "      <td>32.509702</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.734976</td>\n",
       "      <td>3200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_151</td>\n",
       "      <td>Histogram Equalization - Histogram Equalization</td>\n",
       "      <td>129.763214</td>\n",
       "      <td>4829.863844</td>\n",
       "      <td>74.248876</td>\n",
       "      <td>131.088958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Image_ID                                        Technique  Brightness  \\\n",
       "0  Image_690                                         Original   95.739700   \n",
       "1  Image_690  Histogram Equalization - Histogram Equalization  128.691757   \n",
       "2  Image_690                   Histogram Equalization - CLAHE  114.178329   \n",
       "3  Image_151                                         Original  108.298706   \n",
       "4  Image_151  Histogram Equalization - Histogram Equalization  129.763214   \n",
       "\n",
       "     Sharpness   Contrast       Noise  Skew  Line Spacing  Tables Detected  \\\n",
       "0  1399.912185  50.254875   44.090835 -90.0      2.833333              2.0   \n",
       "1  3721.812831  73.488796  102.422597   NaN           NaN              NaN   \n",
       "2  3236.298742  53.423689   83.468484   NaN           NaN              NaN   \n",
       "3   944.638775  42.713477   32.509702 -90.0      0.000000              1.0   \n",
       "4  4829.863844  74.248876  131.088958   NaN           NaN              NaN   \n",
       "\n",
       "   Resolution  Detected Elements    Texture  Patterns  \n",
       "0     65536.0               91.0  37.415400    4754.0  \n",
       "1         NaN                NaN        NaN       NaN  \n",
       "2         NaN                NaN        NaN       NaN  \n",
       "3     65536.0                1.0  30.734976    3200.0  \n",
       "4         NaN                NaN        NaN       NaN  "
      ]
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table for Step 3:\n"
     ]
    },
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "  Image_ID                               Technique  Brightness     Sharpness  \\\n0  Image_1                                Original  100.038606     19.325682   \n1  Image_1         Binarization - Global Threshold  115.433574  19104.307726   \n2  Image_1       Binarization - Adaptive Threshold  225.141598  76869.538482   \n3  Image_1           Binarization - Otsu Threshold  187.034569    933.412905   \n4  Image_1  Binarization - Inverted Otsu Threshold   67.965431    933.412905   \n\n     Contrast        Noise  \n0   49.248767     0.611743  \n1  126.927741   650.472755  \n2   81.990050  1960.812235  \n3  112.746996    36.078179  \n4  112.746996    36.068114  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_ID</th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_1</td>\n      <td>Original</td>\n      <td>100.038606</td>\n      <td>19.325682</td>\n      <td>49.248767</td>\n      <td>0.611743</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_1</td>\n      <td>Binarization - Global Threshold</td>\n      <td>115.433574</td>\n      <td>19104.307726</td>\n      <td>126.927741</td>\n      <td>650.472755</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_1</td>\n      <td>Binarization - Adaptive Threshold</td>\n      <td>225.141598</td>\n      <td>76869.538482</td>\n      <td>81.990050</td>\n      <td>1960.812235</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_1</td>\n      <td>Binarization - Otsu Threshold</td>\n      <td>187.034569</td>\n      <td>933.412905</td>\n      <td>112.746996</td>\n      <td>36.078179</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_1</td>\n      <td>Binarization - Inverted Otsu Threshold</td>\n      <td>67.965431</td>\n      <td>933.412905</td>\n      <td>112.746996</td>\n      <td>36.068114</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
=======
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Brightness</th>\n",
       "      <th>Sharpness</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Noise</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Line Spacing</th>\n",
       "      <th>Tables Detected</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Detected Elements</th>\n",
       "      <th>Texture</th>\n",
       "      <th>Patterns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_690</td>\n",
       "      <td>Original</td>\n",
       "      <td>95.739700</td>\n",
       "      <td>1399.912185</td>\n",
       "      <td>50.254875</td>\n",
       "      <td>44.090835</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>37.4154</td>\n",
       "      <td>4754.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_690</td>\n",
       "      <td>Binarization - Global Threshold</td>\n",
       "      <td>90.064774</td>\n",
       "      <td>31350.630191</td>\n",
       "      <td>121.880490</td>\n",
       "      <td>1023.297722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_690</td>\n",
       "      <td>Binarization - Adaptive Threshold</td>\n",
       "      <td>188.615799</td>\n",
       "      <td>158213.635930</td>\n",
       "      <td>111.897762</td>\n",
       "      <td>2542.838376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_690</td>\n",
       "      <td>Binarization - Otsu Threshold</td>\n",
       "      <td>168.028564</td>\n",
       "      <td>21434.556183</td>\n",
       "      <td>120.887077</td>\n",
       "      <td>758.319225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_690</td>\n",
       "      <td>Binarization - Inverted Otsu Threshold</td>\n",
       "      <td>86.971436</td>\n",
       "      <td>21434.556183</td>\n",
       "      <td>120.887077</td>\n",
       "      <td>757.182218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Image_ID                               Technique  Brightness  \\\n",
       "0  Image_690                                Original   95.739700   \n",
       "1  Image_690         Binarization - Global Threshold   90.064774   \n",
       "2  Image_690       Binarization - Adaptive Threshold  188.615799   \n",
       "3  Image_690           Binarization - Otsu Threshold  168.028564   \n",
       "4  Image_690  Binarization - Inverted Otsu Threshold   86.971436   \n",
       "\n",
       "       Sharpness    Contrast        Noise  Skew  Line Spacing  \\\n",
       "0    1399.912185   50.254875    44.090835 -90.0      2.833333   \n",
       "1   31350.630191  121.880490  1023.297722   NaN           NaN   \n",
       "2  158213.635930  111.897762  2542.838376   NaN           NaN   \n",
       "3   21434.556183  120.887077   758.319225   NaN           NaN   \n",
       "4   21434.556183  120.887077   757.182218   NaN           NaN   \n",
       "\n",
       "   Tables Detected  Resolution  Detected Elements  Texture  Patterns  \n",
       "0              2.0     65536.0               91.0  37.4154    4754.0  \n",
       "1              NaN         NaN                NaN      NaN       NaN  \n",
       "2              NaN         NaN                NaN      NaN       NaN  \n",
       "3              NaN         NaN                NaN      NaN       NaN  \n",
       "4              NaN         NaN                NaN      NaN       NaN  "
      ]
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table for Step 4:\n"
     ]
    },
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "  Image_ID                            Technique  Brightness  Sharpness  \\\n0  Image_1                             Original  100.038606  19.325682   \n1  Image_1  Morphological Operations - Dilation  103.327429   5.518534   \n2  Image_1   Morphological Operations - Erosion   96.712300   6.179660   \n3  Image_1   Morphological Operations - Opening   98.675308   5.591603   \n4  Image_1   Morphological Operations - Closing  101.526125   4.817830   \n\n    Contrast     Noise  \n0  49.248767  0.611743  \n1  48.967120  0.261983  \n2  49.558644  0.294743  \n3  49.403211  0.258792  \n4  49.040901  0.221248  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_ID</th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_1</td>\n      <td>Original</td>\n      <td>100.038606</td>\n      <td>19.325682</td>\n      <td>49.248767</td>\n      <td>0.611743</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_1</td>\n      <td>Morphological Operations - Dilation</td>\n      <td>103.327429</td>\n      <td>5.518534</td>\n      <td>48.967120</td>\n      <td>0.261983</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_1</td>\n      <td>Morphological Operations - Erosion</td>\n      <td>96.712300</td>\n      <td>6.179660</td>\n      <td>49.558644</td>\n      <td>0.294743</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_1</td>\n      <td>Morphological Operations - Opening</td>\n      <td>98.675308</td>\n      <td>5.591603</td>\n      <td>49.403211</td>\n      <td>0.258792</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_1</td>\n      <td>Morphological Operations - Closing</td>\n      <td>101.526125</td>\n      <td>4.817830</td>\n      <td>49.040901</td>\n      <td>0.221248</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
=======
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Brightness</th>\n",
       "      <th>Sharpness</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Noise</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Line Spacing</th>\n",
       "      <th>Tables Detected</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Detected Elements</th>\n",
       "      <th>Texture</th>\n",
       "      <th>Patterns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_690</td>\n",
       "      <td>Original</td>\n",
       "      <td>95.739700</td>\n",
       "      <td>1399.912185</td>\n",
       "      <td>50.254875</td>\n",
       "      <td>44.090835</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>37.4154</td>\n",
       "      <td>4754.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_690</td>\n",
       "      <td>Morphological Operations - Dilation</td>\n",
       "      <td>106.936340</td>\n",
       "      <td>153.574488</td>\n",
       "      <td>48.947292</td>\n",
       "      <td>7.616972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_690</td>\n",
       "      <td>Morphological Operations - Erosion</td>\n",
       "      <td>74.356354</td>\n",
       "      <td>765.695244</td>\n",
       "      <td>49.365490</td>\n",
       "      <td>30.793594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_690</td>\n",
       "      <td>Morphological Operations - Opening</td>\n",
       "      <td>89.443726</td>\n",
       "      <td>690.886814</td>\n",
       "      <td>49.658296</td>\n",
       "      <td>28.624921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_690</td>\n",
       "      <td>Morphological Operations - Closing</td>\n",
       "      <td>101.178070</td>\n",
       "      <td>138.299262</td>\n",
       "      <td>49.690097</td>\n",
       "      <td>6.868499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Image_ID                            Technique  Brightness    Sharpness  \\\n",
       "0  Image_690                             Original   95.739700  1399.912185   \n",
       "1  Image_690  Morphological Operations - Dilation  106.936340   153.574488   \n",
       "2  Image_690   Morphological Operations - Erosion   74.356354   765.695244   \n",
       "3  Image_690   Morphological Operations - Opening   89.443726   690.886814   \n",
       "4  Image_690   Morphological Operations - Closing  101.178070   138.299262   \n",
       "\n",
       "    Contrast      Noise  Skew  Line Spacing  Tables Detected  Resolution  \\\n",
       "0  50.254875  44.090835 -90.0      2.833333              2.0     65536.0   \n",
       "1  48.947292   7.616972   NaN           NaN              NaN         NaN   \n",
       "2  49.365490  30.793594   NaN           NaN              NaN         NaN   \n",
       "3  49.658296  28.624921   NaN           NaN              NaN         NaN   \n",
       "4  49.690097   6.868499   NaN           NaN              NaN         NaN   \n",
       "\n",
       "   Detected Elements  Texture  Patterns  \n",
       "0               91.0  37.4154    4754.0  \n",
       "1                NaN      NaN       NaN  \n",
       "2                NaN      NaN       NaN  \n",
       "3                NaN      NaN       NaN  \n",
       "4                NaN      NaN       NaN  "
      ]
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table for Step 5:\n"
     ]
    },
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "  Image_ID                      Technique  Brightness   Sharpness   Contrast  \\\n0  Image_1                       Original  100.038606   19.325682  49.248767   \n1  Image_1    Edge Detection - Canny Edge    0.278076  673.600260   8.416173   \n2  Image_1    Edge Detection - Sobel Edge    2.406605   78.485498   2.535573   \n3  Image_1  Edge Detection - Unsharp Mask  100.038911   45.461158  49.366554   \n4  Image_2                       Original   98.179438   25.128856  45.808319   \n\n       Noise  \n0   0.611743  \n1  26.700883  \n2   1.497698  \n3   1.229335  \n4   0.793025  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_ID</th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_1</td>\n      <td>Original</td>\n      <td>100.038606</td>\n      <td>19.325682</td>\n      <td>49.248767</td>\n      <td>0.611743</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_1</td>\n      <td>Edge Detection - Canny Edge</td>\n      <td>0.278076</td>\n      <td>673.600260</td>\n      <td>8.416173</td>\n      <td>26.700883</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_1</td>\n      <td>Edge Detection - Sobel Edge</td>\n      <td>2.406605</td>\n      <td>78.485498</td>\n      <td>2.535573</td>\n      <td>1.497698</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_1</td>\n      <td>Edge Detection - Unsharp Mask</td>\n      <td>100.038911</td>\n      <td>45.461158</td>\n      <td>49.366554</td>\n      <td>1.229335</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_2</td>\n      <td>Original</td>\n      <td>98.179438</td>\n      <td>25.128856</td>\n      <td>45.808319</td>\n      <td>0.793025</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
=======
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Brightness</th>\n",
       "      <th>Sharpness</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Noise</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Line Spacing</th>\n",
       "      <th>Tables Detected</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Detected Elements</th>\n",
       "      <th>Texture</th>\n",
       "      <th>Patterns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_690</td>\n",
       "      <td>Original</td>\n",
       "      <td>95.739700</td>\n",
       "      <td>1399.912185</td>\n",
       "      <td>50.254875</td>\n",
       "      <td>44.090835</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>37.415400</td>\n",
       "      <td>4754.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_690</td>\n",
       "      <td>Edge Detection - Canny Edge</td>\n",
       "      <td>18.497772</td>\n",
       "      <td>43150.897980</td>\n",
       "      <td>66.142001</td>\n",
       "      <td>1553.399409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_690</td>\n",
       "      <td>Edge Detection - Sobel Edge</td>\n",
       "      <td>7.828064</td>\n",
       "      <td>2681.382180</td>\n",
       "      <td>14.366376</td>\n",
       "      <td>66.193151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_690</td>\n",
       "      <td>Edge Detection - Unsharp Mask</td>\n",
       "      <td>95.797897</td>\n",
       "      <td>3044.710875</td>\n",
       "      <td>52.593546</td>\n",
       "      <td>94.948241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_151</td>\n",
       "      <td>Original</td>\n",
       "      <td>108.298706</td>\n",
       "      <td>944.638775</td>\n",
       "      <td>42.713477</td>\n",
       "      <td>32.509702</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.734976</td>\n",
       "      <td>3200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Image_ID                      Technique  Brightness     Sharpness  \\\n",
       "0  Image_690                       Original   95.739700   1399.912185   \n",
       "1  Image_690    Edge Detection - Canny Edge   18.497772  43150.897980   \n",
       "2  Image_690    Edge Detection - Sobel Edge    7.828064   2681.382180   \n",
       "3  Image_690  Edge Detection - Unsharp Mask   95.797897   3044.710875   \n",
       "4  Image_151                       Original  108.298706    944.638775   \n",
       "\n",
       "    Contrast        Noise  Skew  Line Spacing  Tables Detected  Resolution  \\\n",
       "0  50.254875    44.090835 -90.0      2.833333              2.0     65536.0   \n",
       "1  66.142001  1553.399409   NaN           NaN              NaN         NaN   \n",
       "2  14.366376    66.193151   NaN           NaN              NaN         NaN   \n",
       "3  52.593546    94.948241   NaN           NaN              NaN         NaN   \n",
       "4  42.713477    32.509702 -90.0      0.000000              1.0     65536.0   \n",
       "\n",
       "   Detected Elements    Texture  Patterns  \n",
       "0               91.0  37.415400    4754.0  \n",
       "1                NaN        NaN       NaN  \n",
       "2                NaN        NaN       NaN  \n",
       "3                NaN        NaN       NaN  \n",
       "4                1.0  30.734976    3200.0  "
      ]
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display comparison tables within the notebook\n",
    "for i, comparison_df in enumerate(comparison_tables):\n",
    "    print(f\"Comparison Table for Step {i+1}:\")\n",
    "    display(comparison_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "624d20d42c755cc5",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-19T14:46:32.601406Z",
     "start_time": "2024-11-19T14:46:32.555405Z"
    }
   },
   "id": "22cfb8654a8557fc",
   "execution_count": 163
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-19T08:20:11.771653Z",
     "start_time": "2024-11-19T08:20:11.742653Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
   "outputs": [],
   "source": [
    "# Generate Average Comparison Table\n",
    "average_comparison_data = []\n",
    "for comparison_df in comparison_tables:\n",
    "    avg_stats = comparison_df.groupby(\"Technique\").mean().reset_index()\n",
    "    average_comparison_data.append(avg_stats)\n",
    "\n",
    "# Combine average stats from all steps\n",
    "average_comparison_df = pd.concat(average_comparison_data, ignore_index=True)\n",
    "# Save the average comparison table to a CSV file\n",
    "average_comparison_df.to_csv(\"comparison tables/average_comparison_table.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe7133144103efbc",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-19T14:46:32.649406Z",
     "start_time": "2024-11-19T14:46:32.603406Z"
    }
   },
   "id": "624d20d42c755cc5",
   "execution_count": 164
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                          Technique  Brightness     Sharpness  \\\n0                   Noise Reduction - Gaussian Blur  100.078415      7.058257   \n1                     Noise Reduction - Median Blur  100.196160     15.377021   \n2                 Noise Reduction - Non-Local Means  100.174134     17.121810   \n3                                          Original  100.076533     51.313566   \n4                    Histogram Equalization - CLAHE  116.414853    204.474269   \n5   Histogram Equalization - Histogram Equalization  129.263661    517.948236   \n6                                          Original  100.076533     51.313566   \n7                 Binarization - Adaptive Threshold  212.573648  89752.053635   \n8                   Binarization - Global Threshold   80.765910  13360.740813   \n9            Binarization - Inverted Otsu Threshold   63.983960   4555.143994   \n10                    Binarization - Otsu Threshold  191.016040   4555.143994   \n11                                         Original  100.076533     51.313566   \n12               Morphological Operations - Closing  102.471315     14.159538   \n13              Morphological Operations - Dilation  105.114731     16.195067   \n14               Morphological Operations - Erosion   94.700945     26.037474   \n15               Morphological Operations - Opening   98.209995     26.220077   \n16                                         Original  100.076533     51.313566   \n17                      Edge Detection - Canny Edge    2.882256   6418.176086   \n18                      Edge Detection - Sobel Edge    3.239745    162.682403   \n19                    Edge Detection - Unsharp Mask  100.102893    114.775559   \n20                                         Original  100.076533     51.313566   \n\n      Contrast        Noise  \n0    40.804637     0.328592  \n1    40.825361     0.723504  \n2    40.926299     0.918400  \n3    41.088002     1.819684  \n4    44.714736     5.229613  \n5    74.011280    15.940374  \n6    41.088002     1.819684  \n7    93.131020  1992.570933  \n8   112.119747   465.271962  \n9   109.228718   178.121482  \n10  109.228718   178.192149  \n11   41.088002     1.819684  \n12   40.633289     0.685542  \n13   40.525243     0.781439  \n14   41.890878     1.232602  \n15   41.020134     1.288609  \n16   41.088002     1.819684  \n17   24.095135   263.488489  \n18    4.081468     3.424144  \n19   41.698787     3.763249  \n20   41.088002     1.819684  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Technique</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Noise Reduction - Gaussian Blur</td>\n      <td>100.078415</td>\n      <td>7.058257</td>\n      <td>40.804637</td>\n      <td>0.328592</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Noise Reduction - Median Blur</td>\n      <td>100.196160</td>\n      <td>15.377021</td>\n      <td>40.825361</td>\n      <td>0.723504</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Noise Reduction - Non-Local Means</td>\n      <td>100.174134</td>\n      <td>17.121810</td>\n      <td>40.926299</td>\n      <td>0.918400</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Original</td>\n      <td>100.076533</td>\n      <td>51.313566</td>\n      <td>41.088002</td>\n      <td>1.819684</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Histogram Equalization - CLAHE</td>\n      <td>116.414853</td>\n      <td>204.474269</td>\n      <td>44.714736</td>\n      <td>5.229613</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Histogram Equalization - Histogram Equalization</td>\n      <td>129.263661</td>\n      <td>517.948236</td>\n      <td>74.011280</td>\n      <td>15.940374</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Original</td>\n      <td>100.076533</td>\n      <td>51.313566</td>\n      <td>41.088002</td>\n      <td>1.819684</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Binarization - Adaptive Threshold</td>\n      <td>212.573648</td>\n      <td>89752.053635</td>\n      <td>93.131020</td>\n      <td>1992.570933</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Binarization - Global Threshold</td>\n      <td>80.765910</td>\n      <td>13360.740813</td>\n      <td>112.119747</td>\n      <td>465.271962</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Binarization - Inverted Otsu Threshold</td>\n      <td>63.983960</td>\n      <td>4555.143994</td>\n      <td>109.228718</td>\n      <td>178.121482</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Binarization - Otsu Threshold</td>\n      <td>191.016040</td>\n      <td>4555.143994</td>\n      <td>109.228718</td>\n      <td>178.192149</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Original</td>\n      <td>100.076533</td>\n      <td>51.313566</td>\n      <td>41.088002</td>\n      <td>1.819684</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Morphological Operations - Closing</td>\n      <td>102.471315</td>\n      <td>14.159538</td>\n      <td>40.633289</td>\n      <td>0.685542</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Morphological Operations - Dilation</td>\n      <td>105.114731</td>\n      <td>16.195067</td>\n      <td>40.525243</td>\n      <td>0.781439</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Morphological Operations - Erosion</td>\n      <td>94.700945</td>\n      <td>26.037474</td>\n      <td>41.890878</td>\n      <td>1.232602</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Morphological Operations - Opening</td>\n      <td>98.209995</td>\n      <td>26.220077</td>\n      <td>41.020134</td>\n      <td>1.288609</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Original</td>\n      <td>100.076533</td>\n      <td>51.313566</td>\n      <td>41.088002</td>\n      <td>1.819684</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Edge Detection - Canny Edge</td>\n      <td>2.882256</td>\n      <td>6418.176086</td>\n      <td>24.095135</td>\n      <td>263.488489</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Edge Detection - Sobel Edge</td>\n      <td>3.239745</td>\n      <td>162.682403</td>\n      <td>4.081468</td>\n      <td>3.424144</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Edge Detection - Unsharp Mask</td>\n      <td>100.102893</td>\n      <td>114.775559</td>\n      <td>41.698787</td>\n      <td>3.763249</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Original</td>\n      <td>100.076533</td>\n      <td>51.313566</td>\n      <td>41.088002</td>\n      <td>1.819684</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
=======
     "end_time": "2024-11-19T08:20:11.802653Z",
     "start_time": "2024-11-19T08:20:11.773653Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Technique</th>\n",
       "      <th>Brightness</th>\n",
       "      <th>Sharpness</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Noise</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Line Spacing</th>\n",
       "      <th>Tables Detected</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Detected Elements</th>\n",
       "      <th>Texture</th>\n",
       "      <th>Patterns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Noise Reduction - Gaussian Blur</td>\n",
       "      <td>105.304456</td>\n",
       "      <td>28.095397</td>\n",
       "      <td>44.798519</td>\n",
       "      <td>1.225846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Noise Reduction - Median Blur</td>\n",
       "      <td>107.189792</td>\n",
       "      <td>101.215860</td>\n",
       "      <td>45.844607</td>\n",
       "      <td>5.287063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Noise Reduction - Non-Local Means</td>\n",
       "      <td>105.678824</td>\n",
       "      <td>714.632667</td>\n",
       "      <td>45.898716</td>\n",
       "      <td>28.856954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Original</td>\n",
       "      <td>105.298602</td>\n",
       "      <td>1475.447150</td>\n",
       "      <td>46.355469</td>\n",
       "      <td>45.731151</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>2.543452</td>\n",
       "      <td>1.8</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>73.4</td>\n",
       "      <td>37.179248</td>\n",
       "      <td>4640.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Histogram Equalization - CLAHE</td>\n",
       "      <td>124.084998</td>\n",
       "      <td>3310.648974</td>\n",
       "      <td>50.853785</td>\n",
       "      <td>86.451521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Histogram Equalization - Histogram Equalization</td>\n",
       "      <td>129.065079</td>\n",
       "      <td>4802.121954</td>\n",
       "      <td>73.824866</td>\n",
       "      <td>131.859308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Original</td>\n",
       "      <td>105.298602</td>\n",
       "      <td>1475.447150</td>\n",
       "      <td>46.355469</td>\n",
       "      <td>45.731151</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>2.543452</td>\n",
       "      <td>1.8</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>73.4</td>\n",
       "      <td>37.179248</td>\n",
       "      <td>4640.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Binarization - Adaptive Threshold</td>\n",
       "      <td>194.455399</td>\n",
       "      <td>140741.555539</td>\n",
       "      <td>108.385823</td>\n",
       "      <td>2530.041546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Binarization - Global Threshold</td>\n",
       "      <td>112.815399</td>\n",
       "      <td>40359.432543</td>\n",
       "      <td>125.698597</td>\n",
       "      <td>1253.831050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Binarization - Inverted Otsu Threshold</td>\n",
       "      <td>67.716476</td>\n",
       "      <td>19787.298731</td>\n",
       "      <td>111.403663</td>\n",
       "      <td>690.209641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Binarization - Otsu Threshold</td>\n",
       "      <td>187.283524</td>\n",
       "      <td>19787.298731</td>\n",
       "      <td>111.403663</td>\n",
       "      <td>691.193310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Original</td>\n",
       "      <td>105.298602</td>\n",
       "      <td>1475.447150</td>\n",
       "      <td>46.355469</td>\n",
       "      <td>45.731151</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>2.543452</td>\n",
       "      <td>1.8</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>73.4</td>\n",
       "      <td>37.179248</td>\n",
       "      <td>4640.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Morphological Operations - Closing</td>\n",
       "      <td>110.671228</td>\n",
       "      <td>144.089226</td>\n",
       "      <td>45.483240</td>\n",
       "      <td>7.462193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Morphological Operations - Dilation</td>\n",
       "      <td>115.863940</td>\n",
       "      <td>151.731249</td>\n",
       "      <td>44.186398</td>\n",
       "      <td>7.833668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Morphological Operations - Erosion</td>\n",
       "      <td>83.089850</td>\n",
       "      <td>841.356188</td>\n",
       "      <td>46.588018</td>\n",
       "      <td>32.814400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Morphological Operations - Opening</td>\n",
       "      <td>99.286642</td>\n",
       "      <td>743.263812</td>\n",
       "      <td>46.018403</td>\n",
       "      <td>29.903468</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Original</td>\n",
       "      <td>105.298602</td>\n",
       "      <td>1475.447150</td>\n",
       "      <td>46.355469</td>\n",
       "      <td>45.731151</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>2.543452</td>\n",
       "      <td>1.8</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>73.4</td>\n",
       "      <td>37.179248</td>\n",
       "      <td>4640.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Edge Detection - Canny Edge</td>\n",
       "      <td>18.054977</td>\n",
       "      <td>41787.608937</td>\n",
       "      <td>64.115666</td>\n",
       "      <td>1477.198366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Edge Detection - Sobel Edge</td>\n",
       "      <td>7.995236</td>\n",
       "      <td>2922.728427</td>\n",
       "      <td>14.944568</td>\n",
       "      <td>71.446407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Edge Detection - Unsharp Mask</td>\n",
       "      <td>105.343637</td>\n",
       "      <td>3226.065615</td>\n",
       "      <td>49.005192</td>\n",
       "      <td>99.029571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Original</td>\n",
       "      <td>105.298602</td>\n",
       "      <td>1475.447150</td>\n",
       "      <td>46.355469</td>\n",
       "      <td>45.731151</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>2.543452</td>\n",
       "      <td>1.8</td>\n",
       "      <td>65536.0</td>\n",
       "      <td>73.4</td>\n",
       "      <td>37.179248</td>\n",
       "      <td>4640.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Technique  Brightness  \\\n",
       "0                   Noise Reduction - Gaussian Blur  105.304456   \n",
       "1                     Noise Reduction - Median Blur  107.189792   \n",
       "2                 Noise Reduction - Non-Local Means  105.678824   \n",
       "3                                          Original  105.298602   \n",
       "4                    Histogram Equalization - CLAHE  124.084998   \n",
       "5   Histogram Equalization - Histogram Equalization  129.065079   \n",
       "6                                          Original  105.298602   \n",
       "7                 Binarization - Adaptive Threshold  194.455399   \n",
       "8                   Binarization - Global Threshold  112.815399   \n",
       "9            Binarization - Inverted Otsu Threshold   67.716476   \n",
       "10                    Binarization - Otsu Threshold  187.283524   \n",
       "11                                         Original  105.298602   \n",
       "12               Morphological Operations - Closing  110.671228   \n",
       "13              Morphological Operations - Dilation  115.863940   \n",
       "14               Morphological Operations - Erosion   83.089850   \n",
       "15               Morphological Operations - Opening   99.286642   \n",
       "16                                         Original  105.298602   \n",
       "17                      Edge Detection - Canny Edge   18.054977   \n",
       "18                      Edge Detection - Sobel Edge    7.995236   \n",
       "19                    Edge Detection - Unsharp Mask  105.343637   \n",
       "20                                         Original  105.298602   \n",
       "\n",
       "        Sharpness    Contrast        Noise  Skew  Line Spacing  \\\n",
       "0       28.095397   44.798519     1.225846   NaN           NaN   \n",
       "1      101.215860   45.844607     5.287063   NaN           NaN   \n",
       "2      714.632667   45.898716    28.856954   NaN           NaN   \n",
       "3     1475.447150   46.355469    45.731151 -90.0      2.543452   \n",
       "4     3310.648974   50.853785    86.451521   NaN           NaN   \n",
       "5     4802.121954   73.824866   131.859308   NaN           NaN   \n",
       "6     1475.447150   46.355469    45.731151 -90.0      2.543452   \n",
       "7   140741.555539  108.385823  2530.041546   NaN           NaN   \n",
       "8    40359.432543  125.698597  1253.831050   NaN           NaN   \n",
       "9    19787.298731  111.403663   690.209641   NaN           NaN   \n",
       "10   19787.298731  111.403663   691.193310   NaN           NaN   \n",
       "11    1475.447150   46.355469    45.731151 -90.0      2.543452   \n",
       "12     144.089226   45.483240     7.462193   NaN           NaN   \n",
       "13     151.731249   44.186398     7.833668   NaN           NaN   \n",
       "14     841.356188   46.588018    32.814400   NaN           NaN   \n",
       "15     743.263812   46.018403    29.903468   NaN           NaN   \n",
       "16    1475.447150   46.355469    45.731151 -90.0      2.543452   \n",
       "17   41787.608937   64.115666  1477.198366   NaN           NaN   \n",
       "18    2922.728427   14.944568    71.446407   NaN           NaN   \n",
       "19    3226.065615   49.005192    99.029571   NaN           NaN   \n",
       "20    1475.447150   46.355469    45.731151 -90.0      2.543452   \n",
       "\n",
       "    Tables Detected  Resolution  Detected Elements    Texture  Patterns  \n",
       "0               NaN         NaN                NaN        NaN       NaN  \n",
       "1               NaN         NaN                NaN        NaN       NaN  \n",
       "2               NaN         NaN                NaN        NaN       NaN  \n",
       "3               1.8     65536.0               73.4  37.179248    4640.2  \n",
       "4               NaN         NaN                NaN        NaN       NaN  \n",
       "5               NaN         NaN                NaN        NaN       NaN  \n",
       "6               1.8     65536.0               73.4  37.179248    4640.2  \n",
       "7               NaN         NaN                NaN        NaN       NaN  \n",
       "8               NaN         NaN                NaN        NaN       NaN  \n",
       "9               NaN         NaN                NaN        NaN       NaN  \n",
       "10              NaN         NaN                NaN        NaN       NaN  \n",
       "11              1.8     65536.0               73.4  37.179248    4640.2  \n",
       "12              NaN         NaN                NaN        NaN       NaN  \n",
       "13              NaN         NaN                NaN        NaN       NaN  \n",
       "14              NaN         NaN                NaN        NaN       NaN  \n",
       "15              NaN         NaN                NaN        NaN       NaN  \n",
       "16              1.8     65536.0               73.4  37.179248    4640.2  \n",
       "17              NaN         NaN                NaN        NaN       NaN  \n",
       "18              NaN         NaN                NaN        NaN       NaN  \n",
       "19              NaN         NaN                NaN        NaN       NaN  \n",
       "20              1.8     65536.0               73.4  37.179248    4640.2  "
      ]
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_comparison_df"
<<<<<<< HEAD
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:46:32.665404Z",
     "start_time": "2024-11-19T14:46:32.651424Z"
    }
   },
   "id": "fe7133144103efbc",
   "execution_count": 165
=======
   ]
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
  },
  {
   "cell_type": "markdown",
   "id": "c5d61986dc386f3b",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad8595b15fd7fa24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:20:11.818653Z",
     "start_time": "2024-11-19T08:20:11.804654Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning Function\n",
    "def hyperparameter_tuning(images, best_techniques_list, param_grids, evaluation_function):\n",
    "    tuned_results = {}\n",
    "\n",
    "    # Choose one image to save for comparison purposes\n",
    "    save_image_id = total_image_ids[0] if len(total_image_ids) > 0 else None\n",
    "\n",
    "    for step_name, technique_name, best_technique_func in best_techniques_list:\n",
    "        print(f\"\\nHyperparameter Tuning for Step: {step_name}\\n{'-' * 40}\")\n",
    "        best_params = None\n",
    "        best_score = -np.inf\n",
    "        param_grid = param_grids.get(technique_name, [])\n",
    "\n",
    "        for params in param_grid:\n",
    "            total_score = 0\n",
    "\n",
    "            # Convert parameter dict to string for filename (e.g., 'param1_val1_param2_val2')\n",
    "            params_str = \"_\".join([f\"{key}_{value}\" for key, value in params.items()])\n",
    "\n",
    "            for img, img_id in zip(images, total_image_ids):\n",
    "                try:\n",
    "                    # Apply the best technique with the given parameters explicitly based on technique name\n",
    "                    if technique_name == \"Gaussian Blur\":\n",
    "                        processed_image = apply_gaussian_blur(img, **params)\n",
    "                    elif technique_name == \"Median Blur\":\n",
    "                        processed_image = apply_median_blur(img, **params)\n",
    "                    elif technique_name == \"Non-Local Means\":\n",
    "                        processed_image = apply_non_local_means(img, **params)\n",
    "                    elif technique_name == \"CLAHE\":\n",
    "                        processed_image = apply_clahe(img, **params)\n",
    "                    elif technique_name == \"Global Threshold\":\n",
    "                        processed_image = apply_global_threshold(img, **params)\n",
    "                    elif technique_name == \"Adaptive Threshold\":\n",
    "                        processed_image = apply_adaptive_threshold(img, **params)\n",
    "                    elif technique_name == \"Otsu Threshold\":\n",
    "                        processed_image = apply_otsu_threshold(img)\n",
    "                    elif technique_name == \"Inverted Otsu Threshold\":\n",
    "                        processed_image = apply_inverted_otsu_threshold(img)\n",
    "                    elif technique_name == \"Dilation\":\n",
    "                        processed_image = apply_dilation(img, **params)\n",
    "                    elif technique_name == \"Erosion\":\n",
    "                        processed_image = apply_erosion(img, **params)\n",
    "                    elif technique_name == \"Morphological Opening\":\n",
    "                        processed_image = apply_opening(img, **params)\n",
    "                    elif technique_name == \"Morphological Closing\":\n",
    "                        processed_image = apply_closing(img, **params)\n",
    "                    elif technique_name == \"Canny Edge\":\n",
    "                        processed_image = apply_canny_edge(img, **params)\n",
    "                    elif technique_name == \"Sobel Edge\":\n",
    "                        processed_image = apply_sobel_edge(img, **params)\n",
    "                    elif technique_name == \"Unsharp Masking\":\n",
    "                        processed_image = apply_unsharp_masking(img, **params)\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unknown technique: {technique_name}\")\n",
    "\n",
    "                except TypeError as e:\n",
    "                    print(f\"Skipping parameters {params} due to TypeError: {e}\")\n",
    "                    continue\n",
    "\n",
    "                # Retrieve original stats for comparison\n",
    "                original_stats = images_stats_df[images_stats_df['Image'] == img_id].iloc[0].to_dict()\n",
    "                evaluation_result = evaluation_function(processed_image, {technique_name: best_technique_func}, original_stats)\n",
    "                step_score = evaluation_result[\"Evaluation Results\"][technique_name][\"Score\"]\n",
    "                total_score += step_score\n",
    "\n",
    "                # Save the processed image if it is the one designated for saving\n",
    "                if img_id == save_image_id:\n",
    "                    # Specify folder for best techniques and their parameters\n",
    "                    output_folder_tuning = f\"./Data/It2/Best Techniques/{step_name}_{technique_name}\"\n",
    "                    os.makedirs(output_folder_tuning, exist_ok=True)\n",
    "\n",
    "                    # Save the processed image\n",
    "                    cv2.imwrite(f\"{output_folder_tuning}/{technique_name}_Params_{params_str}_Image_{img_id}.jpg\", processed_image)\n",
    "\n",
    "            avg_score = total_score / len(images) if len(images) > 0 else -np.inf\n",
    "\n",
    "            if avg_score > best_score:\n",
    "                best_score = avg_score\n",
    "                best_params = params\n",
    "\n",
    "            print(f\"Parameters: {params}, Score: {avg_score}\")\n",
    "\n",
    "        tuned_results[step_name] = {\n",
    "            \"Best Parameters\": best_params,\n",
    "            \"Best Score\": best_score\n",
    "        }\n",
    "        print(f\"Best Parameters for {step_name}: {best_params} with Score: {best_score}\\n\")\n",
    "\n",
    "    return tuned_results\n"
<<<<<<< HEAD
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:46:32.681407Z",
     "start_time": "2024-11-19T14:46:32.667406Z"
    }
   },
   "id": "ad8595b15fd7fa24",
   "execution_count": 166
=======
   ]
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
  },
  {
   "cell_type": "markdown",
   "id": "55d2b04c1e9428ca",
   "metadata": {},
   "source": [
    "#### Explanation of Techniques and Parameters\n",
    "\n",
    "##### 1. Noise Reduction\n",
    "###### Gaussian Blur (`ksize`)\n",
    "- **Parameter**: `ksize` (kernel size)\n",
    "- **Meaning**: Defines the extent of smoothing applied. A small kernel (e.g., `(3, 3)`) produces minimal blurring, preserving details, while larger kernels (e.g., `(9, 9)`) apply more significant blurring, which is useful for reducing noise but may remove finer details.\n",
    "- **Range**:\n",
    "  - `(3, 3)`, `(5, 5)`, `(7, 7)`, `(9, 9)`\n",
    "  - Smaller sizes preserve more details, larger sizes reduce noise more aggressively.\n",
    "\n",
    "###### Non-Local Means (`h`, `templateWindowSize`, `searchWindowSize`)\n",
    "- **Parameters**:\n",
    "  - `h`: Filtering strength (higher values = stronger filtering).\n",
    "  - `templateWindowSize`: Size of the patch used for comparison.\n",
    "  - `searchWindowSize`: Size of the window around the pixel for searching similar patches.\n",
    "- **Range**:\n",
    "  - `h`: `5`, `10`, `15`, `20`\n",
    "  - `templateWindowSize`: `7`, `10`\n",
    "  - `searchWindowSize`: `21`, `31`\n",
    "  - Balances noise reduction quality and processing time.\n",
    "\n",
    "###### Median Blur (`ksize`)\n",
    "- **Parameter**: `ksize` (kernel size)\n",
    "- **Meaning**: Reduces \"salt-and-pepper\" noise by replacing each pixel with the median of neighboring pixels. Larger kernels apply stronger noise reduction, potentially losing details.\n",
    "- **Range**:\n",
    "  - `3`, `5`, `7`, `9`\n",
    "  - Smaller values (`3`, `5`) are useful for mild noise; larger values (`7`, `9`) are effective for more significant noise.\n",
    "\n",
    "##### 2. Histogram Equalization\n",
    "###### CLAHE (`clipLimit`, `tileGridSize`)\n",
    "- **Parameters**:\n",
    "  - `clipLimit`: Controls contrast enhancement limit.\n",
    "  - `tileGridSize`: Size of the grid for local histogram equalization.\n",
    "- **Range**:\n",
    "  - `clipLimit`: `2.0` to `6.0`\n",
    "  - `tileGridSize`: `(4, 4)`, `(6, 6)`, `(8, 8)`\n",
    "  - Lower `clipLimit` values reduce noise amplification, larger `tileGridSize` produces smoother results.\n",
    "\n",
    "##### 3. Binarization\n",
    "###### Global Threshold (`thresholdValue`)\n",
    "- **Parameter**: `thresholdValue`\n",
    "- **Meaning**: Used to convert grayscale images to binary by comparing pixel values to a threshold. Lower values produce more white areas.\n",
    "- **Range**:\n",
    "  - `100`, `127`, `150`, `200`\n",
    "  - Balances the separation between foreground and background.\n",
    "\n",
    "###### Adaptive Threshold (`adaptiveMethod`, `blockSize`, `C`)\n",
    "- **Parameters**:\n",
    "  - `adaptiveMethod`: The method used for calculating the threshold (`cv2.ADAPTIVE_THRESH_MEAN_C` or `cv2.ADAPTIVE_THRESH_GAUSSIAN_C`).\n",
    "  - `blockSize`: Size of the local area considered for thresholding.\n",
    "  - `C`: Constant subtracted from the mean or weighted sum.\n",
    "- **Range**:\n",
    "  - `adaptiveMethod`: `cv2.ADAPTIVE_THRESH_MEAN_C` or `cv2.ADAPTIVE_THRESH_GAUSSIAN_C`\n",
    "  - `blockSize`: `11`, `15`\n",
    "  - `C`: `2`, `3`\n",
    "  - Allows adjustment to local image variations for better segmentation.\n",
    "\n",
    "###### Otsu Threshold\n",
    "- **Meaning**: Automatically determines the optimal threshold value to convert grayscale images to binary.\n",
    "- **Use**: Effective for images with bimodal histograms, making it suitable for foreground and background separation.\n",
    "- **Parameters**: None, Otsu's method calculates the optimal threshold automatically.\n",
    "\n",
    "###### Inverted Otsu Threshold\n",
    "- **Meaning**: Applies Otsu's method for thresholding but inverts the resulting binary image, making foreground black and background white.\n",
    "- **Use**: Useful when the target regions are originally white on a dark background.\n",
    "- **Parameters**: None, as Otsu's method calculates the optimal threshold automatically.\n",
    "\n",
    "##### 4. Morphological Operations\n",
    "###### Operation (`MORPH_OPEN`, `MORPH_CLOSE`, `DILATE`, `ERODE`, `kernel_size`)\n",
    "- **Parameters**:\n",
    "  - `operation`: The morphological transformation to apply.\n",
    "    - `cv2.MORPH_OPEN`: Removes small white noise.\n",
    "    - `cv2.MORPH_CLOSE`: Fills small black gaps in white areas.\n",
    "    - `cv2.MORPH_DILATE`: Expands white areas to connect small features.\n",
    "    - `cv2.MORPH_ERODE`: Shrinks white areas to reduce noise.\n",
    "  - `kernel_size`: Size of the structuring element.\n",
    "- **Range**:\n",
    "  - `kernel_size`: `(3, 3)`, `(5, 5)`, `(7, 7)`, `(9, 9)`\n",
    "  - Larger kernels apply more aggressive changes for connecting, removing, or shrinking features.\n",
    "\n",
    "##### 5. Edge Detection\n",
    "###### Canny Edge Detection (`threshold1`, `threshold2`)\n",
    "- **Parameters**:\n",
    "  - `threshold1`: Lower threshold for weak edges.\n",
    "  - `threshold2`: Upper threshold for strong edges.\n",
    "- **Range**:\n",
    "  - `threshold1` and `threshold2`: `(50, 150)`, `(100, 200)`, `(150, 250)`, `(200, 300)`\n",
    "  - Lower values detect more edges, useful for detailed images; higher values highlight stronger, more defined edges.\n",
    "\n",
    "###### Sobel Edge Detection (`ksize`, `scale`, `delta`, `borderType`)\n",
    "- **Parameters**:\n",
    "  - `ksize`: Kernel size for the Sobel operator.\n",
    "  - `scale`: Scaling factor for gradients.\n",
    "  - `delta`: Value added to the result.\n",
    "  - `borderType`: Border handling for edges.\n",
    "- **Range**:\n",
    "  - `ksize`: `3`, `5`, `7`\n",
    "  - `scale`: `1`, `2`\n",
    "  - `delta`: `0` (default)\n",
    "  - `borderType`: `cv2.BORDER_DEFAULT`\n",
    "  - Adjusts the level of detail and sharpness captured by the filter.\n",
    "\n",
    "###### Unsharp Masking (`amount`, `kernel_size`)\n",
    "- **Parameters**:\n",
    "  - `amount`: Strength of sharpening effect applied to the image.\n",
    "  - `kernel_size`: Size of the kernel used for blurring in the unsharp mask process.\n",
    "- **Range**:\n",
    "  - `amount`: `1.0` to `2.5` (Higher values produce stronger sharpening)\n",
    "  - `kernel_size`: `(3, 3)`, `(5, 5)`, `(7, 7)`, `(9, 9)`\n",
    "  - Sharpening enhances edges and contrasts to make features more prominent, but excessively high values can introduce artifacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fa67a991c4e1ef8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:20:11.834654Z",
     "start_time": "2024-11-19T08:20:11.819654Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define expanded parameter grids for hyperparameter tuning for each technique\n",
    "technique_param_grids = {\n",
    "    # Noise Reduction Techniques Parameters\n",
    "    # Gaussian Blur - kernel size affects the degree of blurring\n",
    "    \"Gaussian Blur\": [\n",
    "        {\"ksize\": (3, 3)},  # Small blur, preserves more details while reducing minor noise\n",
    "        {\"ksize\": (5, 5)},  # Moderate blur, balances noise reduction and detail preservation\n",
    "        {\"ksize\": (7, 7)},  # Stronger blur, reduces more noise but may lose more details\n",
    "        {\"ksize\": (9, 9)}   # High blur, significant reduction of noise, more detail loss\n",
    "    ],\n",
    "\n",
    "    # Median Blur - kernel size affects the reduction of salt-and-pepper noise\n",
    "    \"Median Blur\": [\n",
    "        {\"ksize\": 3},  # Small kernel, effective for minor salt-and-pepper noise\n",
    "        {\"ksize\": 5},  # Moderate kernel, more aggressive noise reduction\n",
    "        {\"ksize\": 7},  # Large kernel, used for significant salt-and-pepper noise reduction\n",
    "        {\"ksize\": 9}   # Largest kernel, aggressive noise reduction but may lose finer details\n",
    "    ],\n",
    "\n",
    "    # Non-Local Means - affects noise reduction strength and quality\n",
    "    \"Non-Local Means\": [\n",
    "        {\"h\": 5, \"templateWindowSize\": 7, \"searchWindowSize\": 21},   # Low filter strength (h), smaller template\n",
    "        {\"h\": 10, \"templateWindowSize\": 7, \"searchWindowSize\": 21},  # Moderate filter strength (h), balance of denoising and details\n",
    "        {\"h\": 15, \"templateWindowSize\": 7, \"searchWindowSize\": 21},  # Strong filter strength, more noise reduction but risk of over-smoothing\n",
    "        {\"h\": 20, \"templateWindowSize\": 10, \"searchWindowSize\": 31}  # Higher strength and larger search windows for stronger denoising\n",
    "    ],\n",
    "\n",
    "    # Histogram Equalization Techniques Parameters\n",
    "    # CLAHE - clip limit controls contrast, tile grid size controls local regions\n",
    "    \"CLAHE\": [\n",
    "        {\"clipLimit\": 2.0, \"tileGridSize\": (8, 8)},  # Low clip limit, preserves global contrast, effective for mild contrast enhancement\n",
    "        {\"clipLimit\": 3.0, \"tileGridSize\": (8, 8)},  # Moderate clip limit, better enhancement for darker/lighter regions\n",
    "        {\"clipLimit\": 4.0, \"tileGridSize\": (4, 4)},  # Higher clip limit, can lead to artifacts but increases local contrast\n",
    "        {\"clipLimit\": 5.0, \"tileGridSize\": (6, 6)}   # High clip limit, strong local contrast enhancement\n",
    "    ],\n",
    "\n",
    "    # Binarization Techniques Parameters\n",
    "    # Global Threshold - value for the threshold, used to separate foreground from background\n",
    "    \"Global Threshold\": [\n",
    "        {\"thresholdValue\": 100},  # Low threshold, makes more areas white, may overexpose\n",
    "        {\"thresholdValue\": 127},  # Middle threshold, balance between foreground and background\n",
    "        {\"thresholdValue\": 150},  # High threshold, less white, more black areas\n",
    "        {\"thresholdValue\": 200}   # Higher threshold, darkest parts retained as foreground\n",
    "    ],\n",
    "\n",
    "    # Adaptive Threshold - block size and constant C, used for adaptive thresholding\n",
    "    \"Adaptive Threshold\": [\n",
    "        {\"adaptiveMethod\": cv2.ADAPTIVE_THRESH_MEAN_C, \"blockSize\": 11, \"C\": 2},  # Small block size, captures smaller variations\n",
    "        {\"adaptiveMethod\": cv2.ADAPTIVE_THRESH_MEAN_C, \"blockSize\": 15, \"C\": 3},  # Larger block size, averages larger areas\n",
    "        {\"adaptiveMethod\": cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \"blockSize\": 11, \"C\": 2},  # Gaussian weighting, better for uneven lighting\n",
    "        {\"adaptiveMethod\": cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \"blockSize\": 15, \"C\": 3}   # Larger area, smoother output\n",
    "    ],\n",
    "\n",
    "    \"Otsu Threshold\": [\n",
    "        {}  # No parameters needed, automatic threshold selection\n",
    "    ],\n",
    "    \n",
    "    \"Inverted Otsu Threshold\": [{}],\n",
    "\n",
    "    # Morphological Operations Techniques Parameters\n",
    "    # Dilation - kernel size affects how much an object is expanded, helps to highlight and connect features in the image\n",
    "    \"Dilation\": [\n",
    "        {\"kernel_size\": (3, 3)},  # Small kernel, slight expansion of features\n",
    "        {\"kernel_size\": (5, 5)},  # Medium kernel, moderate expansion, often used to fill small holes\n",
    "        {\"kernel_size\": (7, 7)},  # Larger kernel, more significant expansion, fills larger gaps\n",
    "        {\"kernel_size\": (9, 9)}   # Largest kernel, aggressive expansion, can connect disjoint parts\n",
    "    ],\n",
    "\n",
    "    # Erosion - kernel size affects how much an object is eroded, used to reduce noise by shrinking foreground areas\n",
    "    \"Erosion\": [\n",
    "        {\"kernel_size\": (3, 3)},  # Small kernel, minimal shrinking of features\n",
    "        {\"kernel_size\": (5, 5)},  # Medium kernel, reduces small noise while keeping the main features intact\n",
    "        {\"kernel_size\": (7, 7)},  # Larger kernel, removes more fine details, useful for stronger noise reduction\n",
    "        {\"kernel_size\": (9, 9)}   # Largest kernel, aggressive erosion, may result in significant information loss\n",
    "    ],\n",
    "\n",
    "    # Morphological Opening - kernel size affects noise removal, used for removing small white noise from black backgrounds\n",
    "    \"Morphological Opening\": [\n",
    "        {\"kernel_size\": (3, 3)},  # Small kernel, removes small white noise but keeps the main structure\n",
    "        {\"kernel_size\": (5, 5)},  # Medium kernel, better noise removal, may affect finer details\n",
    "        {\"kernel_size\": (7, 7)}   # Larger kernel, stronger noise reduction, potentially removes small features\n",
    "    ],\n",
    "\n",
    "    # Morphological Closing - kernel size affects how gaps in foreground objects are filled, used to close small black holes within objects\n",
    "    \"Morphological Closing\": [\n",
    "        {\"kernel_size\": (3, 3)},  # Small kernel, fills tiny holes, maintains object shape\n",
    "        {\"kernel_size\": (5, 5)},  # Medium kernel, closes medium-sized gaps, useful for refining object borders\n",
    "        {\"kernel_size\": (7, 7)}   # Larger kernel, aggressively closes gaps, useful for solidifying larger structures\n",
    "    ],\n",
    "\n",
    "    # Edge Detection Techniques Parameters\n",
    "    # Canny Edge Detection - lower and upper thresholds for edge linking\n",
    "    \"Canny Edge\": [\n",
    "        {\"threshold1\": 50, \"threshold2\": 150},  # Low thresholds, more edges detected\n",
    "        {\"threshold1\": 100, \"threshold2\": 200},  # Moderate thresholds, balanced edge detection\n",
    "        {\"threshold1\": 150, \"threshold2\": 250},  # High thresholds, only strong edges detected\n",
    "        {\"threshold1\": 200, \"threshold2\": 300}   # Very high thresholds, detects fewer edges, focused on major features\n",
    "    ],\n",
    "\n",
    "    # Sobel Edge - kernel size, scale, delta, border type for Sobel edge detection\n",
    "    \"Sobel Edge\": [\n",
    "        {\"ksize\": 3, \"scale\": 1, \"delta\": 0, \"borderType\": cv2.BORDER_DEFAULT},  # Small kernel, detects finer details\n",
    "        {\"ksize\": 5, \"scale\": 1, \"delta\": 0, \"borderType\": cv2.BORDER_DEFAULT},  # Medium kernel, balances detail and noise suppression\n",
    "        {\"ksize\": 7, \"scale\": 1, \"delta\": 0, \"borderType\": cv2.BORDER_DEFAULT},  # Larger kernel, captures broader gradients\n",
    "        {\"ksize\": 3, \"scale\": 2, \"delta\": 0, \"borderType\": cv2.BORDER_DEFAULT}   # Increased scale, emphasizes detected gradients more strongly\n",
    "    ],\n",
    "    \"Unsharp Masking\": [\n",
    "        {\"amount\": 1.0, \"kernel_size\": (3, 3)},\n",
    "        {\"amount\": 1.5, \"kernel_size\": (5, 5)},\n",
    "        {\"amount\": 2.0, \"kernel_size\": (7, 7)},\n",
    "        {\"amount\": 2.5, \"kernel_size\": (9, 9)}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c9a00a06b7381b7",
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2024-11-19T14:46:32.713407Z",
     "start_time": "2024-11-19T14:46:32.683409Z"
    }
   },
   "id": "5fa67a991c4e1ef8",
   "execution_count": 167
  },
  {
   "cell_type": "code",
=======
     "end_time": "2024-11-19T08:20:18.978433Z",
     "start_time": "2024-11-19T08:20:11.835654Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyperparameter Tuning for Step: Noise Reduction\n",
      "----------------------------------------\n",
      "Parameters: {'ksize': 3}, Score: -0.030960453544665437\n",
      "Parameters: {'ksize': 5}, Score: -0.03304974269363378\n",
      "Parameters: {'ksize': 7}, Score: -0.03614893562233756\n",
      "Parameters: {'ksize': 9}, Score: -0.03826699030759918\n",
      "Best Parameters for Noise Reduction: {'ksize': 3} with Score: -0.030960453544665437\n",
      "\n",
      "\n",
      "Hyperparameter Tuning for Step: Histogram Equalization\n",
      "----------------------------------------\n",
      "Best Parameters for Histogram Equalization: None with Score: -inf\n",
      "\n",
      "\n",
      "Hyperparameter Tuning for Step: Binarization\n",
      "----------------------------------------\n",
      "Parameters: {'adaptiveMethod': 0, 'blockSize': 11, 'C': 2}, Score: 74.58572938407688\n",
      "Parameters: {'adaptiveMethod': 0, 'blockSize': 15, 'C': 3}, Score: 38.90066557469885\n",
      "Parameters: {'adaptiveMethod': 1, 'blockSize': 11, 'C': 2}, Score: 78.83981478198945\n",
      "Parameters: {'adaptiveMethod': 1, 'blockSize': 15, 'C': 3}, Score: 39.56523222817501\n",
      "Best Parameters for Binarization: {'adaptiveMethod': 1, 'blockSize': 11, 'C': 2} with Score: 78.83981478198945\n",
      "\n",
      "\n",
      "Hyperparameter Tuning for Step: Morphological Operations\n",
      "----------------------------------------\n",
      "Parameters: {'kernel_size': (3, 3)}, Score: -0.014393186044428454\n",
      "Parameters: {'kernel_size': (5, 5)}, Score: -0.013179805102278378\n",
      "Parameters: {'kernel_size': (7, 7)}, Score: -0.011333033678723951\n",
      "Parameters: {'kernel_size': (9, 9)}, Score: -0.009614895802121283\n",
      "Best Parameters for Morphological Operations: {'kernel_size': (9, 9)} with Score: -0.009614895802121283\n",
      "\n",
      "\n",
      "Hyperparameter Tuning for Step: Edge Detection\n",
      "----------------------------------------\n",
      "Parameters: {'threshold1': 50, 'threshold2': 150}, Score: 12.234653635492874\n",
      "Parameters: {'threshold1': 100, 'threshold2': 200}, Score: 8.312877711844704\n",
      "Parameters: {'threshold1': 150, 'threshold2': 250}, Score: 5.264774016871201\n",
      "Parameters: {'threshold1': 200, 'threshold2': 300}, Score: 3.237083899404304\n",
      "Best Parameters for Edge Detection: {'threshold1': 50, 'threshold2': 150} with Score: 12.234653635492874\n",
      "\n",
      "\n",
      "Tuned Results:\n",
      "Noise Reduction: Best Parameters: {'ksize': 3}, Best Score: -0.030960453544665437\n",
      "Histogram Equalization: Best Parameters: None, Best Score: -inf\n",
      "Binarization: Best Parameters: {'adaptiveMethod': 1, 'blockSize': 11, 'C': 2}, Best Score: 78.83981478198945\n",
      "Morphological Operations: Best Parameters: {'kernel_size': (9, 9)}, Best Score: -0.009614895802121283\n",
      "Edge Detection: Best Parameters: {'threshold1': 50, 'threshold2': 150}, Best Score: 12.234653635492874\n"
     ]
    }
   ],
   "source": [
    "# Run hyperparameter tuning\n",
    "tuned_results = hyperparameter_tuning(total_images, best_techniques_list, technique_param_grids, advanced_evaluation)\n",
    "print(\"\\nTuned Results:\")\n",
    "\n",
    "for step_name, result in tuned_results.items():\n",
    "    print(f\"{step_name}: Best Parameters: {result['Best Parameters']}, Best Score: {result['Best Score']}\")"
<<<<<<< HEAD
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:47:58.643579Z",
     "start_time": "2024-11-19T14:46:32.714408Z"
    }
   },
   "id": "8c9a00a06b7381b7",
   "execution_count": 168
=======
   ]
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
  },
  {
   "cell_type": "markdown",
   "id": "bb737e3b48923f3b",
   "metadata": {},
   "source": [
    "#### Interpretations of Results\n",
    "\n",
    "Let's break down and interpret the hyperparameter tuning results for each step. Here's what each section tells us:\n",
    "\n",
    "##### **1. Noise Reduction: Median Blur**\n",
    "- **Best Parameters**: `{'ksize': 3}`\n",
    "- **Best Score**: `-0.03`\n",
    "\n",
    "**Interpretation**:\n",
    "- **Median Blur** was selected as the best noise reduction technique.\n",
    "- The slightly negative score (`-0.03`) indicates a small deviation from the original characteristics, with `ksize=3` performing the best among the tested values. This result shows that a smaller kernel size effectively reduces noise while avoiding excessive smoothing, which helps retain image clarity. Since noise negatively impacts image quality, preserving details while reducing noise was key to achieving a good balance.\n",
    "\n",
    "##### **2. Histogram Equalization: Histogram Equalization**\n",
    "- **Best Parameters**: `None`\n",
    "- **Best Score**: `-inf`\n",
    "\n",
    "**Interpretation**:\n",
    "- The hyperparameter tuning for **Histogram Equalization** did not find any beneficial parameters, resulting in a score of `-inf`. This suggests that histogram equalization might not be effective for enhancing this specific dataset. Given that histogram equalization aims to enhance contrast, the lack of improvement implies that the initial contrast levels may already have been optimal, or that equalization introduced inconsistencies that were detrimental to the image quality.\n",
    "\n",
    "##### **3. Binarization: Adaptive Threshold**\n",
    "- **Best Parameters**: `{'adaptiveMethod': 1, 'blockSize': 11, 'C': 2}`\n",
    "- **Best Score**: `78.84`\n",
    "\n",
    "**Interpretation**:\n",
    "- The **Adaptive Threshold** method, using the **Gaussian adaptive method** (`adaptiveMethod=1`), a **block size** of `11`, and a **constant C** of `2`, achieved a high score of `78.84`.\n",
    "- This positive score indicates effective enhancement of key metrics such as contrast and sharpness, as well as noise reduction. The use of a **Gaussian adaptive method** along with a smaller block size allowed for better handling of local variations in illumination, which improved segmentation and detail clarity. The evaluation rewarded the technique because contrast was notably improved, which is crucial for extracting meaningful features in the images.\n",
    "\n",
    "##### **4. Morphological Operations: Dilation**\n",
    "- **Best Parameters**: `{'kernel_size': (9, 9)}`\n",
    "- **Best Score**: `-0.01`\n",
    "\n",
    "**Interpretation**:\n",
    "- **Dilation** was selected as the best morphological operation for this dataset.\n",
    "- A **kernel size of `(9, 9)`** provided the least negative score (`-0.01`), indicating that the larger kernel size was successful in connecting fragmented elements, which improved the structure of features in the image. The score's slight negativity implies a trade-off, where some minor details were lost, but the benefit of connecting important features outweighed the drawbacks, especially in terms of preparing the images for content recognition.\n",
    "\n",
    "##### **5. Edge Detection: Canny Edge**\n",
    "- **Best Parameters**: `{'threshold1': 50, 'threshold2': 150}`\n",
    "- **Best Score**: `12.23`\n",
    "\n",
    "**Interpretation**:\n",
    "- The **Canny Edge Detection** method, with **thresholds of `50` and `150`**, achieved a score of `12.23`.\n",
    "- The positive score indicates that these threshold values effectively highlighted edges, which was beneficial for extracting structures such as table lines and text outlines. The evaluation rewarded the improvement in contrast and sharpness, which contributed to making the details clearer and reducing the impact of noise. Lower thresholds allowed the detection of more edges, which in turn enhanced the structure and features of the image.\n",
    "\n",
    "##### **Summary & Key Insights**:\n",
    "\n",
    "1. **Negative Scores**:\n",
    "   - Negative scores (e.g., **Noise Reduction** and **Morphological Operations**) indicate that the processed images deviated slightly from the original characteristics in ways that were detrimental based on the evaluation metrics.\n",
    "   - The least negative scores represent the best parameters that resulted in minimal detrimental changes while preserving key features.\n",
    "\n",
    "2. **Positive Scores**:\n",
    "   - Positive scores (e.g., **Binarization** and **Edge Detection**) indicate significant improvements in metrics such as **contrast**, **sharpness**, and **detection of elements**.\n",
    "   - Techniques with higher positive scores effectively enhanced image quality by improving features that are crucial for content recognition and extraction.\n",
    "\n",
    "3. **Histogram Equalization Issue**:\n",
    "   - The score of `-inf` for **Histogram Equalization** indicates that this technique was not effective for improving the evaluated characteristics. This could imply that the dataset's initial contrast was already optimal, or that the equalization process introduced artifacts that degraded the overall quality.\n",
    "\n",
    "4. **Best Techniques Overview**:\n",
    "   - For each step, the parameter combination with the highest score (least negative or most positive) was selected.\n",
    "   - It is important to note that the magnitude of scores can vary greatly, depending on the evaluation metrics and their relative weights. In this evaluation, **contrast** and **sharpness** were given higher importance, leading to higher scores for techniques that excelled in these areas.\n",
    "\n",
    "##### Recommendations:\n",
    "- **Median Blur (Noise Reduction)**: A smaller kernel size (`ksize=3`) provided the least negative impact, suggesting that moderate noise reduction without excessive smoothing was most effective.\n",
    "- **Adaptive Threshold (Binarization)**: Using a **Gaussian adaptive method** with a **smaller block size** resulted in the highest improvement in contrast and sharpness, which are crucial for effective segmentation.\n",
    "- **Dilation (Morphological Operations)**: A larger kernel size (`9x9`) helped enhance the structure of the features, which was beneficial for preparing the images for subsequent recognition steps.\n",
    "- **Canny Edge Detection**: Lower thresholds (`50` and `150`) proved effective for enhancing edge details, resulting in a high score and indicating that comprehensive edge detection was valuable for downstream tasks.\n",
    "\n",
<<<<<<< HEAD
    "Overall, the results align with expectations, where **moderate parameter choices** (e.g., smaller kernel sizes for noise reduction, larger dilation kernels, and lower thresholds for edge detection) effectively preserved and enhanced important image features. The evaluation function's emphasis on **contrast enhancement** and **sharpness** was reflected in the selection of techniques that performed best in these metrics, which is crucial for improving the quality of the images before further analysis.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb737e3b48923f3b"
=======
    "Overall, the results are consistent with expectations—lower parameters (e.g., less aggressive filtering or morphological operations) often preserve original characteristics better, while edge detection benefits from more comprehensive edge capturing with lower thresholds.\n"
   ]
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "915f0ec865424bf5",
   "metadata": {
<<<<<<< HEAD
    "collapsed": false
   },
   "id": "e76eac6730f28598"
=======
    "ExecuteTime": {
     "end_time": "2024-11-19T08:20:18.994432Z",
     "start_time": "2024-11-19T08:20:18.980432Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
>>>>>>> 0f9b744bc80000f8cbdd73fde540c0c745865353
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
