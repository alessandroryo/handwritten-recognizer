{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-07T14:49:10.529123Z",
     "start_time": "2024-10-07T14:49:10.214440Z"
    }
   },
   "source": [
    "import cv2\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Global variables",
   "id": "e1d5aa9785036498"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T15:19:14.199729Z",
     "start_time": "2024-10-07T15:19:14.193588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# folder path of the original images\n",
    "folder_path = '/Users/naominorris/cps/original-photos'\n",
    "\n",
    "# folders where the proccessed images are saved \n",
    "# noise reduction folders\n",
    "output_noise_gaussian = '/Users/naominorris/cps/modified-photos/noise-reduction/gaussian'\n",
    "output_noise_median = '/Users/naominorris/cps/modified-photos/noise-reduction/median'\n",
    "\n",
    "# histogram equalization folders\n",
    "output_hist_clahe = '/Users/naominorris/cps/modified-photos/histogram-equalization/clahe'\n",
    "output_hist_standard = '/Users/naominorris/cps/modified-photos/histogram-equalization/standard'\n",
    "\n",
    "# binarization folders\n",
    "output_bi_global = '/Users/naominorris/cps/modified-photos/binarization/global'\n",
    "output_bi_otsu = '/Users/naominorris/cps/modified-photos/binarization/otsu'\n",
    "output_bi_adaptive = '/Users/naominorris/cps/modified-photos/binarization/adaptive'\n",
    "output_bi_otsu_inv = '/Users/naominorris/cps/modified-photos/binarization/inv-otsu'\n",
    "\n",
    "# morphological operations folders\n",
    "output_morphological_opening = '/Users/naominorris/cps/modified-photos/morphological/opening'\n",
    "output_morphological_closing = '/Users/naominorris/cps/modified-photos/morphological/closing'\n",
    "\n",
    "# Edge detection folders\n",
    "output_edge_unsharp = '/Users/naominorris/cps/modified-photos/edge-detection/unsharp-masking'\n",
    "output_edge_sobel = '/Users/naominorris/cps/modified-photos/edge-detection/sobel'\n",
    "output_edge_laplacian = '/Users/naominorris/cps/modified-photos/edge-detection/laplacian'  "
   ],
   "id": "df6fe04b191886f6",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "load images",
   "id": "5e1779decfce5332"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T15:18:53.831269Z",
     "start_time": "2024-10-07T15:18:53.825295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_images_from_folder(folder_path, extensions=('.png', '.jpg', '.jpeg', '.JPG')):\n",
    "    \n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        raise FileNotFoundError(f\"The specified folder does not exist: {folder_path}\")\n",
    "\n",
    "    # List comprehension to gather all image paths with the specified extensions\n",
    "    image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(extensions)]\n",
    "\n",
    "    return image_paths"
   ],
   "id": "be23110657e8f755",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Noise Reduction",
   "id": "bc493f1867f2faee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T15:04:12.703449Z",
     "start_time": "2024-10-07T15:04:12.697706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_gaussian_blur(image_paths, output_folder, kernel_size=(5, 5), sigma=0):\n",
    "    \"\"\"\n",
    "    Applies Gaussian blur to the input images and saves the results.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Error loading image {image_path}\")\n",
    "            continue\n",
    "\n",
    "        blurred_img = cv2.GaussianBlur(img, kernel_size, sigma)\n",
    "        output_path = os.path.join(output_folder, f\"gaussian_{os.path.basename(image_path)}\")\n",
    "        cv2.imwrite(output_path, blurred_img)"
   ],
   "id": "5775210733ea4022",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Histogram Equlalization",
   "id": "de2b9b8a4f85ca53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T15:04:15.530311Z",
     "start_time": "2024-10-07T15:04:15.523078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_clahe(image_paths, output_folder, clip_limit=2.0, grid_size=(8, 8)):\n",
    "    \"\"\"\n",
    "    Applies CLAHE (Contrast Limited Adaptive Histogram Equalization) to the input images.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=grid_size)\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Error loading image {image_path}\")\n",
    "            continue\n",
    "\n",
    "        cl1 = clahe.apply(img)\n",
    "        output_path = os.path.join(output_folder, f'clahe_{os.path.basename(image_path)}')\n",
    "        cv2.imwrite(output_path, cl1)"
   ],
   "id": "68b564fcfe556618",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Biniarzation",
   "id": "d70b59aa2842821d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T15:04:18.478062Z",
     "start_time": "2024-10-07T15:04:18.470942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_otsu_thresholding_inv(image_paths, output_folder):\n",
    "    \"\"\"\n",
    "    Applies Otsu's thresholding with binary inversion to the input images.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Error loading image {image_path}\")\n",
    "            continue\n",
    "\n",
    "        _, binary_inv = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        output_path = os.path.join(output_folder, f\"otsu_inv_{os.path.basename(image_path)}\")\n",
    "        cv2.imwrite(output_path, binary_inv)\n"
   ],
   "id": "1b74782ca12c01f0",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T15:18:30.506478Z",
     "start_time": "2024-10-07T15:18:30.500483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_otsu_thresholding(image_paths, output_folder):\n",
    "    \"\"\"\n",
    "    Applies Otsu's thresholding to the input images.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        # Read the image in grayscale\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Error loading image {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Apply Otsu's thresholding\n",
    "        _, th2 = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        # Save the thresholded image\n",
    "        output_path = os.path.join(output_folder, f\"otsu_{os.path.basename(image_path)}\")\n",
    "        cv2.imwrite(output_path, th2)\n"
   ],
   "id": "49d41fa0e60493fa",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Morophological Operations",
   "id": "6ac5316341f796c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T15:04:21.198971Z",
     "start_time": "2024-10-07T15:04:21.191662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_morphological_closing(image_paths, output_folder, kernel_size=(5, 5)):\n",
    "    \"\"\"\n",
    "    Applies morphological closing to the input images.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernel_size)\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Error loading image {image_path}\")\n",
    "            continue\n",
    "\n",
    "        closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "        output_path = os.path.join(output_folder, f\"closing_{os.path.basename(image_path)}\")\n",
    "        cv2.imwrite(output_path, closing)\n"
   ],
   "id": "8339df9788d48ad3",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T15:18:24.053608Z",
     "start_time": "2024-10-07T15:18:24.046922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_morphological_opening(image_paths, output_folder, kernel_size=(5, 5)):\n",
    "    \"\"\"\n",
    "    Applies morphological opening to the input images.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernel_size)\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Error loading image {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Apply morphological opening\n",
    "        opened_img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # Save the processed image\n",
    "        output_path = os.path.join(output_folder, f\"opened_{os.path.basename(image_path)}\")\n",
    "        cv2.imwrite(output_path, opened_img)\n",
    " \n"
   ],
   "id": "48fadfaafeb97a3e",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Edge Decetion",
   "id": "c86bbb1dab6b013"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T15:04:24.142502Z",
     "start_time": "2024-10-07T15:04:24.135233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_sobel_edge_detection(image_paths, output_folder):\n",
    "    \"\"\"\n",
    "    Applies Sobel edge detection to the input images.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Error loading image {image_path}\")\n",
    "            continue\n",
    "\n",
    "        sobel_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        sobel_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        sobel_combined = cv2.magnitude(sobel_x, sobel_y)\n",
    "        sobel_combined = cv2.convertScaleAbs(sobel_combined)\n",
    "\n",
    "        output_path = os.path.join(output_folder, f\"sobel_{os.path.basename(image_path)}\")\n",
    "        cv2.imwrite(output_path, sobel_combined)"
   ],
   "id": "4a66a6420dd0da6f",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T15:30:22.219680Z",
     "start_time": "2024-10-07T15:30:22.212369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_unsharp_masking(image_paths, output_folder, sigma=1.0, strength=1.5):\n",
    "    \"\"\"\n",
    "    Applies unsharp masking to the input images.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Error loading image {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Apply Gaussian blur to create the mask\n",
    "        blurred = cv2.GaussianBlur(img, (0, 0), sigma)\n",
    "\n",
    "        # Create the unsharp mask\n",
    "        mask = cv2.subtract(img, blurred)\n",
    "\n",
    "        # Enhance the image using the unsharp mask\n",
    "        sharpened = cv2.addWeighted(img, 1 + strength, mask, strength, 0)\n",
    "\n",
    "        # Save the sharpened image\n",
    "        output_path = os.path.join(output_folder, f\"unsharp_{os.path.basename(image_path)}\")\n",
    "        cv2.imwrite(output_path, sharpened)\n"
   ],
   "id": "bccf8d4e90a737e4",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Image flows",
   "id": "9babfe77bf8585ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Main Flow ending with Sobel",
   "id": "647f43130c12116e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T15:04:27.819385Z",
     "start_time": "2024-10-07T15:04:27.810470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_image_flow_sobel(folder_path, output_noise_gaussian, output_hist_clahe, output_bi_otsu_inv, output_morphological_closing, output_edge_sobel):\n",
    "    # Step 1: Load images\n",
    "    image_paths = load_images_from_folder(folder_path)\n",
    "\n",
    "    # Step 2: Apply Gaussian Blur\n",
    "    apply_gaussian_blur(image_paths, output_noise_gaussian)\n",
    "\n",
    "    # Step 3: Apply CLAHE\n",
    "    blurred_image_paths = load_images_from_folder(output_noise_gaussian)\n",
    "    apply_clahe(blurred_image_paths, output_hist_clahe)\n",
    "\n",
    "    # Step 4: Apply Otsu Thresholding Inverted\n",
    "    clahe_image_paths = load_images_from_folder(output_hist_clahe)\n",
    "    apply_otsu_thresholding_inv(clahe_image_paths, output_bi_otsu_inv)\n",
    "\n",
    "    # Step 5: Apply Morphological Closing\n",
    "    otsu_image_paths = load_images_from_folder(output_bi_otsu_inv)\n",
    "    apply_morphological_closing(otsu_image_paths, output_morphological_closing)\n",
    "\n",
    "    # Step 6: Apply Sobel Edge Detection\n",
    "    morph_image_paths = load_images_from_folder(output_morphological_closing)\n",
    "    apply_sobel_edge_detection(morph_image_paths, output_edge_sobel)"
   ],
   "id": "ea0efc5ecee638e9",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Main flow ending with unsharp",
   "id": "d4c0328030c9f7ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def process_image_flow_sharp(folder_path, output_noise_gaussian, output_hist_clahe, output_bi_otsu_inv, output_morphological_closing, output_edge_unsharp):\n",
    "    # Step 1: Load images\n",
    "    image_paths = load_images_from_folder(folder_path)\n",
    "\n",
    "    # Step 2: Apply Gaussian Blur\n",
    "    apply_gaussian_blur(image_paths, output_noise_gaussian)\n",
    "\n",
    "    # Step 3: Apply CLAHE\n",
    "    blurred_image_paths = load_images_from_folder(output_noise_gaussian)\n",
    "    apply_clahe(blurred_image_paths, output_hist_clahe)\n",
    "\n",
    "    # Step 4: Apply Otsu Thresholding Inverted\n",
    "    clahe_image_paths = load_images_from_folder(output_hist_clahe)\n",
    "    apply_otsu_thresholding_inv(clahe_image_paths, output_bi_otsu_inv)\n",
    "\n",
    "    # Step 5: Apply Morphological Closing\n",
    "    otsu_image_paths = load_images_from_folder(output_bi_otsu_inv)\n",
    "    apply_morphological_closing(otsu_image_paths, output_morphological_closing)\n",
    "\n",
    "    # Step 6: Apply Sobel Edge Detection\n",
    "    morph_image_paths = load_images_from_folder(output_morphological_closing)\n",
    "    apply_unsharp_masking(morph_image_paths, output_edge_unsharp)"
   ],
   "id": "bbef6aa5efb9c66d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Main flow but with black on white images ending with sharp",
   "id": "10bb0067496516fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def process_image_flow_normal_thresh(folder_path, output_noise_gaussian, output_hist_clahe, output_bi_otsu, output_morphological_opening, output_edge_unsharp):\n",
    "    # Step 1: Load images\n",
    "    image_paths = load_images_from_folder(folder_path)\n",
    "\n",
    "    # Step 2: Apply Gaussian Blur\n",
    "    apply_gaussian_blur(image_paths, output_noise_gaussian)\n",
    "\n",
    "    # Step 3: Apply CLAHE\n",
    "    blurred_image_paths = load_images_from_folder(output_noise_gaussian)\n",
    "    apply_clahe(blurred_image_paths, output_hist_clahe)\n",
    "\n",
    "    # Step 4: Apply Otsu Thresholding \n",
    "    clahe_image_paths = load_images_from_folder(output_hist_clahe)\n",
    "    apply_otsu_thresholding(clahe_image_paths, output_bi_otsu)\n",
    "\n",
    "    # Step 5: Apply Morphological Opening\n",
    "    otsu_image_paths = load_images_from_folder(output_bi_otsu)\n",
    "    apply_morphological_opening(otsu_image_paths, output_morphological_opening)\n",
    "\n",
    "    # Step 6: Apply Sobel Edge Detection\n",
    "    morph_image_paths = load_images_from_folder(output_morphological_opening)\n",
    "    apply_unsharp_masking(morph_image_paths, output_edge_unsharp)"
   ],
   "id": "8d474500dea21d99"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Flow with just Morphological changes",
   "id": "b954cdf79fd8bcdc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def process_image_flow_morph(folder_path, output_noise_gaussian, output_hist_clahe, output_bi_otsu_inv, output_morphological_closing):\n",
    "    # Step 1: Load images\n",
    "    image_paths = load_images_from_folder(folder_path)\n",
    "\n",
    "    # Step 2: Apply Gaussian Blur\n",
    "    apply_gaussian_blur(image_paths, output_noise_gaussian)\n",
    "\n",
    "    # Step 3: Apply CLAHE\n",
    "    blurred_image_paths = load_images_from_folder(output_noise_gaussian)\n",
    "    apply_clahe(blurred_image_paths, output_hist_clahe)\n",
    "\n",
    "    # Step 4: Apply Otsu Thresholding Inverted\n",
    "    clahe_image_paths = load_images_from_folder(output_hist_clahe)\n",
    "    apply_otsu_thresholding_inv(clahe_image_paths, output_bi_otsu_inv)\n",
    "\n",
    "    # Step 5: Apply Morphological Closing\n",
    "    otsu_image_paths = load_images_from_folder(output_bi_otsu_inv)\n",
    "    apply_morphological_closing(otsu_image_paths, output_morphological_closing)\n"
   ],
   "id": "c1b09cecacfb73e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Flow with just binization",
   "id": "dbbc20872232eb8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def process_image_flow_bi(folder_path, output_noise_gaussian, output_hist_clahe, output_bi_otsu_inv):\n",
    "    # Step 1: Load images\n",
    "    image_paths = load_images_from_folder(folder_path)\n",
    "\n",
    "    # Step 2: Apply Gaussian Blur\n",
    "    apply_gaussian_blur(image_paths, output_noise_gaussian)\n",
    "\n",
    "    # Step 3: Apply CLAHE\n",
    "    blurred_image_paths = load_images_from_folder(output_noise_gaussian)\n",
    "    apply_clahe(blurred_image_paths, output_hist_clahe)\n",
    "\n",
    "    # Step 4: Apply Otsu Thresholding Inverted\n",
    "    clahe_image_paths = load_images_from_folder(output_hist_clahe)\n",
    "    apply_otsu_thresholding_inv(clahe_image_paths, output_bi_otsu_inv)\n"
   ],
   "id": "6c137ec23a55e3cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Flow with just CLAHE",
   "id": "9adaa251f01f6fbe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def process_image_flow_clahe(folder_path, output_noise_gaussian, output_hist_clahe):\n",
    "    # Step 1: Load images\n",
    "    image_paths = load_images_from_folder(folder_path)\n",
    "\n",
    "    # Step 2: Apply Gaussian Blur\n",
    "    apply_gaussian_blur(image_paths, output_noise_gaussian)\n",
    "\n",
    "    # Step 3: Apply CLAHE\n",
    "    blurred_image_paths = load_images_from_folder(output_noise_gaussian)\n",
    "    apply_clahe(blurred_image_paths, output_hist_clahe)"
   ],
   "id": "34ec69ce1f367e88"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
