{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preparation - IT2 - Choosing best flow "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f2763dd6ef39f85"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47c25980e7f919ae",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:59:45.933340Z",
     "start_time": "2024-11-19T14:59:45.924341Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the paths\n",
    "folder_path = '../data/subset'  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:59:46.025344Z",
     "start_time": "2024-11-19T14:59:46.013346Z"
    }
   },
   "id": "8b59f9c089d5576e",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Images and stats"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fe9242f22a8b58c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load image paths\n",
    "def load_images_from_folder(folder_path, extensions=('.png', '.jpg', '.jpeg', '.JPG')):\n",
    "    \"\"\"\n",
    "    Load all image file paths from a specified folder that match the given file extensions.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing the images.\n",
    "    extensions (tuple of str): A tuple of file extensions to filter the images by. \n",
    "                               Default is ('.png', '.jpg', '.jpeg', '.JPG').\n",
    "\n",
    "    Returns:\n",
    "    list: A list of full file paths to images in the folder that match the specified extensions.\n",
    "    \n",
    "    Raises:\n",
    "    FileNotFoundError: If the specified folder does not exist.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        raise FileNotFoundError(f\"The specified folder does not exist: {folder_path}\")\n",
    "\n",
    "    # List comprehension to gather all image paths with the specified extensions\n",
    "    image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(extensions)]\n",
    "\n",
    "    return image_paths\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:59:46.041341Z",
     "start_time": "2024-11-19T14:59:46.027339Z"
    }
   },
   "id": "aa5e77ec95ee7c9f",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load and preprocess images\n",
    "def load_and_preprocess_images(image_paths, resize_dim=(256, 256)):\n",
    "    images = []\n",
    "    image_ids = []\n",
    "\n",
    "    # Initialize tqdm progress bar\n",
    "    for path in tqdm(image_paths, desc=\"Loading and preprocessing images\", unit=\"image\"):\n",
    "        img = cv2.imread(path)\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "        # img_resized = cv2.resize(img_gray, resize_dim)  # Resize for consistency\n",
    "        images.append(img_gray)\n",
    "        image_ids.append(f'Image_{len(images)}')  # Assign image ID as Image_1, Image_2, etc.\n",
    "\n",
    "    return images, image_ids\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:59:46.057339Z",
     "start_time": "2024-11-19T14:59:46.043341Z"
    }
   },
   "id": "361e15f49831c54f",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing images: 100%|██████████| 12/12 [00:02<00:00,  4.99image/s]\n"
     ]
    }
   ],
   "source": [
    "# Load all image file paths from the specified folder\n",
    "image_paths_all = load_images_from_folder(folder_path)\n",
    "\n",
    "# Load and preprocess all images\n",
    "total_images, total_image_ids = load_and_preprocess_images(image_paths_all)\n",
    "\n",
    "# Randomly select 10 images for experimentation\n",
    "# experiment_indices = random.sample(range(len(total_images)), 10)\n",
    "# test_images = [total_images[i] for i in experiment_indices]\n",
    "# test_image_ids = [total_image_ids[i] for i in experiment_indices]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:59:48.491343Z",
     "start_time": "2024-11-19T14:59:46.059341Z"
    }
   },
   "id": "22a4ddc7dcb0bfc2",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions of Characteristics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a24c604acb58db6b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Image Characteristics Calculation Functions - from data understanding it2\n",
    "def calculate_brightness(image):\n",
    "    return np.mean(image)\n",
    "\n",
    "def calculate_sharpness(image):\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\n",
    "def calculate_contrast(image):\n",
    "    return image.std()\n",
    "\n",
    "def calculate_noise(image):\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    noise = cv2.absdiff(image, blurred)\n",
    "    return np.var(noise)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:59:48.523339Z",
     "start_time": "2024-11-19T14:59:48.510350Z"
    }
   },
   "id": "a9420b3f68d65e4e",
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculating Original Stats"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f700a2a4a42c4ad9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### If from the original dataframe created"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cde21bfbec49b656"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the CSV file with the image statistics\n",
    "# images_stats_path = \"../data-understanding/images_stats.csv\"  \n",
    "# images_stats_df = pd.read_csv(images_stats_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:59:48.539340Z",
     "start_time": "2024-11-19T14:59:48.524341Z"
    }
   },
   "id": "a46a6ea1ee1ce718",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# images_stats_df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:59:48.555340Z",
     "start_time": "2024-11-19T14:59:48.541341Z"
    }
   },
   "id": "9d7c048ae3c0deb7",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# images_stats_df.drop(['Skew','Line Spacing', 'Tables Detected', 'Resolution', 'Detected Elements','Texture', 'Patterns'],axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:59:48.571340Z",
     "start_time": "2024-11-19T14:59:48.557356Z"
    }
   },
   "id": "3db206d6336dcd5a",
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "source": [
    "### From the subset "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7b28af7bae86354"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def image_statistics_table(images, imagesId):\n",
    "    stats_data = {'Image': [],\n",
    "                  'Brightness': [],\n",
    "                  'Sharpness': [],\n",
    "                  'Contrast': [],\n",
    "                  'Noise': [],}\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        stats_data['Image'].append(imagesId[i])\n",
    "        stats_data['Brightness'].append(calculate_brightness(img))\n",
    "        stats_data['Sharpness'].append(calculate_sharpness(img))\n",
    "        stats_data['Contrast'].append(calculate_contrast(img))\n",
    "        stats_data['Noise'].append(calculate_noise(img))\n",
    "    # Create a DataFrame to store per-image statistics\n",
    "    df = pd.DataFrame(stats_data)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:59:48.587340Z",
     "start_time": "2024-11-19T14:59:48.573341Z"
    }
   },
   "id": "a3b90ee885001e98",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Statistics Table:\n"
     ]
    },
    {
     "data": {
      "text/plain": "       Image  Brightness   Sharpness   Contrast     Noise\n0    Image_1  100.038606   19.325682  49.248767  0.611743\n1    Image_2   98.179438   25.128856  45.808319  0.793025\n2    Image_3  102.128122   20.476350  44.327512  0.670412\n3    Image_4  103.643973   26.898489  40.046309  0.955973\n4    Image_5  109.058805   24.906567  42.498071  0.730254\n5    Image_6  111.614181   24.875000  37.462779  0.757413\n6    Image_7  106.277182   19.551871  36.462511  0.697440\n7    Image_8  102.769224   67.817982  38.631583  1.579164\n8    Image_9   95.099688   87.266055  51.179098  2.935492\n9   Image_10   95.865772   62.674985  50.360914  2.025381\n10  Image_11   88.401153   79.075827  29.147155  3.275595\n11  Image_12   87.842252  157.765130  27.883001  6.804315",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image</th>\n      <th>Brightness</th>\n      <th>Sharpness</th>\n      <th>Contrast</th>\n      <th>Noise</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Image_1</td>\n      <td>100.038606</td>\n      <td>19.325682</td>\n      <td>49.248767</td>\n      <td>0.611743</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Image_2</td>\n      <td>98.179438</td>\n      <td>25.128856</td>\n      <td>45.808319</td>\n      <td>0.793025</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Image_3</td>\n      <td>102.128122</td>\n      <td>20.476350</td>\n      <td>44.327512</td>\n      <td>0.670412</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Image_4</td>\n      <td>103.643973</td>\n      <td>26.898489</td>\n      <td>40.046309</td>\n      <td>0.955973</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Image_5</td>\n      <td>109.058805</td>\n      <td>24.906567</td>\n      <td>42.498071</td>\n      <td>0.730254</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Image_6</td>\n      <td>111.614181</td>\n      <td>24.875000</td>\n      <td>37.462779</td>\n      <td>0.757413</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Image_7</td>\n      <td>106.277182</td>\n      <td>19.551871</td>\n      <td>36.462511</td>\n      <td>0.697440</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Image_8</td>\n      <td>102.769224</td>\n      <td>67.817982</td>\n      <td>38.631583</td>\n      <td>1.579164</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Image_9</td>\n      <td>95.099688</td>\n      <td>87.266055</td>\n      <td>51.179098</td>\n      <td>2.935492</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Image_10</td>\n      <td>95.865772</td>\n      <td>62.674985</td>\n      <td>50.360914</td>\n      <td>2.025381</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Image_11</td>\n      <td>88.401153</td>\n      <td>79.075827</td>\n      <td>29.147155</td>\n      <td>3.275595</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Image_12</td>\n      <td>87.842252</td>\n      <td>157.765130</td>\n      <td>27.883001</td>\n      <td>6.804315</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_stats_df = image_statistics_table(total_images, total_image_ids)\n",
    "print(\"Image Statistics Table:\")\n",
    "images_stats_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:59:53.137342Z",
     "start_time": "2024-11-19T14:59:48.590340Z"
    }
   },
   "id": "4be21678a70462d4",
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation Function"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76105296fc098baa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def advanced_evaluation(image, techniques_dict, original_stats):\n",
    "    evaluation_results = {}\n",
    "\n",
    "    for technique_name, technique_func in techniques_dict.items():\n",
    "        # Apply the technique\n",
    "        processed_image = technique_func(image)\n",
    "\n",
    "        # Calculate characteristics for the processed image\n",
    "        stats = {\n",
    "            \"Brightness\": calculate_brightness(processed_image),\n",
    "            \"Sharpness\": calculate_sharpness(processed_image),\n",
    "            \"Contrast\": calculate_contrast(processed_image),\n",
    "            \"Noise\": calculate_noise(processed_image),\n",
    "        }\n",
    "\n",
    "        # Normalize metrics to comparable ranges (between 0 and 1, roughly)\n",
    "        stats_normalized = {\n",
    "            \"Brightness\": stats[\"Brightness\"] / 255,\n",
    "            \"Sharpness\": stats[\"Sharpness\"] / 1000,\n",
    "            \"Contrast\": stats[\"Contrast\"] / 255,\n",
    "            \"Noise\": stats[\"Noise\"] / 255,\n",
    "        }\n",
    "\n",
    "        # Normalize the original stats for comparison\n",
    "        original_stats_normalized = {\n",
    "            \"Brightness\": original_stats[\"Brightness\"] / 255,\n",
    "            \"Sharpness\": original_stats[\"Sharpness\"] / 1000,\n",
    "            \"Contrast\": original_stats[\"Contrast\"] / 255,\n",
    "            \"Noise\": original_stats[\"Noise\"] / 255,\n",
    "        }\n",
    "\n",
    "        # Weights for each characteristic (to determine their importance)\n",
    "        weights = {\n",
    "            \"Brightness\": 1.0,  # Higher is better (rewarded if improved)\n",
    "            \"Sharpness\": 1.0,    # Higher is better (rewarded if improved) but images were generally sharp already \n",
    "            \"Contrast\": 2.0,     # Higher is better (rewarded if improved) the levels of contrast were lower and obstructed details\n",
    "            \"Noise\": -1.5,       # Lower is better (penalized if increased)\n",
    "        }\n",
    "\n",
    "        # Calculate score using normalized metrics and weights\n",
    "        score = 0\n",
    "        for metric, value in stats_normalized.items():\n",
    "            original_value = original_stats_normalized.get(metric, 0)\n",
    "            score += weights[metric] * (value - original_value)\n",
    "\n",
    "        evaluation_results[technique_name] = {\"Score\": score, \"Stats\": stats}\n",
    "\n",
    "    # Determine the best technique based on the highest score\n",
    "    best_technique = max(evaluation_results, key=lambda x: evaluation_results[x][\"Score\"])\n",
    "    return {\"Best Technique\": best_technique, \"Evaluation Results\": evaluation_results}\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:59:53.153340Z",
     "start_time": "2024-11-19T14:59:53.138340Z"
    }
   },
   "id": "initial_id",
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting the best techniques based on step 1.1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3610bf59adbc3b51"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the best techniques and parameters for each step\n",
    "best_techniques = {\n",
    "    \"Noise Reduction\": (lambda img: cv2.medianBlur(img, ksize=3)),\n",
    "    \"Histogram Equalization\": (lambda img: cv2.equalizeHist(img)),  # No parameters were found to be beneficial\n",
    "    \"Binarization\": (lambda img: cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, blockSize=11, C=2)),\n",
    "    \"Morphological Operations\": (lambda img: cv2.dilate(img, np.ones((9, 9), np.uint8))),\n",
    "    \"Edge Detection\": (lambda img: cv2.Canny(img, threshold1=50, threshold2=150)),\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:59:53.169340Z",
     "start_time": "2024-11-19T14:59:53.155341Z"
    }
   },
   "id": "2cbfc1560547af5e",
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using the previous flows found to be most suitable"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42c95072259bce52"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Best Flows from Previous Iteration\n",
    "previous_best_flows = {\n",
    "    \"Flow - CLAHE\": [\n",
    "        (\"Gaussian Blur\", lambda img: cv2.GaussianBlur(img, (5, 5), 0)),\n",
    "        (\"CLAHE\", lambda img: cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(img))\n",
    "    ]\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:59:53.185340Z",
     "start_time": "2024-11-19T14:59:53.170341Z"
    }
   },
   "id": "ea1849a781f0e5f7",
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting flows based on best techniques"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba0642c4b3339434"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create New Flows Incrementally\n",
    "new_flows = {\n",
    "    \"Flow 1 Noise Reduction\": [\n",
    "        (\"Noise Reduction\", best_techniques[\"Noise Reduction\"])\n",
    "    ],\n",
    "    \"Flow 2 Noise Reduction + Histogram Equalization\": [\n",
    "        (\"Noise Reduction\", best_techniques[\"Noise Reduction\"]),\n",
    "        (\"Histogram Equalization\", best_techniques[\"Histogram Equalization\"])\n",
    "    ],\n",
    "    \"Flow 3 Noise Reduction + Histogram Equalization + Binarization\": [\n",
    "        (\"Noise Reduction\", best_techniques[\"Noise Reduction\"]),\n",
    "        (\"Histogram Equalization\", best_techniques[\"Histogram Equalization\"]),\n",
    "        (\"Binarization\", best_techniques[\"Binarization\"])\n",
    "    ],\n",
    "    \"Flow 4 Noise Reduction + Histogram Equalization + Binarization + Morphological Operations\": [\n",
    "        (\"Noise Reduction\", best_techniques[\"Noise Reduction\"]),\n",
    "        (\"Histogram Equalization\", best_techniques[\"Histogram Equalization\"]),\n",
    "        (\"Binarization\", best_techniques[\"Binarization\"]),\n",
    "        (\"Morphological Operations\", best_techniques[\"Morphological Operations\"])\n",
    "    ],\n",
    "    \"Flow 5 Full Flow\": [\n",
    "        (\"Noise Reduction\", best_techniques[\"Noise Reduction\"]),\n",
    "        (\"Histogram Equalization\", best_techniques[\"Histogram Equalization\"]),\n",
    "        (\"Binarization\", best_techniques[\"Binarization\"]),\n",
    "        (\"Morphological Operations\", best_techniques[\"Morphological Operations\"]),\n",
    "        (\"Edge Detection\", best_techniques[\"Edge Detection\"])\n",
    "    ]\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:59:53.201340Z",
     "start_time": "2024-11-19T14:59:53.186340Z"
    }
   },
   "id": "60a34877d455cb05",
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepearing and running the flows"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "147cb3cb7f879f27"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Combine all flows\n",
    "all_flows = {**previous_best_flows, **new_flows}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:59:53.216339Z",
     "start_time": "2024-11-19T14:59:53.203342Z"
    }
   },
   "id": "84ba0ef4c75cb75e",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to apply a flow to an image\n",
    "def apply_flow(flow, image):\n",
    "    for step_name, technique in flow:\n",
    "        image = technique(image)\n",
    "    return image\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:59:53.231341Z",
     "start_time": "2024-11-19T14:59:53.217340Z"
    }
   },
   "id": "96fc83f73b2a4041",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Flow: Flow - CLAHE\n",
      "----------------------------------------\n",
      "Image Image_1: Score = 0.06169536056771593\n",
      "Image Image_2: Score = 0.07898004046606698\n",
      "Image Image_3: Score = 0.06065598633179331\n",
      "Image Image_4: Score = 0.0676560965565005\n",
      "Image Image_5: Score = 0.09260820738941113\n",
      "Image Image_6: Score = 0.09955002190101941\n",
      "Image Image_7: Score = 0.09406687210972073\n",
      "Image Image_8: Score = 0.08532877794197584\n",
      "Image Image_9: Score = 0.05379625775123446\n",
      "Image Image_10: Score = 0.04384334413520083\n",
      "Image Image_11: Score = 0.0896755389754957\n",
      "Image Image_12: Score = 0.08952760079399172\n",
      "Average Score for Flow 'Flow - CLAHE': 0.07644867541001053\n",
      "\n",
      "Testing Flow: Flow 1 Noise Reduction\n",
      "----------------------------------------\n",
      "Image Image_1: Score = -0.010987027282247222\n",
      "Image Image_2: Score = -0.013700469270125814\n",
      "Image Image_3: Score = -0.011114293069925214\n",
      "Image Image_4: Score = -0.01204227570192167\n",
      "Image Image_5: Score = -0.014686089631650454\n",
      "Image Image_6: Score = -0.013961430638968984\n",
      "Image Image_7: Score = -0.00868987682986953\n",
      "Image Image_8: Score = -0.04082488614332184\n",
      "Image Image_9: Score = -0.03586310681515047\n",
      "Image Image_10: Score = -0.02960603742201722\n",
      "Image Image_11: Score = -0.02677553199127187\n",
      "Image Image_12: Score = -0.04892862220358525\n",
      "Average Score for Flow 'Flow 1 Noise Reduction': -0.02226497058333796\n",
      "\n",
      "Testing Flow: Flow 2 Noise Reduction + Histogram Equalization\n",
      "----------------------------------------\n",
      "Image Image_1: Score = 0.40526903655674396\n",
      "Image Image_2: Score = 0.40423747441218766\n",
      "Image Image_3: Score = 0.41690550258829373\n",
      "Image Image_4: Score = 0.4632330554566116\n",
      "Image Image_5: Score = 0.36013023077987477\n",
      "Image Image_6: Score = 0.4148128197180131\n",
      "Image Image_7: Score = 0.45949660738622783\n",
      "Image Image_8: Score = 0.5258643903401349\n",
      "Image Image_9: Score = 0.3601087332414066\n",
      "Image Image_10: Score = 0.348100240761626\n",
      "Image Image_11: Score = 0.772094097823457\n",
      "Image Image_12: Score = 1.1483942684173603\n",
      "Average Score for Flow 'Flow 2 Noise Reduction + Histogram Equalization': 0.5065538714568281\n",
      "\n",
      "Testing Flow: Flow 3 Noise Reduction + Histogram Equalization + Binarization\n",
      "----------------------------------------\n",
      "Image Image_1: Score = 91.19447905167488\n",
      "Image Image_2: Score = 90.05178945331537\n",
      "Image Image_3: Score = 93.46417330755882\n",
      "Image Image_4: Score = 92.09373051809003\n",
      "Image Image_5: Score = 74.01274734885395\n",
      "Image Image_6: Score = 79.56034311247872\n",
      "Image Image_7: Score = 78.63470562595592\n",
      "Image Image_8: Score = 99.53464817406761\n",
      "Image Image_9: Score = 75.36208891454427\n",
      "Image Image_10: Score = 80.19496625009886\n",
      "Image Image_11: Score = 77.2169223816312\n",
      "Image Image_12: Score = 71.30893796986732\n",
      "Average Score for Flow 'Flow 3 Noise Reduction + Histogram Equalization + Binarization': 83.55246100901141\n",
      "\n",
      "Testing Flow: Flow 4 Noise Reduction + Histogram Equalization + Binarization + Morphological Operations\n",
      "----------------------------------------\n",
      "Image Image_1: Score = 0.21392590056191454\n",
      "Image Image_2: Score = 0.24626160647227033\n",
      "Image Image_3: Score = 0.30367831682428514\n",
      "Image Image_4: Score = 0.2821163900438813\n",
      "Image Image_5: Score = 0.25188054961411116\n",
      "Image Image_6: Score = 0.303365648664365\n",
      "Image Image_7: Score = 0.39423718472452196\n",
      "Image Image_8: Score = 0.2622840544550231\n",
      "Image Image_9: Score = 0.16321795765792307\n",
      "Image Image_10: Score = 0.17968669726626846\n",
      "Image Image_11: Score = 0.3698158757505943\n",
      "Image Image_12: Score = 0.3247921790631565\n",
      "Average Score for Flow 'Flow 4 Noise Reduction + Histogram Equalization + Binarization + Morphological Operations': 0.2746051967581929\n",
      "\n",
      "Testing Flow: Flow 5 Full Flow\n",
      "----------------------------------------\n",
      "Image Image_1: Score = -0.7782218177509675\n",
      "Image Image_2: Score = -0.7430210855759847\n",
      "Image Image_3: Score = -0.617053450071051\n",
      "Image Image_4: Score = -0.6877435710177976\n",
      "Image Image_5: Score = -0.7183554389381827\n",
      "Image Image_6: Score = -0.6375820258953147\n",
      "Image Image_7: Score = -0.4667228957949249\n",
      "Image Image_8: Score = -0.7012157065497234\n",
      "Image Image_9: Score = -0.8289613571821686\n",
      "Image Image_10: Score = -0.8195958968138296\n",
      "Image Image_11: Score = -0.6301717265121227\n",
      "Image Image_12: Score = -0.6701369367551705\n",
      "Average Score for Flow 'Flow 5 Full Flow': -0.6915651590714366\n"
     ]
    }
   ],
   "source": [
    "# Testing the Flows\n",
    "flow_results = {}\n",
    "\n",
    "# Define a specific image to save across all flows\n",
    "image_to_save_id = total_image_ids[0]  # Choose the first image (or any specific image)\n",
    "\n",
    "# Loop over each flow\n",
    "for flow_name, flow_steps in all_flows.items():\n",
    "    total_score = 0\n",
    "    print(f\"Testing Flow: {flow_name}\\n{'-' * 40}\")\n",
    "\n",
    "    # Loop over each image for evaluation\n",
    "    for img, img_id in zip(total_images, total_image_ids):\n",
    "        original_stats = images_stats_df[images_stats_df['Image'] == img_id].iloc[0].to_dict()\n",
    "\n",
    "        # Apply the flow on the image\n",
    "        processed_image = apply_flow(flow_steps, img)\n",
    "\n",
    "        # Save the processed image only for the selected image ID\n",
    "        if img_id == image_to_save_id:\n",
    "            # Specify the folder to save the processed images for the flows\n",
    "            output_folder_flow = f\"./Data/It2/Flows/{flow_name}\"\n",
    "            os.makedirs(output_folder_flow, exist_ok=True)\n",
    "\n",
    "            # Save the processed image with the flow name and image ID\n",
    "            cv2.imwrite(f\"{output_folder_flow}/{flow_name}_Image_{img_id}.jpg\", processed_image)\n",
    "\n",
    "        # Using advanced evaluation function to evaluate the processed image\n",
    "        evaluation_results = advanced_evaluation(processed_image, {\"Flow\": lambda x: x}, original_stats)\n",
    "\n",
    "        # Access the score for the flow (since only one technique is passed, we can directly fetch it)\n",
    "        flow_score = evaluation_results[\"Evaluation Results\"][\"Flow\"][\"Score\"]\n",
    "\n",
    "        # Add the score to the total score\n",
    "        total_score += flow_score\n",
    "        print(f\"Image {img_id}: Score = {flow_score}\")\n",
    "\n",
    "    # Calculate the average score for the flow\n",
    "    avg_score = total_score / len(total_images)\n",
    "    print(f\"Average Score for Flow '{flow_name}': {avg_score}\\n\")\n",
    "    flow_results[flow_name] = avg_score\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T15:00:22.333588Z",
     "start_time": "2024-11-19T14:59:53.233356Z"
    }
   },
   "id": "ad651372d796060",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Flow Testing Results (Sorted by Score):\n",
      "Flow 3 Noise Reduction + Histogram Equalization + Binarization: Average Score = 83.55246100901141\n",
      "Flow 2 Noise Reduction + Histogram Equalization: Average Score = 0.5065538714568281\n",
      "Flow 4 Noise Reduction + Histogram Equalization + Binarization + Morphological Operations: Average Score = 0.2746051967581929\n",
      "Flow - CLAHE: Average Score = 0.07644867541001053\n",
      "Flow 1 Noise Reduction: Average Score = -0.02226497058333796\n",
      "Flow 5 Full Flow: Average Score = -0.6915651590714366\n"
     ]
    }
   ],
   "source": [
    "# Display Final Results\n",
    "sorted_results = sorted(flow_results.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nFinal Flow Testing Results (Sorted by Score):\")\n",
    "for flow_name, score in sorted_results:\n",
    "    print(f\"{flow_name}: Average Score = {score}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T15:00:22.348589Z",
     "start_time": "2024-11-19T15:00:22.335589Z"
    }
   },
   "id": "fd8d377f5268b95a",
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "source": [
    "Final Flow Testing Results (Sorted by Score):\n",
    "Flow 3: Noise Reduction + Histogram Equalization + Binarization: Average Score = 83.55\n",
    "Flow 2: Noise Reduction + Histogram Equalization: Average Score = 0.51\n",
    "Flow 4: Noise Reduction + Histogram Equalization + Binarization + Morphological Operations: Average Score = 0.27\n",
    "Flow - CLAHE: Average Score = 0.08\n",
    "Flow 1: Noise Reduction: Average Score = -0.02\n",
    "Flow 5: Full Flow: Average Score = -0.69\n",
    "\n",
    "# Flow Testing Results and Interpretation\n",
    "\n",
    "## 1. Flow 3: Noise Reduction + Histogram Equalization + Binarization\n",
    "- **Score**: 83.55\n",
    "- **Steps**: Noise Reduction, Histogram Equalization, Binarization.\n",
    "- **Interpretation**:\n",
    "  - This flow produced the **highest average score**, indicating that combining these three techniques—**Noise Reduction**, **Histogram Equalization**, and **Binarization**—resulted in a significant improvement in image quality metrics compared to the original images.\n",
    "  - **Binarization** helped make text and table lines more distinct, providing better separation of content from the background.\n",
    "  - However, the absence of **Morphological Operations** and **Edge Detection** means that further refinement and edge enhancement could potentially yield even better results.\n",
    "\n",
    "## 2. Flow 2: Noise Reduction + Histogram Equalization\n",
    "- **Score**: 0.51\n",
    "- **Steps**: Noise Reduction, Histogram Equalization.\n",
    "- **Interpretation**:\n",
    "  - Adding **Histogram Equalization** improved the results compared to just using noise reduction, suggesting that enhancing contrast played a crucial role in making text and lines stand out more.\n",
    "  - The relatively low positive score indicates that although the images were improved, without **Binarization** or more advanced techniques like **Morphological Operations** or **Edge Detection**, the enhancement was limited.\n",
    "\n",
    "## 3. Flow 4: Noise Reduction + Histogram Equalization + Binarization + Morphological Operations\n",
    "- **Score**: 0.27\n",
    "- **Steps**: Noise Reduction, Histogram Equalization, Binarization, Morphological Operations.\n",
    "- **Interpretation**:\n",
    "  - Adding **Morphological Operations** to the binarization step provided some improvement, but not as much as expected compared to Flow 3.\n",
    "  - The low score indicates that while **Morphological Operations** added some structure to the images, they also introduced some level of distortion or data loss that negatively impacted the overall quality.\n",
    "\n",
    "## 4. Flow - CLAHE\n",
    "- **Score**: 0.08\n",
    "- **Steps**: CLAHE.\n",
    "- **Interpretation**:\n",
    "  - This flow, which only used **CLAHE** (Contrast Limited Adaptive Histogram Equalization), yielded a very small positive score.\n",
    "  - The limited improvement suggests that **contrast enhancement** alone, without noise reduction or edge enhancement, was not sufficient to achieve significant quality gains.\n",
    "\n",
    "## 5. Flow 1: Noise Reduction\n",
    "- **Score**: -0.02\n",
    "- **Steps**: Noise Reduction.\n",
    "- **Interpretation**:\n",
    "  - This flow produced a **negative score**, meaning that **Noise Reduction** alone did not improve image quality and instead slightly degraded it.\n",
    "  - The smoothed images lost some contrast and detail, which led to reduced image quality in terms of the evaluation metrics.\n",
    "\n",
    "## 6. Flow 5: Full Flow\n",
    "- **Score**: -0.69\n",
    "- **Steps**: Noise Reduction, Histogram Equalization, Binarization, Morphological Operations, Edge Detection.\n",
    "- **Interpretation**:\n",
    "  - Surprisingly, the **Full Flow**—which combined all the techniques—produced the **lowest average score**.\n",
    "  - This suggests that adding all five techniques together introduced too many transformations, which may have led to over-processing, resulting in the loss of important image characteristics.\n",
    "  - The **Edge Detection** and **Morphological Operations** steps might have contributed to unwanted noise or artifacts, negatively affecting the overall score.\n",
    "\n",
    "## Summary of Findings\n",
    "- **Flow 3** achieved the best result, showing that a combination of **Noise Reduction**, **Histogram Equalization**, and **Binarization** is effective in enhancing the images while keeping transformations minimal.\n",
    "- **Flow 2** also provided some improvement, indicating that **Histogram Equalization** is crucial for enhancing contrast and making features more prominent.\n",
    "- Adding **Morphological Operations**, as in **Flow 4**, did not significantly enhance the results and might have introduced unnecessary noise or detail loss.\n",
    "- The **Full Flow** (Flow 5) produced a negative score, suggesting that combining all techniques together without careful parameter tuning can lead to over-processing.\n",
    "- The **best flows** balance noise reduction, contrast enhancement, and binarization to make content more distinct without over-processing the images.\n",
    "\n",
    "Based on these results, a simplified image processing pipeline involving **Noise Reduction**, **Histogram Equalization**, and **Binarization** yields the best preparation for further tasks. More complex flows, such as adding **Morphological Operations** or **Edge Detection**, may require additional careful parameter tuning to prevent degradation in quality.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f026bf981a4c580"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T15:00:22.364589Z",
     "start_time": "2024-11-19T15:00:22.350589Z"
    }
   },
   "id": "5de9fd33b2569524",
   "execution_count": 39
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
