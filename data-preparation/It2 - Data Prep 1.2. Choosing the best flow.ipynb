{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47c25980e7f919ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T15:18:45.211740Z",
     "start_time": "2024-11-13T15:18:45.206740Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b59f9c089d5576e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T15:18:45.288738Z",
     "start_time": "2024-11-13T15:18:45.274740Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the paths\n",
    "folder_path = '../data/original'  # Update this path to point to your specific folder containing images\n",
    "output_folder = '../data/processed'  # Update this path to the desired output folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5e77ec95ee7c9f",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load image paths\n",
    "def load_images_from_folder(folder_path, extensions=('.png', '.jpg', '.jpeg', '.JPG')):\n",
    "    \"\"\"\n",
    "    Load all image file paths from a specified folder that match the given file extensions.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing the images.\n",
    "    extensions (tuple of str): A tuple of file extensions to filter the images by. \n",
    "                               Default is ('.png', '.jpg', '.jpeg', '.JPG').\n",
    "\n",
    "    Returns:\n",
    "    list: A list of full file paths to images in the folder that match the specified extensions.\n",
    "    \n",
    "    Raises:\n",
    "    FileNotFoundError: If the specified folder does not exist.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        raise FileNotFoundError(f\"The specified folder does not exist: {folder_path}\")\n",
    "\n",
    "    # List comprehension to gather all image paths with the specified extensions\n",
    "    image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(extensions)]\n",
    "\n",
    "    return image_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361e15f49831c54f",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load and preprocess images\n",
    "def load_and_preprocess_images(image_paths, resize_dim=(256, 256)):\n",
    "    images = []\n",
    "    image_ids = []\n",
    "\n",
    "    # Initialize tqdm progress bar\n",
    "    for path in tqdm(image_paths, desc=\"Loading and preprocessing images\", unit=\"image\"):\n",
    "        img = cv2.imread(path)\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "        img_resized = cv2.resize(img_gray, resize_dim)  # Resize for consistency\n",
    "        images.append(img_resized)\n",
    "        image_ids.append(f'Image_{len(images)}')  # Assign image ID as Image_1, Image_2, etc.\n",
    "\n",
    "    return images, image_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22a4ddc7dcb0bfc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T15:21:28.575581Z",
     "start_time": "2024-11-13T15:18:45.830784Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing images: 100%|██████████| 698/698 [02:42<00:00,  4.29image/s]\n"
     ]
    }
   ],
   "source": [
    "# Load all image file paths from the specified folder\n",
    "image_paths_all = load_images_from_folder(folder_path)\n",
    "\n",
    "# Load and preprocess all images\n",
    "total_images, total_image_ids = load_and_preprocess_images(image_paths_all)\n",
    "\n",
    "# Randomly select 10 images for experimentation\n",
    "experiment_indices = random.sample(range(len(total_images)), 10)\n",
    "test_images = [total_images[i] for i in experiment_indices]\n",
    "test_image_ids = [total_image_ids[i] for i in experiment_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37eaa079e7c6d124",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T15:21:28.590582Z",
     "start_time": "2024-11-13T15:21:28.577582Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the CSV file with the image statistics\n",
    "images_stats_path = \"../data-understanding/images_stats.csv\"\n",
    "images_stats_df = pd.read_csv(images_stats_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9420b3f68d65e4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T15:21:28.621582Z",
     "start_time": "2024-11-13T15:21:28.591583Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Image Characteristics Calculation Functions - from data understanding it2\n",
    "def calculate_brightness(image):\n",
    "    return np.mean(image)\n",
    "\n",
    "def calculate_sharpness(image):\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\n",
    "def calculate_contrast(image):\n",
    "    return image.std()\n",
    "\n",
    "def calculate_noise(image):\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    noise = cv2.absdiff(image, blurred)\n",
    "    return np.var(noise)\n",
    "\n",
    "def calculate_skew(image):\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "    _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    coords = np.column_stack(np.where(binary > 0))\n",
    "    if coords.size == 0:\n",
    "        return 0\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    if abs(angle) < 1e-2:\n",
    "        angle = 0\n",
    "    return round(angle, 2)\n",
    "\n",
    "def calculate_line_spacing(image):\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "\n",
    "    # Ensure the image is in the correct format for findContours\n",
    "    if image.dtype != np.uint8:\n",
    "        image = cv2.convertScaleAbs(image)\n",
    "\n",
    "    _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    heights = [cv2.boundingRect(contour)[3] for contour in contours]\n",
    "    if len(heights) > 1:\n",
    "        line_spacing = np.mean(np.diff(sorted(heights)))\n",
    "    else:\n",
    "        line_spacing = 0\n",
    "    return line_spacing\n",
    "\n",
    "\n",
    "def detect_tables(image):\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "\n",
    "    # Ensure the image is in the correct format for adaptiveThreshold\n",
    "    if image.dtype != np.uint8:\n",
    "        image = cv2.convertScaleAbs(image)\n",
    "\n",
    "    # Apply binary threshold and adaptive threshold\n",
    "    _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    binary = cv2.adaptiveThreshold(binary, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "    # Find contours in the image\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    table_contours = [contour for contour in contours if cv2.contourArea(contour) > 1000]\n",
    "\n",
    "    return len(table_contours)\n",
    "\n",
    "\n",
    "def calculate_resolution(image):\n",
    "    height, width = image.shape[:2]\n",
    "    return height * width\n",
    "\n",
    "def calculate_elements_detection(image):\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "\n",
    "    # Ensure the image is in the correct format for findContours\n",
    "    if image.dtype != np.uint8:\n",
    "        image = cv2.convertScaleAbs(image)\n",
    "\n",
    "    # Apply binary threshold\n",
    "    _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return len(contours)\n",
    "\n",
    "\n",
    "def calculate_texture(image):\n",
    "    laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "    return laplacian.std()\n",
    "\n",
    "def calculate_patterns(image):\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "\n",
    "    # Ensure the image is in the correct format for Canny edge detection\n",
    "    if image.dtype != np.uint8:\n",
    "        image = cv2.convertScaleAbs(image)\n",
    "\n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(image, 100, 200)\n",
    "\n",
    "    # Count the number of edge pixels\n",
    "    return np.sum(edges > 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T15:21:28.636585Z",
     "start_time": "2024-11-13T15:21:28.623582Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def advanced_evaluation(image, techniques_dict, original_stats):\n",
    "    evaluation_results = {}\n",
    "\n",
    "    # We assume there is only one technique (in this case, the flow)\n",
    "    for technique_name, technique_func in techniques_dict.items():\n",
    "        # Apply the technique (flow) on the image\n",
    "        processed_image = technique_func(image)\n",
    "\n",
    "        # Calculate characteristics for the processed image\n",
    "        stats = {\n",
    "            \"Brightness\": calculate_brightness(processed_image),\n",
    "            \"Sharpness\": calculate_sharpness(processed_image),\n",
    "            \"Contrast\": calculate_contrast(processed_image),\n",
    "            \"Noise\": calculate_noise(processed_image),\n",
    "            \"Skew\": calculate_skew(processed_image),\n",
    "            \"Line Spacing\": calculate_line_spacing(processed_image),\n",
    "            \"Tables Detected\": detect_tables(processed_image),\n",
    "            \"Resolution\": calculate_resolution(processed_image),\n",
    "            \"Detected Elements\": calculate_elements_detection(processed_image),\n",
    "            \"Texture\": calculate_texture(processed_image),\n",
    "            \"Patterns\": calculate_patterns(processed_image)\n",
    "        }\n",
    "\n",
    "        # Normalize metrics to comparable ranges (between 0 and 1, roughly)\n",
    "        stats_normalized = {\n",
    "            \"Brightness\": stats[\"Brightness\"] / 255,\n",
    "            \"Sharpness\": stats[\"Sharpness\"] / 1000,\n",
    "            \"Contrast\": stats[\"Contrast\"] / 255,\n",
    "            \"Noise\": stats[\"Noise\"] / 255,\n",
    "            \"Skew\": stats[\"Skew\"] / 45,\n",
    "            \"Line Spacing\": stats[\"Line Spacing\"] / 100,\n",
    "            \"Tables Detected\": stats[\"Tables Detected\"] / 10,\n",
    "            \"Resolution\": stats[\"Resolution\"] / (512 * 512),\n",
    "            \"Detected Elements\": stats[\"Detected Elements\"] / 100,\n",
    "            \"Texture\": stats[\"Texture\"] / 100,\n",
    "            \"Patterns\": stats[\"Patterns\"] / 1000\n",
    "        }\n",
    "\n",
    "        # Normalize the original stats for comparison\n",
    "        original_stats_normalized = {\n",
    "            \"Brightness\": original_stats[\"Brightness\"] / 255,\n",
    "            \"Sharpness\": original_stats[\"Sharpness\"] / 1000,\n",
    "            \"Contrast\": original_stats[\"Contrast\"] / 255,\n",
    "            \"Noise\": original_stats[\"Noise\"] / 255,\n",
    "            \"Skew\": original_stats[\"Skew\"] / 45,\n",
    "            \"Line Spacing\": original_stats[\"Line Spacing\"] / 100,\n",
    "            \"Tables Detected\": original_stats[\"Tables Detected\"] / 10,\n",
    "            \"Resolution\": original_stats[\"Resolution\"] / (512 * 512),\n",
    "            \"Detected Elements\": original_stats[\"Detected Elements\"] / 100,\n",
    "            \"Texture\": original_stats[\"Texture\"] / 100,\n",
    "            \"Patterns\": original_stats[\"Patterns\"] / 1000\n",
    "        }\n",
    "\n",
    "        # Weights for each characteristic (to determine their importance)\n",
    "        weights = {\n",
    "            \"Brightness\": -1.0,  # Closer to original is better (penalized if different)\n",
    "            \"Sharpness\": 2.0,    # Higher is better (rewarded if improved)\n",
    "            \"Contrast\": 1.0,     # Higher is better (rewarded if improved)\n",
    "            \"Noise\": -1.5,       # Lower is better (penalized if increased)\n",
    "            \"Skew\": -0.5,        # Closer to original is better (penalized if different)\n",
    "            \"Line Spacing\": -0.5,  # Closer to original is better (penalized if different)\n",
    "            \"Tables Detected\": 1.0,  # More tables detected is better\n",
    "            \"Resolution\": 1.0,    # Higher is better\n",
    "            \"Detected Elements\": 1.0,  # More elements detected is better\n",
    "            \"Texture\": 1.0,       # Higher texture complexity is better\n",
    "            \"Patterns\": 1.0       # More patterns detected is better\n",
    "        }\n",
    "\n",
    "        # Calculate score using normalized metrics and weights\n",
    "        score = 0\n",
    "        for metric, value in stats_normalized.items():\n",
    "            original_value = original_stats_normalized.get(metric, 0)\n",
    "            score += weights[metric] * (value - original_value)\n",
    "\n",
    "        # Store the score and statistics for the technique (flow)\n",
    "        evaluation_results[technique_name] = {\"Score\": score, \"Stats\": stats}\n",
    "\n",
    "    return {\"Evaluation Results\": evaluation_results}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cbfc1560547af5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T15:21:28.652582Z",
     "start_time": "2024-11-13T15:21:28.638582Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the best techniques and parameters for each step\n",
    "best_techniques = {\n",
    "    \"Noise Reduction\": (lambda img: cv2.fastNlMeansDenoising(img, None, 5, 7, 21)),\n",
    "    \"Histogram Equalization\": (lambda img: cv2.equalizeHist(img)),\n",
    "    \"Binarization\": (lambda img: cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)),\n",
    "    \"Morphological Operations\": (lambda img: cv2.erode(img, np.ones((3, 3), np.uint8))),\n",
    "    \"Edge Detection\": (lambda img: cv2.Canny(img, 50, 150)),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea1849a781f0e5f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T15:21:28.668582Z",
     "start_time": "2024-11-13T15:21:28.654581Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Best Flows from Previous Iteration\n",
    "previous_best_flows = {\n",
    "    \"Inverted Sobel Flow\": [\n",
    "        (\"Gaussian Blur\", lambda img: cv2.GaussianBlur(img, (5, 5), 0)),\n",
    "        (\"CLAHE\", lambda img: cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(img)),\n",
    "        (\"Otsu Inverted\", lambda img: cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]),\n",
    "        (\"Closing\", lambda img: cv2.morphologyEx(img, cv2.MORPH_CLOSE, np.ones((5, 5), np.uint8))),\n",
    "        (\"Sobel Edge Detection\", lambda img: cv2.Sobel(img, cv2.CV_64F, 1, 1, ksize=3))\n",
    "    ],\n",
    "    \"Standard Unsharp Mask Flow\": [\n",
    "        (\"Gaussian Blur\", lambda img: cv2.GaussianBlur(img, (5, 5), 0)),\n",
    "        (\"CLAHE\", lambda img: cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(img)),\n",
    "        (\"Otsu\", lambda img: cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]),\n",
    "        (\"Opening\", lambda img: cv2.morphologyEx(img, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))),\n",
    "        (\"Unsharp Mask\", lambda img: cv2.addWeighted(img, 1.5, cv2.GaussianBlur(img, (0, 0), 3), -0.5, 0))\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60a34877d455cb05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T15:21:28.684584Z",
     "start_time": "2024-11-13T15:21:28.670583Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create New Flows Incrementally\n",
    "new_flows = {\n",
    "    \"Flow 1: Noise Reduction\": [\n",
    "        (\"Noise Reduction\", best_techniques[\"Noise Reduction\"])\n",
    "    ],\n",
    "    \"Flow 2: Noise Reduction + Histogram Equalization\": [\n",
    "        (\"Noise Reduction\", best_techniques[\"Noise Reduction\"]),\n",
    "        (\"Histogram Equalization\", best_techniques[\"Histogram Equalization\"])\n",
    "    ],\n",
    "    \"Flow 3: Noise Reduction + Histogram Equalization + Binarization\": [\n",
    "        (\"Noise Reduction\", best_techniques[\"Noise Reduction\"]),\n",
    "        (\"Histogram Equalization\", best_techniques[\"Histogram Equalization\"]),\n",
    "        (\"Binarization\", best_techniques[\"Binarization\"])\n",
    "    ],\n",
    "    \"Flow 4: Noise Reduction + Histogram Equalization + Binarization + Morphological Operations\": [\n",
    "        (\"Noise Reduction\", best_techniques[\"Noise Reduction\"]),\n",
    "        (\"Histogram Equalization\", best_techniques[\"Histogram Equalization\"]),\n",
    "        (\"Binarization\", best_techniques[\"Binarization\"]),\n",
    "        (\"Morphological Operations\", best_techniques[\"Morphological Operations\"])\n",
    "    ],\n",
    "    \"Flow 5: Full Flow\": [\n",
    "        (\"Noise Reduction\", best_techniques[\"Noise Reduction\"]),\n",
    "        (\"Histogram Equalization\", best_techniques[\"Histogram Equalization\"]),\n",
    "        (\"Binarization\", best_techniques[\"Binarization\"]),\n",
    "        (\"Morphological Operations\", best_techniques[\"Morphological Operations\"]),\n",
    "        (\"Edge Detection\", best_techniques[\"Edge Detection\"])\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84ba0ef4c75cb75e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T15:21:28.700581Z",
     "start_time": "2024-11-13T15:21:28.686582Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Combine all flows\n",
    "all_flows = {**previous_best_flows, **new_flows}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96fc83f73b2a4041",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T15:21:28.716582Z",
     "start_time": "2024-11-13T15:21:28.702582Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Function to apply a flow to an image\n",
    "def apply_flow(flow, image):\n",
    "    for step_name, technique in flow:\n",
    "        image = technique(image)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad651372d796060",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T15:21:35.826511Z",
     "start_time": "2024-11-13T15:21:28.717582Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Flow: Inverted Sobel Flow\n",
      "----------------------------------------\n",
      "Image Image_578: Score = 25.68682366355018\n",
      "Image Image_270: Score = 17.02987284040099\n",
      "Image Image_358: Score = 22.374029183093526\n",
      "Image Image_119: Score = 12.18512047438687\n",
      "Image Image_557: Score = 20.342073153707553\n",
      "Image Image_691: Score = 46.54453507797555\n",
      "Image Image_452: Score = 22.156773258662326\n",
      "Image Image_39: Score = 14.766668547327804\n",
      "Image Image_450: Score = 21.477320796421537\n",
      "Image Image_357: Score = 17.967124668557805\n",
      "Average Score for Flow 'Inverted Sobel Flow': 22.053034166408416\n",
      "\n",
      "Testing Flow: Standard Unsharp Mask Flow\n",
      "----------------------------------------\n",
      "Image Image_578: Score = 4.06307086519465\n",
      "Image Image_270: Score = 5.919570163372748\n",
      "Image Image_358: Score = 8.481252892836062\n",
      "Image Image_119: Score = 3.6639902141415117\n",
      "Image Image_557: Score = 6.295550085930158\n",
      "Image Image_691: Score = 15.814334427646806\n",
      "Image Image_452: Score = 6.7949839291707175\n",
      "Image Image_39: Score = 6.267748473988354\n",
      "Image Image_450: Score = 7.401523513341798\n",
      "Image Image_357: Score = 7.14082846124036\n",
      "Average Score for Flow 'Standard Unsharp Mask Flow': 7.184285302686317\n",
      "\n",
      "Testing Flow: Flow 1: Noise Reduction\n",
      "----------------------------------------\n",
      "Image Image_578: Score = -1.1272084272490168\n",
      "Image Image_270: Score = -0.2923236372904081\n",
      "Image Image_358: Score = -1.905768713989203\n",
      "Image Image_119: Score = -0.62933641015285\n",
      "Image Image_557: Score = -1.0064974694837945\n",
      "Image Image_691: Score = 0.20827178999784957\n",
      "Image Image_452: Score = -0.27966564296852836\n",
      "Image Image_39: Score = -0.7271683731614329\n",
      "Image Image_450: Score = -1.4053510050184026\n",
      "Image Image_357: Score = -0.9809239930653385\n",
      "Average Score for Flow 'Flow 1: Noise Reduction': -0.8145971882381126\n",
      "\n",
      "Testing Flow: Flow 2: Noise Reduction + Histogram Equalization\n",
      "----------------------------------------\n",
      "Image Image_578: Score = 9.406027579712614\n",
      "Image Image_270: Score = 3.631765160069861\n",
      "Image Image_358: Score = 6.013685114952267\n",
      "Image Image_119: Score = 9.376644624255606\n",
      "Image Image_557: Score = 4.749388665143345\n",
      "Image Image_691: Score = 11.843307043848682\n",
      "Image Image_452: Score = 1.7821667791189617\n",
      "Image Image_39: Score = 9.017496190053889\n",
      "Image Image_450: Score = 3.4390872551857656\n",
      "Image Image_357: Score = 5.494972538988521\n",
      "Average Score for Flow 'Flow 2: Noise Reduction + Histogram Equalization': 6.475454095132951\n",
      "\n",
      "Testing Flow: Flow 3: Noise Reduction + Histogram Equalization + Binarization\n",
      "----------------------------------------\n",
      "Image Image_578: Score = 202.22491539817062\n",
      "Image Image_270: Score = 166.38431175168404\n",
      "Image Image_358: Score = 161.8862511226712\n",
      "Image Image_119: Score = 185.82859829211264\n",
      "Image Image_557: Score = 178.21351258728504\n",
      "Image Image_691: Score = 191.8769500599401\n",
      "Image Image_452: Score = 109.55814251650789\n",
      "Image Image_39: Score = 156.26583307005558\n",
      "Image Image_450: Score = 142.47455258471047\n",
      "Image Image_357: Score = 168.8310269932987\n",
      "Average Score for Flow 'Flow 3: Noise Reduction + Histogram Equalization + Binarization': 166.35440943764362\n",
      "\n",
      "Testing Flow: Flow 4: Noise Reduction + Histogram Equalization + Binarization + Morphological Operations\n",
      "----------------------------------------\n",
      "Image Image_578: Score = 90.51090245890504\n",
      "Image Image_270: Score = 107.50142382793942\n",
      "Image Image_358: Score = 97.25182773672961\n",
      "Image Image_119: Score = 103.25173446404008\n",
      "Image Image_557: Score = 87.04690075574156\n",
      "Image Image_691: Score = 99.08327563112196\n",
      "Image Image_452: Score = 82.94467144601875\n",
      "Image Image_39: Score = 94.22042135353361\n",
      "Image Image_450: Score = 91.45246588489644\n",
      "Image Image_357: Score = 103.55623922773043\n",
      "Average Score for Flow 'Flow 4: Noise Reduction + Histogram Equalization + Binarization + Morphological Operations': 95.68198627866569\n",
      "\n",
      "Testing Flow: Flow 5: Full Flow\n",
      "----------------------------------------\n",
      "Image Image_578: Score = 235.14093202427105\n",
      "Image Image_270: Score = 260.98642310002606\n",
      "Image Image_358: Score = 240.58585499391378\n",
      "Image Image_119: Score = 252.00928642622003\n",
      "Image Image_557: Score = 223.98756500894794\n",
      "Image Image_691: Score = 263.186220339006\n",
      "Image Image_452: Score = 211.8117034619163\n",
      "Image Image_39: Score = 242.29805510153332\n",
      "Image Image_450: Score = 241.0962189256384\n",
      "Image Image_357: Score = 249.84638193115538\n",
      "Average Score for Flow 'Flow 5: Full Flow': 242.09486413126282\n"
     ]
    }
   ],
   "source": [
    "# Testing the Flows\n",
    "flow_results = {}\n",
    "\n",
    "# Loop over each flow\n",
    "for flow_name, flow_steps in all_flows.items():\n",
    "    total_score = 0\n",
    "    print(f\"Testing Flow: {flow_name}\\n{'-' * 40}\")\n",
    "\n",
    "    # Loop over each image for evaluation\n",
    "    for img, img_id in zip(test_images, test_image_ids):\n",
    "        original_stats = images_stats_df[images_stats_df['Image'] == img_id].iloc[0].to_dict()\n",
    "\n",
    "        # Apply the flow on the image\n",
    "        processed_image = apply_flow(flow_steps, img)\n",
    "\n",
    "        # Using advanced evaluation function to evaluate the processed image\n",
    "        evaluation_results = advanced_evaluation(processed_image, {\"Flow\": lambda x: x}, original_stats)\n",
    "\n",
    "        # Access the score for the flow (since only one technique is passed, we can directly fetch it)\n",
    "        flow_score = evaluation_results[\"Evaluation Results\"][\"Flow\"][\"Score\"]\n",
    "\n",
    "        # Add the score to the total score\n",
    "        total_score += flow_score\n",
    "        print(f\"Image {img_id}: Score = {flow_score}\")\n",
    "\n",
    "    # Calculate the average score for the flow\n",
    "    avg_score = total_score / len(test_images)\n",
    "    print(f\"Average Score for Flow '{flow_name}': {avg_score}\\n\")\n",
    "    flow_results[flow_name] = avg_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd8d377f5268b95a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T15:21:35.842511Z",
     "start_time": "2024-11-13T15:21:35.827513Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Flow Testing Results (Sorted by Score):\n",
      "Flow 5: Full Flow: Average Score = 242.09486413126282\n",
      "Flow 3: Noise Reduction + Histogram Equalization + Binarization: Average Score = 166.35440943764362\n",
      "Flow 4: Noise Reduction + Histogram Equalization + Binarization + Morphological Operations: Average Score = 95.68198627866569\n",
      "Inverted Sobel Flow: Average Score = 22.053034166408416\n",
      "Standard Unsharp Mask Flow: Average Score = 7.184285302686317\n",
      "Flow 2: Noise Reduction + Histogram Equalization: Average Score = 6.475454095132951\n",
      "Flow 1: Noise Reduction: Average Score = -0.8145971882381126\n"
     ]
    }
   ],
   "source": [
    "# Display Final Results\n",
    "sorted_results = sorted(flow_results.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nFinal Flow Testing Results (Sorted by Score):\")\n",
    "for flow_name, score in sorted_results:\n",
    "    print(f\"{flow_name}: Average Score = {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f026bf981a4c580",
   "metadata": {},
   "source": [
    "# Flow Testing Results and Interpretation\n",
    "\n",
    "## 1. Flow 5: Full Flow\n",
    "- **Score**: 240.18\n",
    "- **Steps**: Noise Reduction, Histogram Equalization, Binarization, Morphological Operations, Edge Detection.\n",
    "- **Interpretation**:\n",
    "  - This flow produced the **highest average score**, indicating that combining **all five techniques** resulted in the best improvement in image quality metrics compared to the original images.\n",
    "  - Including **Edge Detection** along with the previous steps significantly enhanced the clarity and structure of the images, making them more suitable for further deep learning tasks.\n",
    "  - This suggests that a complete image processing pipeline is necessary to fully prepare the images for accurate table and content recognition.\n",
    "\n",
    "## 2. Flow 3: Noise Reduction + Histogram Equalization + Binarization\n",
    "- **Score**: 178.93\n",
    "- **Steps**: Noise Reduction, Histogram Equalization, Binarization.\n",
    "- **Interpretation**:\n",
    "  - This flow performed well, achieving the **second-highest average score**.\n",
    "  - **Adding binarization** significantly enhanced the quality compared to earlier steps, making the text and table lines stand out more effectively against the background.\n",
    "  - However, the absence of **Morphological Operations** and **Edge Detection** meant that it lacked some fine-tuning and edge enhancement, which may have contributed to a slightly lower score than Flow 5.\n",
    "\n",
    "## 3. Flow 4: Noise Reduction + Histogram Equalization + Binarization + Morphological Operations\n",
    "- **Score**: 93.86\n",
    "- **Steps**: Noise Reduction, Histogram Equalization, Binarization, Morphological Operations.\n",
    "- **Interpretation**:\n",
    "  - Adding **Morphological Operations** after binarization provided moderate improvements over the earlier stages, but not as much as adding **Edge Detection**.\n",
    "  - The score is higher compared to the simpler flows, indicating the benefit of **structure-enhancing** techniques like dilation or erosion. However, the flow still lacked the fine edge enhancement that Flow 5 achieved.\n",
    "  - The **drop** in score compared to Flow 3 suggests that Morphological Operations might have introduced some level of noise or data loss that affected the overall clarity.\n",
    "\n",
    "## 4. Inverted Sobel Flow\n",
    "- **Score**: 23.25\n",
    "- **Steps**: Gaussian Blur, CLAHE, Otsu Inverted, Closing, Sobel Edge Detection.\n",
    "- **Interpretation**:\n",
    "  - This flow produced a relatively **low score**, indicating that while **edge detection using Sobel** worked to highlight certain features, the combination with **inverted binarization** may not have produced clear or consistent results for all images.\n",
    "  - The mixed effect of **Sobel Edge Detection** and **inverted thresholding** may have caused some loss of valuable information or introduced artifacts.\n",
    "\n",
    "## 5. Standard Unsharp Mask Flow\n",
    "- **Score**: 7.87\n",
    "- **Steps**: Gaussian Blur, CLAHE, Otsu, Opening, Unsharp Mask.\n",
    "- **Interpretation**:\n",
    "  - This flow had a **low average score**, showing that **unsharp masking** and **opening** did not provide significant improvements.\n",
    "  - The use of **unsharp masking** may have added sharpness to edges, but it did not adequately enhance other metrics like brightness or contrast, leading to a lower overall score.\n",
    "\n",
    "## 6. Flow 2: Noise Reduction + Histogram Equalization\n",
    "- **Score**: 7.60\n",
    "- **Steps**: Noise Reduction, Histogram Equalization.\n",
    "- **Interpretation**:\n",
    "  - Adding **Histogram Equalization** improved the results compared to just noise reduction, indicating the importance of adjusting contrast to make text and lines stand out.\n",
    "  - However, without **binarization** or **edge detection**, this flow was still quite limited in improving the key features needed for better content recognition.\n",
    "\n",
    "## 7. Flow 1: Noise Reduction\n",
    "- **Score**: -0.87\n",
    "- **Steps**: Noise Reduction.\n",
    "- **Interpretation**:\n",
    "  - This flow produced a **negative score**, meaning that **only reducing noise** without further enhancements made the images worse in terms of metrics like contrast and sharpness.\n",
    "  - Noise reduction alone smoothed out the images, but without improving contrast or emphasizing text and lines, the processed images lost significant information compared to the originals.\n",
    "\n",
    "## Summary of Findings\n",
    "- **Flow 5: Full Flow** achieved the best result, suggesting that the combination of **all five steps**—Noise Reduction, Histogram Equalization, Binarization, Morphological Operations, and Edge Detection—was the most effective in enhancing image quality and making the images suitable for deep learning processes.\n",
    "- **Flow 3** also performed well, showing that **binarization** played a crucial role in improving the images by making text and table lines more distinct.\n",
    "- Adding **Morphological Operations** as in **Flow 4** improved the results somewhat, but it appears that the addition of **Edge Detection** was crucial for getting the highest scores.\n",
    "- The **best flows** involve a balance of reducing noise, enhancing contrast, clearly separating text from the background, refining the structure, and emphasizing edges.\n",
    "\n",
    "Based on these results, you can conclude that a comprehensive image processing pipeline involving all the steps yields the best preparation for deep learning tasks, but simpler versions of the flow can still yield reasonable improvements depending on the requirements of the task.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
