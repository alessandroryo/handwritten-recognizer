{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preparation - IT2 - Choosing best flow "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f2763dd6ef39f85"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47c25980e7f919ae",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:41:28.317070Z",
     "start_time": "2024-11-18T16:41:28.282071Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the paths\n",
    "folder_path = '../data/original'  # Update this path to point to your specific folder containing images\n",
    "output_folder = '../data/processed'  # Update this path to the desired output folder\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:41:28.333070Z",
     "start_time": "2024-11-18T16:41:28.320073Z"
    }
   },
   "id": "8b59f9c089d5576e",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Images and stats"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fe9242f22a8b58c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load image paths\n",
    "def load_images_from_folder(folder_path, extensions=('.png', '.jpg', '.jpeg', '.JPG')):\n",
    "    \"\"\"\n",
    "    Load all image file paths from a specified folder that match the given file extensions.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing the images.\n",
    "    extensions (tuple of str): A tuple of file extensions to filter the images by. \n",
    "                               Default is ('.png', '.jpg', '.jpeg', '.JPG').\n",
    "\n",
    "    Returns:\n",
    "    list: A list of full file paths to images in the folder that match the specified extensions.\n",
    "    \n",
    "    Raises:\n",
    "    FileNotFoundError: If the specified folder does not exist.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        raise FileNotFoundError(f\"The specified folder does not exist: {folder_path}\")\n",
    "\n",
    "    # List comprehension to gather all image paths with the specified extensions\n",
    "    image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(extensions)]\n",
    "\n",
    "    return image_paths\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:41:28.348070Z",
     "start_time": "2024-11-18T16:41:28.334070Z"
    }
   },
   "id": "aa5e77ec95ee7c9f",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load and preprocess images\n",
    "def load_and_preprocess_images(image_paths, resize_dim=(256, 256)):\n",
    "    images = []\n",
    "    image_ids = []\n",
    "\n",
    "    # Initialize tqdm progress bar\n",
    "    for path in tqdm(image_paths, desc=\"Loading and preprocessing images\", unit=\"image\"):\n",
    "        img = cv2.imread(path)\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "        img_resized = cv2.resize(img_gray, resize_dim)  # Resize for consistency\n",
    "        images.append(img_resized)\n",
    "        image_ids.append(f'Image_{len(images)}')  # Assign image ID as Image_1, Image_2, etc.\n",
    "\n",
    "    return images, image_ids\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:41:28.363071Z",
     "start_time": "2024-11-18T16:41:28.352070Z"
    }
   },
   "id": "361e15f49831c54f",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing images: 100%|██████████| 698/698 [02:41<00:00,  4.32image/s]\n"
     ]
    }
   ],
   "source": [
    "# Load all image file paths from the specified folder\n",
    "image_paths_all = load_images_from_folder(folder_path)\n",
    "\n",
    "# Load and preprocess all images\n",
    "total_images, total_image_ids = load_and_preprocess_images(image_paths_all)\n",
    "\n",
    "# Randomly select 10 images for experimentation\n",
    "experiment_indices = random.sample(range(len(total_images)), 10)\n",
    "test_images = [total_images[i] for i in experiment_indices]\n",
    "test_image_ids = [total_image_ids[i] for i in experiment_indices]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:44:10.139192Z",
     "start_time": "2024-11-18T16:41:28.365091Z"
    }
   },
   "id": "22a4ddc7dcb0bfc2",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the CSV file with the image statistics\n",
    "images_stats_path = \"../data-understanding/images_stats.csv\"\n",
    "images_stats_df = pd.read_csv(images_stats_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:44:10.187191Z",
     "start_time": "2024-11-18T16:44:10.142192Z"
    }
   },
   "id": "37eaa079e7c6d124",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions of Characteristics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a24c604acb58db6b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Image Characteristics Calculation Functions - from data understanding it2\n",
    "def calculate_brightness(image):\n",
    "    return np.mean(image)\n",
    "\n",
    "def calculate_sharpness(image):\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\n",
    "def calculate_contrast(image):\n",
    "    return image.std()\n",
    "\n",
    "def calculate_noise(image):\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    noise = cv2.absdiff(image, blurred)\n",
    "    return np.var(noise)\n",
    "\n",
    "# def calculate_skew(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "#     _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "#     coords = np.column_stack(np.where(binary > 0))\n",
    "#     if coords.size == 0:\n",
    "#         return 0\n",
    "#     angle = cv2.minAreaRect(coords)[-1]\n",
    "#     if angle < -45:\n",
    "#         angle = -(90 + angle)\n",
    "#     else:\n",
    "#         angle = -angle\n",
    "#     if abs(angle) < 1e-2:\n",
    "#         angle = 0\n",
    "#     return round(angle, 2)\n",
    "# \n",
    "# def calculate_line_spacing(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "# \n",
    "#     # Ensure the image is in the correct format for findContours\n",
    "#     if image.dtype != np.uint8:\n",
    "#         image = cv2.convertScaleAbs(image)\n",
    "# \n",
    "#     _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "#     contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     heights = [cv2.boundingRect(contour)[3] for contour in contours]\n",
    "#     if len(heights) > 1:\n",
    "#         line_spacing = np.mean(np.diff(sorted(heights)))\n",
    "#     else:\n",
    "#         line_spacing = 0\n",
    "#     return line_spacing\n",
    "# \n",
    "# \n",
    "# def detect_tables(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "# \n",
    "#     # Ensure the image is in the correct format for adaptiveThreshold\n",
    "#     if image.dtype != np.uint8:\n",
    "#         image = cv2.convertScaleAbs(image)\n",
    "# \n",
    "#     # Apply binary threshold and adaptive threshold\n",
    "#     _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "#     binary = cv2.adaptiveThreshold(binary, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "# \n",
    "#     # Find contours in the image\n",
    "#     contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     table_contours = [contour for contour in contours if cv2.contourArea(contour) > 1000]\n",
    "# \n",
    "#     return len(table_contours)\n",
    "# \n",
    "# \n",
    "# def calculate_resolution(image):\n",
    "#     height, width = image.shape[:2]\n",
    "#     return height * width\n",
    "# \n",
    "# def calculate_elements_detection(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "# \n",
    "#     # Ensure the image is in the correct format for findContours\n",
    "#     if image.dtype != np.uint8:\n",
    "#         image = cv2.convertScaleAbs(image)\n",
    "# \n",
    "#     # Apply binary threshold\n",
    "#     _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "# \n",
    "#     # Find contours\n",
    "#     contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     return len(contours)\n",
    "# \n",
    "# \n",
    "# def calculate_texture(image):\n",
    "#     laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "#     return laplacian.std()\n",
    "# \n",
    "# def calculate_patterns(image):\n",
    "#     if len(image.shape) != 2:\n",
    "#         raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "# \n",
    "#     # Ensure the image is in the correct format for Canny edge detection\n",
    "#     if image.dtype != np.uint8:\n",
    "#         image = cv2.convertScaleAbs(image)\n",
    "# \n",
    "#     # Apply Canny edge detection\n",
    "#     edges = cv2.Canny(image, 100, 200)\n",
    "# \n",
    "#     # Count the number of edge pixels\n",
    "#     return np.sum(edges > 0)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:44:10.203192Z",
     "start_time": "2024-11-18T16:44:10.190192Z"
    }
   },
   "id": "a9420b3f68d65e4e",
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation Function"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76105296fc098baa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def advanced_evaluation(image, techniques_dict, original_stats):\n",
    "    evaluation_results = {}\n",
    "\n",
    "    for technique_name, technique_func in techniques_dict.items():\n",
    "        # Apply the technique\n",
    "        processed_image = technique_func(image)\n",
    "\n",
    "        # Calculate characteristics for the processed image\n",
    "        stats = {\n",
    "            \"Brightness\": calculate_brightness(processed_image),\n",
    "            \"Sharpness\": calculate_sharpness(processed_image),\n",
    "            \"Contrast\": calculate_contrast(processed_image),\n",
    "            \"Noise\": calculate_noise(processed_image),\n",
    "        }\n",
    "\n",
    "        # Normalize metrics to comparable ranges (between 0 and 1, roughly)\n",
    "        stats_normalized = {\n",
    "            \"Brightness\": stats[\"Brightness\"] / 255,\n",
    "            \"Sharpness\": stats[\"Sharpness\"] / 1000,\n",
    "            \"Contrast\": stats[\"Contrast\"] / 255,\n",
    "            \"Noise\": stats[\"Noise\"] / 255,\n",
    "        }\n",
    "\n",
    "        # Normalize the original stats for comparison\n",
    "        original_stats_normalized = {\n",
    "            \"Brightness\": original_stats[\"Brightness\"] / 255,\n",
    "            \"Sharpness\": original_stats[\"Sharpness\"] / 1000,\n",
    "            \"Contrast\": original_stats[\"Contrast\"] / 255,\n",
    "            \"Noise\": original_stats[\"Noise\"] / 255,\n",
    "        }\n",
    "\n",
    "        # Weights for each characteristic (to determine their importance)\n",
    "        weights = {\n",
    "            \"Brightness\": -1.0,  # Closer to original is better (penalized if different) as they were in a good level before\n",
    "            \"Sharpness\": 2.0,    # Higher is better (rewarded if improved)\n",
    "            \"Contrast\": 1.0,     # Higher is better (rewarded if improved)\n",
    "            \"Noise\": -1.5,       # Lower is better (penalized if increased)\n",
    "        }\n",
    "\n",
    "        # Calculate score using normalized metrics and weights\n",
    "        score = 0\n",
    "        for metric, value in stats_normalized.items():\n",
    "            original_value = original_stats_normalized.get(metric, 0)\n",
    "            score += weights[metric] * (value - original_value)\n",
    "\n",
    "        evaluation_results[technique_name] = {\"Score\": score, \"Stats\": stats}\n",
    "\n",
    "    # Determine the best technique based on the highest score\n",
    "    best_technique = max(evaluation_results, key=lambda x: evaluation_results[x][\"Score\"])\n",
    "    return {\"Best Technique\": best_technique, \"Evaluation Results\": evaluation_results}\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:44:10.218201Z",
     "start_time": "2024-11-18T16:44:10.204193Z"
    }
   },
   "id": "initial_id",
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting the best techniques based on step 1.1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3610bf59adbc3b51"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the best techniques and parameters for each step\n",
    "best_techniques = {\n",
    "    \"Noise Reduction\": (lambda img: cv2.fastNlMeansDenoising(img, None, h=5, templateWindowSize=7, searchWindowSize=21)),\n",
    "    \"Histogram Equalization\": (lambda img: cv2.equalizeHist(img)),\n",
    "    \"Binarization\": (lambda img: cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, blockSize=11, C=2)),\n",
    "    \"Morphological Operations\": (lambda img: cv2.erode(img, np.ones((3, 3), np.uint8))),\n",
    "    \"Edge Detection\": (lambda img: cv2.Canny(img, threshold1=50, threshold2=150)),\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:44:10.233191Z",
     "start_time": "2024-11-18T16:44:10.220215Z"
    }
   },
   "id": "2cbfc1560547af5e",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using the previous flows found to be most suitable"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42c95072259bce52"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Best Flows from Previous Iteration\n",
    "previous_best_flows = {\n",
    "    \"Flow - CLAHE\": [\n",
    "        (\"Gaussian Blur\", lambda img: cv2.GaussianBlur(img, (5, 5), 0)),\n",
    "        (\"CLAHE\", lambda img: cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(img))\n",
    "    ]\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:44:10.249192Z",
     "start_time": "2024-11-18T16:44:10.234192Z"
    }
   },
   "id": "ea1849a781f0e5f7",
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting flows based on best techniques"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba0642c4b3339434"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create New Flows Incrementally\n",
    "new_flows = {\n",
    "    \"Flow 1: Noise Reduction\": [\n",
    "        (\"Noise Reduction\", best_techniques[\"Noise Reduction\"])\n",
    "    ],\n",
    "    \"Flow 2: Noise Reduction + Histogram Equalization\": [\n",
    "        (\"Noise Reduction\", best_techniques[\"Noise Reduction\"]),\n",
    "        (\"Histogram Equalization\", best_techniques[\"Histogram Equalization\"])\n",
    "    ],\n",
    "    \"Flow 3: Noise Reduction + Histogram Equalization + Binarization\": [\n",
    "        (\"Noise Reduction\", best_techniques[\"Noise Reduction\"]),\n",
    "        (\"Histogram Equalization\", best_techniques[\"Histogram Equalization\"]),\n",
    "        (\"Binarization\", best_techniques[\"Binarization\"])\n",
    "    ],\n",
    "    \"Flow 4: Noise Reduction + Histogram Equalization + Binarization + Morphological Operations\": [\n",
    "        (\"Noise Reduction\", best_techniques[\"Noise Reduction\"]),\n",
    "        (\"Histogram Equalization\", best_techniques[\"Histogram Equalization\"]),\n",
    "        (\"Binarization\", best_techniques[\"Binarization\"]),\n",
    "        (\"Morphological Operations\", best_techniques[\"Morphological Operations\"])\n",
    "    ],\n",
    "    \"Flow 5: Full Flow\": [\n",
    "        (\"Noise Reduction\", best_techniques[\"Noise Reduction\"]),\n",
    "        (\"Histogram Equalization\", best_techniques[\"Histogram Equalization\"]),\n",
    "        (\"Binarization\", best_techniques[\"Binarization\"]),\n",
    "        (\"Morphological Operations\", best_techniques[\"Morphological Operations\"]),\n",
    "        (\"Edge Detection\", best_techniques[\"Edge Detection\"])\n",
    "    ]\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:44:10.264198Z",
     "start_time": "2024-11-18T16:44:10.251192Z"
    }
   },
   "id": "60a34877d455cb05",
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepearing and running the flows"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "147cb3cb7f879f27"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Combine all flows\n",
    "all_flows = {**previous_best_flows, **new_flows}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:44:10.280191Z",
     "start_time": "2024-11-18T16:44:10.266191Z"
    }
   },
   "id": "84ba0ef4c75cb75e",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to apply a flow to an image\n",
    "def apply_flow(flow, image):\n",
    "    for step_name, technique in flow:\n",
    "        image = technique(image)\n",
    "    return image\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:44:10.296202Z",
     "start_time": "2024-11-18T16:44:10.282191Z"
    }
   },
   "id": "96fc83f73b2a4041",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Flow: Flow - CLAHE\n",
      "----------------------------------------\n",
      "Image Image_338: Score = -0.7962729785216383\n",
      "Image Image_372: Score = -2.2091320467620092\n",
      "Image Image_539: Score = -3.394193565020206\n",
      "Image Image_128: Score = -1.743632209612172\n",
      "Image Image_173: Score = -1.5284510925833246\n",
      "Image Image_41: Score = -1.5275381477795635\n",
      "Image Image_690: Score = -2.404918095628553\n",
      "Image Image_498: Score = -1.7921267088557724\n",
      "Image Image_38: Score = -2.1785407206770686\n",
      "Image Image_83: Score = -1.176229097051851\n",
      "Average Score for Flow 'Flow - CLAHE': -1.8751034662492159\n",
      "\n",
      "Testing Flow: Flow 1: Noise Reduction\n",
      "----------------------------------------\n",
      "Image Image_338: Score = -0.2547880676802674\n",
      "Image Image_372: Score = -0.20983468310315936\n",
      "Image Image_539: Score = -0.22989545345595758\n",
      "Image Image_128: Score = -0.2427408631386082\n",
      "Image Image_173: Score = -0.3012814414122185\n",
      "Image Image_41: Score = -0.41469975947918564\n",
      "Image Image_690: Score = -0.2869703949106332\n",
      "Image Image_498: Score = -0.2601519296331101\n",
      "Image Image_38: Score = -0.3973018058381782\n",
      "Image Image_83: Score = -0.3435373256730224\n",
      "Average Score for Flow 'Flow 1: Noise Reduction': -0.29412017243243405\n",
      "\n",
      "Testing Flow: Flow 2: Noise Reduction + Histogram Equalization\n",
      "----------------------------------------\n",
      "Image Image_338: Score = 3.291384849885259\n",
      "Image Image_372: Score = 5.1544774672105715\n",
      "Image Image_539: Score = 5.356154875709988\n",
      "Image Image_128: Score = 4.762689134432041\n",
      "Image Image_173: Score = 4.423213240217878\n",
      "Image Image_41: Score = 4.139182581533152\n",
      "Image Image_690: Score = 2.6039806563714065\n",
      "Image Image_498: Score = 2.024283700275477\n",
      "Image Image_38: Score = 5.4313318091496985\n",
      "Image Image_83: Score = 3.556922705936809\n",
      "Average Score for Flow 'Flow 2: Noise Reduction + Histogram Equalization': 4.074362102072227\n",
      "\n",
      "Testing Flow: Flow 3: Noise Reduction + Histogram Equalization + Binarization\n",
      "----------------------------------------\n",
      "Image Image_338: Score = 150.03752528526636\n",
      "Image Image_372: Score = 172.9298321053755\n",
      "Image Image_539: Score = 178.82753022893553\n",
      "Image Image_128: Score = 168.96957975296476\n",
      "Image Image_173: Score = 171.42233041967492\n",
      "Image Image_41: Score = 156.32391917247085\n",
      "Image Image_690: Score = 142.41826178939365\n",
      "Image Image_498: Score = 136.6846811294871\n",
      "Image Image_38: Score = 177.207288272991\n",
      "Image Image_83: Score = 153.42308061387052\n",
      "Average Score for Flow 'Flow 3: Noise Reduction + Histogram Equalization + Binarization': 160.82440287704304\n",
      "\n",
      "Testing Flow: Flow 4: Noise Reduction + Histogram Equalization + Binarization + Morphological Operations\n",
      "----------------------------------------\n",
      "Image Image_338: Score = 83.35004907189695\n",
      "Image Image_372: Score = 89.72773857566018\n",
      "Image Image_539: Score = 80.37910971806144\n",
      "Image Image_128: Score = 82.50083209436173\n",
      "Image Image_173: Score = 86.53552076993488\n",
      "Image Image_41: Score = 82.29104522832336\n",
      "Image Image_690: Score = 75.52753215419656\n",
      "Image Image_498: Score = 86.98688000624739\n",
      "Image Image_38: Score = 77.75467345757731\n",
      "Image Image_83: Score = 78.91637611503724\n",
      "Average Score for Flow 'Flow 4: Noise Reduction + Histogram Equalization + Binarization + Morphological Operations': 82.3969757191297\n",
      "\n",
      "Testing Flow: Flow 5: Full Flow\n",
      "----------------------------------------\n",
      "Image Image_338: Score = 217.57329874236592\n",
      "Image Image_372: Score = 241.31225174043095\n",
      "Image Image_539: Score = 218.891150750291\n",
      "Image Image_128: Score = 222.2166707243861\n",
      "Image Image_173: Score = 229.35730614181008\n",
      "Image Image_41: Score = 219.2627744651352\n",
      "Image Image_690: Score = 215.00733972859163\n",
      "Image Image_498: Score = 234.9134191612073\n",
      "Image Image_38: Score = 214.9793319857995\n",
      "Image Image_83: Score = 212.17903175684185\n",
      "Average Score for Flow 'Flow 5: Full Flow': 222.56925751968592\n"
     ]
    }
   ],
   "source": [
    "# Testing the Flows\n",
    "flow_results = {}\n",
    "\n",
    "# Loop over each flow\n",
    "for flow_name, flow_steps in all_flows.items():\n",
    "    total_score = 0\n",
    "    print(f\"Testing Flow: {flow_name}\\n{'-' * 40}\")\n",
    "\n",
    "    # Loop over each image for evaluation\n",
    "    for img, img_id in zip(test_images, test_image_ids):\n",
    "        original_stats = images_stats_df[images_stats_df['Image'] == img_id].iloc[0].to_dict()\n",
    "\n",
    "        # Apply the flow on the image\n",
    "        processed_image = apply_flow(flow_steps, img)\n",
    "\n",
    "        # Using advanced evaluation function to evaluate the processed image\n",
    "        evaluation_results = advanced_evaluation(processed_image, {\"Flow\": lambda x: x}, original_stats)\n",
    "\n",
    "        # Access the score for the flow (since only one technique is passed, we can directly fetch it)\n",
    "        flow_score = evaluation_results[\"Evaluation Results\"][\"Flow\"][\"Score\"]\n",
    "\n",
    "        # Add the score to the total score\n",
    "        total_score += flow_score\n",
    "        print(f\"Image {img_id}: Score = {flow_score}\")\n",
    "\n",
    "    # Calculate the average score for the flow\n",
    "    avg_score = total_score / len(test_images)\n",
    "    print(f\"Average Score for Flow '{flow_name}': {avg_score}\\n\")\n",
    "    flow_results[flow_name] = avg_score\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:44:17.111198Z",
     "start_time": "2024-11-18T16:44:10.298192Z"
    }
   },
   "id": "ad651372d796060",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Flow Testing Results (Sorted by Score):\n",
      "Flow 5: Full Flow: Average Score = 222.56925751968592\n",
      "Flow 3: Noise Reduction + Histogram Equalization + Binarization: Average Score = 160.82440287704304\n",
      "Flow 4: Noise Reduction + Histogram Equalization + Binarization + Morphological Operations: Average Score = 82.3969757191297\n",
      "Flow 2: Noise Reduction + Histogram Equalization: Average Score = 4.074362102072227\n",
      "Flow 1: Noise Reduction: Average Score = -0.29412017243243405\n",
      "Flow - CLAHE: Average Score = -1.8751034662492159\n"
     ]
    }
   ],
   "source": [
    "# Display Final Results\n",
    "sorted_results = sorted(flow_results.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nFinal Flow Testing Results (Sorted by Score):\")\n",
    "for flow_name, score in sorted_results:\n",
    "    print(f\"{flow_name}: Average Score = {score}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T16:44:17.127191Z",
     "start_time": "2024-11-18T16:44:17.112192Z"
    }
   },
   "id": "fd8d377f5268b95a",
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "Final Flow Testing Results (Sorted by Score):\n",
    "Flow 5: Full Flow: Average Score = 222.57\n",
    "Flow 3: Noise Reduction + Histogram Equalization + Binarization: Average Score = 160.82\n",
    "Flow 4: Noise Reduction + Histogram Equalization + Binarization + Morphological Operations: Average Score = 82.40\n",
    "Flow 2: Noise Reduction + Histogram Equalization: Average Score = 4.07\n",
    "Flow 1: Noise Reduction: Average Score = -0.29\n",
    "Flow - CLAHE: Average Score = -1.88\n",
    "\n",
    "# Flow Testing Results and Interpretation\n",
    "\n",
    "## 1. Flow 5: Full Flow\n",
    "- **Score**: 222.57\n",
    "- **Steps**: Noise Reduction, Histogram Equalization, Binarization, Morphological Operations, Edge Detection.\n",
    "- **Interpretation**:\n",
    "  - This flow produced the **highest average score**, indicating that combining **all five techniques** resulted in the best improvement in image quality metrics compared to the original images.\n",
    "  - Including **Edge Detection** along with the previous steps significantly enhanced the clarity and structure of the images, making them more suitable for further deep learning tasks.\n",
    "  - This suggests that a complete image processing pipeline is necessary to fully prepare the images for accurate table and content recognition.\n",
    "\n",
    "## 2. Flow 3: Noise Reduction + Histogram Equalization + Binarization\n",
    "- **Score**: 160.82\n",
    "- **Steps**: Noise Reduction, Histogram Equalization, Binarization.\n",
    "- **Interpretation**:\n",
    "  - This flow performed well, achieving the **second-highest average score**.\n",
    "  - **Adding Binarization** significantly enhanced the quality compared to earlier steps, making the text and table lines stand out more effectively against the background.\n",
    "  - However, the absence of **Morphological Operations** and **Edge Detection** meant that it lacked some fine-tuning and edge enhancement, which may have contributed to a slightly lower score than Flow 5.\n",
    "\n",
    "## 3. Flow 4: Noise Reduction + Histogram Equalization + Binarization + Morphological Operations\n",
    "- **Score**: 82.40\n",
    "- **Steps**: Noise Reduction, Histogram Equalization, Binarization, Morphological Operations.\n",
    "- **Interpretation**:\n",
    "  - Adding **Morphological Operations** after binarization provided moderate improvements over the earlier stages, but not as much as adding **Edge Detection**.\n",
    "  - The score is higher compared to the simpler flows, indicating the benefit of **structure-enhancing** techniques like erosion. However, the flow still lacked the fine edge enhancement that Flow 5 achieved.\n",
    "  - The **drop** in score compared to Flow 3 suggests that Morphological Operations might have introduced some level of noise or data loss that affected the overall clarity.\n",
    "\n",
    "## 4. Flow 2: Noise Reduction + Histogram Equalization\n",
    "- **Score**: 4.07\n",
    "- **Steps**: Noise Reduction, Histogram Equalization.\n",
    "- **Interpretation**:\n",
    "  - Adding **Histogram Equalization** improved the results compared to just noise reduction, indicating the importance of adjusting contrast to make text and lines stand out.\n",
    "  - However, without **binarization** or **edge detection**, this flow was still quite limited in improving the key features needed for better content recognition.\n",
    "\n",
    "## 5. Flow 1: Noise Reduction\n",
    "- **Score**: -0.29\n",
    "- **Steps**: Noise Reduction.\n",
    "- **Interpretation**:\n",
    "  - This flow produced a **negative score**, meaning that **only reducing noise** without further enhancements made the images worse in terms of metrics like contrast and sharpness.\n",
    "  - Noise reduction alone smoothed out the images, but without improving contrast or emphasizing text and lines, the processed images lost significant information compared to the originals.\n",
    "\n",
    "## 6. Flow - CLAHE\n",
    "- **Score**: -1.88\n",
    "- **Steps**: CLAHE.\n",
    "- **Interpretation**:\n",
    "  - This flow produced a **negative score**, indicating that applying **CLAHE** alone did not effectively enhance the images.\n",
    "  - The results suggest that **contrast enhancement** without additional noise reduction or edge detection was not sufficient to improve the overall image quality.\n",
    "\n",
    "## Summary of Findings\n",
    "- **Flow 5: Full Flow** achieved the best result, suggesting that the combination of **all five steps**—Noise Reduction, Histogram Equalization, Binarization, Morphological Operations, and Edge Detection—was the most effective in enhancing image quality and making the images suitable for deep learning processes.\n",
    "- **Flow 3** also performed well, showing that **Binarization** played a crucial role in improving the images by making text and table lines more distinct.\n",
    "- Adding **Morphological Operations** as in **Flow 4** improved the results somewhat, but it appears that the addition of **Edge Detection** was crucial for getting the highest scores.\n",
    "- The **best flows** involve a balance of reducing noise, enhancing contrast, clearly separating text from the background, refining the structure, and emphasizing edges.\n",
    "\n",
    "Based on these results, you can conclude that a comprehensive image processing pipeline involving all the steps yields the best preparation for deep learning tasks, but simpler versions of the flow can still yield reasonable improvements depending on the requirements of the task.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f026bf981a4c580"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5de9fd33b2569524"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
