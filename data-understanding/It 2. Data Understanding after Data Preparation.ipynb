{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 2 - Data Understanding after Data Preparation\n",
    "\n",
    "> **Creator**: Ryo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the folder containing the images to be processed\n",
    "folder_path = '../data/data-understanding/2. Non Duplicated/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Images Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Image Paths From Source Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder_path, extensions=('.png', '.jpg', '.jpeg', '.JPG')):\n",
    "    \"\"\"\n",
    "    Load all image file paths from a specified folder that match the given file extensions.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing the images.\n",
    "    extensions (tuple of str): A tuple of file extensions to filter the images by. \n",
    "                                Default is ('.png', '.jpg', '.jpeg', '.JPG').\n",
    "\n",
    "    Returns:\n",
    "    list: A list of full file paths to images in the folder that match the specified extensions.\n",
    "    \n",
    "    Raises:\n",
    "    FileNotFoundError: If the specified folder does not exist.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        raise FileNotFoundError(f\"The specified folder does not exist: {folder_path}\")\n",
    "\n",
    "    # List comprehension to gather all image paths with the specified extensions\n",
    "    image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(extensions)]\n",
    "\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Pre-Process Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_images(image_paths):\n",
    "    \"\"\"\n",
    "    Load and preprocess a list of images by converting to grayscale without resizing.\n",
    "    \n",
    "    Parameters:\n",
    "    image_paths (list): List of paths to image files.\n",
    "    \n",
    "    Returns:\n",
    "    list: List of preprocessed images as numpy arrays (grayscale images).\n",
    "    \"\"\"\n",
    "    images = []  # Initialize list to store preprocessed images\n",
    "\n",
    "    # Initialize tqdm progress bar to track loading and processing of images\n",
    "    for path in tqdm(image_paths, desc=\"Loading and preprocessing images\", unit=\"image\"):\n",
    "        # Load the image from file\n",
    "        img = cv2.imread(path)  \n",
    "        \n",
    "        # Check if the image is loaded successfully\n",
    "        if img is None:\n",
    "            print(f\"Warning: Unable to load image at {path}\")\n",
    "            continue\n",
    "        \n",
    "        # Convert image to grayscale\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  \n",
    "        \n",
    "        # Append the processed image to the list\n",
    "        images.append(img_gray)  \n",
    "\n",
    "    return images  # Return list of preprocessed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(image_paths):\n",
    "    \"\"\"\n",
    "    Load a list of original images without any preprocessing.\n",
    "    \n",
    "    Parameters:\n",
    "    image_paths (list): List of paths to image files.\n",
    "    \n",
    "    Returns:\n",
    "    list: List of original images as numpy arrays.\n",
    "    \"\"\"\n",
    "    original_images = []  # Initialize list to store original images\n",
    "\n",
    "    # Loop over each image path in the provided list\n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path)  # Load the original image from file\n",
    "        original_images.append(img)  # Add the loaded image to the list\n",
    "\n",
    "    return original_images  # Return list of original images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = load_images_from_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = load_and_preprocess_images(image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_brightness(image):\n",
    "    \"\"\"\n",
    "    Calculate the brightness of an image based on the mean pixel intensity.\n",
    "    \n",
    "    Parameters:\n",
    "    image (numpy array): Input image as a numpy array. Should be in grayscale or \n",
    "                        single-channel format for accurate brightness calculation.\n",
    "                        \n",
    "    Returns:\n",
    "    float: The average brightness of the image.\n",
    "    \"\"\"\n",
    "    return np.mean(image)  # Calculate and return the mean pixel intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharpness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sharpness(image):\n",
    "    \"\"\"\n",
    "    Calculate the sharpness of an image based on the variance of the Laplacian.\n",
    "    \n",
    "    Parameters:\n",
    "    image (numpy array): Input image as a numpy array, preferably in grayscale \n",
    "                        for accurate sharpness calculation.\n",
    "                        \n",
    "    Returns:\n",
    "    float: A sharpness score based on the variance of the Laplacian. \n",
    "            Higher values indicate sharper images.\n",
    "    \"\"\"\n",
    "    # Apply Laplacian filter to the image and calculate its variance\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()  # Variance of Laplacian method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_contrast(image):\n",
    "    \"\"\"\n",
    "    Calculate the contrast of an image based on the standard deviation of pixel values.\n",
    "    \n",
    "    Parameters:\n",
    "    image (numpy array): Input image as a numpy array, preferably in grayscale.\n",
    "    \n",
    "    Returns:\n",
    "    float: A contrast score based on the standard deviation of pixel values.\n",
    "    \"\"\"\n",
    "    return image.std()  # Standard deviation of pixel values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_noise(image):\n",
    "    \"\"\"\n",
    "    Calculate the noise level of an image by analyzing the difference between\n",
    "    the original and a blurred version.\n",
    "    \n",
    "    Parameters:\n",
    "    image (numpy array): Input image as a numpy array.\n",
    "    \n",
    "    Returns:\n",
    "    float: A noise score based on the variance of the difference between the \n",
    "            original and blurred images.\n",
    "    \"\"\"\n",
    "    # Convert to grayscale if necessary\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to create a smoothed version of the image\n",
    "    blurred = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    \n",
    "    # Calculate the absolute difference between the original and blurred images\n",
    "    noise = cv2.absdiff(image, blurred)\n",
    "    \n",
    "    # Return the variance of the noise map as a measure of noise level\n",
    "    return np.var(noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_skew(image, max_lines=3):\n",
    "    \"\"\"\n",
    "    Detect vertical lines in the image and calculate their average skew angle.\n",
    "    \n",
    "    Parameters:\n",
    "    image (numpy array): Grayscale input image.\n",
    "    max_lines (int): Maximum number of vertical lines to detect and include in calculations.\n",
    "    \n",
    "    Returns:\n",
    "    float: \n",
    "        - Average skew angle in degrees between detected vertical lines and a perfectly vertical line.\n",
    "    list:\n",
    "        - Detected vertical lines in the format [(x1, y1, x2, y2), ...].\n",
    "    \"\"\"\n",
    "    # Validate input image\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Input image must be grayscale.\")\n",
    "\n",
    "    # Step 1: Adaptive thresholding for binary image\n",
    "    binary = cv2.adaptiveThreshold(\n",
    "        image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 10\n",
    "    )\n",
    "\n",
    "    # Step 2: Morphological operations to enhance vertical lines\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 25))  # Vertical emphasis\n",
    "    processed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Step 3: Detect edges using Canny edge detection\n",
    "    edges = cv2.Canny(processed, 50, 150, apertureSize=3)\n",
    "\n",
    "    # Step 4: Hough Line Transform to detect vertical lines\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=80, minLineLength=100, maxLineGap=20)\n",
    "\n",
    "    vertical_lines = []\n",
    "    angles = []\n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines[:max_lines]:  # Limit to max_lines\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "\n",
    "            # Calculate the angle of the line\n",
    "            delta_x = x2 - x1\n",
    "            delta_y = y2 - y1\n",
    "            angle = np.arctan2(delta_y, delta_x) * 180 / np.pi  # Angle in degrees\n",
    "\n",
    "            # Filter near-vertical lines (absolute angle close to 90째)\n",
    "            if abs(angle) > 80:  # Close to vertical\n",
    "                skew_angle = abs(90 - abs(angle))  # Calculate skew relative to 90째\n",
    "                vertical_lines.append((x1, y1, x2, y2))\n",
    "                angles.append(skew_angle)\n",
    "\n",
    "    # Calculate the average skew angle\n",
    "    average_skew = np.mean(angles) if angles else 0.0\n",
    "    return round(average_skew, 2), vertical_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Statistical Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Statistics Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_statistics_table(images, image_paths):\n",
    "    \"\"\"\n",
    "    Generate a table of essential statistics (brightness, sharpness, contrast, noise, skew) for a list of images.\n",
    "    \n",
    "    Parameters:\n",
    "    images (list): List of image arrays.\n",
    "    image_paths (list): List of image file names (not full paths) corresponding to each image.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing essential statistics for each image.\n",
    "    \"\"\"\n",
    "    stats_data = {\n",
    "        'Image': [], \n",
    "        'Brightness': [], \n",
    "        'Sharpness': [], \n",
    "        'Contrast': [], \n",
    "        'Noise': [], \n",
    "        'Skew': []\n",
    "    }\n",
    "\n",
    "    # Initialize tqdm progress bar for processing images\n",
    "    for img, image_name in tqdm(zip(images, image_paths), desc=\"Processing Images\", unit=\"image\"):\n",
    "        # Use the actual file name in the 'Image' column\n",
    "        stats_data['Image'].append(image_name)\n",
    "        \n",
    "        # Validate the image\n",
    "        if img is None or not isinstance(img, np.ndarray) or img.size == 0:\n",
    "            # Append None for each statistic if the image is invalid\n",
    "            for key in stats_data.keys():\n",
    "                if key != 'Image':\n",
    "                    stats_data[key].append(None)\n",
    "            print(f\"Warning: {image_name} is invalid or empty, setting values to None.\")\n",
    "            continue\n",
    "\n",
    "        # Calculate and append each statistic to the stats_data dictionary\n",
    "        stats_data['Brightness'].append(calculate_brightness(img))\n",
    "        stats_data['Sharpness'].append(calculate_sharpness(img))\n",
    "        stats_data['Contrast'].append(calculate_contrast(img))\n",
    "        stats_data['Noise'].append(calculate_noise(img))\n",
    "        skew, _ = calculate_skew(img)  # Only the skew value\n",
    "        stats_data['Skew'].append(skew)\n",
    "    \n",
    "    # Create a DataFrame to store per-image statistics\n",
    "    df = pd.DataFrame(stats_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Statistical Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_statistical_summary(df):\n",
    "    \"\"\"\n",
    "    Calculate an overall statistical summary for selected features in the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing image statistics with columns such as\n",
    "                    'Brightness', 'Sharpness', 'Contrast', 'Noise', and 'Skew'.\n",
    "                    \n",
    "    Returns:\n",
    "    pd.DataFrame: A summary DataFrame with descriptive statistics for each feature.\n",
    "    \"\"\"\n",
    "    # Select relevant columns for statistical summary\n",
    "    columns_to_summarize = ['Brightness', 'Sharpness', 'Contrast', 'Noise', 'Skew']\n",
    "    \n",
    "    # Filter only existing columns to avoid errors\n",
    "    available_columns = [col for col in columns_to_summarize if col in df.columns]\n",
    "    \n",
    "    if not available_columns:\n",
    "        raise ValueError(\"No relevant columns available in the DataFrame for summary.\")\n",
    "    \n",
    "    # Calculate summary statistics for the selected columns\n",
    "    summary_df = df[available_columns].describe()\n",
    "    \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Create Data Table*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a statistics table using the list of image paths\n",
    "df_stats = image_statistics_table(images, image_paths)\n",
    "\n",
    "# Display the full statistics table for all images\n",
    "print(\"Image Data Table:\")\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Overall Statistics Table*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and display the overall statistical summary\n",
    "summary_df = overall_statistical_summary(df_stats)\n",
    "\n",
    "print(\"\\nOverall Statistical Summary:\")\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristics Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define characteristics and their units in a single dictionary\n",
    "characteristics_units = {\n",
    "    'Brightness': 'Pixel Value (0-255)',\n",
    "    'Contrast': 'Pixel Value (0-255) Std Dev',\n",
    "    'Sharpness': 'Pixel Intensity Variability',\n",
    "    'Noise': 'Pixel Value (0-255) Std Dev',\n",
    "    'Skew': 'Degrees (째)'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Characteristics Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_characteristic_distribution(df, characteristic, unit, plot_type='hist'):\n",
    "    \"\"\"\n",
    "    Visualize the distribution of a specific characteristic in a DataFrame using histograms or box plots.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the data.\n",
    "    characteristic (str): The column name of the characteristic to plot.\n",
    "    unit (str): The unit of the characteristic, for labeling purposes.\n",
    "    plot_type (str): Type of plot to generate ('hist' for histogram, 'box' for box plot).\n",
    "                    Default is 'hist'.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Set up figure size for consistent visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Generate histogram or box plot based on the specified plot type\n",
    "    if plot_type == 'hist':\n",
    "        sns.histplot(df[characteristic], kde=True, bins=30, color='blue')\n",
    "    elif plot_type == 'box':\n",
    "        sns.boxplot(x=df[characteristic], color='green')\n",
    "    else:\n",
    "        raise ValueError(\"Invalid plot_type. Choose 'hist' for histogram or 'box' for box plot.\")\n",
    "\n",
    "    # Customize the plot with titles and labels\n",
    "    plt.title(f\"Distribution of {characteristic}\")\n",
    "    plt.xlabel(f\"{characteristic} ({unit})\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True)  # Add grid for better readability\n",
    "    plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily suppress FutureWarnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "    \n",
    "    # Loop through each characteristic and plot type\n",
    "    for characteristic, unit in characteristics_units.items():\n",
    "        for plot_type in ['hist', 'box']:\n",
    "            # Plot the distribution for each characteristic using the specified plot type\n",
    "            plot_characteristic_distribution(df_stats, characteristic, unit, plot_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Characteristics Relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_characteristic_relationship(df, characteristic_1, characteristic_2, unit_1, unit_2, use_color=False):\n",
    "    \"\"\"\n",
    "    Plot the relationship between two characteristics in a DataFrame using scatter plots.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the data.\n",
    "    characteristic_1 (str): The column name of the first characteristic (x-axis).\n",
    "    characteristic_2 (str): The column name of the second characteristic (y-axis).\n",
    "    unit_1 (str): The unit of the first characteristic, for x-axis labeling.\n",
    "    unit_2 (str): The unit of the second characteristic, for y-axis labeling.\n",
    "    use_color (bool): If True, color points by the values of `characteristic_2` to show variation.\n",
    "                    Default is False.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Set up figure size for consistent visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot scatter plot with optional color encoding\n",
    "    if use_color:\n",
    "        sns.scatterplot(x=df[characteristic_1], y=df[characteristic_2], \n",
    "                        hue=df[characteristic_2], palette='coolwarm', s=50)\n",
    "    else:\n",
    "        sns.scatterplot(x=df[characteristic_1], y=df[characteristic_2], s=50)\n",
    "\n",
    "    # Customize the plot with titles and labels\n",
    "    plt.title(f\"Relationship between {characteristic_1} and {characteristic_2}\")\n",
    "    plt.xlabel(f\"{characteristic_1} ({unit_1})\")\n",
    "    plt.ylabel(f\"{characteristic_2} ({unit_2})\")\n",
    "    plt.grid(True)  # Add grid for better readability\n",
    "    plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all possible pairs of characteristics for plotting relationships\n",
    "pairs = itertools.combinations(characteristics_units.keys(), 2)\n",
    "\n",
    "# Loop through each pair of characteristics and create relationship plots\n",
    "for char1, char2 in pairs:\n",
    "    plot_characteristic_relationship(\n",
    "        df_stats,\n",
    "        char1,\n",
    "        char2,\n",
    "        characteristics_units[char1],  # Retrieve unit for the first characteristic\n",
    "        characteristics_units[char2]   # Retrieve unit for the second characteristic\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_heatmap(df, characteristics, characteristic_units):\n",
    "    \"\"\"\n",
    "    Create a heatmap to visualize correlations between different characteristics.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the data.\n",
    "    characteristics (list of str): List of column names representing characteristics to include in the heatmap.\n",
    "    characteristic_units (list of str): List of units corresponding to each characteristic.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Set figure size for visibility\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Calculate the correlation matrix for the specified characteristics\n",
    "    correlation_matrix = df[characteristics].corr()\n",
    "\n",
    "    # Create annotations for the heatmap with correlation values and units\n",
    "    annot = correlation_matrix.round(2).astype(str)  # Round to 2 decimal places and convert to string\n",
    "    for i in range(len(characteristics)):\n",
    "        for j in range(len(characteristics)):\n",
    "            annot.iloc[i, j] += f\"\\n({characteristic_units[j]})\"  # Append unit to each cell annotation\n",
    "\n",
    "    # Generate the heatmap with annotations and a color map for visual clarity\n",
    "    sns.heatmap(correlation_matrix, annot=annot, cmap='coolwarm', linewidths=0.5, fmt='',\n",
    "                cbar_kws={'shrink': 0.8}, annot_kws={\"size\": 10})\n",
    "\n",
    "    # Add plot titles and labels\n",
    "    plt.title(\"Correlation Heatmap Between Characteristics\", fontsize=16)\n",
    "    plt.xlabel(\"Characteristics (Unit)\", fontsize=14)\n",
    "    plt.ylabel(\"Characteristics (Unit)\", fontsize=14)\n",
    "\n",
    "    # Customize tick labels with characteristic names and units, adjusting font size and rotation\n",
    "    plt.xticks(ticks=range(len(characteristics)),\n",
    "                labels=[f\"{char} ({unit})\" for char, unit in zip(characteristics, characteristic_units)],\n",
    "                rotation=45, fontsize=12)\n",
    "    plt.yticks(ticks=range(len(characteristics)),\n",
    "                labels=[f\"{char} ({unit})\" for char, unit in zip(characteristics, characteristic_units)],\n",
    "                rotation=0, fontsize=12)\n",
    "\n",
    "    # Adjust layout to prevent clipping of tick labels\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only numeric columns for correlation matrix and statistical tests\n",
    "numeric_df = df_stats.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = numeric_df.corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_statistical_tests(df):\n",
    "    \"\"\"\n",
    "    Perform statistical tests on characteristics within a DataFrame, including normality tests \n",
    "    and Pearson correlation tests between characteristics.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing characteristics for statistical testing.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing the results of the statistical tests.\n",
    "    \"\"\"\n",
    "    # Relevant characteristics\n",
    "    relevant_columns = ['Brightness', 'Sharpness', 'Contrast', 'Noise', 'Skew']\n",
    "    \n",
    "    # Helper function for safe normality test\n",
    "    def normality_test(column):\n",
    "        try:\n",
    "            stat, p_value = stats.normaltest(df[column].dropna())\n",
    "            return 'Normality', column, None, stat, p_value\n",
    "        except ValueError:\n",
    "            return 'Normality (Skipped)', column, None, None, None\n",
    "    \n",
    "    # Helper function for safe Pearson correlation test\n",
    "    def correlation_test(col1, col2):\n",
    "        if df[col1].nunique() <= 1 or df[col2].nunique() <= 1:\n",
    "            return 'Pearson Correlation (Skipped)', col1, col2, None, None\n",
    "        corr_stat, corr_p_val = stats.pearsonr(df[col1].dropna(), df[col2].dropna())\n",
    "        return 'Pearson Correlation', col1, col2, corr_stat, corr_p_val\n",
    "    \n",
    "    # Perform normality tests\n",
    "    normality_results = [normality_test(col) for col in relevant_columns]\n",
    "\n",
    "    # Perform Pearson correlation tests\n",
    "    correlation_results = [\n",
    "        correlation_test(col1, col2) for col1, col2 in itertools.combinations(relevant_columns, 2)\n",
    "    ]\n",
    "    \n",
    "    # Combine results\n",
    "    results = normality_results + correlation_results\n",
    "    \n",
    "    # Convert results to DataFrame\n",
    "    return pd.DataFrame(results, columns=['Test', 'Characteristic_1', 'Characteristic_2', 'Statistic', 'P-Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform overall statistical tests\n",
    "test_results_table = overall_statistical_tests(numeric_df)\n",
    "test_results_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Special Visualization per Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random image from the list of preprocessed images (assuming `images` is a list of grayscale images)\n",
    "random_image = random.choice(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_brightness_overall(df):\n",
    "    \"\"\"\n",
    "    Plot the distribution of brightness across the entire dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing brightness statistics for each image.\n",
    "    \n",
    "    Returns:\n",
    "    None: Displays the brightness distribution plot for the dataset.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df['Brightness'], kde=True, bins=30, color='skyblue')\n",
    "    plt.title(\"Distribution of Brightness Across Dataset\")\n",
    "    plt.xlabel(\"Brightness (Pixel Value 0-255)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_brightness_single(image):\n",
    "    \"\"\"\n",
    "    Plot the brightness histogram for a single image and display the mean brightness value.\n",
    "    \n",
    "    Parameters:\n",
    "    image (numpy array): Grayscale image to analyze brightness distribution.\n",
    "    \n",
    "    Returns:\n",
    "    None: Displays the brightness histogram for the image.\n",
    "    \"\"\"\n",
    "    # Calculate the mean brightness using the provided function\n",
    "    mean_brightness = calculate_brightness(image)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(image.ravel(), bins=256, range=(0, 255), color='skyblue', alpha=0.7)\n",
    "    plt.title(f\"Brightness Histogram of Single Image (Mean Brightness: {mean_brightness:.2f})\")\n",
    "    plt.xlabel(\"Brightness (Pixel Value)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_brightness_heatmap(image):\n",
    "    \"\"\"\n",
    "    Display a smoothed heatmap of brightness intensity for a single image using Gaussian blur,\n",
    "    and display the mean brightness value in the title.\n",
    "    \n",
    "    Parameters:\n",
    "    image (numpy array): Grayscale image to visualize brightness intensity.\n",
    "    \n",
    "    Returns:\n",
    "    None: Displays a blurred heatmap visualization of the image's brightness.\n",
    "    \"\"\"\n",
    "    # Calculate the mean brightness using the provided function\n",
    "    mean_brightness = calculate_brightness(image)\n",
    "    \n",
    "    # Convert the image to float64 for accurate processing\n",
    "    brightness_image = image.astype(np.float64)\n",
    "    \n",
    "    # Apply Gaussian blur to create a smooth brightness map\n",
    "    blurred_brightness = cv2.GaussianBlur(brightness_image, (5, 5), 0)\n",
    "    \n",
    "    # Normalize the blurred brightness to fall between 0 and 255 for visualization\n",
    "    brightness_heatmap = cv2.normalize(blurred_brightness, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    # Plot the smoothed heatmap with the mean brightness in the title\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(brightness_heatmap, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.colorbar(label=\"Brightness Intensity (Normalized 0-255)\")\n",
    "    plt.title(f\"Brightness Heatmap of Image (Mean Brightness: {mean_brightness:.2f})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_brightness_overall(df_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_brightness_single(random_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_brightness_heatmap(random_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contrast_overall(df):\n",
    "    \"\"\"\n",
    "    Plot the distribution of contrast across the entire dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing contrast statistics for each image.\n",
    "    \n",
    "    Returns:\n",
    "    None: Displays the contrast distribution plot for the dataset.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df['Contrast'], kde=True, bins=30, color='purple')\n",
    "    plt.title(\"Distribution of Contrast Across Dataset\")\n",
    "    plt.xlabel(\"Contrast (Pixel Value Std Dev)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contrast_single(image):\n",
    "    \"\"\"\n",
    "    Plot the contrast histogram for a single image and display the mean contrast value.\n",
    "    \n",
    "    Parameters:\n",
    "    image (numpy array): Grayscale image to analyze contrast distribution.\n",
    "    \n",
    "    Returns:\n",
    "    None: Displays the contrast histogram for the image.\n",
    "    \"\"\"\n",
    "    # Calculate the mean contrast using the provided function\n",
    "    mean_contrast = calculate_contrast(image)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(image.ravel(), bins=256, range=(0, 255), color='purple', alpha=0.7)\n",
    "    plt.title(f\"Contrast Histogram of Single Image (Mean Contrast: {mean_contrast:.2f})\")\n",
    "    plt.xlabel(\"Pixel Intensity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contrast_map(image):\n",
    "    \"\"\"\n",
    "    Display a contrast map for a single image by normalizing brightness values to enhance contrast,\n",
    "    and display the mean contrast value in the title.\n",
    "    \n",
    "    Parameters:\n",
    "    image (numpy array): Grayscale image to visualize contrast intensity.\n",
    "    \n",
    "    Returns:\n",
    "    None: Displays a contrast map visualization of the image.\n",
    "    \"\"\"\n",
    "    # Calculate the mean contrast using the provided function\n",
    "    mean_contrast = calculate_contrast(image)\n",
    "    \n",
    "    # Normalize the image brightness to the range 0-255 to enhance contrast visibility\n",
    "    contrast_map_normalized = cv2.normalize(image.astype(np.float64), None, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    # Plot the contrast map with the mean contrast in the title\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(contrast_map_normalized, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.colorbar(label=\"Contrast Intensity (Normalized 0-255)\")\n",
    "    plt.title(f\"Contrast Map of Image (Mean Contrast: {mean_contrast:.2f})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contrast_overall(df_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contrast_single(random_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contrast_map(random_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharpness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sharpness_overall(df):\n",
    "    \"\"\"\n",
    "    Plot the distribution of sharpness across the entire dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing sharpness statistics for each image.\n",
    "    \n",
    "    Returns:\n",
    "    None: Displays the sharpness distribution plot for the dataset.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df['Sharpness'], kde=True, bins=30, color='orange')\n",
    "    plt.title(\"Distribution of Sharpness Across Dataset\")\n",
    "    plt.xlabel(\"Sharpness (Variance of Laplacian)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sharpness_single(image):\n",
    "    \"\"\"\n",
    "    Plot the sharpness histogram for a single image based on edge intensity,\n",
    "    and display the mean sharpness value in the title.\n",
    "    \n",
    "    Parameters:\n",
    "    image (numpy array): Grayscale image to analyze sharpness distribution.\n",
    "    \n",
    "    Returns:\n",
    "    None: Displays the sharpness histogram for the image.\n",
    "    \"\"\"\n",
    "    # Calculate the mean sharpness using the provided function\n",
    "    mean_sharpness = calculate_sharpness(image)\n",
    "    \n",
    "    # Apply Laplacian to detect edges\n",
    "    edges = cv2.Laplacian(image, cv2.CV_64F)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(np.abs(edges).ravel(), bins=256, range=(0, edges.max()), color='orange', alpha=0.7)\n",
    "    plt.title(f\"Sharpness Histogram of Single Image (Mean Sharpness: {mean_sharpness:.2f})\")\n",
    "    plt.xlabel(\"Edge Intensity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sharpness_edge_map(image):\n",
    "    \"\"\"\n",
    "    Display an edge map for a single image to visualize areas with high sharpness,\n",
    "    and display the mean sharpness value in the title.\n",
    "    \n",
    "    Parameters:\n",
    "    image (numpy array): Grayscale image to visualize edge intensity.\n",
    "    \n",
    "    Returns:\n",
    "    None: Displays an edge map visualization of the image.\n",
    "    \"\"\"\n",
    "    # Calculate the mean sharpness using the provided function\n",
    "    mean_sharpness = calculate_sharpness(image)\n",
    "    \n",
    "    # Apply Laplacian to detect edges\n",
    "    edges = cv2.Laplacian(image, cv2.CV_64F)\n",
    "    \n",
    "    # Normalize edges to the range 0-255 for visualization\n",
    "    edge_map_normalized = cv2.normalize(np.abs(edges), None, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    # Plot the edge map with the mean sharpness in the title\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(edge_map_normalized, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.colorbar(label=\"Edge Intensity (Normalized 0-255)\")\n",
    "    plt.title(f\"Edge Map for Sharpness Visualization (Mean Sharpness: {mean_sharpness:.2f})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sharpness_overall(df_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sharpness_single(random_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sharpness_edge_map(random_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_noise_overall(df):\n",
    "    \"\"\"\n",
    "    Plot the distribution of noise across the entire dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing noise statistics for each image.\n",
    "    \n",
    "    Returns:\n",
    "    None: Displays the noise distribution plot for the dataset.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df['Noise'], kde=True, bins=30, color='red')\n",
    "    plt.title(\"Distribution of Noise Across Dataset\")\n",
    "    plt.xlabel(\"Noise (Pixel Value Std Dev)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_noise_single(image):\n",
    "    \"\"\"\n",
    "    Plot the noise histogram for a single image and display the mean noise value.\n",
    "    \n",
    "    Parameters:\n",
    "    image (numpy array): Grayscale image to analyze noise distribution.\n",
    "    \n",
    "    Returns:\n",
    "    None: Displays the noise histogram for the image.\n",
    "    \"\"\"\n",
    "    # Calculate the mean noise using the provided function\n",
    "    mean_noise = calculate_noise(image)\n",
    "    \n",
    "    # Apply Gaussian blur to simulate noise calculation\n",
    "    blurred_image = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    noise = cv2.absdiff(image, blurred_image)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(noise.ravel(), bins=256, range=(0, 255), color='red', alpha=0.7)\n",
    "    plt.title(f\"Noise Histogram of Single Image (Mean Noise: {mean_noise:.2f})\")\n",
    "    plt.xlabel(\"Noise Intensity (Pixel Value)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_noise_map(image):\n",
    "    \"\"\"\n",
    "    Display a noise map for a single image by highlighting areas with high noise intensity.\n",
    "    \n",
    "    Parameters:\n",
    "    image (numpy array): Grayscale image to visualize noise intensity.\n",
    "    \n",
    "    Returns:\n",
    "    None: Displays a noise map visualization of the image.\n",
    "    \"\"\"\n",
    "    # Calculate the mean noise using the provided function\n",
    "    mean_noise = calculate_noise(image)\n",
    "    \n",
    "    # Apply Gaussian blur and calculate the difference to highlight noise areas\n",
    "    blurred_image = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    noise_map = cv2.absdiff(image, blurred_image)\n",
    "    \n",
    "    # Normalize the noise map to the range 0-255 for visualization\n",
    "    noise_map_normalized = cv2.normalize(noise_map.astype(np.float64), None, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    # Plot the noise map with the mean noise in the title\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(noise_map_normalized, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.colorbar(label=\"Noise Intensity (Normalized 0-255)\")\n",
    "    plt.title(f\"Noise Map of Image (Mean Noise: {mean_noise:.2f})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_noise_overall(df_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_noise_single(random_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_noise_map(random_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_skew_overall(df):\n",
    "    \"\"\"\n",
    "    Plot the distribution of skew across the entire dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing skew statistics for each image.\n",
    "    \n",
    "    Returns:\n",
    "    None: Displays the skew distribution plot for the dataset.\n",
    "    \"\"\"   \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df['Skew'], kde=True, bins=30, color='green')\n",
    "    plt.title(\"Distribution of Skew Across Dataset\")\n",
    "    plt.xlabel(\"Skew (Degrees)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_skew_visualization(image):\n",
    "    \"\"\"\n",
    "    Display an image with the skew angle overlay to visualize its orientation.\n",
    "    \n",
    "    Parameters:\n",
    "    image (numpy array): Grayscale image to visualize skew.\n",
    "    \n",
    "    Returns:\n",
    "    None: Displays the image with the skew angle overlay.\n",
    "    \"\"\"\n",
    "    # Calculate the skew angle and detected vertical lines\n",
    "    skew_angle, vertical_lines = calculate_skew(image)\n",
    "\n",
    "    # Convert image to color for visualization\n",
    "    output_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    colors = [(255, 165, 0), (0, 191, 255), (255, 69, 0)]  # Orange, Light Blue, Red-Orange for vertical lines\n",
    "    \n",
    "    # Draw the detected vertical lines\n",
    "    for idx, (x1, y1, x2, y2) in enumerate(vertical_lines):\n",
    "        color = colors[idx % len(colors)]  # Alternate colors\n",
    "        cv2.line(output_image, (x1, y1), (x2, y2), color, 8)  # Line thickness increased to 8\n",
    "\n",
    "    # Draw reference vertical axis\n",
    "    height, width = image.shape\n",
    "    cv2.line(output_image, (width // 2, 0), (width // 2, height), (50, 205, 50), 3)  # Lime Green for vertical reference\n",
    "\n",
    "    # Display the result\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Skew Visualization (Angle: {skew_angle:.2f}째)\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_skew_overall(df_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_skew_visualization(random_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alessandroryo",
   "language": "python",
   "name": "alessandroryo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
