{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Understanding 1st Iteration"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f53ae8c023994620"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b9297e5335151ec",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd08a7dc39a0883"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading images "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d81372c0b0ae846"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder_path, extensions=('.png', '.jpg', '.jpeg', '.JPG')):\n",
    "    \"\"\"\n",
    "    Load all image file paths from a specified folder that match the given file extensions.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing the images.\n",
    "    extensions (tuple of str): A tuple of file extensions to filter the images by. \n",
    "                               Default is ('.png', '.jpg', '.jpeg', '.JPG').\n",
    "\n",
    "    Returns:\n",
    "    list: A list of full file paths to images in the folder that match the specified extensions.\n",
    "    \n",
    "    Raises:\n",
    "    FileNotFoundError: If the specified folder does not exist.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        raise FileNotFoundError(f\"The specified folder does not exist: {folder_path}\")\n",
    "\n",
    "    # List comprehension to gather all image paths with the specified extensions\n",
    "    image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(extensions)]\n",
    "\n",
    "    return image_paths"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87d9e9f2390c0588",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_and_preprocess_images(image_paths, resize_dim=(256, 256)):\n",
    "    images = []\n",
    "\n",
    "    # Initialize tqdm progress bar\n",
    "    for path in tqdm(image_paths, desc=\"Loading and preprocessing images\", unit=\"image\"):\n",
    "        img = cv2.imread(path)\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "        img_resized = cv2.resize(img_gray, resize_dim)  # Resize for consistency\n",
    "        images.append(img_resized)\n",
    "\n",
    "    return images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e84cffb9c5936cd0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Statistical Analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6dc25929a12a4672"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Functions to calculate the brightness, sharpness and contrast of the images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec595596dd1c7ab1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_brightness(image):\n",
    "    return np.mean(image)  # Mean pixel intensity"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e573fefeb3856e6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_sharpness(image):\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()  # Variance of Laplacian method"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "393f2142e1da3550",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_contrast(image):\n",
    "    return image.std()  # Standard deviation of pixel values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f239be5e396ddef5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_noise(image):\n",
    "    # Calculate the variance of the Laplacian, lower values indicate less noise\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c296c695fc84950",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_skew(image):\n",
    "    # Check if the image is 2D (grayscale)\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "\n",
    "    # Apply thresholding to get a binary image\n",
    "    _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find contours of the binary image\n",
    "    coords = np.column_stack(np.where(binary > 0))\n",
    "\n",
    "    if coords.size == 0:  # Check if there are any coordinates found\n",
    "        return 0  # If no contours found, return 0 as skew\n",
    "\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "\n",
    "    # Adjust angle\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "\n",
    "    return angle"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "444c42aa4b8b9af8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_line_spacing(image):\n",
    "    # Check if the image is 2D (grayscale)\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "    \n",
    "    _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find contours to get bounding boxes of text lines\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    heights = []\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        heights.append(h)\n",
    "\n",
    "    # Calculate average spacing based on the heights of bounding boxes\n",
    "    if len(heights) > 1:\n",
    "        line_spacing = np.mean(np.diff(sorted(heights)))\n",
    "    else:\n",
    "        line_spacing = 0  # No lines found\n",
    "\n",
    "    return line_spacing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d88ff85b26c0a15",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def detect_tables(image):\n",
    "    # Check if the image is 2D (grayscale)\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "    _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    binary = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "    # Find contours that could represent tables\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    table_contours = []\n",
    "\n",
    "    for contour in contours:\n",
    "        # Filter contours by area to identify potential tables\n",
    "        if cv2.contourArea(contour) > 1000:  # Threshold for minimum area\n",
    "            table_contours.append(contour)\n",
    "\n",
    "    return len(table_contours)  # Return the number of detected tables\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76178a7b1b61e4cb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to calculate image resolution\n",
    "def calculate_resolution(image):\n",
    "    height, width = image.shape[:2]  # Get dimensions of the image\n",
    "    return height * width  # Return the total number of pixels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "839090f1a59b3ea4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to calculate text and table alignment (simple heuristic)\n",
    "def calculate_text_table_alignment(image):\n",
    "    # Check if the image is 2D (grayscale)\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "    \n",
    "    _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find contours to identify the alignment of tables and text\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Calculate the alignment based on the bounding box of the contours\n",
    "    alignments = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        alignments.append((x, y, w, h))\n",
    "\n",
    "    # Here, you can develop a more sophisticated measure for alignment if needed\n",
    "    return len(alignments)  # Return number of detected bounding boxes as a simple measure"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7251d78317af707d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to calculate table structure complexity\n",
    "def calculate_table_structure_complexity(image):\n",
    "    # Check if the image is 2D (grayscale)\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "    \n",
    "    _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find contours to identify table structures\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Count the number of contours (tables) as a simple measure of complexity\n",
    "    return len(contours)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a430005dcb458e2c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to calculate image texture (using standard deviation of pixel values)\n",
    "def calculate_texture(image):\n",
    "    # Check if the image is 2D (grayscale)\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "    return image.std()  # Standard deviation as a measure of texture complexity\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95f03800524634a2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to calculate patterns (simple edge detection to find patterns)\n",
    "def calculate_patterns(image):\n",
    "    # Check if the image is 2D (grayscale)\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "    edges = cv2.Canny(image, 100, 200)  # Edge detection\n",
    "    return np.sum(edges > 0)  # Count the number of edge pixels as a measure of patterns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3a337169957cfaf",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Statistical Summary"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cc5caff2972c7d9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This function provides summary statistics for all images based on brightness, sharpness, and contrast."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fb4a939e1f41b1c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58f7891ee3df621",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def image_statistics_table(images):\n",
    "    stats_data = {'Image': [], \n",
    "                  'Brightness': [], \n",
    "                  'Sharpness': [], \n",
    "                  'Contrast': [],\n",
    "                  'Noise': [],\n",
    "                  'Skew': [],\n",
    "                  'Line Spacing': [],\n",
    "                  'Tables Detected': [],\n",
    "                  'Resolution': [],\n",
    "                  'Text and Table Alignment': [],\n",
    "                  'Table Structure Complexity': [],\n",
    "                  'Texture': [],\n",
    "                  'Patterns': []}\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        stats_data['Image'].append(f'Image_{i+1}')\n",
    "        stats_data['Brightness'].append(calculate_brightness(img))\n",
    "        stats_data['Sharpness'].append(calculate_sharpness(img))\n",
    "        stats_data['Contrast'].append(calculate_contrast(img))\n",
    "        stats_data['Noise'].append(calculate_noise(img))\n",
    "        stats_data['Skew'].append(calculate_skew(img))\n",
    "        stats_data['Line Spacing'].append(calculate_line_spacing(img))\n",
    "        stats_data['Tables Detected'].append(detect_tables(img))\n",
    "        stats_data['Resolution'].append(calculate_resolution(img))\n",
    "        stats_data['Text and Table Alignment'].append(calculate_text_table_alignment(img))\n",
    "        stats_data['Table Structure Complexity'].append(calculate_table_structure_complexity(img))\n",
    "        stats_data['Texture'].append(calculate_texture(img))\n",
    "        stats_data['Patterns'].append(calculate_patterns(img))\n",
    "    # Create a DataFrame to store per-image statistics\n",
    "    df = pd.DataFrame(stats_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to calculate overall statistical summary as a table\n",
    "def overall_statistical_summary(df):\n",
    "    # Calculate the summary for Brightness, Sharpness, and Contrast\n",
    "    summary_df = df[['Brightness', 'Sharpness', 'Contrast','Noise','Skew','Line Spacing', 'Tables Detected','Resolution',\n",
    "                 'Text and Table Alignment','Table Structure Complexity','Texture','Patterns']].describe()\n",
    "\n",
    "    # Return the summary table\n",
    "    return summary_df"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualizations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd92cab29e23a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### General functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "adfee87ef78be18f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function for visualizing histograms and other distributions\n",
    "def plot_characteristic_distribution(df, characteristic, unit, plot_type='hist'):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    if plot_type == 'hist':\n",
    "        sns.histplot(df[characteristic], kde=True, bins=30, color='blue')\n",
    "    elif plot_type == 'box':\n",
    "        sns.boxplot(x=df[characteristic], color='green')\n",
    "    elif plot_type == 'violin':\n",
    "        sns.violinplot(x=df[characteristic], color='orange')\n",
    "\n",
    "    plt.title(f\"Distribution of {characteristic}\")\n",
    "    plt.xlabel(f\"{characteristic} ({unit})\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d33123105abe70",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Relationships"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97af57268192b2a7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to plot relationships (scatter plots) between two characteristics\n",
    "def plot_characteristic_relationship(df, characteristic_1, characteristic_2, unit_1, unit_2, use_color=False):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    if use_color:\n",
    "        sns.scatterplot(x=df[characteristic_1], y=df[characteristic_2], hue=df[characteristic_2], palette='coolwarm', s=50)\n",
    "    else:\n",
    "        sns.scatterplot(x=df[characteristic_1], y=df[characteristic_2], s=50)\n",
    "\n",
    "    plt.title(f\"Relationship between {characteristic_1} and {characteristic_2}\")\n",
    "    plt.xlabel(f\"{characteristic_1} ({unit_1})\")\n",
    "    plt.ylabel(f\"{characteristic_2} ({unit_2})\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f2afae4bb2d431d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to create a heatmap for correlations between characteristics\n",
    "def plot_correlation_heatmap(df, characteristics, characteristic_units):\n",
    "    plt.figure(figsize=(10, 8))  # Increase figure size for better visibility\n",
    "    correlation_matrix = df[characteristics].corr()\n",
    "\n",
    "    # Create annotations with correlation values and units\n",
    "    annot = correlation_matrix.round(2).astype(str)  # Round and convert to string\n",
    "    for i in range(len(characteristics)):\n",
    "        for j in range(len(characteristics)):\n",
    "            annot.iloc[i, j] += f\"\\n({characteristic_units[j]})\"  # Append units\n",
    "\n",
    "    # Create the heatmap\n",
    "    sns.heatmap(correlation_matrix, annot=annot, cmap='coolwarm', linewidths=0.5, fmt='',\n",
    "                cbar_kws={'shrink': 0.8}, annot_kws={\"size\": 10})  # Font size for annotations\n",
    "\n",
    "    plt.title(\"Correlation Heatmap Between Characteristics\", fontsize=16)\n",
    "    plt.xlabel(\"Characteristics (Unit)\", fontsize=14)\n",
    "    plt.ylabel(\"Characteristics (Unit)\", fontsize=14)\n",
    "\n",
    "    # Set tick labels with adjusted font size\n",
    "    plt.xticks(ticks=range(len(characteristics)),\n",
    "               labels=[f\"{char} ({unit})\" for char, unit in zip(characteristics, characteristic_units)],\n",
    "               rotation=45, fontsize=12)\n",
    "    plt.yticks(ticks=range(len(characteristics)),\n",
    "               labels=[f\"{char} ({unit})\" for char, unit in zip(characteristics, characteristic_units)],\n",
    "               rotation=0, fontsize=12)\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout to prevent clipping\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "408457e4b91a3e0e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Statistical Tests"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f10d34bd56b047e8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Flexible Statistical Test Function\n",
    "def overall_statistical_tests(df):\n",
    "    # Create a DataFrame to store statistical test results\n",
    "    test_results = {'Test': [], 'Characteristic_1': [], 'Characteristic_2': [], 'Statistic': [], 'P-Value': []}\n",
    "\n",
    "    # Perform normality tests for each characteristic\n",
    "    for col in ['Brightness', 'Sharpness', 'Contrast']:\n",
    "        stat, p_value = stats.normaltest(df[col])\n",
    "        test_results['Test'].append('Normality')\n",
    "        test_results['Characteristic_1'].append(col)\n",
    "        test_results['Characteristic_2'].append(None)  # No second characteristic for univariate tests\n",
    "        test_results['Statistic'].append(stat)\n",
    "        test_results['P-Value'].append(p_value)\n",
    "\n",
    "    # Perform Pearson correlation tests between each pair of characteristics\n",
    "    pairs = itertools.combinations(['Brightness', 'Sharpness', 'Contrast','Noise','Skew','Line Spacing', 'Tables Detected','Resolution','Text and Table Alignment','Table Structure Complexity','Texture','Patterns'], 2)\n",
    "    for char1, char2 in pairs:\n",
    "        corr_stat, corr_p_val = stats.pearsonr(df[char1], df[char2])\n",
    "        test_results['Test'].append('Pearson Correlation')\n",
    "        test_results['Characteristic_1'].append(char1)\n",
    "        test_results['Characteristic_2'].append(char2)\n",
    "        test_results['Statistic'].append(corr_stat)\n",
    "        test_results['P-Value'].append(corr_p_val)\n",
    "\n",
    "    # Return the test results as a DataFrame\n",
    "    return pd.DataFrame(test_results)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c7dfd2e2cab4c72",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Executing the Data Analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1b0b1494bdefb57"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the path to the folder containing the images to be processed\n",
    "folder_path = '../data/original'  # Update this path to point to your specific folder containing images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14ec313a4e5bae75",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "image_paths = load_images_from_folder(folder_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a4ac4343dfa8d8e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 1: Load and preprocess images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c4034f17238144c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "images = load_and_preprocess_images(image_paths)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a62c53c467f08d3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2: Create image statistics table"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28ee69d703f4300b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_stats = image_statistics_table(images)\n",
    "print(\"Image Statistics Table:\")\n",
    "# df_stats\n",
    "df_stats.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7652665d8601b3f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Explenation about the different characteristics and how they are measured:\n",
    "- Brightness represents the overall intensity of light in an image. It is measured by calculating the mean (average) pixel value across the image.\n",
    "    - Units: Pixel intensity values, typically on a scale of 0 to 255 in an 8-bit grayscale image. 0 means completely black. 255 means completely white. \n",
    "    - Values in between represent varying levels of gray. For example, a brightness value of 128 would indicate an image that is midway between black and white (medium gray).\n",
    "- Contrast refers to the difference between the darkest and brightest parts of an image. It is often measured by calculating the standard deviation of pixel values in the image. The standard deviation tells us how much the pixel values are spread out (the higher the contrast, the wider the spread between bright and dark areas).\n",
    "    - Units: The unit is the pixel standard deviation (the spread of pixel intensity values). It reflects how much variation exists in the pixel intensity values. \n",
    "        - A low contrast image would have values close together (e.g., most pixels around a middle gray). \n",
    "        - A high contrast image would have pixel values widely spread (e.g., a mix of very dark and very bright areas).\n",
    "- Sharpness measures how clear or well-defined the edges are in an image. It is calculated using the variance of the Laplacian (a method that highlights the edges in the image). The variance measures how much the values deviate from the average, with higher variance meaning sharper images.\n",
    "    - Units: The unit here is a sharpness index, specifically the variance of the Laplacian, which is a numerical value that reflects how sharp the image is. Like contrast, it doesn’t have a traditional unit but represents how much the pixel values at edges vary.\n",
    "        - A higher value means the image is sharper, with clearer edges.\n",
    "        - A lower value means the image is blurrier or has fewer defined edges."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcaa2b00314a1e8a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3: Overall statistical summary"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cab5e925e02689e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "overall_summary = overall_statistical_summary(df_stats)\n",
    "print(\"Overall Statistical Summary:\")\n",
    "overall_summary"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ecf0ee26ce41a9d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 4: Visualize overall distributions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "904080d745901344"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define characteristics and their units in a single dictionary\n",
    "characteristics_units = {\n",
    "    'Brightness': '0-255',\n",
    "    'Contrast': 'Pixel Std Dev',\n",
    "    'Sharpness': 'Variance (unitless)',\n",
    "    'Noise': 'Standard Deviation (unitless)',\n",
    "    'Skew': 'Degrees (°)',\n",
    "    'Line Spacing': 'Pixels',\n",
    "    'Tables Detected': 'Count',\n",
    "    'Resolution': 'Pixels',\n",
    "    'Text and Table Alignment': 'Alignment Score',\n",
    "    'Table Structure Complexity': 'Complexity Score',\n",
    "    'Texture': 'Texture Index',\n",
    "    'Patterns': 'Pattern Index'\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39b1caa29023b7e2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Loop through each characteristic and its corresponding unit\n",
    "for characteristic, unit in characteristics_units.items():\n",
    "    for plot_type in ['hist', 'box', 'violin']:\n",
    "        plot_characteristic_distribution(df_stats, characteristic, unit, plot_type)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33e9048429bc7448",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Distribution of Brightness"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53d0c0c084f13dfb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 5: Visualize relationships between characteristics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "465948057a0ac4ae"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Generate pairs of characteristics\n",
    "pairs = itertools.combinations(characteristics_units.keys(), 2)\n",
    "\n",
    "# Loop through each pair and create the relationship plots\n",
    "for char1, char2 in pairs:\n",
    "    plot_characteristic_relationship(\n",
    "        df_stats,\n",
    "        char1,\n",
    "        char2,\n",
    "        characteristics_units[char1],  # Get the unit for char1\n",
    "        characteristics_units[char2]   # Get the unit for char2\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "def5e978469fe378",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Heat Map"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a77d7ebec74af3c4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "correlation_matrix = df_stats.corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d79cd486fff79af",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 6: Perform statistical tests"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3efe6b0cb1c39562"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_results_table = overall_statistical_tests(df_stats)\n",
    "test_results_table"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c403941a0f15e145",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "617c7281256a2d4a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
