{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a49cbe",
   "metadata": {},
   "source": [
    "# Iteration 1 - Data Understanding\n",
    "\n",
    "> **Creator**: Shirel & Alex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9297e5335151ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:28:34.763357Z",
     "start_time": "2024-11-04T10:28:34.567360Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd08a7dc39a0883",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d81372c0b0ae846",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Loading images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d9e9f2390c0588",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:28:34.778357Z",
     "start_time": "2024-11-04T10:28:34.767358Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder_path, extensions=('.png', '.jpg', '.jpeg', '.JPG')):\n",
    "    \"\"\"\n",
    "    Load all image file paths from a specified folder that match the given file extensions.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing the images.\n",
    "    extensions (tuple of str): A tuple of file extensions to filter the images by. \n",
    "                               Default is ('.png', '.jpg', '.jpeg', '.JPG').\n",
    "\n",
    "    Returns:\n",
    "    list: A list of full file paths to images in the folder that match the specified extensions.\n",
    "    \n",
    "    Raises:\n",
    "    FileNotFoundError: If the specified folder does not exist.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        raise FileNotFoundError(f\"The specified folder does not exist: {folder_path}\")\n",
    "\n",
    "    # List comprehension to gather all image paths with the specified extensions\n",
    "    image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(extensions)]\n",
    "\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84cffb9c5936cd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:28:34.793359Z",
     "start_time": "2024-11-04T10:28:34.784358Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_images(image_paths, resize_dim=(256, 256)):\n",
    "    images = []\n",
    "\n",
    "    # Initialize tqdm progress bar\n",
    "    for path in tqdm(image_paths, desc=\"Loading and preprocessing images\", unit=\"image\"):\n",
    "        img = cv2.imread(path)\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "        img_resized = cv2.resize(img_gray, resize_dim)  # Resize for consistency\n",
    "        images.append(img_resized)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a12f11159da5e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:28:34.809357Z",
     "start_time": "2024-11-04T10:28:34.796358Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_images(image_paths):\n",
    "    original_images = []\n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path)  # Load original image\n",
    "        original_images.append(img)\n",
    "    return original_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc25929a12a4672",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec595596dd1c7ab1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Functions to calculate the characteristics of each of the images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2942e2d5d6b5022f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e573fefeb3856e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:28:34.825357Z",
     "start_time": "2024-11-04T10:28:34.812359Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_brightness(image):\n",
    "    return np.mean(image)  # Mean pixel intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b8b5e35a81e22",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Sharpness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f2142e1da3550",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:28:34.840357Z",
     "start_time": "2024-11-04T10:28:34.827360Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_sharpness(image):\n",
    "    # Sharpness based on the variance of the Laplacian\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()  # Variance of Laplacian method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ded020af19c6d3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f239be5e396ddef5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:28:34.855359Z",
     "start_time": "2024-11-04T10:28:34.842356Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_contrast(image):\n",
    "    return image.std()  # Standard deviation of pixel values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca59876ed0a83c8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c296c695fc84950",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:28:34.871358Z",
     "start_time": "2024-11-04T10:28:34.857359Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_noise(image):\n",
    "    # Convert to grayscale if it's not\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply a Gaussian blur to the image\n",
    "    blurred = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "\n",
    "    # Calculate the difference between the original and blurred image\n",
    "    noise = cv2.absdiff(image, blurred)\n",
    "\n",
    "    # Return the variance of the noise image (higher variance = more noise)\n",
    "    return np.var(noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e6aa3990f06054",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444c42aa4b8b9af8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:28:34.886356Z",
     "start_time": "2024-11-04T10:28:34.873358Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_skew(image):\n",
    "    # Check if the image is 2D (grayscale)\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "\n",
    "    # Apply thresholding to get a binary image\n",
    "    _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find contours of the binary image\n",
    "    coords = np.column_stack(np.where(binary > 0))\n",
    "\n",
    "    if coords.size == 0:  # Check if there are any coordinates found\n",
    "        return 0  # If no contours found, return 0 as skew\n",
    "\n",
    "    # Calculate the minimum area rectangle angle\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "\n",
    "    # Adjust angle\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "\n",
    "    # Round small angles to zero\n",
    "    if abs(angle) < 1e-2:  # If the angle is extremely small (close to 0)\n",
    "        angle = 0\n",
    "\n",
    "    return round(angle, 2)  # Round the angle to two decimal places"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999a623abc6102b4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Line Spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d88ff85b26c0a15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:28:34.901357Z",
     "start_time": "2024-11-04T10:28:34.889359Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_line_spacing(image):\n",
    "    # Check if the image is 2D (grayscale)\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "    \n",
    "    _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find contours to get bounding boxes of text lines\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    heights = []\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        heights.append(h)\n",
    "\n",
    "    # Calculate average spacing based on the heights of bounding boxes\n",
    "    if len(heights) > 1:\n",
    "        line_spacing = np.mean(np.diff(sorted(heights)))\n",
    "    else:\n",
    "        line_spacing = 0  # No lines found\n",
    "\n",
    "    return line_spacing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b1f0ab497671a2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Tables Detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76178a7b1b61e4cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:28:34.916360Z",
     "start_time": "2024-11-04T10:28:34.904358Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def detect_tables(image):\n",
    "    # Check if the image is 2D (grayscale)\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "    _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    binary = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "    # Find contours that could represent tables\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    table_contours = []\n",
    "\n",
    "    for contour in contours:\n",
    "        # Filter contours by area to identify potential tables\n",
    "        if cv2.contourArea(contour) > 1000:  # Threshold for minimum area\n",
    "            table_contours.append(contour)\n",
    "\n",
    "    return len(table_contours)  # Return the number of detected tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6079a049d109c2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839090f1a59b3ea4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:28:34.931356Z",
     "start_time": "2024-11-04T10:28:34.920360Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to calculate image resolution\n",
    "def calculate_resolution(image):\n",
    "    height, width = image.shape[:2]  # Get dimensions of the image\n",
    "    return height * width  # Return the total number of pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1647a787fa2d0435",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Elements Detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7251d78317af707d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:28:34.946357Z",
     "start_time": "2024-11-04T10:28:34.938358Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to calculate Detected Elements (simple heuristic)\n",
    "def calculate_elements_detection(image):\n",
    "    # Check if the image is 2D (grayscale)\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "    \n",
    "    _, binary = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find contours to identify the alignment of tables and text\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Calculate the alignment based on the bounding box of the contours\n",
    "    alignments = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        alignments.append((x, y, w, h))\n",
    "\n",
    "    # Here, you can develop a more sophisticated measure for alignment if needed\n",
    "    return len(alignments)  # Return number of detected bounding boxes as a simple measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450f7e309be303a4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f03800524634a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:28:34.961357Z",
     "start_time": "2024-11-04T10:28:34.949357Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to calculate texture using local variation (Laplacian)\n",
    "def calculate_texture(image):\n",
    "    laplacian = cv2.Laplacian(image, cv2.CV_64F)  # Apply Laplacian filter\n",
    "    return laplacian.std()  # Standard deviation of the Laplacian as a measure of texture complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9c5439e03311d1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a337169957cfaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:28:34.976358Z",
     "start_time": "2024-11-04T10:28:34.963358Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to calculate patterns (simple edge detection to find patterns)\n",
    "def calculate_patterns(image):\n",
    "    # Check if the image is 2D (grayscale)\n",
    "    if len(image.shape) != 2:\n",
    "        raise ValueError(\"Invalid image format. Image must be a 2D grayscale image.\")\n",
    "    edges = cv2.Canny(image, 100, 200)  # Edge detection\n",
    "    return np.sum(edges > 0)  # Count the number of edge pixels as a measure of patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc5caff2972c7d9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Statistical Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb4a939e1f41b1c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This function provides summary statistics for all images based on brightness, sharpness, and contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58f7891ee3df621",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:28:34.991357Z",
     "start_time": "2024-11-04T10:28:34.978358Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def image_statistics_table(images):\n",
    "    stats_data = {'Image': [], \n",
    "                  'Brightness': [], \n",
    "                  'Sharpness': [], \n",
    "                  'Contrast': [],\n",
    "                  'Noise': [],\n",
    "                  'Skew': [],\n",
    "                  'Line Spacing': [],\n",
    "                  'Tables Detected': [],\n",
    "                  'Resolution': [],\n",
    "                  'Detected Elements': [],\n",
    "                  'Texture': [],\n",
    "                  'Patterns': []}\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        stats_data['Image'].append(f'Image_{i+1}')\n",
    "        stats_data['Brightness'].append(calculate_brightness(img))\n",
    "        stats_data['Sharpness'].append(calculate_sharpness(img))\n",
    "        stats_data['Contrast'].append(calculate_contrast(img))\n",
    "        stats_data['Noise'].append(calculate_noise(img))\n",
    "        stats_data['Skew'].append(calculate_skew(img))\n",
    "        stats_data['Line Spacing'].append(calculate_line_spacing(img))\n",
    "        stats_data['Tables Detected'].append(detect_tables(img))\n",
    "        stats_data['Resolution'].append(calculate_resolution(img))\n",
    "        stats_data['Detected Elements'].append(calculate_elements_detection(img))\n",
    "        stats_data['Texture'].append(calculate_texture(img))\n",
    "        stats_data['Patterns'].append(calculate_patterns(img))\n",
    "    # Create a DataFrame to store per-image statistics\n",
    "    df = pd.DataFrame(stats_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:28:35.006358Z",
     "start_time": "2024-11-04T10:28:34.993361Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate overall statistical summary as a table\n",
    "def overall_statistical_summary(df):\n",
    "    # Calculate the summary for Brightness, Sharpness, and Contrast\n",
    "    summary_df = df[['Brightness', 'Sharpness', 'Contrast','Noise','Skew','Line Spacing', 'Tables Detected','Resolution',\n",
    "                 'Detected Elements','Texture','Patterns']].describe()\n",
    "\n",
    "    # Return the summary table\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd92cab29e23a1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfee87ef78be18f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d33123105abe70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:28:35.021355Z",
     "start_time": "2024-11-04T10:28:35.008356Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function for visualizing histograms and other distributions\n",
    "def plot_characteristic_distribution(df, characteristic, unit, plot_type='hist'):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    if plot_type == 'hist':\n",
    "        sns.histplot(df[characteristic], kde=True, bins=30, color='blue')\n",
    "    elif plot_type == 'box':\n",
    "        sns.boxplot(x=df[characteristic], color='green')\n",
    "\n",
    "    plt.title(f\"Distribution of {characteristic}\")\n",
    "    plt.xlabel(f\"{characteristic} ({unit})\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97af57268192b2a7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2afae4bb2d431d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:28:35.037356Z",
     "start_time": "2024-11-04T10:28:35.023357Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to plot relationships (scatter plots) between two characteristics\n",
    "def plot_characteristic_relationship(df, characteristic_1, characteristic_2, unit_1, unit_2, use_color=False):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    if use_color:\n",
    "        sns.scatterplot(x=df[characteristic_1], y=df[characteristic_2], hue=df[characteristic_2], palette='coolwarm', s=50)\n",
    "    else:\n",
    "        sns.scatterplot(x=df[characteristic_1], y=df[characteristic_2], s=50)\n",
    "\n",
    "    plt.title(f\"Relationship between {characteristic_1} and {characteristic_2}\")\n",
    "    plt.xlabel(f\"{characteristic_1} ({unit_1})\")\n",
    "    plt.ylabel(f\"{characteristic_2} ({unit_2})\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408457e4b91a3e0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:28:35.053358Z",
     "start_time": "2024-11-04T10:28:35.039357Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to create a heatmap for correlations between characteristics\n",
    "def plot_correlation_heatmap(df, characteristics, characteristic_units):\n",
    "    plt.figure(figsize=(10, 8))  # Increase figure size for better visibility\n",
    "    correlation_matrix = df[characteristics].corr()\n",
    "\n",
    "    # Create annotations with correlation values and units\n",
    "    annot = correlation_matrix.round(2).astype(str)  # Round and convert to string\n",
    "    for i in range(len(characteristics)):\n",
    "        for j in range(len(characteristics)):\n",
    "            annot.iloc[i, j] += f\"\\n({characteristic_units[j]})\"  # Append units\n",
    "\n",
    "    # Create the heatmap\n",
    "    sns.heatmap(correlation_matrix, annot=annot, cmap='coolwarm', linewidths=0.5, fmt='',\n",
    "                cbar_kws={'shrink': 0.8}, annot_kws={\"size\": 10})  # Font size for annotations\n",
    "\n",
    "    plt.title(\"Correlation Heatmap Between Characteristics\", fontsize=16)\n",
    "    plt.xlabel(\"Characteristics (Unit)\", fontsize=14)\n",
    "    plt.ylabel(\"Characteristics (Unit)\", fontsize=14)\n",
    "\n",
    "    # Set tick labels with adjusted font size\n",
    "    plt.xticks(ticks=range(len(characteristics)),\n",
    "               labels=[f\"{char} ({unit})\" for char, unit in zip(characteristics, characteristic_units)],\n",
    "               rotation=45, fontsize=12)\n",
    "    plt.yticks(ticks=range(len(characteristics)),\n",
    "               labels=[f\"{char} ({unit})\" for char, unit in zip(characteristics, characteristic_units)],\n",
    "               rotation=0, fontsize=12)\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout to prevent clipping\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10d34bd56b047e8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7dfd2e2cab4c72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:28:35.069358Z",
     "start_time": "2024-11-04T10:28:35.055357Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Flexible Statistical Test Function\n",
    "def overall_statistical_tests(df):\n",
    "    # Create a DataFrame to store statistical test results\n",
    "    test_results = {'Test': [], 'Characteristic_1': [], 'Characteristic_2': [], 'Statistic': [], 'P-Value': []}\n",
    "\n",
    "    # Perform normality tests for each characteristic\n",
    "    for col in ['Brightness', 'Sharpness', 'Contrast']:\n",
    "        stat, p_value = stats.normaltest(df[col])\n",
    "        test_results['Test'].append('Normality')\n",
    "        test_results['Characteristic_1'].append(col)\n",
    "        test_results['Characteristic_2'].append(None)  # No second characteristic for univariate tests\n",
    "        test_results['Statistic'].append(stat)\n",
    "        test_results['P-Value'].append(p_value)\n",
    "\n",
    "    # Perform Pearson correlation tests between each pair of characteristics\n",
    "    pairs = itertools.combinations(['Brightness', 'Sharpness', 'Contrast','Noise','Skew','Line Spacing', 'Tables Detected','Resolution','Detected Elements','Texture','Patterns'], 2)\n",
    "    for char1, char2 in pairs:\n",
    "        corr_stat, corr_p_val = stats.pearsonr(df[char1], df[char2])\n",
    "        test_results['Test'].append('Pearson Correlation')\n",
    "        test_results['Characteristic_1'].append(char1)\n",
    "        test_results['Characteristic_2'].append(char2)\n",
    "        test_results['Statistic'].append(corr_stat)\n",
    "        test_results['P-Value'].append(corr_p_val)\n",
    "\n",
    "    # Return the test results as a DataFrame\n",
    "    return pd.DataFrame(test_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b0b1494bdefb57",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Executing the Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ec313a4e5bae75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:28:35.084356Z",
     "start_time": "2024-11-04T10:28:35.072359Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the path to the folder containing the images to be processed\n",
    "folder_path = '../data/original'  # Update this path to point to your specific folder containing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ac4343dfa8d8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:28:35.115357Z",
     "start_time": "2024-11-04T10:28:35.087357Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_paths = load_images_from_folder(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4034f17238144c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 1: Load and preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a62c53c467f08d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:31:41.128174Z",
     "start_time": "2024-11-04T10:28:35.117357Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = load_and_preprocess_images(image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ee69d703f4300b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 2: Create image statistics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7652665d8601b3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:31:51.365459Z",
     "start_time": "2024-11-04T10:31:41.132171Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_stats = image_statistics_table(images)\n",
    "print(\"Image Statistics Table:\")\n",
    "df_stats\n",
    "#df_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfefe13af7a9a811",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:31:51.380457Z",
     "start_time": "2024-11-04T10:31:51.367458Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcaa2b00314a1e8a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Explenation about the different characteristics and how they are measured:\n",
    "- Brightness represents the overall intensity of light in an image. It is measured by calculating the mean (average) pixel value across the image.\n",
    "    - Units: Pixel intensity values, typically on a scale of 0 to 255 in an 8-bit grayscale image. 0 means completely black. 255 means completely white. \n",
    "    - Values in between represent varying levels of gray. For example, a brightness value of 128 would indicate an image that is midway between black and white (medium gray).\n",
    "- Contrast refers to the difference between the darkest and brightest parts of an image. It is often measured by calculating the standard deviation of pixel values in the image. The standard deviation tells us how much the pixel values are spread out (the higher the contrast, the wider the spread between bright and dark areas).\n",
    "    - Units: The unit is the pixel standard deviation (the spread of pixel intensity values). It reflects how much variation exists in the pixel intensity values. \n",
    "        - A low contrast image would have values close together (e.g., most pixels around a middle gray). \n",
    "        - A high contrast image would have pixel values widely spread (e.g., a mix of very dark and very bright areas).\n",
    "- Sharpness measures how clear or well-defined the edges are in an image. It is calculated using the variance of the Laplacian (a method that highlights the edges in the image). The variance measures how much the values deviate from the average, with higher variance meaning sharper images.\n",
    "    - Units: The unit here is a sharpness index, specifically the variance of the Laplacian, which is a numerical value that reflects how sharp the image is. Like contrast, it doesn’t have a traditional unit but represents how much the pixel values at edges vary.\n",
    "        - A higher value means the image is sharper, with clearer edges.\n",
    "        - A lower value means the image is blurrier or has fewer defined edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cab5e925e02689e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 3: Overall statistical summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf0ee26ce41a9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:31:51.443457Z",
     "start_time": "2024-11-04T10:31:51.382457Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overall_summary = overall_statistical_summary(df_stats)\n",
    "print(\"Overall Statistical Summary:\")\n",
    "overall_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904080d745901344",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 4: Visualize overall distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b1caa29023b7e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:31:51.459459Z",
     "start_time": "2024-11-04T10:31:51.445459Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define characteristics and their units in a single dictionary\n",
    "characteristics_units = {\n",
    "    'Brightness': 'Pixel Value (0-255)',\n",
    "    'Contrast': 'Pixel Value (0-255) Std Dev',\n",
    "    'Sharpness': 'Pixel Intensity Squared Variability',\n",
    "    'Noise': 'Pixel Value (0-255) Std Dev',\n",
    "    'Skew': 'Degrees (°)',\n",
    "    'Line Spacing': 'Pixel Count Avg',\n",
    "    'Tables Detected': 'Count',\n",
    "    'Resolution': 'Pixel Count',\n",
    "    'Detected Elements': 'Count',\n",
    "    'Texture': 'Pixel Intensity Variability',\n",
    "    'Patterns': 'Count'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e9048429bc7448",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:31:58.330934Z",
     "start_time": "2024-11-04T10:31:51.461460Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop through each characteristic and its corresponding unit\n",
    "for characteristic, unit in characteristics_units.items():\n",
    "    for plot_type in ['hist', 'box']:\n",
    "        plot_characteristic_distribution(df_stats, characteristic, unit, plot_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465948057a0ac4ae",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 5: Visualize relationships between characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def5e978469fe378",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:32:13.212741Z",
     "start_time": "2024-11-04T10:31:58.332935Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate pairs of characteristics\n",
    "pairs = itertools.combinations(characteristics_units.keys(), 2)\n",
    "\n",
    "# Loop through each pair and create the relationship plots\n",
    "for char1, char2 in pairs:\n",
    "    plot_characteristic_relationship(\n",
    "        df_stats,\n",
    "        char1,\n",
    "        char2,\n",
    "        characteristics_units[char1],  # Get the unit for char1\n",
    "        characteristics_units[char2]   # Get the unit for char2\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77d7ebec74af3c4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d79cd486fff79af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:32:13.833740Z",
     "start_time": "2024-11-04T10:32:13.215740Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correlation_matrix = df_stats.corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efe6b0cb1c39562",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 6: Perform statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c403941a0f15e145",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:32:13.938738Z",
     "start_time": "2024-11-04T10:32:13.835740Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_results_table = overall_statistical_tests(df_stats)\n",
    "test_results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617c7281256a2d4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:32:13.954738Z",
     "start_time": "2024-11-04T10:32:13.940739Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def highlight_brightness_popularity(images):\n",
    "    \"\"\"\n",
    "    Generate a heatmap showing areas with higher or lower brightness popularity across multiple images.\n",
    "    \n",
    "    Parameters:\n",
    "        images (list): List of grayscale images (2D numpy arrays).\n",
    "        \n",
    "    Returns:\n",
    "        None: Displays the heatmap visualization.\n",
    "    \"\"\"\n",
    "    if not images:\n",
    "        raise ValueError(\"No images provided.\")\n",
    "\n",
    "    # Ensure all images have the same dimensions\n",
    "    img_height, img_width = images[0].shape\n",
    "    for image in images:\n",
    "        if image.shape != (img_height, img_width):\n",
    "            raise ValueError(\"All images must have the same dimensions.\")\n",
    "\n",
    "    # Initialize an accumulator for brightness values\n",
    "    brightness_accumulator = np.zeros((img_height, img_width), dtype=np.float64)\n",
    "\n",
    "    # Accumulate brightness values for each pixel across all images\n",
    "    for image in images:\n",
    "        brightness_accumulator += image.astype(np.float64)\n",
    "\n",
    "    # Normalize the accumulated brightness to fall between 0 and 255\n",
    "    brightness_heatmap = cv2.normalize(brightness_accumulator, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.title(\"Heatmap of Brightness Popularity Across Images\")\n",
    "    plt.imshow(brightness_heatmap, cmap='gray', interpolation='nearest')\n",
    "    plt.colorbar(label='Brightness Popularity')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Load your images as grayscale and pass them to the function\n",
    "# images = [cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) for image_path in image_paths]\n",
    "# highlight_brightness_popularity(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0178c3a33d53741",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:32:14.355739Z",
     "start_time": "2024-11-04T10:32:13.956742Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "highlight_brightness_popularity(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3104eaecf2091cef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:32:14.370739Z",
     "start_time": "2024-11-04T10:32:14.357739Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fc45d1ca4961fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:32:14.385738Z",
     "start_time": "2024-11-04T10:32:14.372740Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm\n",
    "# \n",
    "# # Function to load image paths with a loading bar\n",
    "# def load_images_from_folder(folder_path, extensions=('.png', '.jpg', '.jpeg', '.JPG')):\n",
    "#     \"\"\"\n",
    "#     Load all image file paths from a specified folder that match the given file extensions.\n",
    "#     \"\"\"\n",
    "#     if not os.path.exists(folder_path):\n",
    "#         raise FileNotFoundError(f\"The specified folder does not exist: {folder_path}\")\n",
    "# \n",
    "#     # Use tqdm to show progress for collecting file paths\n",
    "#     image_paths = [os.path.join(folder_path, f) for f in tqdm(os.listdir(folder_path),\n",
    "#                                                               desc=\"Gathering image paths\",\n",
    "#                                                               unit=\"file\")\n",
    "#                    if f.endswith(extensions)]\n",
    "#     return image_paths\n",
    "# \n",
    "# # Function to load and preprocess images with a loading bar\n",
    "# def load_and_preprocess_images(image_paths, resize_dim=(256, 256)):\n",
    "#     images = []\n",
    "#     for path in tqdm(image_paths, desc=\"Loading and preprocessing images\", unit=\"image\"):\n",
    "#         img = cv2.imread(path)\n",
    "#         img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#         img_resized = cv2.resize(img_gray, resize_dim)\n",
    "#         images.append(img_resized)\n",
    "#     return images\n",
    "# \n",
    "# # Function to load original images with a loading bar\n",
    "# def load_images(image_paths):\n",
    "#     original_images = []\n",
    "#     for path in tqdm(image_paths, desc=\"Loading original images\", unit=\"image\"):\n",
    "#         img = cv2.imread(path)\n",
    "# \n",
    "#         # Check if image was loaded correctly\n",
    "#         if img is not None:\n",
    "#             original_images.append(img)\n",
    "#         else:\n",
    "#             print(f\"Warning: Unable to load image at {path}. Skipping.\")\n",
    "# \n",
    "#     return original_images[:10]  # Limit to the first 10 images to avoid memory issues\n",
    "# \n",
    "# # Execution code\n",
    "# # folder_path = '../data/original'\n",
    "# image_paths = load_images_from_folder(folder_path)\n",
    "# \n",
    "# # Load original and processed images\n",
    "# original_images = load_images(image_paths)\n",
    "# processed_images = load_and_preprocess_images(image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1897f3b9cdd0ed1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:32:14.400739Z",
     "start_time": "2024-11-04T10:32:14.388740Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import cv2\n",
    "# \n",
    "# # Display each pair of images separately\n",
    "# num_images_to_show = min(3, len(original_images))  # Limit to the first 3 pairs\n",
    "# \n",
    "# for i in range(num_images_to_show):\n",
    "#     # Create a new figure for each pair\n",
    "#     plt.figure(figsize=(6, 6))\n",
    "# \n",
    "#     # Display Original Image\n",
    "#     plt.subplot(2, 1, 1)\n",
    "#     plt.imshow(cv2.cvtColor(original_images[i], cv2.COLOR_BGR2RGB))\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.title(f\"Original Image {i + 1}\")\n",
    "# \n",
    "#     # Display Grayscale Processed Image\n",
    "#     plt.subplot(2, 1, 2)\n",
    "#     plt.imshow(processed_images[i], cmap=\"gray\")\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.title(f\"Grayscale Image {i + 1}\")\n",
    "# \n",
    "#     # Show each figure separately\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97467bc429a02d01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:32:14.416740Z",
     "start_time": "2024-11-04T10:32:14.402740Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alessandroryo",
   "language": "python",
   "name": "alessandroryo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
