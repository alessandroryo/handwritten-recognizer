{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uv-mO0k2wYvo"
   },
   "source": [
    "# Iteration 1 - TableNet Model\n",
    "\n",
    "> **Dataset**: Marmot Dataset <br/>\n",
    "> **Model**: TableNet Model <br/>\n",
    "> **Creator**: Ryo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2IfwC523Q3W"
   },
   "source": [
    "## **Data Collection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mrt2d-j22gUW"
   },
   "source": [
    "### Upload `kaggle.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMpbjxWM13TF"
   },
   "source": [
    "\n",
    "\n",
    "To authenticate with Kaggle and access datasets or competitions, the `kaggle.json` file needs to be uploaded. This file contains your Kaggle API credentials, which allow interaction with Kaggle's services.\n",
    "\n",
    "1. Ensure the `kaggle.json` file is ready on your local machine.\n",
    "2. Run the code below to initiate the file upload process.\n",
    "3. Select the `kaggle.json` file from your local directory when prompted.\n",
    "4. Once uploaded, proceed with the next steps to set up the environment for Kaggle access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "WxsFBiNn9xpf",
    "outputId": "73cbb835-fac4-4ab1-fa4e-72ae949626bb"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "# files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NaCGRYnK5lxY"
   },
   "source": [
    "### Download Marmot Dataset from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjVUcizK2oR5"
   },
   "source": [
    "\n",
    "This code snippet automates the setup process for accessing and downloading the Marmot dataset from Kaggle. It begins by creating a secure directory to store the kaggle.json file, which contains the necessary credentials for Kaggle API access. The kaggle.json file is then copied into this directory, and its permissions are adjusted to ensure only the current user can read it, enhancing security. After setting up the credentials, the script downloads the Marmot dataset directly from Kaggle, extracts its contents into a specified directory, and then removes the original zip file to free up space. This sequence ensures that the dataset is ready for use in the working environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BVvFjMe_91Bq",
    "outputId": "37e0a303-99ad-43a0-9cd8-6847caa18185"
   },
   "outputs": [],
   "source": [
    "# !mkdir -p ~/.kaggle\n",
    "# !cp kaggle.json ~/.kaggle/\n",
    "# !chmod 600 ~/.kaggle/kaggle.json\n",
    "# !kaggle datasets download -d ritvik1909/marmot-dataset\n",
    "# !mkdir -p /content/marmot_data\n",
    "# !unzip marmot-dataset.zip -d /content/marmot_data\n",
    "# !rm marmot-dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_ImlpWg4OGy"
   },
   "source": [
    "### Install Additional Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j86oaXw25Dkv"
   },
   "source": [
    "- **pytesseract**: `pytesseract` is a Python wrapper for Google's Tesseract-OCR engine, used to extract text from images through Optical Character Recognition (OCR), commonly applied in tasks involving text recognition in scanned documents or photos.\n",
    "\n",
    "- **albumentations**: `albumentations` is a fast and versatile image augmentation library designed to enhance training data for deep learning models by applying various transformations, such as rotations, flips, and color adjustments, to create more diverse training examples and improve model generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1kEIRqqhvlG",
    "outputId": "1bd6f603-e72a-45b8-bef1-e688e2d08d13"
   },
   "outputs": [],
   "source": [
    "# !sudo apt install tesseract-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCaeb72I3wiu"
   },
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oq13rWXGffDP",
    "outputId": "15911a39-a091-46d3-e144-ba1ab5a4f5ed"
   },
   "outputs": [],
   "source": [
    "def install_package(package_name):\n",
    "    \"\"\"\n",
    "    Installs a Python package using pip and suppresses all output.\n",
    "    Prints a success message if the installation is successful,\n",
    "    or a failure message if the installation fails.\n",
    "\n",
    "    :param package_name: The name of the package to be installed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Attempt to install the package while suppressing output\n",
    "        subprocess.check_call(['pip', 'install', package_name], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        # Print success message if installation is successful\n",
    "        print(f\"Successfully installed {package_name}\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        # Print failure message if installation fails\n",
    "        print(f\"Failed to install {package_name}\")\n",
    "\n",
    "# Install the pytesseract package\n",
    "install_package('pytesseract')\n",
    "\n",
    "# Install the albumentations package with upgrade option\n",
    "install_package('albumentations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9da4PvQ4EjT"
   },
   "source": [
    "## **Data Understanding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkZ3MfFKUAhL"
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_KPPFaFu9xpe"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, applications\n",
    "from tensorflow.keras.models import load_model\n",
    "import pytesseract\n",
    "import albumentations as A\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfkWL_vHUEFf"
   },
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iNg49Nai9xpf"
   },
   "outputs": [],
   "source": [
    "# Specify the path to the base folder\n",
    "base_folder = '../marmot_data'\n",
    "\n",
    "# Specify the paths to the xml, image, table mask, and column mask folders\n",
    "xml_folder = os.path.join(base_folder, 'xml')\n",
    "image_folder = os.path.join(base_folder, 'image')\n",
    "table_mask_folder = os.path.join(base_folder, 'table_mask')\n",
    "column_mask_folder = os.path.join(base_folder, 'column_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ju8mOjas9xpg"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 100  # Buffer size for shuffling the dataset; larger values result in better shuffling\n",
    "BATCH_SIZE = 1     # Number of samples processed before updating the model; higher values can improve computational efficiency\n",
    "EPOCHS = 20        # Number of times the entire dataset is passed through the model during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pW_gzaieUMpz"
   },
   "source": [
    "### Organize Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZp4mu8_5dhO"
   },
   "source": [
    "#### *Functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "je_Je5nC9xpg"
   },
   "outputs": [],
   "source": [
    "def organize_files(base_folder):\n",
    "    \"\"\"\n",
    "    Organize files by creating 'xml' and 'image' folders in the base directory.\n",
    "    Moves .xml files to the 'xml' folder and .jpeg files to the 'image' folder,\n",
    "    while showing a progress bar.\n",
    "\n",
    "    Parameters:\n",
    "    base_folder (str): The path to the base folder containing the 'data' folder.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Define paths for the new 'xml' and 'image' folders within the base directory\n",
    "    xml_folder = os.path.join(base_folder, 'xml')\n",
    "    image_folder = os.path.join(base_folder, 'image')\n",
    "    data_folder = os.path.join(base_folder, 'data')\n",
    "\n",
    "    # Create the 'xml' and 'image' folders if they don't already exist\n",
    "    os.makedirs(xml_folder, exist_ok=True)\n",
    "    os.makedirs(image_folder, exist_ok=True)\n",
    "\n",
    "    # Check if the 'data' folder exists in the base directory\n",
    "    if os.path.exists(data_folder):\n",
    "        # List all files inside the 'data' folder\n",
    "        files = os.listdir(data_folder)\n",
    "\n",
    "        # Initialize a progress bar to track the file organization process\n",
    "        with tqdm(total=len(files), desc=\"Organizing files\", unit=\"file\", ncols=100) as pbar:\n",
    "            for file_name in files:\n",
    "                # Construct the full file path for the current file\n",
    "                file_path = os.path.join(data_folder, file_name)\n",
    "\n",
    "                try:\n",
    "                    # Move .xml files to the 'xml' folder\n",
    "                    if file_name.endswith('.xml'):\n",
    "                        shutil.move(file_path, os.path.join(xml_folder, file_name))\n",
    "                        # Update the progress bar with the current status\n",
    "                        pbar.set_postfix({\"Moved\": f\"{file_name} to xml\"})\n",
    "                    # Move .jpeg files to the 'image' folder\n",
    "                    elif file_name.endswith('.jpeg'):\n",
    "                        shutil.move(file_path, os.path.join(image_folder, file_name))\n",
    "                        # Update the progress bar with the current status\n",
    "                        pbar.set_postfix({\"Moved\": f\"{file_name} to image\"})\n",
    "                except Exception as e:\n",
    "                    # Log any errors that occur during the file moving process\n",
    "                    pbar.write(f\"Error processing {file_name}: {str(e)}\")\n",
    "\n",
    "                # Increment the progress bar for each processed file\n",
    "                pbar.update(1)\n",
    "\n",
    "        # Remove the 'data' folder after all files have been moved\n",
    "        shutil.rmtree(data_folder)\n",
    "        print(f\"Deleted folder: {data_folder}\")\n",
    "    else:\n",
    "        # Notify the user if the 'data' folder is not found in the base directory\n",
    "        print(f\"No 'data' folder found in {base_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xt58g2n5wcc"
   },
   "source": [
    "#### *Implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1eEx9eq9xpg",
    "outputId": "2da0afc4-5e63-4e3c-cdfa-fe0fedc6974f"
   },
   "outputs": [],
   "source": [
    "organize_files(base_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQwJAieaUQdJ"
   },
   "source": [
    "### Count File Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHOMGV2I6LJA"
   },
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UziQh9Au9xph"
   },
   "outputs": [],
   "source": [
    "def count_file_types(xml_folder, image_folder):\n",
    "    \"\"\"\n",
    "    Count the number of .jpeg files in the image folder and .xml files in the xml folder.\n",
    "\n",
    "    Parameters:\n",
    "    xml_folder (str): The path to the folder containing the .xml files.\n",
    "    image_folder (str): The path to the folder containing the .jpeg files.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the count of .jpeg and .xml files.\n",
    "    \"\"\"\n",
    "\n",
    "    # Count the number of .xml files in the xml folder by filtering files that end with .xml\n",
    "    xml_count = len([file for file in os.listdir(xml_folder) if file.endswith('.xml')])\n",
    "\n",
    "    # Count the number of .jpeg files in the image folder by filtering files that end with .jpeg\n",
    "    jpeg_count = len([file for file in os.listdir(image_folder) if file.endswith('.jpeg')])\n",
    "\n",
    "    # Return the counts as a tuple (jpeg_count, xml_count)\n",
    "    return jpeg_count, xml_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSi-n-zI6OjQ"
   },
   "source": [
    "#### *Implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "msI7hgqk9xph",
    "outputId": "045a0ce5-b37e-4901-9b02-3e709dc7a2a7"
   },
   "outputs": [],
   "source": [
    "jpeg_count, xml_count = count_file_types(xml_folder, image_folder)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total .jpeg files: {jpeg_count}\")\n",
    "print(f\"Total .xml files: {xml_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4rNQ1_6URxV"
   },
   "source": [
    "### Check File Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKjdJUAT7B0K"
   },
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7CdGbVZG9xph"
   },
   "outputs": [],
   "source": [
    "def check_file_pairs(xml_folder, image_folder):\n",
    "    \"\"\"\n",
    "    Check for matching pairs of .jpeg files in the image folder and .xml files in the xml folder.\n",
    "\n",
    "    Parameters:\n",
    "    xml_folder (str): The path to the folder containing the .xml files.\n",
    "    image_folder (str): The path to the folder containing the .jpeg files.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing lists of unmatched .jpeg and .xml files.\n",
    "    \"\"\"\n",
    "    # Create a set of file names (without extensions) from the .jpeg files in the image folder\n",
    "    jpeg_files = set(os.path.splitext(file)[0] for file in os.listdir(image_folder) if file.endswith('.jpeg'))\n",
    "\n",
    "    # Create a set of file names (without extensions) from the .xml files in the xml folder\n",
    "    xml_files = set(os.path.splitext(file)[0] for file in os.listdir(xml_folder) if file.endswith('.xml'))\n",
    "\n",
    "    # Identify .jpeg files that do not have a corresponding .xml file\n",
    "    unmatched_jpeg = jpeg_files - xml_files\n",
    "\n",
    "    # Identify .xml files that do not have a corresponding .jpeg file\n",
    "    unmatched_xml = xml_files - jpeg_files\n",
    "\n",
    "    # Return a dictionary with lists of unmatched .jpeg and .xml files\n",
    "    return {\n",
    "        'unmatched_jpeg': list(unmatched_jpeg),\n",
    "        'unmatched_xml': list(unmatched_xml)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-cpiKYS7Fc-"
   },
   "source": [
    "#### *Implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NuRoZ5Y39xpi",
    "outputId": "57f92cbd-23ab-4e7e-f586-4ccf81d22807"
   },
   "outputs": [],
   "source": [
    "# Call the check_file_pairs function to find unmatched .jpeg and .xml files\n",
    "unmatched_files = check_file_pairs(xml_folder, image_folder)\n",
    "\n",
    "# Check if there are any unmatched .jpeg or .xml files\n",
    "if unmatched_files['unmatched_jpeg'] or unmatched_files['unmatched_xml']:\n",
    "    # If there are unmatched files, print the lists of unmatched .jpeg and .xml files\n",
    "    print(\"Unmatched .jpeg files:\", unmatched_files['unmatched_jpeg'])\n",
    "    print(\"Unmatched .xml files:\", unmatched_files['unmatched_xml'])\n",
    "else:\n",
    "    # If all files are properly paired, print a confirmation message\n",
    "    print(\"All .jpeg and .xml files are properly paired.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s52I8XsVUd0r"
   },
   "source": [
    "### Display Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LeAUfwys7t-F"
   },
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LUyygQS09xpi"
   },
   "outputs": [],
   "source": [
    "def display_random_images_separately(folder_path, num_images=5):\n",
    "    \"\"\"\n",
    "    Display a specified number of random .jpeg images from a given folder using OpenCV.\n",
    "    Each image will be displayed in a separate plot to allow for larger size.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing the images.\n",
    "    num_images (int): The number of images to display (default is 5).\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # List all .jpeg files in the specified folder\n",
    "    jpeg_files = [f for f in os.listdir(folder_path) if f.endswith('.jpeg')]\n",
    "\n",
    "    # Check if the requested number of images exceeds the available images\n",
    "    if num_images > len(jpeg_files):\n",
    "        print(f\"Only {len(jpeg_files)} images are available.\")\n",
    "        num_images = len(jpeg_files)  # Adjust the number of images to the available amount\n",
    "\n",
    "    # Randomly select the specified number of images from the list\n",
    "    random_images = random.sample(jpeg_files, num_images)\n",
    "\n",
    "    # Loop through the selected images and display each one separately\n",
    "    for image_file in random_images:\n",
    "        # Construct the full path to the image file\n",
    "        img_path = os.path.join(folder_path, image_file)\n",
    "\n",
    "        # Read the image using OpenCV\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        # Convert the image from BGR to RGB for correct color display in Matplotlib\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Create a new figure for each image with a larger size\n",
    "        plt.figure(figsize=(8, 8))\n",
    "\n",
    "        # Display the image\n",
    "        plt.imshow(img_rgb)\n",
    "\n",
    "        # Hide the axes for a cleaner display\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Show the image plot\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkoHX09P7xL_"
   },
   "source": [
    "#### *Implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "V_Kt3obY9xpi",
    "outputId": "e9531ba1-b243-4532-944f-69d6ab10bb62"
   },
   "outputs": [],
   "source": [
    "display_random_images_separately(image_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRXHnCDYUhAp"
   },
   "source": [
    "### Display XML File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VRHv-Kl70xC"
   },
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ouc-oaME9xpi"
   },
   "outputs": [],
   "source": [
    "def display_random_xml_content(folder_path):\n",
    "    \"\"\"\n",
    "    Display the content of a random .xml file from the specified folder.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): The path to the folder containing the .xml files.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # List all .xml files in the specified folder\n",
    "    xml_files = [f for f in os.listdir(folder_path) if f.endswith('.xml')]\n",
    "\n",
    "    # Check if there are any .xml files in the folder\n",
    "    if not xml_files:\n",
    "        # If no .xml files are found, notify the user and exit the function\n",
    "        print(\"No .xml files found in the folder.\")\n",
    "        return\n",
    "\n",
    "    # Randomly select one .xml file from the list\n",
    "    random_xml_file = random.choice(xml_files)\n",
    "\n",
    "    # Construct the full path to the selected .xml file\n",
    "    xml_path = os.path.join(folder_path, random_xml_file)\n",
    "\n",
    "    # Open the selected .xml file and read its content\n",
    "    with open(xml_path, 'r') as file:\n",
    "        xml_content = file.read()\n",
    "\n",
    "        # Print the name of the file and its content\n",
    "        print(f\"Content of {random_xml_file}:\\n\")\n",
    "        print(xml_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lh8fLLp_73iG"
   },
   "source": [
    "#### *Implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lNGbUmHv9xpi",
    "outputId": "dbca21b2-2d98-45c6-dbd5-e774a06c335c"
   },
   "outputs": [],
   "source": [
    "display_random_xml_content(xml_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIBAZBwSUkJG"
   },
   "source": [
    "### Calculate Eucledian Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzhbZDMK8UVc"
   },
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nw8EFc5L9xpi"
   },
   "outputs": [],
   "source": [
    "def calculate_euclidean_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two points.\n",
    "\n",
    "    The Euclidean distance is the straight-line distance between two points\n",
    "    in a 2D space (like the distance between two points on a graph). It is\n",
    "    calculated as the square root of the sum of the squared differences\n",
    "    between corresponding coordinates of the points.\n",
    "\n",
    "    Parameters:\n",
    "    point1 (numpy array): Coordinates of the first point (x, y).\n",
    "    point2 (numpy array): Coordinates of the second point (x, y).\n",
    "\n",
    "    Returns:\n",
    "    float: The Euclidean distance between the two points.\n",
    "    \"\"\"\n",
    "    # Calculate the Euclidean distance using the norm function from numpy\n",
    "    return np.linalg.norm(point1 - point2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKXyPmzVU3t5"
   },
   "source": [
    "### Save Numpy Array as Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJHoxYFk8iZN"
   },
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cWD_PuFa9xpi"
   },
   "outputs": [],
   "source": [
    "def save_image(image_array, path):\n",
    "    \"\"\"\n",
    "    Save a numpy array as an image file.\n",
    "\n",
    "    This function takes image data in the form of a numpy array and saves it as an image file\n",
    "    at the specified path. The image is saved using OpenCV's `imwrite` function, which supports\n",
    "    various image formats such as .png, .jpg, etc., depending on the file extension provided in the path.\n",
    "\n",
    "    Parameters:\n",
    "    image_array (numpy array): The image data in numpy array format, where the array represents pixel values.\n",
    "    path (str): The complete file path, including the name and extension, where the image will be saved.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Save the image to the specified path using OpenCV's imwrite function\n",
    "    cv2.imwrite(path, image_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmYpELAyU7Lo"
   },
   "source": [
    "### Generate Masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLNFhylU8ufQ"
   },
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BaAXCoh59xpi"
   },
   "outputs": [],
   "source": [
    "def generate_column_and_table_masks(xml_folder, table_mask_folder, column_mask_folder):\n",
    "    \"\"\"\n",
    "    Generate mask images for columns and tables from XML annotations.\n",
    "    Masks are saved in separate directories for columns and tables.\n",
    "\n",
    "    Parameters:\n",
    "    xml_folder (str): The folder containing the XML files with annotations.\n",
    "    table_mask_folder (str): The folder where the generated table masks will be saved.\n",
    "    column_mask_folder (str): The folder where the generated column masks will be saved.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Create directories for table and column masks if they don't exist\n",
    "    os.makedirs(table_mask_folder, exist_ok=True)\n",
    "    os.makedirs(column_mask_folder, exist_ok=True)\n",
    "\n",
    "    # List all XML files in the specified XML folder\n",
    "    xml_files = [file for file in os.listdir(xml_folder) if file.endswith(\".xml\")]\n",
    "\n",
    "    # Loop through each XML file to generate masks\n",
    "    for xpath in tqdm(xml_files, desc=\"Generating masks\", unit=\"file\", ncols=100):\n",
    "        # Parse the XML file and get the root element\n",
    "        tree = ET.parse(os.path.join(xml_folder, xpath))\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # Retrieve the image dimensions from the XML metadata\n",
    "        size = root.find('size')\n",
    "        width = int(size.find('width').text)\n",
    "        height = int(size.find('height').text)\n",
    "\n",
    "        # Extract the base filename without extension for naming the mask files\n",
    "        fname = os.path.splitext(root.find('filename').text)[0]\n",
    "\n",
    "        # Initialize empty masks for columns and tables\n",
    "        col_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "        table_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "        # Variables to keep track of table boundaries and state\n",
    "        newTable = True\n",
    "        fwdFlag = False\n",
    "        bwdFlag = False\n",
    "        table_xmin, table_xmax, table_ymin, table_ymax = 0, 0, 0, 0\n",
    "        prev_dist = 0\n",
    "\n",
    "        # Get all annotated objects (columns) from the XML\n",
    "        objects = root.findall('object')\n",
    "        for index, obj in enumerate(objects):\n",
    "            # Extract the bounding box coordinates for the column\n",
    "            bndbox = obj.find('bndbox')\n",
    "            xmin = int(bndbox.find('xmin').text)\n",
    "            xmax = int(bndbox.find('xmax').text)\n",
    "            ymin = int(bndbox.find('ymin').text)\n",
    "            ymax = int(bndbox.find('ymax').text)\n",
    "\n",
    "            # Create the column mask by setting the corresponding region to white (255)\n",
    "            col_mask[ymin:ymax, xmin:xmax] = 255\n",
    "\n",
    "            if len(objects) <= 2:\n",
    "                # If there are 2 or fewer columns, consider them as part of the same table\n",
    "                xmins = [int(obj.find('bndbox/xmin').text) for obj in objects]\n",
    "                xmaxes = [int(obj.find('bndbox/xmax').text) for obj in objects]\n",
    "                ymins = [int(obj.find('bndbox/ymin').text) for obj in objects]\n",
    "                ymaxes = [int(obj.find('bndbox/ymax').text) for obj in objects]\n",
    "\n",
    "                table_xmin = min(xmins)\n",
    "                table_xmax = max(xmaxes)\n",
    "                table_ymin = min(ymins)\n",
    "                table_ymax = max(ymaxes)\n",
    "                table_mask[table_ymin:table_ymax, table_xmin:table_xmax] = 255\n",
    "                continue\n",
    "\n",
    "            if index == 0:\n",
    "                # Initialize previous coordinates for the first column\n",
    "                prev_xmin, prev_xmax, prev_ymin, prev_ymax = xmin, xmax, ymin, ymax\n",
    "            else:\n",
    "                # Determine if the table is expanding forward or backward\n",
    "                if xmin > prev_xmin and newTable:\n",
    "                    table_xmin, table_ymin = prev_xmin, prev_ymin\n",
    "                    newTable, fwdFlag = False, True\n",
    "                if xmin < prev_xmin and newTable:\n",
    "                    table_xmax, table_ymax = prev_xmax, prev_ymax\n",
    "                    newTable, bwdFlag = False, True\n",
    "\n",
    "                if fwdFlag:\n",
    "                    # Calculate distance between current and previous column for forward movement\n",
    "                    dist = calculate_euclidean_distance(np.array([xmin, ymin]), np.array([prev_xmax, prev_ymin]))\n",
    "                    if prev_dist == 0:\n",
    "                        prev_dist = dist\n",
    "                    else:\n",
    "                        if dist // prev_dist > 3:\n",
    "                            newTable = True\n",
    "                            table_mask[table_ymin:prev_ymax, table_xmin:prev_xmax] = 255\n",
    "                            prev_dist = 0\n",
    "                        if index == len(objects) - 1:\n",
    "                            newTable = True\n",
    "                            table_mask[table_ymin:ymax, table_xmin:xmax] = 255\n",
    "                            prev_dist = 0\n",
    "\n",
    "                if bwdFlag:\n",
    "                    # Calculate distance between current and previous column for backward movement\n",
    "                    dist = calculate_euclidean_distance(np.array([xmax, ymin]), np.array([prev_xmin, prev_ymin]))\n",
    "                    if prev_dist == 0:\n",
    "                        prev_dist = dist\n",
    "                    else:\n",
    "                        if dist // prev_dist > 3 or index == len(objects) - 1:\n",
    "                            newTable = True\n",
    "                            table_mask[prev_ymin:table_ymax, xmin:table_xmax] = 255\n",
    "                            prev_dist = 0\n",
    "\n",
    "                # Update previous column coordinates and distance for the next iteration\n",
    "                prev_xmin, prev_xmax, prev_ymin, prev_ymax = xmin, xmax, ymin, ymax\n",
    "                prev_dist = dist\n",
    "\n",
    "        # Save the generated masks for columns and tables\n",
    "        col_path = os.path.join(column_mask_folder, f\"{fname}.jpeg\")\n",
    "        table_path = os.path.join(table_mask_folder, f\"{fname}.jpeg\")\n",
    "\n",
    "        save_image(col_mask, col_path)\n",
    "        save_image(table_mask, table_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNJ0Zn7P8poI"
   },
   "source": [
    "#### *Implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "trd7jCWc9xpj",
    "outputId": "b71dd20c-c972-46a7-f7da-9719c23822eb"
   },
   "outputs": [],
   "source": [
    "generate_column_and_table_masks(xml_folder, table_mask_folder, column_mask_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHBR0Lw2VBGS"
   },
   "source": [
    "### Display Random Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phv5vJqS9G_H"
   },
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "snY6pu6q9xpj"
   },
   "outputs": [],
   "source": [
    "def display_random_image_triplets(image_folder, table_mask_folder, column_mask_folder, num_triplets=5):\n",
    "    \"\"\"\n",
    "    Display a specified number of random image triplets, where each triplet consists of:\n",
    "    1. The original image\n",
    "    2. The table mask\n",
    "    3. The column mask\n",
    "\n",
    "    Parameters:\n",
    "    image_folder (str): The folder containing the original images.\n",
    "    table_mask_folder (str): The folder containing the table mask images.\n",
    "    column_mask_folder (str): The folder containing the column mask images.\n",
    "    num_triplets (int): The number of image triplets to display (default is 5).\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # List all .jpeg image files in the specified image folder\n",
    "    image_files = [f for f in os.listdir(image_folder) if f.endswith('.jpeg')]\n",
    "\n",
    "    # Check if the requested number of triplets exceeds the available images\n",
    "    if num_triplets > len(image_files):\n",
    "        print(f\"Only {len(image_files)} images are available.\")\n",
    "        num_triplets = len(image_files)  # Adjust to the number of available images\n",
    "\n",
    "    # Randomly select the specified number of images\n",
    "    random_images = random.sample(image_files, num_triplets)\n",
    "\n",
    "    # Loop through the selected images to display each triplet (original, table mask, column mask)\n",
    "    for image_file in random_images:\n",
    "        # Construct the full paths to the original image and corresponding masks\n",
    "        original_image_path = os.path.join(image_folder, image_file)\n",
    "        table_mask_path = os.path.join(table_mask_folder, image_file)\n",
    "        column_mask_path = os.path.join(column_mask_folder, image_file)\n",
    "\n",
    "        # Load the images from the respective paths\n",
    "        original_image = cv2.imread(original_image_path)\n",
    "        table_mask = cv2.imread(table_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        column_mask = cv2.imread(column_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Convert the original image from BGR to RGB format for correct color display in Matplotlib\n",
    "        original_image_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Create a figure with 3 subplots to display the original image, table mask, and column mask\n",
    "        plt.figure(figsize=(15, 5))\n",
    "\n",
    "        # Display the original image in the first subplot\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(original_image_rgb)\n",
    "        plt.title('Original Image')\n",
    "        plt.axis('off')  # Hide the axes for a cleaner display\n",
    "\n",
    "        # Display the table mask in the second subplot\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(table_mask, cmap='gray')\n",
    "        plt.title('Table Mask')\n",
    "        plt.axis('off')  # Hide the axes for a cleaner display\n",
    "\n",
    "        # Display the column mask in the third subplot\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(column_mask, cmap='gray')\n",
    "        plt.title('Column Mask')\n",
    "        plt.axis('off')  # Hide the axes for a cleaner display\n",
    "\n",
    "        # Show the complete figure with the three images\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57Msg3Pb9Tzs"
   },
   "source": [
    "#### *Implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "aZ1HmHSk9xpj",
    "outputId": "31f315c5-36c1-439c-d0f5-83a5384242cc"
   },
   "outputs": [],
   "source": [
    "display_random_image_triplets(image_folder, table_mask_folder, column_mask_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FoLtUbT3VF-F"
   },
   "source": [
    "### Count Mask Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpnaGdiBtHFF"
   },
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRO15hrM9xpj"
   },
   "outputs": [],
   "source": [
    "def count_mask_files(column_mask_folder, table_mask_folder):\n",
    "    \"\"\"\n",
    "    Count the total number of files in the column mask and table mask folders.\n",
    "    Also checks for any differences in the number of files between the two folders.\n",
    "\n",
    "    Parameters:\n",
    "    column_mask_folder (str): The path to the folder containing the column mask files.\n",
    "    table_mask_folder (str): The path to the folder containing the table mask files.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the counts and any discrepancies between the two folders.\n",
    "    \"\"\"\n",
    "    # Count files in the column mask folder\n",
    "    column_files = [f for f in os.listdir(column_mask_folder) if f.endswith('.jpeg')]\n",
    "    column_count = len(column_files)\n",
    "\n",
    "    # Count files in the table mask folder\n",
    "    table_files = [f for f in os.listdir(table_mask_folder) if f.endswith('.jpeg')]\n",
    "    table_count = len(table_files)\n",
    "\n",
    "    # Find unmatched files\n",
    "    unmatched_column = set(column_files) - set(table_files)\n",
    "    unmatched_table = set(table_files) - set(column_files)\n",
    "\n",
    "    # Return the counts and any discrepancies\n",
    "    return {\n",
    "        'column_count': column_count,\n",
    "        'table_count': table_count,\n",
    "        'unmatched_column': list(unmatched_column),\n",
    "        'unmatched_table': list(unmatched_table)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4ARZwkAtQYj"
   },
   "source": [
    "#### *Implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQlLMxIk9xpj",
    "outputId": "d4bef474-eb16-4ab6-c9a0-1c9fe83343ad"
   },
   "outputs": [],
   "source": [
    "# Get the counts and discrepancies\n",
    "mask_file_info = count_mask_files(column_mask_folder, table_mask_folder)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total .jpeg files in column_mask: {mask_file_info['column_count']}\")\n",
    "print(f\"Total .jpeg files in table_mask: {mask_file_info['table_count']}\")\n",
    "\n",
    "if mask_file_info['unmatched_column'] or mask_file_info['unmatched_table']:\n",
    "    print(\"Discrepancies found:\")\n",
    "    if mask_file_info['unmatched_column']:\n",
    "        print(f\"Files in column_mask but not in table_mask: {mask_file_info['unmatched_column']}\")\n",
    "    if mask_file_info['unmatched_table']:\n",
    "        print(f\"Files in table_mask but not in column_mask: {mask_file_info['unmatched_table']}\")\n",
    "else:\n",
    "    print(\"No discrepancies found. All files are properly paired.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cG8ROZbtZCw"
   },
   "source": [
    "### Create File Pairs Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OESXpjEgtdA6"
   },
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "daeHnHNv9xpj"
   },
   "outputs": [],
   "source": [
    "def create_file_pairs_dataframe(image_folder, xml_folder, column_mask_folder, table_mask_folder):\n",
    "    \"\"\"\n",
    "    Create a pandas DataFrame containing pairs of files from the specified folders.\n",
    "\n",
    "    The DataFrame will include paths to the original images, XML annotation files,\n",
    "    column masks, and table masks, providing a structured way to access related files.\n",
    "\n",
    "    Parameters:\n",
    "    image_folder (str): The path to the folder containing the original images.\n",
    "    xml_folder (str): The path to the folder containing the XML annotation files.\n",
    "    column_mask_folder (str): The path to the folder containing the column mask files.\n",
    "    table_mask_folder (str): The path to the folder containing the table mask files.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with columns representing file paths in each folder.\n",
    "    \"\"\"\n",
    "    # Get the file names without extensions from each specified folder\n",
    "    image_files = set(os.path.splitext(f)[0] for f in os.listdir(image_folder) if f.endswith('.jpeg'))\n",
    "    xml_files = set(os.path.splitext(f)[0] for f in os.listdir(xml_folder) if f.endswith('.xml'))\n",
    "    column_mask_files = set(os.path.splitext(f)[0] for f in os.listdir(column_mask_folder) if f.endswith('.jpeg'))\n",
    "    table_mask_files = set(os.path.splitext(f)[0] for f in os.listdir(table_mask_folder) if f.endswith('.jpeg'))\n",
    "\n",
    "    # Create a sorted list of all unique file names across the four folders\n",
    "    all_files = sorted(list(image_files | xml_files | column_mask_files | table_mask_files))\n",
    "\n",
    "    # Initialize an empty DataFrame with columns for each file type\n",
    "    df = pd.DataFrame(index=all_files, columns=['image', 'xml', 'column_mask', 'table_mask'])\n",
    "\n",
    "    # Populate the DataFrame with full file paths, mapping file names to their corresponding paths\n",
    "    df['image'] = df.index.map(lambda x: os.path.join(image_folder, x + '.jpeg') if x in image_files else None)\n",
    "    df['xml'] = df.index.map(lambda x: os.path.join(xml_folder, x + '.xml') if x in xml_files else None)\n",
    "    df['column_mask'] = df.index.map(lambda x: os.path.join(column_mask_folder, x + '.jpeg') if x in column_mask_files else None)\n",
    "    df['table_mask'] = df.index.map(lambda x: os.path.join(table_mask_folder, x + '.jpeg') if x in table_mask_files else None)\n",
    "\n",
    "    # Reset the index of the DataFrame to start from 0 and drop the original index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7615URxeuMMm"
   },
   "source": [
    "#### *Implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vY6b77Py9xpj",
    "outputId": "fe9c1d72-ad8d-49c2-bd6e-6a5b2a89b669"
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame that pairs files from the image, XML, column mask, and table mask folders\n",
    "file_pairs_df = create_file_pairs_dataframe(image_folder, xml_folder, column_mask_folder, table_mask_folder)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "file_pairs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOR4OgJeu3eF"
   },
   "source": [
    "### Split Train, Validation, and Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-061Ct4u6w9"
   },
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IihV7tvj9xpj"
   },
   "outputs": [],
   "source": [
    "def split_dataset(df, test_size=0.2, val_size=0.1, random_state=42):\n",
    "    \"\"\"\n",
    "    Split the DataFrame into train, validation, and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to be split.\n",
    "    test_size (float): The proportion of the dataset to include in the test set (default is 0.2).\n",
    "    val_size (float): The proportion of the dataset to include in the validation set relative to the train set (default is 0.1).\n",
    "    random_state (int): The random seed for reproducibility (default is 42).\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the train, validation, and test set DataFrames.\n",
    "    \"\"\"\n",
    "    # Split the DataFrame into a combined train + validation set and a test set\n",
    "    train_val_df, test_df = train_test_split(df, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Further split the combined train + validation set into separate train and validation sets\n",
    "    train_df, val_df = train_test_split(train_val_df, test_size=val_size, random_state=random_state)\n",
    "\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yG5Ic3DDu1gh"
   },
   "source": [
    "#### *Implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xhu9rxZN9xpk",
    "outputId": "33899d97-14b2-4d9f-c1d0-b164eafde2a5"
   },
   "outputs": [],
   "source": [
    "# Split the data into train, validation, and test sets\n",
    "train_df, val_df, test_df = split_dataset(file_pairs_df)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Train set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(val_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "dnOdA5179xpk",
    "outputId": "eec30739-2292-4656-d466-78e86de11614"
   },
   "outputs": [],
   "source": [
    "print(\"Train set sample:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "r1uAEJ3LmCnj",
    "outputId": "c5702483-0b7c-4cb0-cdcb-74d8e39bf93e"
   },
   "outputs": [],
   "source": [
    "print(\"Validation set sample:\")\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "2N6KjT9q9xpk",
    "outputId": "982f58c8-24fa-46c1-dba1-45a52900b5ad"
   },
   "outputs": [],
   "source": [
    "print(\"Test set sample:\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cd25SbKovZsW"
   },
   "source": [
    "### Extract Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLZ4Wb_gvdjL"
   },
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ypKYrye8aRTz"
   },
   "outputs": [],
   "source": [
    "def extract_paths(df):\n",
    "    \"\"\"\n",
    "    Extract paths for images, column masks, and table masks from the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the file paths.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing three numpy arrays for image_paths, column_mask_paths, and table_mask_paths.\n",
    "    \"\"\"\n",
    "    # Extract the paths for images, column masks, and table masks from the DataFrame\n",
    "    image_paths = df['image'].values\n",
    "    column_mask_paths = df['column_mask'].values\n",
    "    table_mask_paths = df['table_mask'].values\n",
    "\n",
    "    return image_paths, column_mask_paths, table_mask_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPRexNDKvfNB"
   },
   "source": [
    "#### *Implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o6utoFtPvgG6"
   },
   "outputs": [],
   "source": [
    "# Extract paths for training data\n",
    "train_image_paths, train_column_mask_paths, train_table_mask_paths = extract_paths(train_df)\n",
    "\n",
    "# Extract paths for validation data\n",
    "val_image_paths, val_column_mask_paths, val_table_mask_paths = extract_paths(val_df)\n",
    "\n",
    "# Extract paths for testing data\n",
    "test_image_paths, test_column_mask_paths, test_table_mask_paths = extract_paths(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cVSg8S9vxof"
   },
   "source": [
    "### Augmentation Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JFe1sLPv1ya"
   },
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "htcgUiFkv4wP"
   },
   "outputs": [],
   "source": [
    "# Define the augmentations for the training dataset\n",
    "augmentations = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),          # Randomly flip the image horizontally with a 50% chance\n",
    "    A.VerticalFlip(p=0.5),            # Randomly flip the image vertically with a 50% chance\n",
    "    A.RandomRotate90(p=0.5),          # Randomly rotate the image by 90 degrees with a 50% chance\n",
    "    A.RandomBrightnessContrast(p=0.2) # Randomly adjust brightness and contrast with a 20% chance\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TILmcTnuv-Jm"
   },
   "source": [
    "### Preprocess & Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZnKfMioVv-BW"
   },
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ekxzA0JwGUs"
   },
   "outputs": [],
   "source": [
    "def preprocess_and_augment(image_path, column_mask_path, table_mask_path, augment=True):\n",
    "    \"\"\"\n",
    "    Preprocess and optionally augment the images and masks.\n",
    "\n",
    "    Parameters:\n",
    "    image_path (str): The path to the image file.\n",
    "    column_mask_path (str): The path to the column mask file.\n",
    "    table_mask_path (str): The path to the table mask file.\n",
    "    augment (bool): Whether to apply augmentations or not (default is True).\n",
    "\n",
    "    Returns:\n",
    "    tuple: The processed and optionally augmented image, column mask, and table mask.\n",
    "    \"\"\"\n",
    "    # Read and decode the image\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "\n",
    "    # Read and decode the column mask\n",
    "    column_mask = tf.io.read_file(column_mask_path)\n",
    "    column_mask = tf.image.decode_jpeg(column_mask, channels=1)\n",
    "\n",
    "    # Read and decode the table mask\n",
    "    table_mask = tf.io.read_file(table_mask_path)\n",
    "    table_mask = tf.image.decode_jpeg(table_mask, channels=1)\n",
    "\n",
    "    # Convert tensors to numpy arrays for augmentation\n",
    "    image = image.numpy()\n",
    "    column_mask = column_mask.numpy()\n",
    "    table_mask = table_mask.numpy()\n",
    "\n",
    "    # Apply augmentations if requested\n",
    "    if augment:\n",
    "        augmented = augmentations(image=image, masks=[column_mask, table_mask])\n",
    "        image = augmented['image']\n",
    "        column_mask, table_mask = augmented['masks']\n",
    "\n",
    "    # Resize images and masks to a standard size\n",
    "    image = tf.image.resize(image, [1024, 1024])\n",
    "    column_mask = tf.image.resize(column_mask, [1024, 1024])\n",
    "    table_mask = tf.image.resize(table_mask, [1024, 1024])\n",
    "\n",
    "    # Normalize images and masks to the range [0, 1]\n",
    "    image = image / 255.0\n",
    "    column_mask = column_mask / 255.0\n",
    "    table_mask = table_mask / 255.0\n",
    "\n",
    "    return image, column_mask, table_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3WAYY4DwHl8"
   },
   "source": [
    "### Parse Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5s1LZJZwJk4"
   },
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F1irEazpnUfI"
   },
   "outputs": [],
   "source": [
    "def parse_image(image_path, column_mask_path, table_mask_path, augment=True):\n",
    "    \"\"\"\n",
    "    Function to call preprocess_and_augment using tf.py_function and\n",
    "    explicitly set the shape of the tensors.\n",
    "\n",
    "    Parameters:\n",
    "    image_path (tf.Tensor): Path to the image.\n",
    "    column_mask_path (tf.Tensor): Path to the column mask.\n",
    "    table_mask_path (tf.Tensor): Path to the table mask.\n",
    "    augment (bool): Whether to apply augmentations or not (default is True).\n",
    "\n",
    "    Returns:\n",
    "    tuple: Augmented and processed image, column mask, and table mask tensors.\n",
    "    \"\"\"\n",
    "    # Call preprocess_and_augment using tf.py_function to allow non-TensorFlow operations\n",
    "    [image, column_mask, table_mask] = tf.py_function(\n",
    "        preprocess_and_augment,\n",
    "        [image_path, column_mask_path, table_mask_path, augment],\n",
    "        [tf.float32, tf.float32, tf.float32]\n",
    "    )\n",
    "\n",
    "    # Explicitly set the shape for the output tensors\n",
    "    image.set_shape([1024, 1024, 3])\n",
    "    column_mask.set_shape([1024, 1024, 1])\n",
    "    table_mask.set_shape([1024, 1024, 1])\n",
    "\n",
    "    return image, (column_mask, table_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsqrFCUewWEZ"
   },
   "source": [
    "### Load TF Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85-24F5dwdSF"
   },
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyvzPWcmiZuc"
   },
   "outputs": [],
   "source": [
    "def load_dataset(image_paths, column_mask_paths, table_mask_paths, batch_size, augment=True):\n",
    "    \"\"\"\n",
    "    Create a tf.data.Dataset from the provided paths.\n",
    "\n",
    "    This function constructs a TensorFlow Dataset object from image, column mask, and table mask paths.\n",
    "    The dataset is then processed with optional augmentation, batched, and prefetched for efficiency.\n",
    "\n",
    "    Parameters:\n",
    "    image_paths (np.array): Array of paths to the images.\n",
    "    column_mask_paths (np.array): Array of paths to the column masks.\n",
    "    table_mask_paths (np.array): Array of paths to the table masks.\n",
    "    batch_size (int): The size of each batch.\n",
    "    augment (bool): Whether to apply augmentations or not (default is True).\n",
    "\n",
    "    Returns:\n",
    "    tf.data.Dataset: A batched and preprocessed TensorFlow Dataset.\n",
    "    \"\"\"\n",
    "    # Create a Dataset object from the image, column mask, and table mask paths\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, column_mask_paths, table_mask_paths))\n",
    "\n",
    "    # Map the parsing and augmentation function to the dataset elements\n",
    "    dataset = dataset.map(lambda img, col_mask, tbl_mask: parse_image(img, col_mask, tbl_mask, augment),\n",
    "                          num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    # Batch the dataset\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Prefetch the dataset to improve performance by overlapping the preprocessing and model execution\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset, len(image_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgWkSHdawpos"
   },
   "source": [
    "#### *Implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_K5ijA8KndnD"
   },
   "outputs": [],
   "source": [
    "# Create the training dataset with augmentation enabled\n",
    "train_dataset, train_size = load_dataset(\n",
    "    train_image_paths,\n",
    "    train_column_mask_paths,\n",
    "    train_table_mask_paths,\n",
    "    BATCH_SIZE,\n",
    "    augment=True\n",
    ")\n",
    "\n",
    "# Create the validation dataset without augmentation\n",
    "val_dataset, val_size = load_dataset(\n",
    "    val_image_paths,\n",
    "    val_column_mask_paths,\n",
    "    val_table_mask_paths,\n",
    "    BATCH_SIZE,\n",
    "    augment=False\n",
    ")\n",
    "\n",
    "# Create the test dataset without augmentation\n",
    "test_dataset = load_dataset(\n",
    "    test_image_paths,\n",
    "    test_column_mask_paths,\n",
    "    test_table_mask_paths,\n",
    "    BATCH_SIZE,\n",
    "    augment=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zLeXblhzExhG",
    "outputId": "1562e549-56e3-4ce7-e7f8-01342757c9a6"
   },
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pcGcUrgqxC5u"
   },
   "source": [
    "### Visualize Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_HdNHQHxE1H"
   },
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dypQ-XtHngEw"
   },
   "outputs": [],
   "source": [
    "def visualize_batch(batch, num_samples=5):\n",
    "    \"\"\"\n",
    "    Visualize a batch of processed images and masks.\n",
    "\n",
    "    This function displays a specified number of samples from a batch, including\n",
    "    the original image, the column mask, and the table mask, in a side-by-side layout.\n",
    "\n",
    "    Parameters:\n",
    "    batch (tuple): A tuple containing images and a tuple of masks (column_masks, table_masks).\n",
    "    num_samples (int): The number of samples to visualize (default is 5).\n",
    "    \"\"\"\n",
    "    # Unpack the batch into images, column masks, and table masks\n",
    "    images, (column_masks, table_masks) = batch\n",
    "\n",
    "    # Convert tensors to numpy arrays for visualization\n",
    "    images = images.numpy()\n",
    "    column_masks = column_masks.numpy()\n",
    "    table_masks = table_masks.numpy()\n",
    "\n",
    "    # Determine the actual number of samples to visualize\n",
    "    batch_size = images.shape[0]\n",
    "    num_samples = min(num_samples, batch_size)\n",
    "\n",
    "    # Print information about the batch size and the shapes of the images and masks\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    print(f\"Image shape: {images.shape}\")\n",
    "    print(f\"Column mask shape: {column_masks.shape}\")\n",
    "    print(f\"Table mask shape: {table_masks.shape}\")\n",
    "\n",
    "    # Loop through the specified number of samples to visualize them\n",
    "    for i in range(num_samples):\n",
    "        plt.figure(figsize=(15, 5))\n",
    "\n",
    "        # Visualize the original image\n",
    "        plt.subplot(131)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f\"Sample {i+1}: Image\")\n",
    "        plt.axis('off')  # Hide the axes for a cleaner display\n",
    "\n",
    "        # Visualize the column mask\n",
    "        plt.subplot(132)\n",
    "        plt.imshow(column_masks[i, :, :, 0], cmap='gray')\n",
    "        plt.title(f\"Sample {i+1}: Column Mask\")\n",
    "        plt.axis('off')  # Hide the axes for a cleaner display\n",
    "\n",
    "        # Visualize the table mask\n",
    "        plt.subplot(133)\n",
    "        plt.imshow(table_masks[i, :, :, 0], cmap='gray')\n",
    "        plt.title(f\"Sample {i+1}: Table Mask\")\n",
    "        plt.axis('off')  # Hide the axes for a cleaner display\n",
    "\n",
    "        # Display the figure\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAskK1MFxH2I"
   },
   "source": [
    "#### *Implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6RuEc8Ef1xUb",
    "outputId": "faa7d19f-4695-4f99-ae9f-245f163fbd12"
   },
   "outputs": [],
   "source": [
    "for batch in train_dataset.take(1):\n",
    "    visualize_batch(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14XSDJ4JxWbR"
   },
   "source": [
    "## **Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJUyUsEFxdyG"
   },
   "source": [
    "### TableNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-x6-PFDjr92"
   },
   "outputs": [],
   "source": [
    "def TableNet(input_shape=(1024, 1024, 3)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # VGG19 as encoder\n",
    "    vgg19 = applications.VGG19(include_top=False, weights='imagenet', input_tensor=inputs)\n",
    "\n",
    "    # Freeze the encoder layers\n",
    "    for layer in vgg19.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Extract features from different layers of VGG19\n",
    "    skip1 = vgg19.get_layer(\"block1_conv2\").output\n",
    "    skip2 = vgg19.get_layer(\"block2_conv2\").output\n",
    "    skip3 = vgg19.get_layer(\"block3_conv4\").output\n",
    "    skip4 = vgg19.get_layer(\"block4_conv4\").output\n",
    "    bottleneck = vgg19.get_layer(\"block5_conv4\").output\n",
    "\n",
    "    def decoder_block(x, skip_features, filters):\n",
    "        x = layers.Conv2DTranspose(filters, (2, 2), strides=2, padding='same')(x)\n",
    "        x = layers.Concatenate()([x, skip_features])\n",
    "        x = layers.SeparableConv2D(filters, (3, 3), padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "        x = layers.SeparableConv2D(filters, (3, 3), padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        return x\n",
    "\n",
    "    # Table output decoder\n",
    "    x_table = decoder_block(bottleneck, skip4, 256)\n",
    "    x_table = decoder_block(x_table, skip3, 128)\n",
    "    x_table = decoder_block(x_table, skip2, 64)\n",
    "    x_table = decoder_block(x_table, skip1, 32)\n",
    "    table_output = layers.Conv2D(1, (1, 1), activation='sigmoid', name='table_output')(x_table)\n",
    "\n",
    "    # Column output decoder\n",
    "    x_column = decoder_block(bottleneck, skip4, 256)\n",
    "    x_column = decoder_block(x_column, skip3, 128)\n",
    "    x_column = decoder_block(x_column, skip2, 64)\n",
    "    x_column = decoder_block(x_column, skip1, 32)\n",
    "    column_output = layers.Conv2D(1, (1, 1), activation='sigmoid', name='column_output')(x_column)\n",
    "\n",
    "    # Define the model\n",
    "    model = models.Model(inputs=inputs, outputs=[table_output, column_output])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBwf79gex8GV"
   },
   "source": [
    "### Initialize TableNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OeDKlCh6qprz",
    "outputId": "b97b951e-9c2c-487a-856d-79fce7a7ccd2"
   },
   "outputs": [],
   "source": [
    "# Create the TableNet model with the specified input shape\n",
    "model = TableNet(input_shape=(1024, 1024, 3))\n",
    "\n",
    "# Display the model summary to review the architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-MNbeF_yC_u"
   },
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7V8Yy9CfyCJg"
   },
   "outputs": [],
   "source": [
    "# Compile the model with Adam optimizer, binary crossentropy loss, and accuracy metrics for both outputs\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'table_output': 'binary_crossentropy',\n",
    "        'column_output': 'binary_crossentropy'\n",
    "    },\n",
    "    loss_weights={\n",
    "        'table_output': 1.0,\n",
    "        'column_output': 1.0\n",
    "    },\n",
    "    metrics={\n",
    "        'table_output': 'accuracy',\n",
    "        'column_output': 'accuracy'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfRqEB9wyTmR"
   },
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hGCjGHwVk7YW",
    "outputId": "2d38285e-e6cb-44d3-8c21-2a9d02055d7d"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=10,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcO-DcukYkgk"
   },
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9c1YiBmYnUm"
   },
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W46NjcmiYqHx"
   },
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KXKsS03Io1NE"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset, dataset_name):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the given dataset and prints the results.\n",
    "\n",
    "    Args:\n",
    "    model (tf.keras.Model): The model to evaluate\n",
    "    dataset (tuple or tf.data.Dataset): The dataset to evaluate on, possibly with sample count\n",
    "    dataset_name (str): Name of the dataset (e.g., 'Validation' or 'Test')\n",
    "    \"\"\"\n",
    "    # Check if dataset is a tuple and extract only the dataset part\n",
    "    if isinstance(dataset, tuple):\n",
    "        dataset, _ = dataset\n",
    "\n",
    "    eval_results = model.evaluate(dataset, verbose=0)  # Set verbose=0 to suppress the progress bar\n",
    "\n",
    "    print(f\"\\n{dataset_name} Evaluation Results:\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # Assuming eval_results contains [total_loss, table_output_accuracy, column_output_accuracy]\n",
    "    print(f\"Loss: {eval_results[0]:.4f}\")\n",
    "    print(f\"Table output accuracy: {eval_results[1] * 100:.2f}%\")\n",
    "    print(f\"Column output accuracy: {eval_results[2] * 100:.2f}%\")\n",
    "\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ldC_PGSYsLW"
   },
   "source": [
    "#### *Implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gUq9vmBSo2OQ",
    "outputId": "83ea7439-9ab2-4e8d-a6b4-27c575ca1d32"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on validation and test datasets\n",
    "evaluate_model(model, val_dataset, \"Validation\")\n",
    "evaluate_model(model, test_dataset, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VW2VIod9h3Rc"
   },
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4yCGmOBh51s",
    "outputId": "469d08bb-5141-4768-f343-12f427605abe"
   },
   "outputs": [],
   "source": [
    "model.save('tablenet_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7aFSgv5Yxq5"
   },
   "source": [
    "### Plot Training History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EavYg866Yz2Q"
   },
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zd6sAeT2n9Tt"
   },
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(131)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Accuracy for Table Output\n",
    "    plt.subplot(132)\n",
    "    plt.plot(history.history['table_output_accuracy'], label='Train Table Accuracy', color='blue')\n",
    "    plt.plot(history.history['val_table_output_accuracy'], label='Val Table Accuracy', color='cyan')\n",
    "    plt.title('Table Output Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Accuracy for Column Output\n",
    "    plt.subplot(133)\n",
    "    plt.plot(history.history['column_output_accuracy'], label='Train Column Accuracy', color='orange')\n",
    "    plt.plot(history.history['val_column_output_accuracy'], label='Val Column Accuracy', color='red')\n",
    "    plt.title('Column Output Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WektWNscZOhb"
   },
   "source": [
    "#### *Implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "ZXL_T_OVZNyg",
    "outputId": "4e56ee35-4db3-49bb-c1f4-471fdef6a620"
   },
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yppHfdCv6YJI"
   },
   "source": [
    "## **Deployment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqI1GxWpiGNA"
   },
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TmTU5ZluiFpO",
    "outputId": "e4b1e455-efc6-437a-9cd4-2c5bb9093a7e"
   },
   "outputs": [],
   "source": [
    "model = load_model('tablenet_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdFlBM9Mab0y"
   },
   "source": [
    "### Predict Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdtCeXL1aeAq"
   },
   "source": [
    "#### *Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COAWKsvKjuT3"
   },
   "outputs": [],
   "source": [
    "def load_random_image(image_folder, image_size=(1024, 1024)):\n",
    "    \"\"\"\n",
    "    Load a random image from a specified folder and preprocess it.\n",
    "\n",
    "    Parameters:\n",
    "    image_folder (str): Path to the folder containing images.\n",
    "    image_size (tuple): The target size for resizing the image (default is 1024x1024).\n",
    "\n",
    "    Returns:\n",
    "    np.array: Preprocessed image ready for model prediction.\n",
    "    str: The path of the randomly selected image.\n",
    "    \"\"\"\n",
    "    # Get a list of all image files in the folder\n",
    "    image_files = [f for f in os.listdir(image_folder) if f.endswith('.jpeg')]\n",
    "\n",
    "    # Select a random image file\n",
    "    random_image_file = random.choice(image_files)\n",
    "    random_image_path = os.path.join(image_folder, random_image_file)\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    image = cv2.imread(random_image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, image_size)\n",
    "    image = image.astype(np.float32) / 255.0  # Normalize the image\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "\n",
    "    return image, random_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XHFFme8zaiRh"
   },
   "outputs": [],
   "source": [
    "def visualize_random_image_prediction(model, image_folder):\n",
    "    \"\"\"\n",
    "    Visualize the model's prediction for a randomly selected image from a folder.\n",
    "\n",
    "    Parameters:\n",
    "    model (tf.keras.Model): The trained model used for making predictions.\n",
    "    image_folder (str): Path to the folder containing images.\n",
    "    \"\"\"\n",
    "    # Load a random image from the folder\n",
    "    image, image_path = load_random_image(image_folder)\n",
    "\n",
    "    # Generate predictions from the model\n",
    "    predictions = model.predict(image)\n",
    "\n",
    "    # Visualize the image and its predictions\n",
    "    plt.figure(figsize=(18, 5))\n",
    "\n",
    "    # Input Image\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(image[0])  # Remove batch dimension for visualization\n",
    "    plt.title('Input Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Predicted Table Mask\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(predictions[1][0, ..., 0], cmap='gray')  # Remove batch dimension\n",
    "    plt.title('Predicted Table Mask')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Predicted Column Mask\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(predictions[0][0, ..., 0], cmap='gray')  # Remove batch dimension\n",
    "    plt.title('Predicted Column Mask')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "cRHL7k18o6w6",
    "outputId": "95b7c2ae-74e1-4c71-e403-602d8ac4249a"
   },
   "outputs": [],
   "source": [
    "visualize_random_image_prediction(model, '../data/improved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LRZSxij6hRGb"
   },
   "outputs": [],
   "source": [
    "def detect_tables(table_mask, min_area=5000):\n",
    "    \"\"\"\n",
    "    Detect distinct tables in the table mask using connected components.\n",
    "\n",
    "    Parameters:\n",
    "    table_mask (np.array): The binary mask for table regions.\n",
    "    min_area (int): Minimum area to consider as a valid table.\n",
    "\n",
    "    Returns:\n",
    "    list of tuples: Bounding boxes for detected tables.\n",
    "    \"\"\"\n",
    "    # Label connected components in the table mask\n",
    "    labels = measure.label(table_mask, connectivity=2)\n",
    "\n",
    "    # Find bounding boxes for all connected components (each table)\n",
    "    regions = measure.regionprops(labels)\n",
    "    tables = [region.bbox for region in regions if region.area >= min_area]\n",
    "\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QmQRdHJYhWTK"
   },
   "outputs": [],
   "source": [
    "def extract_columns_from_table(column_mask, table_bbox, min_column_width=30):\n",
    "    \"\"\"\n",
    "    Extract columns within a table using the column mask.\n",
    "\n",
    "    Parameters:\n",
    "    column_mask (np.array): The binary mask for columns.\n",
    "    table_bbox (tuple): Bounding box for the detected table.\n",
    "    min_column_width (int): Minimum width to consider as a valid column.\n",
    "\n",
    "    Returns:\n",
    "    list of tuples: Bounding boxes for detected columns within the table.\n",
    "    \"\"\"\n",
    "    # Crop the column mask to the table region\n",
    "    y1, x1, y2, x2 = table_bbox\n",
    "    table_column_mask = column_mask[y1:y2, x1:x2]\n",
    "\n",
    "    # Label connected components in the column mask (within the table region)\n",
    "    labels = measure.label(table_column_mask, connectivity=2)\n",
    "\n",
    "    # Find bounding boxes for all connected components (each column)\n",
    "    regions = measure.regionprops(labels)\n",
    "    columns = [region.bbox for region in regions if (region.bbox[3] - region.bbox[1]) >= min_column_width]\n",
    "\n",
    "    # Adjust column coordinates relative to the full image\n",
    "    columns = [(y1 + region[0], x1 + region[1], y1 + region[2], x1 + region[3]) for region in columns]\n",
    "\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4TmhBwephbd7"
   },
   "outputs": [],
   "source": [
    "def extract_text_from_columns(image, columns):\n",
    "    \"\"\"\n",
    "    Perform OCR on each column and extract text.\n",
    "\n",
    "    Parameters:\n",
    "    image (np.array): The original image.\n",
    "    columns (list of tuples): Bounding boxes for each column.\n",
    "\n",
    "    Returns:\n",
    "    list: OCR results for each column.\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    for column in columns:\n",
    "        y1, x1, y2, x2 = column\n",
    "        column_image = image[y1:y2, x1:x2]\n",
    "        text = pytesseract.image_to_string(column_image, config='--psm 6').strip()\n",
    "        texts.append(text)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kyYu4KR0hdNF"
   },
   "outputs": [],
   "source": [
    "def perform_ocr_on_detected_tables(model, image_folder):\n",
    "    \"\"\"\n",
    "    Perform OCR on detected tables and columns in a randomly selected image.\n",
    "\n",
    "    Parameters:\n",
    "    model (tf.keras.Model): The trained model used for making predictions.\n",
    "    image_folder (str): Path to the folder containing images.\n",
    "\n",
    "    Returns:\n",
    "    list of pandas.DataFrame: A list of DataFrames containing the OCR results.\n",
    "    \"\"\"\n",
    "    # Load a random image from the folder\n",
    "    image, image_path = load_random_image(image_folder)\n",
    "\n",
    "    # Generate predictions from the model\n",
    "    predictions = model.predict(image)\n",
    "    table_mask = predictions[1][0, ..., 0] > 0.5  # Thresholding the table mask\n",
    "    column_mask = predictions[0][0, ..., 0] > 0.5  # Thresholding the column mask\n",
    "\n",
    "    # Convert masks to uint8 format for further processing\n",
    "    table_mask_uint8 = (table_mask * 255).astype(np.uint8)\n",
    "    column_mask_uint8 = (column_mask * 255).astype(np.uint8)\n",
    "\n",
    "    # Detect tables from the table mask\n",
    "    tables = detect_tables(table_mask_uint8)\n",
    "\n",
    "    # Visualize detected tables\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image[0])\n",
    "    for table_bbox in tables:\n",
    "        y1, x1, y2, x2 = table_bbox\n",
    "        plt.plot([x1, x2, x2, x1, x1], [y1, y1, y2, y2, y1], 'r-')\n",
    "    plt.title(\"Detected Tables\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # List to store DataFrames for each table\n",
    "    table_dfs = []\n",
    "\n",
    "    # Loop over each detected table\n",
    "    for table_bbox in tables:\n",
    "        # Extract columns within the table\n",
    "        columns = extract_columns_from_table(column_mask_uint8, table_bbox)\n",
    "\n",
    "        # Filter columns by width (remove too small columns)\n",
    "        columns = [col for col in columns if (col[3] - col[1]) >= 30]\n",
    "\n",
    "        # Extract text from each column\n",
    "        table_image = image[0]\n",
    "        column_texts = extract_text_from_columns(table_image, columns)\n",
    "\n",
    "        # Store the OCR results as a DataFrame\n",
    "        num_cols = len(columns)\n",
    "        data_reshaped = [column_texts[i:i + num_cols] for i in range(0, len(column_texts), num_cols)]\n",
    "        df = pd.DataFrame(data_reshaped)\n",
    "        table_dfs.append(df)\n",
    "\n",
    "        # Visualize the detected columns within the table\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(table_image)\n",
    "        for column_bbox in columns:\n",
    "            y1, x1, y2, x2 = column_bbox\n",
    "            plt.plot([x1, x2, x2, x1, x1], [y1, y1, y2, y2, y1], 'g-')\n",
    "        plt.title(\"Detected Columns in Table\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return table_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "PRNru7T4hjSt",
    "outputId": "02c57e67-9226-4ee2-ddb9-0acc70b4c245"
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "dfs = perform_ocr_on_detected_tables(model, image_folder)\n",
    "\n",
    "# Print all the extracted DataFrames\n",
    "for i, df in enumerate(dfs):\n",
    "    print(f\"Table {i+1}:\")\n",
    "    print(df)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "NaCGRYnK5lxY",
    "pW_gzaieUMpz",
    "vZp4mu8_5dhO",
    "VQwJAieaUQdJ",
    "tHOMGV2I6LJA",
    "d4rNQ1_6URxV",
    "MKjdJUAT7B0K",
    "i-cpiKYS7Fc-",
    "s52I8XsVUd0r",
    "LeAUfwys7t-F",
    "IkoHX09P7xL_",
    "QRXHnCDYUhAp",
    "1VRHv-Kl70xC",
    "Lh8fLLp_73iG",
    "zIBAZBwSUkJG",
    "yzhbZDMK8UVc",
    "SKXyPmzVU3t5",
    "PJHoxYFk8iZN",
    "QmYpELAyU7Lo",
    "oLNFhylU8ufQ",
    "pNJ0Zn7P8poI",
    "jHBR0Lw2VBGS",
    "57Msg3Pb9Tzs",
    "FoLtUbT3VF-F",
    "LpnaGdiBtHFF",
    "M4ARZwkAtQYj",
    "0cG8ROZbtZCw",
    "OESXpjEgtdA6",
    "7615URxeuMMm",
    "bOR4OgJeu3eF",
    "X-061Ct4u6w9",
    "yG5Ic3DDu1gh",
    "cd25SbKovZsW",
    "LLZ4Wb_gvdjL",
    "3cVSg8S9vxof",
    "5JFe1sLPv1ya",
    "14XSDJ4JxWbR"
   ],
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "alessandroryo",
   "language": "python",
   "name": "alessandroryo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
