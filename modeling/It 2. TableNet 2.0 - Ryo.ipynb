{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 2 - TableNet Model 2.0\n",
    "\n",
    "> **Dataset**: Client Dataset <br/>\n",
    "> **Model**: TableNet Model <br/>\n",
    "> **Creator**: Ryo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, applications\n",
    "from tensorflow.keras.layers import RandomRotation, RandomTranslation, RandomZoom\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, MeanIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None) \n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.width', 1000)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FOLDER = \"../data/tablenet_data/images/3. Resized\"\n",
    "MASK_FOLDER = \"../data/tablenet_data/masking/3. Resized Masks\"\n",
    "\n",
    "ANNOTATION_TYPES = [\"row\", \"column\", \"cell\", \"year\", \"location\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_complete_file_table(image_folder, mask_folder):\n",
    "    image_paths = [\n",
    "        os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith(\".JPG\")\n",
    "    ]\n",
    "\n",
    "    mask_paths = {annotation_type: [] for annotation_type in ANNOTATION_TYPES}\n",
    "\n",
    "    def find_mask_path(base_name, subfolder):\n",
    "        for root, _, files in os.walk(subfolder):\n",
    "            for file in files:\n",
    "                if file == f\"{base_name}.png\":\n",
    "                    return os.path.join(root, file)\n",
    "        return None\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        base_name = os.path.splitext(os.path.basename(image_path))[0] \n",
    "        \n",
    "        for annotation_type in ANNOTATION_TYPES:\n",
    "            mask_subfolder = os.path.join(mask_folder, annotation_type)\n",
    "            mask_file = find_mask_path(base_name, mask_subfolder)\n",
    "            mask_paths[annotation_type].append(mask_file)\n",
    "\n",
    "    data = {\"image\": image_paths}\n",
    "    for annotation_type in ANNOTATION_TYPES:\n",
    "        data[f\"{annotation_type}_mask\"] = mask_paths[annotation_type]\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_table = create_complete_file_table(IMAGE_FOLDER, MASK_FOLDER)\n",
    "file_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df, test_size=0.2, val_size=0.1, random_state=42):\n",
    "    train_val_df, test_df = train_test_split(df, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    train_df, val_df = train_test_split(train_val_df, test_size=val_size, random_state=random_state)\n",
    "\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = split_dataset(\n",
    "    file_table, \n",
    "    test_size=0.05,\n",
    "    val_size=0.15,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training set size (80%):\", len(train_df))\n",
    "print(\"Validation set size (15%):\", len(val_df))\n",
    "print(\"Test set size (5%):\", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_paths(df):\n",
    "    image_paths = df['image'].values\n",
    "    mask_paths = {col: df[col].values for col in df.columns if '_mask' in col}\n",
    "    return image_paths, mask_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths, train_mask_paths = extract_paths(train_df)\n",
    "val_image_paths, val_mask_paths = extract_paths(val_df)\n",
    "test_image_paths, test_mask_paths = extract_paths(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replicate_data(image_paths, mask_paths, replicate_count):\n",
    "    image_paths = np.tile(image_paths, replicate_count)\n",
    "    mask_paths = {key: np.tile(mask_paths[key], replicate_count) for key in mask_paths.keys()}\n",
    "    return image_paths, mask_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image_path, *mask_paths):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "    masks = [\n",
    "        tf.image.decode_jpeg(tf.io.read_file(mask_path), channels=1) / 255.0\n",
    "        for mask_path in mask_paths\n",
    "    ]\n",
    "\n",
    "    return [image] + masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image(image_path, row_mask_path, column_mask_path, cell_mask_path, year_mask_path, location_mask_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "    masks = {\n",
    "        'row_output': tf.cast(tf.image.decode_jpeg(tf.io.read_file(row_mask_path), channels=1), tf.float32) / 255.0,\n",
    "        'column_output': tf.cast(tf.image.decode_jpeg(tf.io.read_file(column_mask_path), channels=1), tf.float32) / 255.0,\n",
    "        'cell_output': tf.cast(tf.image.decode_jpeg(tf.io.read_file(cell_mask_path), channels=1), tf.float32) / 255.0,\n",
    "        'year_output': tf.cast(tf.image.decode_jpeg(tf.io.read_file(year_mask_path), channels=1), tf.float32) / 255.0,\n",
    "        'location_output': tf.cast(tf.image.decode_jpeg(tf.io.read_file(location_mask_path), channels=1), tf.float32) / 255.0,\n",
    "    }\n",
    "\n",
    "    return image, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(image_paths, mask_paths, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        image_paths,\n",
    "        mask_paths['row_mask'],\n",
    "        mask_paths['column_mask'],\n",
    "        mask_paths['cell_mask'],\n",
    "        mask_paths['year_mask'],\n",
    "        mask_paths['location_mask']\n",
    "    ))\n",
    "\n",
    "    dataset = dataset.map(\n",
    "        lambda img, row_mask, col_mask, cell_mask, year_mask, loc_mask: parse_image(\n",
    "            img, row_mask, col_mask, cell_mask, year_mask, loc_mask\n",
    "        ),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset, len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_TRAIN = 8\n",
    "BATCH_SIZE_VAL = 3\n",
    "BATCH_SIZE_TEST = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replicate_count = 3\n",
    "train_image_paths, train_mask_paths = replicate_data(train_image_paths, train_mask_paths, replicate_count)\n",
    "\n",
    "train_dataset, train_size = load_dataset(\n",
    "    train_image_paths,\n",
    "    train_mask_paths,\n",
    "    batch_size=BATCH_SIZE_TRAIN\n",
    ")\n",
    "\n",
    "val_dataset, val_size = load_dataset(\n",
    "    val_image_paths,\n",
    "    val_mask_paths,\n",
    "    batch_size=BATCH_SIZE_VAL,\n",
    ")\n",
    "\n",
    "test_dataset, test_size = load_dataset(\n",
    "    test_image_paths,\n",
    "    test_mask_paths,\n",
    "    batch_size=BATCH_SIZE_TEST,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_batch(batch, num_samples=5):\n",
    "    images, masks = batch\n",
    "    \n",
    "    images = images.numpy()\n",
    "    masks = {key: mask.numpy() for key, mask in masks.items()}\n",
    "    \n",
    "    batch_size = images.shape[0]\n",
    "    num_samples = min(num_samples, batch_size)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        \n",
    "        plt.subplot(1, len(masks) + 1, 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f\"Sample {i + 1}: Image\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        for j, (mask_name, mask_array) in enumerate(masks.items()):\n",
    "            plt.subplot(1, len(masks) + 1, j + 2)\n",
    "            plt.imshow(mask_array[i, :, :, 0], cmap='gray')\n",
    "            plt.title(f\"Sample {i + 1}: {mask_name.replace('_', ' ').capitalize()}\")\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataset.take(1):\n",
    "    visualize_batch(batch, num_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TableNet(input_shape=(960, 1280, 3)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # VGG19 as encoder\n",
    "    vgg19 = applications.VGG19(include_top=False, weights='imagenet', input_tensor=inputs)\n",
    "\n",
    "    # Freeze the encoder layers\n",
    "    for layer in vgg19.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Extract features from different layers of VGG19\n",
    "    skip1 = vgg19.get_layer(\"block1_conv2\").output\n",
    "    skip2 = vgg19.get_layer(\"block2_conv2\").output\n",
    "    skip3 = vgg19.get_layer(\"block3_conv4\").output\n",
    "    skip4 = vgg19.get_layer(\"block4_conv4\").output\n",
    "    bottleneck = vgg19.get_layer(\"block5_conv4\").output\n",
    "\n",
    "    def decoder_block(x, skip_features, filters):\n",
    "        x = layers.Conv2DTranspose(filters, (2, 2), strides=2, padding='same')(x)\n",
    "        x = layers.Concatenate()([x, skip_features])\n",
    "        x = layers.SeparableConv2D(filters, (3, 3), padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.LeakyReLU(negative_slope=0.1)(x)\n",
    "        x = layers.SeparableConv2D(filters, (3, 3), padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.LeakyReLU(negative_slope=0.1)(x)\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        return x\n",
    "\n",
    "    # Row output decoder\n",
    "    x_row = decoder_block(bottleneck, skip4, 256)\n",
    "    x_row = decoder_block(x_row, skip3, 128)\n",
    "    x_row = decoder_block(x_row, skip2, 64)\n",
    "    x_row = decoder_block(x_row, skip1, 32)\n",
    "    row_output = layers.Conv2D(1, (1, 1), activation='sigmoid', name='row_output')(x_row)\n",
    "\n",
    "    # Column output decoder\n",
    "    x_column = decoder_block(bottleneck, skip4, 256)\n",
    "    x_column = decoder_block(x_column, skip3, 128)\n",
    "    x_column = decoder_block(x_column, skip2, 64)\n",
    "    x_column = decoder_block(x_column, skip1, 32)\n",
    "    column_output = layers.Conv2D(1, (1, 1), activation='sigmoid', name='column_output')(x_column)\n",
    "\n",
    "    # Cell output decoder\n",
    "    x_cell = decoder_block(bottleneck, skip4, 256)\n",
    "    x_cell = decoder_block(x_cell, skip3, 128)\n",
    "    x_cell = decoder_block(x_cell, skip2, 64)\n",
    "    x_cell = decoder_block(x_cell, skip1, 32)\n",
    "    cell_output = layers.Conv2D(1, (1, 1), activation='sigmoid', name='cell_output')(x_cell)\n",
    "\n",
    "    # Year output decoder\n",
    "    x_year = decoder_block(bottleneck, skip4, 256)\n",
    "    x_year = decoder_block(x_year, skip3, 128)\n",
    "    x_year = decoder_block(x_year, skip2, 64)\n",
    "    x_year = decoder_block(x_year, skip1, 32)\n",
    "    year_output = layers.Conv2D(1, (1, 1), activation='sigmoid', name='year_output')(x_year)\n",
    "\n",
    "    # Location output decoder\n",
    "    x_location = decoder_block(bottleneck, skip4, 256)\n",
    "    x_location = decoder_block(x_location, skip3, 128)\n",
    "    x_location = decoder_block(x_location, skip2, 64)\n",
    "    x_location = decoder_block(x_location, skip1, 32)\n",
    "    location_output = layers.Conv2D(1, (1, 1), activation='sigmoid', name='location_output')(x_location)\n",
    "\n",
    "    # Define the model\n",
    "    model = models.Model(\n",
    "        inputs=inputs,\n",
    "        outputs=[row_output, column_output, cell_output, year_output, location_output]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SIZE = (960, 1280) # Height x Width\n",
    "input_shape = (TARGET_SIZE[0], TARGET_SIZE[1], 3)\n",
    "\n",
    "model = TableNet(input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_iou(y_true, y_pred):\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "    return intersection / (union + tf.keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss={\n",
    "        'row_output': 'binary_crossentropy',\n",
    "        'column_output': 'binary_crossentropy',\n",
    "        'cell_output': 'binary_crossentropy',\n",
    "        'year_output': 'binary_crossentropy',\n",
    "        'location_output': 'binary_crossentropy'\n",
    "    },\n",
    "    metrics={\n",
    "        'row_output': [BinaryAccuracy(name='accuracy'), binary_iou],\n",
    "        'column_output': [BinaryAccuracy(name='accuracy'), binary_iou],\n",
    "        'cell_output': [BinaryAccuracy(name='accuracy'), binary_iou],\n",
    "        'year_output': [BinaryAccuracy(name='accuracy'), binary_iou],\n",
    "        'location_output': [BinaryAccuracy(name='accuracy'), binary_iou]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [\n",
    "#     EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "#     ModelCheckpoint(filepath='best_model.keras', save_best_only=True, monitor='val_loss'),\n",
    "#     ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=20,\n",
    "    # callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_tablenet_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alessandroryo",
   "language": "python",
   "name": "alessandroryo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
